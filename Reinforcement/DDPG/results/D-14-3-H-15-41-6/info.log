INFO:Reinforcement.Functions:settings:[{'minGameScore': 2736, u'TAU': 0.001, u'minGameScoreRatio': 0.95, u'batchSize': 256, u'nGamesPerSave': 10, u'nEpochs': 1, u'minGameSequence': 500, u'nModelBackups': 3, u'gameMinutesLength': 2880, u'dequeSize': 50000, u'learningRate': 0.001, u'gamma': 0.95, u'trainSetSize': 128}]
INFO:Reinforcement.Functions:args:[{'random': True, 'gpuFrac': 0.3, 'sequential': False, 'gpuNum': 1, 'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json'}]
INFO:Reinforcement.Functions:results:[{'loss': [], 'score': []}]
INFO:Reinforcement.Functions:Actor:[{'epsilon_decay': 0.99, 'epsilon': 1.0, 'curBackupIdx': 0, 'epsilon_min': 0.01, 'TAU': 0.001, 'nBackups': 3, 'k': 205, 'actionDim': 11}]
INFO:Reinforcement.Functions:Critic:[{'TAU': 0.001, 'nBackups': 3, 'curBackupIdx': 0, 'actionDim': 11}]
INFO:Reinforcement.Functions:policy:[{'numOfDevices': 11, 'stateDim': (1, 14), 'seqLen': 1, 'policyJSON': {u'10': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'21:00', u'23:29']]}, {u'days': [5], u'times': [[u'21:00', u'23:29']]}], u'6': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:14'], [u'20:40', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'weekdays': [0, 1, 2, 3, 6], u'Devices': [u'Room light1', u'Room light2', u'Room light3 (backdoor)', u'Kitchen light', u'Toilets light', u'Bathroom light', u'Living room light1', u'Living room light2', u'Hallway light', u'Entrance light', u'Boiler'], u'days': [u'Monday', u'Tuesday', u'Wednesday', u'Thursday', u'Friday', u'Saturday', u'Sunday'], u'1': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:59'], [u'20:30', u'21:29']]}, {u'days': [4], u'times': [[u'10:00', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'0': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:29'], [u'08:00', u'08:59'], [u'20:30', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:59'], [u'09:30', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'23:59']]}], u'3': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:44'], [u'20:45', u'21:29'], [u'23:15', u'23:44']]}, {u'days': [4], u'times': [[u'10:00', u'10:59'], [u'12:45', u'13:14']]}, {u'days': [5], u'times': [[u'18:00', u'19:59'], [u'21:00', u'23:14']]}], u'2': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:30', u'01:09']]}, {u'days': [4], u'times': [[u'00:30', u'01:09']]}], u'5': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:05', u'00:24'], [u'08:35', u'08:42'], [u'21:09', u'21:11']]}, {u'days': [4], u'times': [[u'00:05', u'00:24'], [u'10:18', u'10:29']]}, {u'days': [5], u'times': [[u'19:09', u'19:09'], [u'21:34', u'21:34']]}], u'4': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:34'], [u'21:05', u'21:08']]}, {u'days': [4], u'times': [[u'10:10', u'10:17']]}, {u'days': [5], u'times': [[u'19:05', u'19:08'], [u'21:20', u'21:33']]}], u'7': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:14'], [u'20:40', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'Time format': u'%H:%M', u'9': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'09:00', u'09:00'], [u'20:30', u'20:30']]}, {u'days': [4], u'times': [[u'13:29', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:00']]}], u'8': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'20:31', u'20:54']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'weekend': [4, 5]}}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 14)             0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 512)            7680      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            131328    
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 11)             2827      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 11)                0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 141,835
INFO:Reinforcement.Functions:Trainable params: 141,835
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 14)        0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)                 (None, 1, 512)       7680        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 11)           0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)                 (None, 1, 256)       131328      dense_4[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)                 (None, 256)          3072        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_5[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_6[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 1)         257         activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_7[0][0]                    
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 142,337
INFO:Reinforcement.Functions:Trainable params: 142,337
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[1692.55], loss:[10.05778], sequence:[0], random actions:[122], eInit:[1.0000], init state:[ 3  8 49  1  1  0  0  0  0  0  0  0  0  0], end state:[ 5  8 49  0  0  0  0  0  0  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2, score:[2267.09], loss:[10.48089], sequence:[0], random actions:[130], eInit:[0.9900], init state:[ 0 11 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 3, score:[2372.91], loss:[7.78326], sequence:[0], random actions:[130], eInit:[0.9801], init state:[ 0  1 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 4, score:[2414.18], loss:[8.84440], sequence:[0], random actions:[124], eInit:[0.9703], init state:[ 1 12  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12  0  1  1  0  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 5, score:[2257.27], loss:[8.46959], sequence:[0], random actions:[130], eInit:[0.9606], init state:[ 5  2 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 6, score:[2348.00], loss:[9.09952], sequence:[0], random actions:[128], eInit:[0.9510], init state:[ 3  6 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  6 54  1  0  1  1  1  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 7, score:[2463.45], loss:[7.75704], sequence:[0], random actions:[97], eInit:[0.9415], init state:[ 4 19 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 8, score:[2399.64], loss:[6.14765], sequence:[0], random actions:[128], eInit:[0.9321], init state:[ 2  0 54  0  0  1  0  0  0  0  0  0  0  0], end state:[ 4  0 54  0  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 9, score:[2478.36], loss:[5.53304], sequence:[0], random actions:[118], eInit:[0.9227], init state:[ 1  1 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 10, score:[2516.91], loss:[5.01306], sequence:[0], random actions:[112], eInit:[0.9135], init state:[ 1 19 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2516.909090909093, [10]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
INFO:Reinforcement.Functions:episode: 11, score:[2452.73], loss:[4.84051], sequence:[0], random actions:[109], eInit:[0.9044], init state:[ 4 13 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 36  0  0  0  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 12, score:[2491.64], loss:[4.91737], sequence:[0], random actions:[123], eInit:[0.8953], init state:[ 5  2 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 13, score:[2515.64], loss:[4.85169], sequence:[0], random actions:[103], eInit:[0.8864], init state:[ 0  5 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 14, score:[2527.09], loss:[4.44193], sequence:[0], random actions:[107], eInit:[0.8775], init state:[ 2  4 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 15, score:[2446.91], loss:[4.66300], sequence:[0], random actions:[99], eInit:[0.8687], init state:[ 5 14 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 16, score:[2516.36], loss:[4.30631], sequence:[0], random actions:[116], eInit:[0.8601], init state:[ 4 16 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 54  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 17, score:[2469.82], loss:[4.44717], sequence:[0], random actions:[93], eInit:[0.8515], init state:[ 2 23  8  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 23  8  0  0  0  0  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 18, score:[2536.18], loss:[4.52851], sequence:[0], random actions:[113], eInit:[0.8429], init state:[ 6 22 45  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 45  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 19, score:[2539.45], loss:[4.00654], sequence:[0], random actions:[107], eInit:[0.8345], init state:[ 6  3 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 20, score:[2493.82], loss:[3.98931], sequence:[0], random actions:[108], eInit:[0.8262], init state:[ 3 11 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2539.454545454558, [19]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])
INFO:Reinforcement.Functions:episode: 21, score:[2519.45], loss:[3.90175], sequence:[0], random actions:[102], eInit:[0.8179], init state:[ 6 17 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 22, score:[2488.18], loss:[3.55624], sequence:[0], random actions:[118], eInit:[0.8097], init state:[ 3  2 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 23, score:[2512.36], loss:[3.18597], sequence:[0], random actions:[113], eInit:[0.8016], init state:[ 3  0 56  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 24, score:[2522.36], loss:[3.18725], sequence:[0], random actions:[104], eInit:[0.7936], init state:[ 3 17  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 25, score:[2546.00], loss:[2.92808], sequence:[0], random actions:[92], eInit:[0.7857], init state:[4 3 8 0 0 0 0 0 0 0 0 0 0 0], end state:[6 3 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 26, score:[2576.91], loss:[2.89981], sequence:[0], random actions:[101], eInit:[0.7778], init state:[ 2 23 12  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 23 12  0  0  0  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 27, score:[2542.55], loss:[3.13933], sequence:[0], random actions:[97], eInit:[0.7700], init state:[ 5 22  0  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 22  0  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 28, score:[2574.91], loss:[2.84917], sequence:[0], random actions:[86], eInit:[0.7623], init state:[ 6  1 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 29, score:[2581.09], loss:[2.75913], sequence:[0], random actions:[95], eInit:[0.7547], init state:[0 7 0 0 0 0 0 0 0 0 0 0 0 0], end state:[2 7 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 30, score:[2574.91], loss:[2.54529], sequence:[0], random actions:[97], eInit:[0.7472], init state:[ 2  5 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  5 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2581.09090909094, [29]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])
INFO:Reinforcement.Functions:episode: 31, score:[2588.18], loss:[2.52528], sequence:[0], random actions:[96], eInit:[0.7397], init state:[ 0 13 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 32, score:[2538.18], loss:[2.68837], sequence:[0], random actions:[100], eInit:[0.7323], init state:[ 6 18 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 35  0  0  0  0  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 33, score:[2589.09], loss:[2.34313], sequence:[0], random actions:[113], eInit:[0.7250], init state:[ 1 15 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 34, score:[2556.91], loss:[2.48249], sequence:[0], random actions:[93], eInit:[0.7177], init state:[ 4  6 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 35, score:[2555.45], loss:[2.40311], sequence:[0], random actions:[97], eInit:[0.7106], init state:[ 0 18 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 36, score:[2599.64], loss:[2.39484], sequence:[0], random actions:[87], eInit:[0.7034], init state:[ 6 20 53  1  1  0  1  0  0  1  1  1  0  0], end state:[ 1 20 53  0  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 37, score:[2571.27], loss:[2.20929], sequence:[0], random actions:[81], eInit:[0.6964], init state:[ 2 13 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 38, score:[2636.36], loss:[2.13321], sequence:[0], random actions:[97], eInit:[0.6894], init state:[ 0 14 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 39, score:[2648.00], loss:[1.99639], sequence:[0], random actions:[90], eInit:[0.6826], init state:[ 1 12 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 40, score:[2543.27], loss:[2.36788], sequence:[0], random actions:[84], eInit:[0.6757], init state:[ 2 17 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 53  0  0  0  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2648.0000000000077, [39]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40])
INFO:Reinforcement.Functions:episode: 41, score:[2626.00], loss:[2.13872], sequence:[0], random actions:[99], eInit:[0.6690], init state:[ 2  9 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 56  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 42, score:[2615.45], loss:[2.10770], sequence:[0], random actions:[111], eInit:[0.6623], init state:[ 6 23  5  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 23  5  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 43, score:[2587.09], loss:[2.28931], sequence:[0], random actions:[97], eInit:[0.6557], init state:[ 6  8 15  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  8 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 44, score:[2584.36], loss:[2.12590], sequence:[0], random actions:[82], eInit:[0.6491], init state:[ 4  5 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 45, score:[2648.73], loss:[2.16392], sequence:[0], random actions:[82], eInit:[0.6426], init state:[ 1 20 51  1  1  0  1  0  0  1  1  1  0  0], end state:[ 3 20 51  1  0  0  0  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 46, score:[2600.18], loss:[2.10320], sequence:[0], random actions:[89], eInit:[0.6362], init state:[ 6 13 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 47, score:[2679.82], loss:[1.89094], sequence:[0], random actions:[93], eInit:[0.6298], init state:[ 1  7 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 48, score:[2621.09], loss:[1.90391], sequence:[0], random actions:[95], eInit:[0.6235], init state:[ 0 11 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 49, score:[2597.82], loss:[1.92883], sequence:[0], random actions:[100], eInit:[0.6173], init state:[ 4 13 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 50, score:[2644.18], loss:[1.81841], sequence:[0], random actions:[85], eInit:[0.6111], init state:[ 2  7 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2679.8181818181965, [47]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])
INFO:Reinforcement.Functions:episode: 51, score:[2634.36], loss:[1.90320], sequence:[0], random actions:[85], eInit:[0.6050], init state:[ 6  6 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 52, score:[2669.27], loss:[1.71618], sequence:[0], random actions:[84], eInit:[0.5990], init state:[ 2  8 45  1  1  0  0  0  0  0  0  0  0  0], end state:[ 4  8 45  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 53, score:[2608.36], loss:[1.71436], sequence:[0], random actions:[85], eInit:[0.5930], init state:[ 2 14 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 54, score:[2661.27], loss:[1.79860], sequence:[0], random actions:[88], eInit:[0.5870], init state:[ 2  1 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 55, score:[2674.18], loss:[1.69693], sequence:[0], random actions:[84], eInit:[0.5812], init state:[ 0  4 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 56, score:[2549.45], loss:[1.74066], sequence:[0], random actions:[89], eInit:[0.5754], init state:[ 5  7 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 57, score:[2671.45], loss:[1.62772], sequence:[0], random actions:[73], eInit:[0.5696], init state:[ 1  4 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 58, score:[2578.36], loss:[1.87246], sequence:[0], random actions:[85], eInit:[0.5639], init state:[ 3 22 56  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 56  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 59, score:[2596.55], loss:[1.84768], sequence:[0], random actions:[84], eInit:[0.5583], init state:[ 6 16 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 60, score:[2673.82], loss:[1.62534], sequence:[0], random actions:[81], eInit:[0.5527], init state:[ 2  4 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2679.8181818181965, [47]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60])
INFO:Reinforcement.Functions:episode: 61, score:[2656.36], loss:[1.58204], sequence:[0], random actions:[76], eInit:[0.5472], init state:[ 4  4 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 34  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 62, score:[2675.82], loss:[1.52381], sequence:[0], random actions:[81], eInit:[0.5417], init state:[ 0  2 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 63, score:[2614.55], loss:[1.49833], sequence:[0], random actions:[64], eInit:[0.5363], init state:[3 0 8 1 0 0 0 0 1 1 1 0 0 0], end state:[5 0 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 64, score:[2583.64], loss:[1.80174], sequence:[0], random actions:[75], eInit:[0.5309], init state:[ 5 14 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 65, score:[2657.82], loss:[1.53149], sequence:[0], random actions:[67], eInit:[0.5256], init state:[ 2 10 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 10 11  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 66, score:[2683.82], loss:[1.60963], sequence:[0], random actions:[78], eInit:[0.5203], init state:[ 1  6 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 67, score:[2672.36], loss:[1.51946], sequence:[0], random actions:[73], eInit:[0.5151], init state:[ 4  0 36  1  0  1  0  0  0  0  0  0  0  0], end state:[ 6  0 36  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 68, score:[2593.64], loss:[1.83592], sequence:[0], random actions:[83], eInit:[0.5100], init state:[ 5 21 28  1  0  0  1  1  0  1  1  0  0  1], end state:[ 0 21 28  1  1  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 69, score:[2687.64], loss:[1.53998], sequence:[0], random actions:[67], eInit:[0.5049], init state:[2 2 5 0 0 0 0 0 0 0 0 0 0 0], end state:[4 2 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 70, score:[2722.36], loss:[1.39359], sequence:[0], random actions:[62], eInit:[0.4998], init state:[ 0 23 13  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 23 13  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2722.3636363636374, [70]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70])
INFO:Reinforcement.Functions:episode: 71, score:[2698.36], loss:[1.34606], sequence:[0], random actions:[68], eInit:[0.4948], init state:[ 0  9 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 72, score:[2680.18], loss:[1.30653], sequence:[0], random actions:[74], eInit:[0.4899], init state:[ 0 22 26  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 26  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 73, score:[2657.82], loss:[1.47369], sequence:[0], random actions:[76], eInit:[0.4850], init state:[ 0 13 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 74, score:[2703.82], loss:[1.27428], sequence:[0], random actions:[81], eInit:[0.4801], init state:[ 1 13 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 75, score:[2696.91], loss:[1.25036], sequence:[0], random actions:[77], eInit:[0.4753], init state:[0 7 4 0 0 0 0 0 0 0 0 0 0 0], end state:[2 7 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 76, score:[2584.36], loss:[1.34099], sequence:[0], random actions:[67], eInit:[0.4706], init state:[ 4 21 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 14  1  1  0  1  0  0  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 77, score:[2668.18], loss:[1.35798], sequence:[0], random actions:[64], eInit:[0.4659], init state:[ 6 23 19  1  0  0  1  0  0  1  1  0  0  1], end state:[ 1 23 19  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 78, score:[2712.36], loss:[1.23818], sequence:[0], random actions:[64], eInit:[0.4612], init state:[ 1 22  9  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22  9  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 79, score:[2647.82], loss:[1.36622], sequence:[0], random actions:[70], eInit:[0.4566], init state:[ 4 17 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 80, score:[2629.09], loss:[1.47783], sequence:[0], random actions:[75], eInit:[0.4520], init state:[ 5 16 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2722.3636363636374, [70]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80])
INFO:Reinforcement.Functions:episode: 81, score:[2658.18], loss:[1.44371], sequence:[0], random actions:[72], eInit:[0.4475], init state:[ 4  7 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 82, score:[2706.73], loss:[1.28674], sequence:[0], random actions:[66], eInit:[0.4430], init state:[ 3  5 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 83, score:[2674.55], loss:[1.40874], sequence:[0], random actions:[61], eInit:[0.4386], init state:[ 1 16 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 84, score:[2685.64], loss:[1.26479], sequence:[0], random actions:[71], eInit:[0.4342], init state:[ 1 23 22  1  0  0  1  0  0  1  1  0  0  1], end state:[ 3 23 22  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 85, score:[2587.09], loss:[1.45460], sequence:[0], random actions:[71], eInit:[0.4299], init state:[ 5 12 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 86, score:[2651.09], loss:[1.39979], sequence:[0], random actions:[67], eInit:[0.4256], init state:[ 4 11  9  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 87, score:[2669.45], loss:[1.34915], sequence:[0], random actions:[64], eInit:[0.4213], init state:[ 2 15 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 88, score:[2668.36], loss:[1.37570], sequence:[0], random actions:[63], eInit:[0.4171], init state:[ 3  6 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  6 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 89, score:[2656.36], loss:[1.40198], sequence:[0], random actions:[63], eInit:[0.4129], init state:[ 4 15 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 90, score:[2684.36], loss:[1.35285], sequence:[0], random actions:[50], eInit:[0.4088], init state:[ 3 11 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2722.3636363636374, [70]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90])
INFO:Reinforcement.Functions:episode: 91, score:[2670.91], loss:[1.38362], sequence:[0], random actions:[66], eInit:[0.4047], init state:[ 4 17 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 92, score:[2729.82], loss:[1.25403], sequence:[0], random actions:[52], eInit:[0.4007], init state:[ 4  2 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 93, score:[2704.00], loss:[1.28547], sequence:[0], random actions:[61], eInit:[0.3967], init state:[ 0  1 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 94, score:[2716.73], loss:[1.33550], sequence:[0], random actions:[61], eInit:[0.3927], init state:[3 8 6 1 0 0 0 0 0 0 0 0 0 0], end state:[5 8 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 95, score:[2733.82], loss:[1.21451], sequence:[0], random actions:[56], eInit:[0.3888], init state:[ 0 12 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 96, score:[2657.45], loss:[1.27260], sequence:[0], random actions:[65], eInit:[0.3849], init state:[ 4  3 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 97, score:[2656.00], loss:[1.38787], sequence:[0], random actions:[67], eInit:[0.3810], init state:[ 2  8 25  1  0  0  0  0  0  0  0  0  0  0], end state:[ 4  8 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 98, score:[2720.55], loss:[1.26098], sequence:[0], random actions:[57], eInit:[0.3772], init state:[ 1 21 32  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 21 32  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 99, score:[2705.27], loss:[1.22578], sequence:[0], random actions:[56], eInit:[0.3735], init state:[ 0 23  2  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 23  2  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 100, score:[2766.73], loss:[1.11501], sequence:[1], random actions:[50], eInit:[0.3697], init state:[ 3 12 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2766.7272727272743, [100]) , maxSequence:(1, [100])
INFO:Reinforcement.Functions:episode: 101, score:[2740.73], loss:[1.09883], sequence:[2], random actions:[53], eInit:[0.3660], init state:[ 3  5 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 102, score:[2601.82], loss:[1.31711], sequence:[0], random actions:[57], eInit:[0.3624], init state:[ 4 23 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 19  1  0  0  1  0  0  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 103, score:[2724.55], loss:[1.25361], sequence:[0], random actions:[61], eInit:[0.3587], init state:[ 2  6 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 104, score:[2633.82], loss:[1.24688], sequence:[0], random actions:[41], eInit:[0.3552], init state:[ 5  8 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 50  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 105, score:[2686.55], loss:[1.31943], sequence:[0], random actions:[72], eInit:[0.3516], init state:[ 1 16 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 106, score:[2699.45], loss:[1.19241], sequence:[0], random actions:[83], eInit:[0.3481], init state:[ 3 14  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 107, score:[2711.64], loss:[1.02042], sequence:[0], random actions:[52], eInit:[0.3446], init state:[ 6 23 49  1  0  0  0  0  0  1  1  0  0  0], end state:[ 1 23 49  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 108, score:[2677.64], loss:[1.11587], sequence:[0], random actions:[51], eInit:[0.3412], init state:[ 6  1 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 109, score:[2644.55], loss:[1.34255], sequence:[0], random actions:[67], eInit:[0.3378], init state:[ 5 19  9  1  0  0  1  0  1  0  0  0  0  0], end state:[ 0 19  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 110, score:[2722.00], loss:[1.23484], sequence:[0], random actions:[54], eInit:[0.3344], init state:[3 8 7 1 0 0 0 0 0 0 0 0 0 0], end state:[5 8 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2766.7272727272743, [100]) , maxSequence:(2, [101])
INFO:Reinforcement.Functions:episode: 111, score:[2665.45], loss:[1.26166], sequence:[0], random actions:[70], eInit:[0.3310], init state:[ 1 14 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 112, score:[2574.91], loss:[1.34943], sequence:[0], random actions:[57], eInit:[0.3277], init state:[ 5  2 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 113, score:[2677.27], loss:[1.53128], sequence:[0], random actions:[60], eInit:[0.3244], init state:[ 2 19 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 114, score:[2732.73], loss:[1.28676], sequence:[0], random actions:[57], eInit:[0.3212], init state:[ 1 12 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 115, score:[2775.45], loss:[1.14323], sequence:[1], random actions:[52], eInit:[0.3180], init state:[ 2  4 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 116, score:[2664.36], loss:[1.33142], sequence:[0], random actions:[52], eInit:[0.3148], init state:[ 5 13 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 117, score:[2673.09], loss:[1.18789], sequence:[0], random actions:[56], eInit:[0.3117], init state:[ 5  9 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 118, score:[2662.36], loss:[1.47135], sequence:[0], random actions:[49], eInit:[0.3085], init state:[ 5 20 16  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 119, score:[2703.45], loss:[1.33382], sequence:[0], random actions:[54], eInit:[0.3055], init state:[ 3 13 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 120, score:[2708.36], loss:[1.21945], sequence:[0], random actions:[52], eInit:[0.3024], init state:[ 1 18  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2775.4545454545523, [115]) , maxSequence:(2, [101])
INFO:Reinforcement.Functions:episode: 121, score:[2690.91], loss:[1.21700], sequence:[0], random actions:[52], eInit:[0.2994], init state:[ 5 15 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 122, score:[2676.55], loss:[1.27371], sequence:[0], random actions:[55], eInit:[0.2964], init state:[ 2 17 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 123, score:[2668.00], loss:[1.38439], sequence:[0], random actions:[54], eInit:[0.2934], init state:[ 0 13  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 124, score:[2685.09], loss:[1.39654], sequence:[0], random actions:[48], eInit:[0.2905], init state:[ 4  6 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 125, score:[2724.91], loss:[1.30187], sequence:[0], random actions:[37], eInit:[0.2876], init state:[ 6 17 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 126, score:[2612.55], loss:[1.37353], sequence:[0], random actions:[42], eInit:[0.2847], init state:[ 4  5 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 127, score:[2731.27], loss:[1.25989], sequence:[0], random actions:[51], eInit:[0.2819], init state:[ 6 17 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 128, score:[2664.00], loss:[1.21592], sequence:[0], random actions:[60], eInit:[0.2790], init state:[ 4  4 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 129, score:[2711.64], loss:[1.17849], sequence:[0], random actions:[63], eInit:[0.2763], init state:[ 3 14 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 130, score:[2743.64], loss:[1.09164], sequence:[1], random actions:[46], eInit:[0.2735], init state:[ 0 14 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2775.4545454545523, [115]) , maxSequence:(2, [101])
INFO:Reinforcement.Functions:episode: 131, score:[2684.55], loss:[1.15868], sequence:[0], random actions:[56], eInit:[0.2708], init state:[ 0 16  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 132, score:[2692.91], loss:[1.07088], sequence:[0], random actions:[55], eInit:[0.2680], init state:[ 5  5 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 133, score:[2734.36], loss:[1.17930], sequence:[0], random actions:[41], eInit:[0.2654], init state:[ 0 20 33  1  1  0  0  0  0  0  0  1  0  0], end state:[ 2 20 33  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 134, score:[2678.00], loss:[1.10800], sequence:[0], random actions:[60], eInit:[0.2627], init state:[ 0 21 37  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 37  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 135, score:[2649.64], loss:[1.13644], sequence:[0], random actions:[60], eInit:[0.2601], init state:[ 5  7 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 136, score:[2749.45], loss:[1.10102], sequence:[1], random actions:[41], eInit:[0.2575], init state:[ 0  0 50  0  0  1  0  0  0  0  0  0  0  0], end state:[ 2  0 50  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 137, score:[2744.36], loss:[1.04308], sequence:[2], random actions:[47], eInit:[0.2549], init state:[ 0 18 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 138, score:[2691.82], loss:[1.28297], sequence:[0], random actions:[42], eInit:[0.2524], init state:[ 5 18 38  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 139, score:[2712.00], loss:[1.15112], sequence:[0], random actions:[51], eInit:[0.2498], init state:[ 6 11 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 140, score:[2714.91], loss:[1.05925], sequence:[0], random actions:[47], eInit:[0.2473], init state:[ 0  8 54  1  1  0  0  0  0  0  0  0  0  0], end state:[ 2  8 54  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2775.4545454545523, [115]) , maxSequence:(2, [101, 137])
INFO:Reinforcement.Functions:episode: 141, score:[2700.36], loss:[1.06547], sequence:[0], random actions:[47], eInit:[0.2449], init state:[ 5  8 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 22  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 142, score:[2728.73], loss:[1.02760], sequence:[0], random actions:[48], eInit:[0.2424], init state:[ 6 22 32  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 32  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 143, score:[2704.18], loss:[1.05719], sequence:[0], random actions:[39], eInit:[0.2400], init state:[5 2 5 0 0 0 0 0 0 0 0 0 0 0], end state:[0 2 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 144, score:[2695.82], loss:[1.06051], sequence:[0], random actions:[59], eInit:[0.2376], init state:[2 8 6 1 0 0 0 0 0 0 0 0 0 0], end state:[4 8 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 145, score:[2665.09], loss:[1.11267], sequence:[0], random actions:[52], eInit:[0.2352], init state:[ 4 11 45  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 146, score:[2671.82], loss:[1.21324], sequence:[0], random actions:[56], eInit:[0.2329], init state:[ 5 18 56  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 147, score:[2748.18], loss:[1.01142], sequence:[1], random actions:[44], eInit:[0.2305], init state:[ 1  5 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  5 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 148, score:[2777.09], loss:[0.94632], sequence:[2], random actions:[41], eInit:[0.2282], init state:[ 0  1 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 149, score:[2604.18], loss:[1.16584], sequence:[0], random actions:[44], eInit:[0.2259], init state:[ 4  3 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 26  0  0  0  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 150, score:[2714.91], loss:[1.12572], sequence:[0], random actions:[50], eInit:[0.2237], init state:[ 0 18 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2777.09090909091, [148]) , maxSequence:(2, [101, 137, 148])
INFO:Reinforcement.Functions:episode: 151, score:[2721.82], loss:[0.96496], sequence:[0], random actions:[51], eInit:[0.2215], init state:[ 1 14 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 152, score:[2741.09], loss:[0.95784], sequence:[1], random actions:[49], eInit:[0.2192], init state:[ 0 18 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 153, score:[2713.09], loss:[1.00807], sequence:[0], random actions:[50], eInit:[0.2170], init state:[ 6  0 13  1  0  0  0  0  1  1  1  0  0  0], end state:[ 1  0 13  1  0  0  0  0  1  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 154, score:[2752.18], loss:[0.95945], sequence:[1], random actions:[35], eInit:[0.2149], init state:[ 6  1 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 155, score:[2657.09], loss:[1.01593], sequence:[0], random actions:[44], eInit:[0.2127], init state:[ 2 22  2  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22  2  1  1  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 156, score:[2663.64], loss:[1.04507], sequence:[0], random actions:[44], eInit:[0.2106], init state:[ 4 21 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 26  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 157, score:[2691.09], loss:[1.11229], sequence:[0], random actions:[51], eInit:[0.2085], init state:[ 0 20 33  1  1  0  0  0  0  0  0  1  0  0], end state:[ 2 20 33  1  1  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 158, score:[2726.55], loss:[1.03292], sequence:[0], random actions:[44], eInit:[0.2064], init state:[ 6  8 10  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  8 10  1  0  1  0  1  1  0  1  0  1  1]
INFO:Reinforcement.Functions:episode: 159, score:[2674.00], loss:[0.99460], sequence:[0], random actions:[45], eInit:[0.2043], init state:[ 4  2 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 160, score:[2755.82], loss:[1.03653], sequence:[1], random actions:[36], eInit:[0.2023], init state:[ 1 15  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2777.09090909091, [148]) , maxSequence:(2, [101, 137, 148])
INFO:Reinforcement.Functions:episode: 161, score:[2700.18], loss:[0.94268], sequence:[0], random actions:[44], eInit:[0.2003], init state:[ 2 22  5  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 162, score:[2664.00], loss:[0.95633], sequence:[0], random actions:[37], eInit:[0.1983], init state:[ 5 13 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 163, score:[2656.91], loss:[1.01729], sequence:[0], random actions:[48], eInit:[0.1963], init state:[3 8 0 1 0 0 0 0 0 0 0 0 0 0], end state:[5 8 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 164, score:[2681.64], loss:[1.05412], sequence:[0], random actions:[40], eInit:[0.1943], init state:[ 4 20 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 165, score:[2696.18], loss:[1.07020], sequence:[0], random actions:[37], eInit:[0.1924], init state:[ 5 14 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 166, score:[2692.55], loss:[1.15281], sequence:[0], random actions:[51], eInit:[0.1905], init state:[ 6 20 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 20 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 167, score:[2693.27], loss:[1.00426], sequence:[0], random actions:[37], eInit:[0.1886], init state:[ 3  8 13  1  0  0  0  0  0  0  0  0  0  0], end state:[ 5  8 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 168, score:[2683.27], loss:[1.04302], sequence:[0], random actions:[44], eInit:[0.1867], init state:[ 6 16 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 169, score:[2755.82], loss:[0.90407], sequence:[1], random actions:[41], eInit:[0.1848], init state:[ 2  2 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 170, score:[2718.18], loss:[0.92551], sequence:[0], random actions:[33], eInit:[0.1830], init state:[ 6 13 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2777.09090909091, [148]) , maxSequence:(2, [101, 137, 148])
INFO:Reinforcement.Functions:episode: 171, score:[2776.91], loss:[0.86804], sequence:[1], random actions:[31], eInit:[0.1811], init state:[ 2  3 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 172, score:[2669.09], loss:[1.00462], sequence:[0], random actions:[35], eInit:[0.1793], init state:[ 4 22 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22 44  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 173, score:[2708.91], loss:[1.11908], sequence:[0], random actions:[44], eInit:[0.1775], init state:[ 2  1 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 174, score:[2682.55], loss:[1.03836], sequence:[0], random actions:[51], eInit:[0.1757], init state:[ 1 12 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 175, score:[2711.82], loss:[1.03176], sequence:[0], random actions:[39], eInit:[0.1740], init state:[ 3 13 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 176, score:[2725.27], loss:[0.98865], sequence:[0], random actions:[32], eInit:[0.1722], init state:[ 5 18 52  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 177, score:[2761.45], loss:[0.97805], sequence:[1], random actions:[48], eInit:[0.1705], init state:[ 1 22 35  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 35  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 178, score:[2727.09], loss:[0.88286], sequence:[0], random actions:[42], eInit:[0.1688], init state:[ 2 13 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 24  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 179, score:[2714.55], loss:[1.02003], sequence:[0], random actions:[51], eInit:[0.1671], init state:[ 3  8 33  1  1  0  1  1  0  0  0  0  0  0], end state:[ 5  8 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 180, score:[2706.18], loss:[1.08205], sequence:[0], random actions:[40], eInit:[0.1655], init state:[ 3 20 30  1  1  0  0  0  0  0  0  0  1  0], end state:[ 5 20 30  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2777.09090909091, [148]) , maxSequence:(2, [101, 137, 148])
INFO:Reinforcement.Functions:episode: 181, score:[2748.18], loss:[1.00049], sequence:[1], random actions:[38], eInit:[0.1638], init state:[ 2 18 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 182, score:[2744.36], loss:[1.04513], sequence:[2], random actions:[37], eInit:[0.1622], init state:[ 1 15 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 183, score:[2761.64], loss:[1.01183], sequence:[3], random actions:[34], eInit:[0.1605], init state:[ 1  6 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 184, score:[2700.73], loss:[1.00550], sequence:[0], random actions:[44], eInit:[0.1589], init state:[ 4 15 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 185, score:[2656.55], loss:[1.04227], sequence:[0], random actions:[27], eInit:[0.1574], init state:[5 2 2 0 0 0 0 0 0 0 0 0 0 0], end state:[0 2 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 186, score:[2745.09], loss:[1.03078], sequence:[1], random actions:[50], eInit:[0.1558], init state:[ 0 19 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 187, score:[2713.27], loss:[1.01339], sequence:[0], random actions:[46], eInit:[0.1542], init state:[ 2 19 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 188, score:[2734.73], loss:[1.07897], sequence:[0], random actions:[29], eInit:[0.1527], init state:[ 2 15 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 189, score:[2738.73], loss:[1.01392], sequence:[1], random actions:[33], eInit:[0.1512], init state:[ 2 20 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 190, score:[2708.36], loss:[1.05408], sequence:[0], random actions:[49], eInit:[0.1496], init state:[ 3 18  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18  5  0  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2777.09090909091, [148]) , maxSequence:(3, [183])
INFO:Reinforcement.Functions:episode: 191, score:[2731.82], loss:[0.93777], sequence:[0], random actions:[42], eInit:[0.1481], init state:[ 2  6 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 192, score:[2718.91], loss:[0.92423], sequence:[0], random actions:[40], eInit:[0.1467], init state:[ 1 12 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 193, score:[2713.45], loss:[0.85673], sequence:[0], random actions:[40], eInit:[0.1452], init state:[ 6 11 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 194, score:[2668.73], loss:[0.88483], sequence:[0], random actions:[46], eInit:[0.1437], init state:[ 6 13 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 195, score:[2700.18], loss:[0.89986], sequence:[0], random actions:[48], eInit:[0.1423], init state:[ 6 14  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 196, score:[2774.73], loss:[0.74079], sequence:[1], random actions:[38], eInit:[0.1409], init state:[1 0 6 1 0 0 0 0 1 1 1 0 0 0], end state:[3 0 6 1 0 0 0 0 1 0 1 0 0 0]
INFO:Reinforcement.Functions:episode: 197, score:[2613.09], loss:[1.07180], sequence:[0], random actions:[50], eInit:[0.1395], init state:[ 3 16 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 198, score:[2596.00], loss:[0.99957], sequence:[0], random actions:[50], eInit:[0.1381], init state:[ 4  4 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 199, score:[2745.82], loss:[1.01999], sequence:[1], random actions:[46], eInit:[0.1367], init state:[ 0 13  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 200, score:[2773.27], loss:[0.77237], sequence:[2], random actions:[32], eInit:[0.1353], init state:[1 3 3 0 0 0 0 0 0 0 0 0 0 0], end state:[3 3 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2777.09090909091, [148]) , maxSequence:(3, [183])
INFO:Reinforcement.Functions:episode: 201, score:[2756.00], loss:[0.93375], sequence:[3], random actions:[41], eInit:[0.1340], init state:[ 0 13 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 202, score:[2644.91], loss:[1.07321], sequence:[0], random actions:[36], eInit:[0.1326], init state:[ 4 12  6  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 203, score:[2681.27], loss:[0.97515], sequence:[0], random actions:[38], eInit:[0.1313], init state:[ 4  6 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 204, score:[2658.91], loss:[0.99301], sequence:[0], random actions:[38], eInit:[0.1300], init state:[ 4 22 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22 47  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 205, score:[2674.73], loss:[1.03015], sequence:[0], random actions:[48], eInit:[0.1287], init state:[ 5  6 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 206, score:[2716.00], loss:[1.03230], sequence:[0], random actions:[35], eInit:[0.1274], init state:[ 6 13 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 207, score:[2622.73], loss:[1.05861], sequence:[0], random actions:[42], eInit:[0.1261], init state:[ 3 23 39  1  0  0  1  0  0  1  1  0  0  0], end state:[ 5 23 39  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 208, score:[2686.18], loss:[1.04589], sequence:[0], random actions:[45], eInit:[0.1249], init state:[ 3  5 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 209, score:[2756.55], loss:[0.95694], sequence:[1], random actions:[39], eInit:[0.1236], init state:[ 3  9 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 210, score:[2772.36], loss:[0.84338], sequence:[2], random actions:[38], eInit:[0.1224], init state:[ 1  6 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2777.09090909091, [148]) , maxSequence:(3, [183, 201])
INFO:Reinforcement.Functions:episode: 211, score:[2750.36], loss:[0.82217], sequence:[3], random actions:[39], eInit:[0.1212], init state:[ 0 18 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 212, score:[2744.36], loss:[0.78455], sequence:[4], random actions:[36], eInit:[0.1200], init state:[ 6  0 59  0  0  1  0  0  0  0  0  0  0  0], end state:[ 1  0 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 213, score:[2714.00], loss:[0.89498], sequence:[0], random actions:[44], eInit:[0.1188], init state:[ 6  8 27  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  8 27  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 214, score:[2742.73], loss:[0.78371], sequence:[1], random actions:[35], eInit:[0.1176], init state:[ 6 12 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 215, score:[2719.82], loss:[0.93259], sequence:[0], random actions:[36], eInit:[0.1164], init state:[4 5 4 0 0 0 0 0 0 0 0 0 0 0], end state:[6 5 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 216, score:[2815.09], loss:[0.75718], sequence:[1], random actions:[25], eInit:[0.1152], init state:[ 0 11  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 217, score:[2748.00], loss:[0.77749], sequence:[2], random actions:[33], eInit:[0.1141], init state:[ 1  4 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 218, score:[2757.27], loss:[0.77858], sequence:[3], random actions:[35], eInit:[0.1129], init state:[ 1 17 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 219, score:[2751.82], loss:[0.80173], sequence:[4], random actions:[37], eInit:[0.1118], init state:[ 2 19  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 220, score:[2767.09], loss:[0.79873], sequence:[5], random actions:[28], eInit:[0.1107], init state:[ 4 13 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 221, score:[2706.73], loss:[0.90526], sequence:[0], random actions:[44], eInit:[0.1096], init state:[6 7 5 0 0 0 0 0 0 0 0 0 0 0], end state:[1 7 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 222, score:[2703.27], loss:[0.90497], sequence:[0], random actions:[34], eInit:[0.1085], init state:[ 5 11 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 223, score:[2742.73], loss:[0.81344], sequence:[1], random actions:[39], eInit:[0.1074], init state:[ 1 20 39  1  1  0  0  0  0  0  0  1  0  0], end state:[ 3 20 39  1  1  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 224, score:[2767.64], loss:[0.77630], sequence:[2], random actions:[33], eInit:[0.1063], init state:[ 6 21  7  1  1  0  1  1  0  1  1  0  0  1], end state:[ 1 21  7  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 225, score:[2743.27], loss:[0.75766], sequence:[3], random actions:[31], eInit:[0.1053], init state:[ 5 23  9  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 23  9  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 226, score:[2677.64], loss:[0.91446], sequence:[0], random actions:[38], eInit:[0.1042], init state:[ 5 18 57  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 227, score:[2760.18], loss:[0.84294], sequence:[1], random actions:[38], eInit:[0.1032], init state:[ 2  2 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 228, score:[2746.36], loss:[0.83065], sequence:[2], random actions:[39], eInit:[0.1021], init state:[1 6 6 0 0 0 0 0 0 0 0 0 0 0], end state:[3 6 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 229, score:[2767.27], loss:[0.78022], sequence:[3], random actions:[36], eInit:[0.1011], init state:[ 1 13 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 230, score:[2762.73], loss:[0.68909], sequence:[4], random actions:[27], eInit:[0.1001], init state:[ 6 12 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 231, score:[2663.45], loss:[0.91963], sequence:[0], random actions:[45], eInit:[0.0991], init state:[ 5 18 31  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 31  0  0  0  0  1  0  1  1  1  0  1]
INFO:Reinforcement.Functions:episode: 232, score:[2721.82], loss:[0.85338], sequence:[0], random actions:[40], eInit:[0.0981], init state:[ 5 13  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 233, score:[2735.27], loss:[0.76276], sequence:[0], random actions:[28], eInit:[0.0971], init state:[ 2 15 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 234, score:[2616.18], loss:[1.17164], sequence:[0], random actions:[33], eInit:[0.0962], init state:[ 4  4 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 235, score:[2729.64], loss:[1.03457], sequence:[0], random actions:[46], eInit:[0.0952], init state:[ 6 19 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 236, score:[2756.18], loss:[0.83433], sequence:[1], random actions:[34], eInit:[0.0942], init state:[ 1 22 21  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 21  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 237, score:[2679.45], loss:[0.94824], sequence:[0], random actions:[35], eInit:[0.0933], init state:[ 4 23 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 25  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 238, score:[2754.91], loss:[0.94531], sequence:[1], random actions:[41], eInit:[0.0924], init state:[ 1  4 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 239, score:[2761.27], loss:[0.84149], sequence:[2], random actions:[29], eInit:[0.0914], init state:[ 3 19 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 48  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 240, score:[2665.09], loss:[1.01955], sequence:[0], random actions:[35], eInit:[0.0905], init state:[ 3 18  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18  9  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 241, score:[2782.00], loss:[0.89049], sequence:[1], random actions:[31], eInit:[0.0896], init state:[ 2 12 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 32  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 242, score:[2647.27], loss:[1.03312], sequence:[0], random actions:[34], eInit:[0.0887], init state:[ 4 22 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22 15  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 243, score:[2696.55], loss:[1.08473], sequence:[0], random actions:[36], eInit:[0.0878], init state:[ 3  6 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  6 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 244, score:[2731.09], loss:[0.98028], sequence:[0], random actions:[30], eInit:[0.0870], init state:[ 4 18 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 12  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 245, score:[2729.82], loss:[1.06107], sequence:[0], random actions:[37], eInit:[0.0861], init state:[ 5 19  9  1  0  0  1  0  1  0  0  0  0  0], end state:[ 0 19  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 246, score:[2704.91], loss:[1.02682], sequence:[0], random actions:[34], eInit:[0.0852], init state:[ 2  7 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 247, score:[2687.27], loss:[1.01610], sequence:[0], random actions:[41], eInit:[0.0844], init state:[ 3  0 51  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 248, score:[2770.91], loss:[0.91404], sequence:[1], random actions:[29], eInit:[0.0835], init state:[ 1 17 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 249, score:[2771.09], loss:[0.88759], sequence:[2], random actions:[21], eInit:[0.0827], init state:[ 6  7 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 250, score:[2699.09], loss:[0.94755], sequence:[0], random actions:[41], eInit:[0.0819], init state:[ 0 12 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 251, score:[2794.91], loss:[0.76730], sequence:[1], random actions:[30], eInit:[0.0811], init state:[ 0  4 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 252, score:[2758.00], loss:[0.80365], sequence:[2], random actions:[32], eInit:[0.0802], init state:[ 1 20 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 20 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 253, score:[2749.82], loss:[0.79168], sequence:[3], random actions:[33], eInit:[0.0794], init state:[ 6  0 26  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  0 26  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 254, score:[2662.00], loss:[0.86933], sequence:[0], random actions:[34], eInit:[0.0787], init state:[ 4  9 30  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 255, score:[2747.09], loss:[0.82969], sequence:[1], random actions:[29], eInit:[0.0779], init state:[ 2  1 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 256, score:[2717.45], loss:[0.87879], sequence:[0], random actions:[27], eInit:[0.0771], init state:[6 3 4 0 0 0 0 0 0 0 0 0 0 0], end state:[1 3 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 257, score:[2723.27], loss:[0.85225], sequence:[0], random actions:[35], eInit:[0.0763], init state:[2 7 7 0 0 0 0 0 0 0 0 0 0 0], end state:[4 7 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 258, score:[2796.55], loss:[0.75800], sequence:[1], random actions:[29], eInit:[0.0756], init state:[ 1 15 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 259, score:[2681.82], loss:[0.82905], sequence:[0], random actions:[39], eInit:[0.0748], init state:[ 5 21 20  1  0  0  1  1  0  1  1  0  0  1], end state:[ 0 21 20  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 260, score:[2709.64], loss:[0.84223], sequence:[0], random actions:[39], eInit:[0.0740], init state:[ 6 17  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 261, score:[2701.45], loss:[0.82009], sequence:[0], random actions:[25], eInit:[0.0733], init state:[4 0 5 1 0 0 0 0 1 1 1 0 0 0], end state:[6 0 5 1 0 0 0 0 0 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 262, score:[2771.45], loss:[0.75960], sequence:[1], random actions:[30], eInit:[0.0726], init state:[ 1  5 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  5 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 263, score:[2786.00], loss:[0.69401], sequence:[2], random actions:[29], eInit:[0.0718], init state:[ 2 21 26  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 264, score:[2721.27], loss:[0.75970], sequence:[0], random actions:[29], eInit:[0.0711], init state:[ 6  8 29  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  8 29  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 265, score:[2689.64], loss:[0.81043], sequence:[0], random actions:[39], eInit:[0.0704], init state:[ 3 17 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17 17  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 266, score:[2738.00], loss:[0.80466], sequence:[1], random actions:[33], eInit:[0.0697], init state:[ 3 18 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 21  0  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 267, score:[2743.82], loss:[0.75848], sequence:[2], random actions:[31], eInit:[0.0690], init state:[ 2  8 14  1  0  0  0  0  0  0  0  0  0  0], end state:[ 4  8 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 268, score:[2769.82], loss:[0.72440], sequence:[3], random actions:[30], eInit:[0.0683], init state:[ 1  6 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 269, score:[2708.18], loss:[0.79324], sequence:[0], random actions:[20], eInit:[0.0676], init state:[ 4 10 20  1  1  0  1  0  1  0  0  0  0  0], end state:[ 6 10 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 270, score:[2670.55], loss:[0.95274], sequence:[0], random actions:[35], eInit:[0.0670], init state:[5 9 0 0 0 0 0 0 0 0 0 0 0 0], end state:[0 9 0 1 1 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 271, score:[2780.36], loss:[0.76852], sequence:[1], random actions:[27], eInit:[0.0663], init state:[ 1  3 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 272, score:[2700.00], loss:[0.82409], sequence:[0], random actions:[29], eInit:[0.0656], init state:[ 5 14 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 273, score:[2711.27], loss:[0.91681], sequence:[0], random actions:[29], eInit:[0.0650], init state:[ 6 13 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 274, score:[2717.27], loss:[0.81249], sequence:[0], random actions:[31], eInit:[0.0643], init state:[ 6  1 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 275, score:[2784.73], loss:[0.74515], sequence:[1], random actions:[37], eInit:[0.0637], init state:[ 0 14 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 276, score:[2689.27], loss:[0.84509], sequence:[0], random actions:[39], eInit:[0.0630], init state:[ 4 10  2  1  1  0  1  0  0  0  0  0  0  0], end state:[ 6 10  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 277, score:[2706.73], loss:[0.85490], sequence:[0], random actions:[36], eInit:[0.0624], init state:[ 5 18 36  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 278, score:[2752.36], loss:[0.78812], sequence:[1], random actions:[35], eInit:[0.0618], init state:[ 3 23 58  1  0  0  0  0  0  1  1  0  0  0], end state:[ 5 23 58  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 279, score:[2702.73], loss:[0.88499], sequence:[0], random actions:[42], eInit:[0.0612], init state:[ 0  6 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  6 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 280, score:[2751.64], loss:[0.74937], sequence:[1], random actions:[25], eInit:[0.0606], init state:[ 4  2 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 281, score:[2633.45], loss:[1.04385], sequence:[0], random actions:[43], eInit:[0.0600], init state:[ 4 11 43  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 282, score:[2729.27], loss:[0.92044], sequence:[0], random actions:[33], eInit:[0.0594], init state:[ 5 13 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 283, score:[2750.18], loss:[0.83796], sequence:[1], random actions:[35], eInit:[0.0588], init state:[ 3  9 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 284, score:[2750.55], loss:[0.87245], sequence:[2], random actions:[38], eInit:[0.0582], init state:[ 3  1 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  1 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 285, score:[2742.91], loss:[0.90200], sequence:[3], random actions:[33], eInit:[0.0576], init state:[ 2  4 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 286, score:[2778.36], loss:[0.77769], sequence:[4], random actions:[25], eInit:[0.0570], init state:[ 1  3 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 287, score:[2699.27], loss:[0.79346], sequence:[0], random actions:[39], eInit:[0.0565], init state:[2 6 4 0 0 0 0 0 0 0 0 0 0 0], end state:[4 6 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 288, score:[2720.91], loss:[0.88104], sequence:[0], random actions:[26], eInit:[0.0559], init state:[ 5 20  4  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 289, score:[2745.64], loss:[0.88318], sequence:[1], random actions:[31], eInit:[0.0553], init state:[ 6 19 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 290, score:[2758.55], loss:[1.01041], sequence:[2], random actions:[30], eInit:[0.0548], init state:[ 3 16 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 291, score:[2779.64], loss:[0.88415], sequence:[3], random actions:[33], eInit:[0.0542], init state:[6 3 3 0 0 0 0 0 0 0 0 0 0 0], end state:[1 3 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 292, score:[2774.73], loss:[0.71841], sequence:[4], random actions:[34], eInit:[0.0537], init state:[ 6 14 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 293, score:[2725.82], loss:[0.72253], sequence:[0], random actions:[34], eInit:[0.0531], init state:[ 0 22 53  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 53  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 294, score:[2794.91], loss:[0.66838], sequence:[1], random actions:[31], eInit:[0.0526], init state:[ 6 19 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 295, score:[2815.09], loss:[0.59940], sequence:[2], random actions:[22], eInit:[0.0521], init state:[ 1  4 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 296, score:[2711.09], loss:[0.78006], sequence:[0], random actions:[28], eInit:[0.0516], init state:[ 5  9 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 297, score:[2762.73], loss:[0.69600], sequence:[1], random actions:[28], eInit:[0.0511], init state:[ 1 22 36  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 36  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 298, score:[2721.64], loss:[0.71967], sequence:[0], random actions:[38], eInit:[0.0505], init state:[ 6 15  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 299, score:[2748.36], loss:[0.62973], sequence:[1], random actions:[41], eInit:[0.0500], init state:[ 1 17 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 300, score:[2719.64], loss:[0.69141], sequence:[0], random actions:[39], eInit:[0.0495], init state:[ 4 11 48  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 301, score:[2742.36], loss:[0.80325], sequence:[1], random actions:[22], eInit:[0.0490], init state:[ 5  9 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 302, score:[2787.82], loss:[0.71828], sequence:[2], random actions:[26], eInit:[0.0486], init state:[ 0 17 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 303, score:[2760.55], loss:[0.58833], sequence:[3], random actions:[32], eInit:[0.0481], init state:[ 2  1 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 304, score:[2708.18], loss:[0.87427], sequence:[0], random actions:[37], eInit:[0.0476], init state:[ 5 13 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 305, score:[2662.18], loss:[0.89999], sequence:[0], random actions:[41], eInit:[0.0471], init state:[ 4  8 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 306, score:[2649.82], loss:[0.93520], sequence:[0], random actions:[41], eInit:[0.0466], init state:[ 4  6 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 307, score:[2748.73], loss:[0.97096], sequence:[1], random actions:[23], eInit:[0.0462], init state:[ 5 14 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 308, score:[2720.91], loss:[0.97804], sequence:[0], random actions:[26], eInit:[0.0457], init state:[ 4  8 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 28  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 309, score:[2711.64], loss:[0.86377], sequence:[0], random actions:[25], eInit:[0.0453], init state:[ 4  1 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 310, score:[2784.00], loss:[0.81637], sequence:[1], random actions:[25], eInit:[0.0448], init state:[ 0 13 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 311, score:[2736.55], loss:[0.86010], sequence:[2], random actions:[27], eInit:[0.0444], init state:[ 5  6 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 312, score:[2708.18], loss:[0.86179], sequence:[0], random actions:[36], eInit:[0.0439], init state:[6 5 7 0 0 0 0 0 0 0 0 0 0 0], end state:[1 5 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 313, score:[2750.91], loss:[0.74787], sequence:[1], random actions:[36], eInit:[0.0435], init state:[ 0  3 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 314, score:[2722.55], loss:[0.82911], sequence:[0], random actions:[33], eInit:[0.0430], init state:[ 6 21 18  1  1  0  1  0  0  1  1  0  0  1], end state:[ 1 21 18  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 315, score:[2748.00], loss:[0.79920], sequence:[1], random actions:[31], eInit:[0.0426], init state:[ 4  7 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 316, score:[2684.36], loss:[0.88773], sequence:[0], random actions:[37], eInit:[0.0422], init state:[ 3 14 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 317, score:[2773.82], loss:[0.78477], sequence:[1], random actions:[28], eInit:[0.0418], init state:[ 0  4 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 318, score:[2747.82], loss:[0.84575], sequence:[2], random actions:[28], eInit:[0.0413], init state:[ 0 20  4  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 20  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 319, score:[2804.73], loss:[0.65169], sequence:[3], random actions:[18], eInit:[0.0409], init state:[ 0  2 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 320, score:[2674.36], loss:[0.93865], sequence:[0], random actions:[35], eInit:[0.0405], init state:[ 5 14 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 321, score:[2733.27], loss:[0.85043], sequence:[0], random actions:[34], eInit:[0.0401], init state:[ 6 17 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 322, score:[2688.36], loss:[0.87000], sequence:[0], random actions:[38], eInit:[0.0397], init state:[ 5  7 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 37  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 323, score:[2801.27], loss:[0.77714], sequence:[1], random actions:[24], eInit:[0.0393], init state:[ 6  6 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 324, score:[2756.00], loss:[0.77293], sequence:[2], random actions:[27], eInit:[0.0389], init state:[ 4 18 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 325, score:[2728.73], loss:[0.87330], sequence:[0], random actions:[33], eInit:[0.0385], init state:[ 4  3 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 326, score:[2684.73], loss:[0.89792], sequence:[0], random actions:[28], eInit:[0.0381], init state:[ 2 12 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 43  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 327, score:[2750.91], loss:[0.95327], sequence:[1], random actions:[30], eInit:[0.0378], init state:[ 6  0 21  1  0  0  0  0  1  0  0  0  0  0], end state:[ 1  0 21  1  0  0  0  0  0  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 328, score:[2782.00], loss:[0.79340], sequence:[2], random actions:[26], eInit:[0.0374], init state:[ 1 18 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 329, score:[2735.45], loss:[0.90239], sequence:[0], random actions:[32], eInit:[0.0370], init state:[ 3 14 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 330, score:[2762.36], loss:[0.79342], sequence:[1], random actions:[28], eInit:[0.0366], init state:[ 3 16 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 331, score:[2746.91], loss:[0.79538], sequence:[2], random actions:[26], eInit:[0.0363], init state:[ 5 19 27  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 332, score:[2714.73], loss:[0.81808], sequence:[0], random actions:[34], eInit:[0.0359], init state:[ 3  4 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 333, score:[2724.91], loss:[0.80166], sequence:[0], random actions:[36], eInit:[0.0356], init state:[ 2  1 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 334, score:[2677.09], loss:[0.95306], sequence:[0], random actions:[28], eInit:[0.0352], init state:[ 4 21 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 58  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 335, score:[2781.64], loss:[0.81432], sequence:[1], random actions:[32], eInit:[0.0348], init state:[ 1  6 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 336, score:[2689.45], loss:[0.88282], sequence:[0], random actions:[32], eInit:[0.0345], init state:[ 3  3 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 337, score:[2772.36], loss:[0.82567], sequence:[1], random actions:[30], eInit:[0.0342], init state:[ 0 10 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 338, score:[2731.64], loss:[0.80863], sequence:[0], random actions:[33], eInit:[0.0338], init state:[ 1  1 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 339, score:[2696.00], loss:[1.02109], sequence:[0], random actions:[30], eInit:[0.0335], init state:[ 5  8 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 58  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 340, score:[2759.09], loss:[0.85364], sequence:[1], random actions:[30], eInit:[0.0331], init state:[ 3  0 48  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 341, score:[2751.82], loss:[1.09320], sequence:[2], random actions:[33], eInit:[0.0328], init state:[ 1 23 57  1  0  0  0  0  0  1  1  0  0  0], end state:[ 3 23 57  0  0  0  0  0  1  0  1  1  1  0]
INFO:Reinforcement.Functions:episode: 342, score:[2793.45], loss:[1.04258], sequence:[3], random actions:[23], eInit:[0.0325], init state:[ 2 15 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 343, score:[2580.91], loss:[1.27124], sequence:[0], random actions:[30], eInit:[0.0322], init state:[5 5 2 0 0 0 0 0 0 0 0 0 0 0], end state:[0 5 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 344, score:[2756.91], loss:[1.11090], sequence:[1], random actions:[33], eInit:[0.0318], init state:[ 1 23 41  1  0  0  1  0  0  1  1  0  0  0], end state:[ 3 23 41  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 345, score:[2771.64], loss:[0.95780], sequence:[2], random actions:[23], eInit:[0.0315], init state:[ 1  5 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  5 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 346, score:[2780.73], loss:[0.79648], sequence:[3], random actions:[26], eInit:[0.0312], init state:[ 1 11 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 347, score:[2777.82], loss:[0.80823], sequence:[4], random actions:[26], eInit:[0.0309], init state:[ 0  5 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 348, score:[2735.82], loss:[0.85324], sequence:[0], random actions:[27], eInit:[0.0306], init state:[ 2 14 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 349, score:[2661.09], loss:[1.03147], sequence:[0], random actions:[30], eInit:[0.0303], init state:[ 5 14 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 350, score:[2679.09], loss:[1.08056], sequence:[0], random actions:[35], eInit:[0.0300], init state:[3 4 6 0 0 0 0 0 0 0 0 0 0 0], end state:[5 4 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 351, score:[2786.00], loss:[1.06213], sequence:[1], random actions:[29], eInit:[0.0297], init state:[ 1 10 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 352, score:[2751.09], loss:[0.85517], sequence:[2], random actions:[31], eInit:[0.0294], init state:[2 2 9 0 0 0 0 0 0 0 0 0 0 0], end state:[4 2 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 353, score:[2636.73], loss:[1.15517], sequence:[0], random actions:[40], eInit:[0.0291], init state:[ 5  3 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 354, score:[2688.00], loss:[1.13343], sequence:[0], random actions:[38], eInit:[0.0288], init state:[ 5 19 14  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 355, score:[2719.82], loss:[0.95885], sequence:[0], random actions:[27], eInit:[0.0285], init state:[ 4 17 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 356, score:[2697.09], loss:[1.06563], sequence:[0], random actions:[35], eInit:[0.0282], init state:[ 5 23 23  1  0  0  0  0  0  1  1  0  0  1], end state:[ 0 23 23  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 357, score:[2792.91], loss:[0.92413], sequence:[1], random actions:[22], eInit:[0.0279], init state:[ 0  7 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 358, score:[2774.00], loss:[0.81959], sequence:[2], random actions:[29], eInit:[0.0277], init state:[ 4  6 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 359, score:[2758.00], loss:[0.89594], sequence:[3], random actions:[28], eInit:[0.0274], init state:[ 3  1 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  1 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 360, score:[2797.45], loss:[0.77950], sequence:[4], random actions:[24], eInit:[0.0271], init state:[ 4  7 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(5, [220])
INFO:Reinforcement.Functions:episode: 361, score:[2748.18], loss:[0.79394], sequence:[5], random actions:[34], eInit:[0.0268], init state:[ 2 14 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 362, score:[2766.00], loss:[0.77480], sequence:[6], random actions:[39], eInit:[0.0266], init state:[ 0  7 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 363, score:[2748.00], loss:[0.83734], sequence:[7], random actions:[29], eInit:[0.0263], init state:[ 6 14 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 364, score:[2777.09], loss:[0.79702], sequence:[8], random actions:[20], eInit:[0.0260], init state:[ 3 13 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 365, score:[2766.91], loss:[0.80321], sequence:[9], random actions:[25], eInit:[0.0258], init state:[ 2 11 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11 48  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 366, score:[2684.36], loss:[0.87332], sequence:[0], random actions:[43], eInit:[0.0255], init state:[ 5  6 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 367, score:[2805.09], loss:[0.81233], sequence:[1], random actions:[24], eInit:[0.0253], init state:[ 0  0 20  1  0  0  0  0  1  0  0  0  0  0], end state:[ 2  0 20  1  0  0  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 368, score:[2753.09], loss:[0.75636], sequence:[2], random actions:[32], eInit:[0.0250], init state:[ 1 22 51  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 51  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 369, score:[2747.45], loss:[0.77888], sequence:[3], random actions:[39], eInit:[0.0248], init state:[ 0 21 32  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 32  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 370, score:[2658.91], loss:[0.93703], sequence:[0], random actions:[39], eInit:[0.0245], init state:[ 5 11 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 371, score:[2736.00], loss:[0.82347], sequence:[1], random actions:[37], eInit:[0.0243], init state:[4 2 7 0 0 0 0 0 0 0 0 0 0 0], end state:[6 2 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 372, score:[2737.64], loss:[0.88687], sequence:[2], random actions:[29], eInit:[0.0240], init state:[ 2 22 36  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 373, score:[2753.45], loss:[0.81102], sequence:[3], random actions:[29], eInit:[0.0238], init state:[ 0 19 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 374, score:[2683.09], loss:[0.98908], sequence:[0], random actions:[32], eInit:[0.0235], init state:[ 5 13 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 375, score:[2803.82], loss:[0.74764], sequence:[1], random actions:[22], eInit:[0.0233], init state:[ 1 17 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 376, score:[2776.36], loss:[0.67463], sequence:[2], random actions:[16], eInit:[0.0231], init state:[ 0 22 38  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 38  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 377, score:[2715.27], loss:[0.91290], sequence:[0], random actions:[27], eInit:[0.0228], init state:[ 5 16 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 378, score:[2775.64], loss:[0.83936], sequence:[1], random actions:[20], eInit:[0.0226], init state:[ 5 21 15  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 15  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 379, score:[2769.64], loss:[0.71570], sequence:[2], random actions:[37], eInit:[0.0224], init state:[2 4 6 0 0 0 0 0 0 0 0 0 0 0], end state:[4 4 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 380, score:[2802.73], loss:[0.71361], sequence:[3], random actions:[31], eInit:[0.0222], init state:[ 1  6 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 381, score:[2702.00], loss:[0.89681], sequence:[0], random actions:[31], eInit:[0.0219], init state:[ 3 12  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 382, score:[2708.91], loss:[0.94912], sequence:[0], random actions:[26], eInit:[0.0217], init state:[ 6  4 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 383, score:[2701.09], loss:[0.94179], sequence:[0], random actions:[49], eInit:[0.0215], init state:[ 6 18  4  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 384, score:[2744.91], loss:[0.85188], sequence:[1], random actions:[36], eInit:[0.0213], init state:[ 1  3 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 385, score:[2788.55], loss:[0.75515], sequence:[2], random actions:[33], eInit:[0.0211], init state:[ 1 15 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 386, score:[2758.91], loss:[0.73070], sequence:[3], random actions:[28], eInit:[0.0209], init state:[ 0 10 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 387, score:[2750.00], loss:[0.72750], sequence:[4], random actions:[28], eInit:[0.0207], init state:[ 6  8 34  1  1  0  1  1  0  0  0  0  0  0], end state:[ 1  8 34  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 388, score:[2717.09], loss:[0.85099], sequence:[0], random actions:[32], eInit:[0.0205], init state:[ 6 23 36  1  0  0  1  0  0  1  1  0  0  0], end state:[ 1 23 36  1  0  0  1  1  0  0  1  1  0  1]
INFO:Reinforcement.Functions:episode: 389, score:[2780.00], loss:[0.75137], sequence:[1], random actions:[24], eInit:[0.0203], init state:[ 2 14 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 390, score:[2737.27], loss:[0.83296], sequence:[2], random actions:[26], eInit:[0.0200], init state:[ 6  6 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2815.090909090914, [216, 295]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 391, score:[2816.91], loss:[0.61556], sequence:[3], random actions:[22], eInit:[0.0198], init state:[ 6 18  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 392, score:[2820.18], loss:[0.57238], sequence:[4], random actions:[20], eInit:[0.0196], init state:[ 2  9 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 393, score:[2764.36], loss:[0.69118], sequence:[5], random actions:[24], eInit:[0.0195], init state:[ 6 12 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 394, score:[2709.82], loss:[0.76864], sequence:[0], random actions:[34], eInit:[0.0193], init state:[ 4 19 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 395, score:[2742.00], loss:[0.74322], sequence:[1], random actions:[30], eInit:[0.0191], init state:[ 2 16  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 16  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 396, score:[2728.36], loss:[0.73094], sequence:[0], random actions:[29], eInit:[0.0189], init state:[ 4 11 57  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 397, score:[2747.64], loss:[0.73478], sequence:[1], random actions:[31], eInit:[0.0187], init state:[ 5  6 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 398, score:[2791.82], loss:[0.71538], sequence:[2], random actions:[29], eInit:[0.0185], init state:[ 1 15  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 399, score:[2747.45], loss:[0.77626], sequence:[3], random actions:[30], eInit:[0.0183], init state:[ 6 10 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 400, score:[2624.00], loss:[0.92618], sequence:[0], random actions:[26], eInit:[0.0181], init state:[ 3 19 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 19  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2820.181818181824, [392]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 401, score:[2735.82], loss:[0.79159], sequence:[0], random actions:[27], eInit:[0.0180], init state:[ 4  2 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 402, score:[2780.55], loss:[0.73390], sequence:[1], random actions:[26], eInit:[0.0178], init state:[ 1  7 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 403, score:[2732.91], loss:[0.74660], sequence:[0], random actions:[22], eInit:[0.0176], init state:[ 4  7 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 404, score:[2775.82], loss:[0.69355], sequence:[1], random actions:[25], eInit:[0.0174], init state:[ 0 20 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 20 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 405, score:[2777.45], loss:[0.66869], sequence:[2], random actions:[32], eInit:[0.0172], init state:[ 1  8 17  1  0  0  0  0  0  0  0  0  0  0], end state:[ 3  8 17  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 406, score:[2687.64], loss:[0.70755], sequence:[0], random actions:[29], eInit:[0.0171], init state:[ 0  9 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 407, score:[2792.73], loss:[0.61176], sequence:[1], random actions:[26], eInit:[0.0169], init state:[ 1 21  8  1  1  0  1  1  0  1  1  0  0  1], end state:[ 3 21  8  1  0  0  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 408, score:[2720.73], loss:[0.75385], sequence:[0], random actions:[36], eInit:[0.0167], init state:[ 2 13 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 18  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 409, score:[2687.45], loss:[0.87885], sequence:[0], random actions:[30], eInit:[0.0166], init state:[ 5 17  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 410, score:[2726.00], loss:[0.81745], sequence:[0], random actions:[27], eInit:[0.0164], init state:[ 4 11 30  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2820.181818181824, [392]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 411, score:[2639.45], loss:[1.01664], sequence:[0], random actions:[36], eInit:[0.0162], init state:[ 5  7 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 412, score:[2772.55], loss:[0.78121], sequence:[1], random actions:[30], eInit:[0.0161], init state:[ 1  6 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 413, score:[2727.82], loss:[0.84137], sequence:[0], random actions:[25], eInit:[0.0159], init state:[ 3 14 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 414, score:[2773.64], loss:[0.71381], sequence:[1], random actions:[27], eInit:[0.0158], init state:[1 1 6 0 0 1 0 0 0 0 0 0 0 0], end state:[3 1 6 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 415, score:[2729.27], loss:[0.69972], sequence:[0], random actions:[26], eInit:[0.0156], init state:[ 2  9 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 40  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 416, score:[2696.00], loss:[0.74705], sequence:[0], random actions:[42], eInit:[0.0154], init state:[ 2 14 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 417, score:[2767.64], loss:[0.86931], sequence:[1], random actions:[24], eInit:[0.0153], init state:[ 6 15 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 418, score:[2744.36], loss:[0.71072], sequence:[2], random actions:[35], eInit:[0.0151], init state:[3 0 1 1 0 0 0 0 0 1 1 0 0 0], end state:[5 0 1 1 0 0 0 0 0 0 1 0 0 0]
INFO:Reinforcement.Functions:episode: 419, score:[2712.36], loss:[0.94753], sequence:[0], random actions:[22], eInit:[0.0150], init state:[ 5 16 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 420, score:[2700.73], loss:[0.88343], sequence:[0], random actions:[36], eInit:[0.0148], init state:[ 1 14 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2820.181818181824, [392]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 421, score:[2776.18], loss:[0.80505], sequence:[1], random actions:[23], eInit:[0.0147], init state:[1 7 7 0 0 0 0 0 0 0 0 0 0 0], end state:[3 7 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 422, score:[2698.55], loss:[0.94298], sequence:[0], random actions:[34], eInit:[0.0145], init state:[ 3  5 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 423, score:[2739.82], loss:[1.03755], sequence:[1], random actions:[27], eInit:[0.0144], init state:[ 6 16 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 424, score:[2785.82], loss:[0.83794], sequence:[2], random actions:[18], eInit:[0.0142], init state:[ 2 17 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 425, score:[2792.73], loss:[0.84358], sequence:[3], random actions:[23], eInit:[0.0141], init state:[ 0 14  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 426, score:[2799.64], loss:[0.73060], sequence:[4], random actions:[26], eInit:[0.0140], init state:[ 6 22  2  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22  2  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 427, score:[2740.18], loss:[0.79973], sequence:[5], random actions:[35], eInit:[0.0138], init state:[ 6 22 45  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 45  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 428, score:[2720.55], loss:[0.93439], sequence:[0], random actions:[31], eInit:[0.0137], init state:[ 5  5 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 429, score:[2794.36], loss:[0.79289], sequence:[1], random actions:[30], eInit:[0.0135], init state:[ 0 18 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 430, score:[2668.36], loss:[0.94569], sequence:[0], random actions:[26], eInit:[0.0134], init state:[ 3  5 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2820.181818181824, [392]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 431, score:[2726.36], loss:[0.99419], sequence:[0], random actions:[27], eInit:[0.0133], init state:[ 3 13 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 432, score:[2661.82], loss:[1.00335], sequence:[0], random actions:[24], eInit:[0.0131], init state:[ 5 17 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 433, score:[2773.09], loss:[0.92387], sequence:[1], random actions:[33], eInit:[0.0130], init state:[ 1 22 27  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 27  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 434, score:[2713.09], loss:[0.92819], sequence:[0], random actions:[37], eInit:[0.0129], init state:[ 3 23 42  1  0  0  1  0  0  1  1  0  0  0], end state:[ 5 23 42  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 435, score:[2644.18], loss:[1.21604], sequence:[0], random actions:[30], eInit:[0.0128], init state:[ 5 11 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 436, score:[2764.18], loss:[0.92354], sequence:[1], random actions:[25], eInit:[0.0126], init state:[ 2 21 54  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 21 54  1  1  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 437, score:[2738.73], loss:[0.95520], sequence:[2], random actions:[30], eInit:[0.0125], init state:[ 2 21 16  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 438, score:[2793.27], loss:[0.95418], sequence:[3], random actions:[24], eInit:[0.0124], init state:[ 0 10 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 439, score:[2627.45], loss:[1.12437], sequence:[0], random actions:[24], eInit:[0.0123], init state:[ 5 11 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 440, score:[2742.00], loss:[0.95078], sequence:[1], random actions:[33], eInit:[0.0121], init state:[ 6 22 24  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 24  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2820.181818181824, [392]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 441, score:[2732.36], loss:[0.92488], sequence:[0], random actions:[27], eInit:[0.0120], init state:[ 4  4 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 442, score:[2699.82], loss:[1.03710], sequence:[0], random actions:[23], eInit:[0.0119], init state:[ 4 21 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 36  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 443, score:[2758.55], loss:[0.95679], sequence:[1], random actions:[28], eInit:[0.0118], init state:[ 0  3 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 444, score:[2740.73], loss:[0.94599], sequence:[2], random actions:[32], eInit:[0.0117], init state:[ 2 18 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 445, score:[2704.73], loss:[1.10519], sequence:[0], random actions:[33], eInit:[0.0115], init state:[ 6 10  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 446, score:[2765.27], loss:[1.02550], sequence:[1], random actions:[28], eInit:[0.0114], init state:[ 6 18 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 447, score:[2744.18], loss:[0.93526], sequence:[2], random actions:[29], eInit:[0.0113], init state:[ 2 18 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 448, score:[2583.64], loss:[1.17150], sequence:[0], random actions:[25], eInit:[0.0112], init state:[ 4  7 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 449, score:[2748.00], loss:[1.01811], sequence:[1], random actions:[28], eInit:[0.0111], init state:[ 2 19 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 450, score:[2709.64], loss:[1.01271], sequence:[0], random actions:[28], eInit:[0.0110], init state:[ 4 18 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2820.181818181824, [392]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 451, score:[2800.18], loss:[0.85616], sequence:[1], random actions:[26], eInit:[0.0109], init state:[ 0 18 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 452, score:[2710.18], loss:[0.97094], sequence:[0], random actions:[28], eInit:[0.0108], init state:[ 5  7 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 453, score:[2760.18], loss:[0.95907], sequence:[1], random actions:[30], eInit:[0.0106], init state:[ 1 17  4  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 454, score:[2745.27], loss:[0.98420], sequence:[2], random actions:[26], eInit:[0.0105], init state:[ 5 20  7  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20  7  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 455, score:[2697.45], loss:[0.95872], sequence:[0], random actions:[27], eInit:[0.0104], init state:[ 5 11  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 456, score:[2761.64], loss:[0.86190], sequence:[1], random actions:[30], eInit:[0.0103], init state:[ 6 21 39  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 21 39  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 457, score:[2813.45], loss:[0.82338], sequence:[2], random actions:[20], eInit:[0.0102], init state:[ 1 14 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 458, score:[2743.09], loss:[0.79138], sequence:[3], random actions:[28], eInit:[0.0101], init state:[ 3 20 35  1  1  0  0  0  0  0  0  1  0  0], end state:[ 5 20 35  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 459, score:[2723.09], loss:[0.89916], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 0 11 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 460, score:[2790.18], loss:[0.78246], sequence:[1], random actions:[25], eInit:[0.0100], init state:[1 9 2 0 0 0 0 0 0 0 0 0 0 0], end state:[3 9 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2820.181818181824, [392]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 461, score:[2722.73], loss:[0.96633], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  8 43  1  1  0  1  0  0  0  0  0  0  0], end state:[ 1  8 43  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 462, score:[2820.91], loss:[0.69200], sequence:[1], random actions:[16], eInit:[0.0100], init state:[ 0 16 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 463, score:[2773.82], loss:[0.73779], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 1 16 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 464, score:[2797.45], loss:[0.71039], sequence:[3], random actions:[27], eInit:[0.0100], init state:[0 4 9 0 0 0 0 0 0 0 0 0 0 0], end state:[2 4 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 465, score:[2709.09], loss:[0.86970], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 21 11  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 11  1  1  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 466, score:[2703.82], loss:[0.98001], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  0 26  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  0 26  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 467, score:[2811.64], loss:[0.96132], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0 10 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 468, score:[2768.18], loss:[0.82987], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2 19 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 469, score:[2798.36], loss:[0.77294], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 1  8 20  1  0  0  0  0  0  0  0  0  0  0], end state:[ 3  8 20  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 470, score:[2712.55], loss:[0.88222], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6  9 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2820.909090909092, [462]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 471, score:[2762.36], loss:[0.78498], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 4 10 58  1  1  0  1  0  0  0  0  0  0  0], end state:[ 6 10 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 472, score:[2702.55], loss:[0.94384], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 15 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 473, score:[2828.73], loss:[0.70003], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0  7 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 474, score:[2730.73], loss:[0.72439], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 4 17 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 475, score:[2795.64], loss:[0.77740], sequence:[1], random actions:[21], eInit:[0.0100], init state:[2 0 7 1 0 0 0 0 1 1 1 0 0 0], end state:[4 0 7 1 0 0 0 0 1 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 476, score:[2792.91], loss:[0.68693], sequence:[2], random actions:[18], eInit:[0.0100], init state:[1 0 6 1 0 0 0 0 1 1 1 0 0 0], end state:[3 0 6 1 0 0 0 0 1 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 477, score:[2726.18], loss:[0.82974], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 0 19 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 478, score:[2679.82], loss:[0.90329], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 2 12 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 27  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 479, score:[2727.45], loss:[0.87511], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 1  2 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 480, score:[2744.00], loss:[0.81671], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 6 14 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2828.7272727272752, [473]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 481, score:[2711.82], loss:[0.86758], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3  2 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 482, score:[2757.45], loss:[0.87692], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 12 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 17  0  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 483, score:[2734.91], loss:[0.98251], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6  6 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 484, score:[2751.45], loss:[0.85825], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0 15 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 485, score:[2690.55], loss:[0.98779], sequence:[0], random actions:[33], eInit:[0.0100], init state:[6 4 3 0 0 0 0 0 0 0 0 0 0 0], end state:[1 4 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 486, score:[2820.55], loss:[0.80347], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 1  8 46  1  1  0  0  0  0  0  0  0  0  0], end state:[ 3  8 46  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 487, score:[2634.18], loss:[1.09759], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 10 29  1  1  0  1  0  1  0  0  0  0  0], end state:[ 6 10 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 488, score:[2670.00], loss:[1.20266], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 13 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 489, score:[2727.27], loss:[1.11809], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 11  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 490, score:[2783.82], loss:[0.97532], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2 22 42  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 42  0  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2828.7272727272752, [473]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 491, score:[2682.36], loss:[1.02698], sequence:[0], random actions:[32], eInit:[0.0100], init state:[5 9 7 0 0 0 0 0 0 0 0 0 0 0], end state:[0 9 7 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 492, score:[2672.00], loss:[1.14485], sequence:[0], random actions:[43], eInit:[0.0100], init state:[ 3 22 46  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 46  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 493, score:[2714.55], loss:[1.21815], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 13 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 494, score:[2750.36], loss:[1.12459], sequence:[1], random actions:[23], eInit:[0.0100], init state:[3 3 4 0 0 0 0 0 0 0 0 0 0 0], end state:[5 3 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 495, score:[2709.09], loss:[1.17734], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 15 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 496, score:[2773.09], loss:[1.09915], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 6 12 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 497, score:[2755.45], loss:[1.05203], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3  8 47  1  1  0  0  0  0  0  0  0  0  0], end state:[ 5  8 47  0  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 498, score:[2698.91], loss:[1.03926], sequence:[0], random actions:[25], eInit:[0.0100], init state:[4 5 0 0 0 0 0 0 0 0 0 0 0 0], end state:[6 5 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 499, score:[2788.00], loss:[1.01006], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1 18 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 500, score:[2770.91], loss:[0.92405], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 14 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2828.7272727272752, [473]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 501, score:[2791.82], loss:[0.86494], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 1  5 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  5 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 502, score:[2768.91], loss:[0.88282], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 0  0 41  0  0  1  0  0  0  0  0  0  0  0], end state:[ 2  0 41  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 503, score:[2737.45], loss:[0.91657], sequence:[5], random actions:[31], eInit:[0.0100], init state:[3 5 5 0 0 0 0 0 0 0 0 0 0 0], end state:[5 5 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 504, score:[2728.00], loss:[1.02610], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 0  1 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 505, score:[2689.64], loss:[1.02924], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 6 15  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 506, score:[2628.73], loss:[1.13889], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  9 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 507, score:[2730.36], loss:[1.00066], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 2 12 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 49  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 508, score:[2783.45], loss:[0.90267], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 18 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 509, score:[2740.73], loss:[0.84314], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2  1 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 510, score:[2739.82], loss:[0.82328], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0 22 41  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 41  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2828.7272727272752, [473]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 511, score:[2793.64], loss:[0.86858], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 1 23 40  1  0  0  1  0  0  1  1  0  0  0], end state:[ 3 23 40  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 512, score:[2725.09], loss:[0.91212], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6 13 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 513, score:[2747.27], loss:[1.01568], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 6  6 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 514, score:[2802.18], loss:[0.82028], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 2  9 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 53  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 515, score:[2833.09], loss:[0.70521], sequence:[3], random actions:[16], eInit:[0.0100], init state:[ 0  5 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 516, score:[2737.27], loss:[0.80033], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 2 21 15  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 517, score:[2774.00], loss:[0.83669], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 2 21 56  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 21 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 518, score:[2771.09], loss:[0.79083], sequence:[6], random actions:[27], eInit:[0.0100], init state:[2 8 8 1 0 0 0 0 0 0 0 0 0 0], end state:[4 8 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 519, score:[2729.82], loss:[0.88598], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6  2 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  2 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 520, score:[2738.00], loss:[0.91806], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 6 17 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 521, score:[2743.64], loss:[0.84296], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 6  2 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  2 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 522, score:[2793.45], loss:[0.92162], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 6 16 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 523, score:[2717.82], loss:[0.96815], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5 20 19  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 524, score:[2654.00], loss:[1.09419], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 3 14 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 525, score:[2691.09], loss:[1.00816], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 22  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22  9  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 526, score:[2708.73], loss:[0.96521], sequence:[0], random actions:[16], eInit:[0.0100], init state:[ 3 11 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 527, score:[2690.18], loss:[1.10589], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4  3 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 528, score:[2743.45], loss:[1.05168], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 6  1 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 529, score:[2719.64], loss:[1.15130], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6  8 55  1  1  0  0  0  0  0  0  0  0  0], end state:[ 1  8 55  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 530, score:[2767.82], loss:[1.01555], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3 23  5  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 23  5  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 531, score:[2780.55], loss:[0.98539], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0  2 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 532, score:[2786.36], loss:[0.96291], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 0  4 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 533, score:[2742.00], loss:[1.05685], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 4 14 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 534, score:[2745.45], loss:[1.06618], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 2 12  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12  3  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 535, score:[2778.73], loss:[1.04415], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 6  4 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 536, score:[2670.18], loss:[1.04424], sequence:[0], random actions:[35], eInit:[0.0100], init state:[4 0 1 1 0 0 0 0 0 1 1 0 0 0], end state:[6 0 1 0 0 0 0 0 0 0 0 0 1 0]
INFO:Reinforcement.Functions:episode: 537, score:[2719.82], loss:[1.20932], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 13 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 538, score:[2782.91], loss:[0.98716], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 4 18 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 539, score:[2761.82], loss:[1.03405], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1  1 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 51  0  0  0  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 540, score:[2763.82], loss:[0.90320], sequence:[3], random actions:[40], eInit:[0.0100], init state:[ 3  2 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 541, score:[2605.64], loss:[1.18331], sequence:[0], random actions:[50], eInit:[0.0100], init state:[ 5 21 21  1  0  0  1  1  0  1  1  0  0  1], end state:[ 0 21 21  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 542, score:[2732.91], loss:[1.15851], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6 12 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 543, score:[2770.18], loss:[1.02988], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 1 20 44  1  1  0  0  0  0  1  1  1  0  0], end state:[ 3 20 44  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 544, score:[2807.64], loss:[0.92254], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 1 11 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 545, score:[2732.36], loss:[0.96384], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3  5 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 546, score:[2726.91], loss:[1.03938], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 2 23 55  1  0  0  0  0  0  1  1  0  0  0], end state:[ 4 23 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 547, score:[2794.55], loss:[0.99633], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1  2 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 548, score:[2702.00], loss:[1.11061], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  3 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 549, score:[2770.00], loss:[1.10716], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6  1 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 550, score:[2748.91], loss:[1.16990], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 4 21 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 42  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 551, score:[2791.82], loss:[1.09565], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 1  5 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  5 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 552, score:[2794.55], loss:[0.91568], sequence:[4], random actions:[30], eInit:[0.0100], init state:[2 1 1 0 0 1 0 0 0 0 0 0 0 0], end state:[4 1 1 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 553, score:[2767.27], loss:[0.92815], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 1 17 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 53  0  0  0  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 554, score:[2730.73], loss:[1.02302], sequence:[0], random actions:[25], eInit:[0.0100], init state:[5 6 2 0 0 0 0 0 0 0 0 0 0 0], end state:[0 6 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 555, score:[2775.45], loss:[1.09801], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6 22 21  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 21  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 556, score:[2704.36], loss:[1.11845], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6  9 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 557, score:[2702.55], loss:[1.11901], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6  1 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 558, score:[2729.82], loss:[1.13041], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6  6 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 559, score:[2818.55], loss:[1.08456], sequence:[1], random actions:[17], eInit:[0.0100], init state:[ 0  9 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 560, score:[2775.45], loss:[0.92102], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1 19 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 561, score:[2719.82], loss:[0.97291], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6  1 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 562, score:[2758.36], loss:[0.88228], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 1 15 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 563, score:[2636.00], loss:[1.02079], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5  4 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  4 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 564, score:[2801.82], loss:[0.98928], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 10 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 565, score:[2717.82], loss:[0.88601], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 17 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 566, score:[2728.36], loss:[0.87078], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3  8 26  1  0  0  0  0  0  0  0  0  0  0], end state:[ 5  8 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 567, score:[2717.09], loss:[1.02123], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 19 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 22  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 568, score:[2734.55], loss:[1.02114], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6  9 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 569, score:[2682.73], loss:[1.06518], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 0  6 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  6 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 570, score:[2664.73], loss:[1.21871], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 13 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 571, score:[2743.27], loss:[1.10330], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 2 21 37  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 21 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 572, score:[2733.82], loss:[1.06644], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 10  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 573, score:[2741.27], loss:[1.14683], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3  9 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 574, score:[2745.82], loss:[1.03235], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2 14 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 575, score:[2745.45], loss:[0.98371], sequence:[3], random actions:[26], eInit:[0.0100], init state:[2 4 4 0 0 0 0 0 0 0 0 0 0 0], end state:[4 4 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 576, score:[2774.36], loss:[0.89906], sequence:[4], random actions:[37], eInit:[0.0100], init state:[ 2 15 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 577, score:[2733.64], loss:[0.98171], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 1  8 14  1  0  0  0  0  0  0  0  0  0  0], end state:[ 3  8 14  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 578, score:[2767.45], loss:[0.93773], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 1  4 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 579, score:[2785.82], loss:[1.08614], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 2  0 16  1  0  0  0  0  1  0  0  0  0  0], end state:[ 4  0 16  1  1  0  0  0  0  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 580, score:[2759.09], loss:[1.04804], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 1 13 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 581, score:[2790.91], loss:[0.90279], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 1  1 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 44  0  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 582, score:[2685.45], loss:[0.92621], sequence:[0], random actions:[30], eInit:[0.0100], init state:[4 1 5 0 0 1 0 0 0 0 0 0 0 0], end state:[6 1 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 583, score:[2751.27], loss:[0.95131], sequence:[1], random actions:[31], eInit:[0.0100], init state:[0 5 7 0 0 0 0 0 0 0 0 0 0 0], end state:[2 5 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 584, score:[2767.27], loss:[0.92816], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 2 18 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 585, score:[2746.18], loss:[0.89251], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 2 18 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 586, score:[2783.09], loss:[0.90961], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 3 14 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 587, score:[2741.64], loss:[0.86201], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 6 20 47  1  1  0  1  0  0  1  1  1  0  0], end state:[ 1 20 47  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 588, score:[2749.27], loss:[0.80597], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 0 15 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 589, score:[2725.45], loss:[0.85206], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6 12 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 590, score:[2754.36], loss:[0.88486], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0  2 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 591, score:[2693.27], loss:[0.97536], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  6 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 592, score:[2646.73], loss:[1.01277], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  3 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 593, score:[2761.64], loss:[1.01708], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 14 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 594, score:[2756.91], loss:[0.94130], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 1  1 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 595, score:[2628.55], loss:[1.20410], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 17 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 596, score:[2753.64], loss:[0.93654], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3  5 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 49  1  0  0  0  0  0  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 597, score:[2797.64], loss:[0.89895], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0  7 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 598, score:[2667.09], loss:[1.02690], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  1 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  1 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 599, score:[2800.91], loss:[0.87081], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1  6 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 600, score:[2678.55], loss:[0.96269], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 17 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 601, score:[2748.00], loss:[0.86480], sequence:[1], random actions:[35], eInit:[0.0100], init state:[2 2 6 0 0 0 0 0 0 0 0 0 0 0], end state:[4 2 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 602, score:[2680.00], loss:[1.12347], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  8 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 41  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 603, score:[2781.82], loss:[0.95000], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1  1 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 604, score:[2732.36], loss:[1.13732], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 17 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 605, score:[2710.55], loss:[1.27812], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6  6 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 606, score:[2772.73], loss:[1.29153], sequence:[1], random actions:[25], eInit:[0.0100], init state:[6 4 2 0 0 0 0 0 0 0 0 0 0 0], end state:[1 4 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 607, score:[2755.64], loss:[1.19415], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 0 19 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 608, score:[2633.82], loss:[1.42203], sequence:[0], random actions:[42], eInit:[0.0100], init state:[ 5 11 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 609, score:[2666.36], loss:[1.45228], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  0 53  1  0  1  0  0  0  0  0  0  0  0], end state:[ 6  0 53  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 610, score:[2770.55], loss:[1.40716], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 22  2  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22  2  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 611, score:[2705.45], loss:[1.51531], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 2 12 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 36  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 612, score:[2655.27], loss:[1.66584], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 18 10  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 613, score:[2764.36], loss:[1.44026], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 6  2 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  2 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 614, score:[2774.73], loss:[1.32817], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1 11  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 615, score:[2695.09], loss:[1.46932], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 15 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 616, score:[2701.09], loss:[1.52218], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 10 13  1  1  0  1  1  0  0  0  0  0  0], end state:[ 6 10 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 617, score:[2687.45], loss:[1.43477], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  1 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 618, score:[2765.82], loss:[1.42874], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1  1 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 619, score:[2741.64], loss:[1.34356], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 5 20 41  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 41  1  1  0  0  0  0  1  1  1  1  0]
INFO:Reinforcement.Functions:episode: 620, score:[2741.27], loss:[1.22201], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 6 21 37  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 21 37  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 621, score:[2733.82], loss:[1.31123], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 2 17 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 622, score:[2677.45], loss:[1.32645], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  3 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 623, score:[2756.00], loss:[1.39089], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6 21 23  1  1  0  1  0  0  1  1  0  0  1], end state:[ 1 21 23  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 624, score:[2719.09], loss:[1.21569], sequence:[0], random actions:[39], eInit:[0.0100], init state:[1 3 6 0 0 0 0 0 0 0 0 0 0 0], end state:[3 3 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 625, score:[2741.45], loss:[1.23336], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2 23 26  1  0  0  1  0  0  1  1  0  0  1], end state:[ 4 23 26  1  0  0  0  0  0  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 626, score:[2798.73], loss:[1.15859], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 0 21 12  1  1  0  1  0  0  1  1  0  0  1], end state:[ 2 21 12  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 627, score:[2695.45], loss:[1.22015], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4 20 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 628, score:[2761.82], loss:[1.17273], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0 10 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 629, score:[2632.36], loss:[1.32341], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 15  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 630, score:[2790.73], loss:[1.12259], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1 21 40  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 21 40  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 631, score:[2747.27], loss:[1.15919], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 2 16 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 16 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 632, score:[2718.91], loss:[1.11202], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 21  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21  7  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 633, score:[2743.82], loss:[1.06390], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 4 10  7  1  1  0  1  0  0  0  0  0  0  0], end state:[ 6 10  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 634, score:[2768.55], loss:[1.02359], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 4 12 43  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 635, score:[2713.82], loss:[1.24207], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6 13  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 636, score:[2708.91], loss:[1.31451], sequence:[0], random actions:[51], eInit:[0.0100], init state:[3 3 9 0 0 0 0 0 0 0 0 0 0 0], end state:[5 3 9 0 0 0 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 637, score:[2744.36], loss:[1.22614], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 2  2 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 638, score:[2713.45], loss:[1.32444], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 19 20  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 639, score:[2760.36], loss:[1.33386], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3 16 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 640, score:[2763.45], loss:[1.35299], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2 20 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 641, score:[2725.82], loss:[1.37970], sequence:[0], random actions:[17], eInit:[0.0100], init state:[ 5 15 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 642, score:[2772.18], loss:[1.30220], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2  8 49  1  1  0  0  0  0  0  0  0  0  0], end state:[ 4  8 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 643, score:[2768.00], loss:[1.22546], sequence:[2], random actions:[24], eInit:[0.0100], init state:[0 7 4 0 0 0 0 0 0 0 0 0 0 0], end state:[2 7 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 644, score:[2708.36], loss:[1.25606], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3  8 37  1  1  0  1  0  1  0  0  0  0  0], end state:[ 5  8 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 645, score:[2695.09], loss:[1.38534], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6 20 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 20 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 646, score:[2746.00], loss:[1.15408], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 22  3  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22  3  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 647, score:[2773.27], loss:[1.11654], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 17 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 648, score:[2748.00], loss:[1.05985], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 4  3 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 649, score:[2778.91], loss:[1.00377], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 2 13 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 650, score:[2781.27], loss:[0.91588], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 1 23 20  1  0  0  1  0  0  1  1  0  0  1], end state:[ 3 23 20  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 651, score:[2691.82], loss:[1.09947], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 11  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 652, score:[2538.36], loss:[1.43857], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 16 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 653, score:[2765.09], loss:[1.17270], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 2 12 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 15  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 654, score:[2768.91], loss:[1.13307], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 3  0 26  1  0  0  0  0  0  0  0  0  0  0], end state:[ 5  0 26  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 655, score:[2746.55], loss:[1.29848], sequence:[3], random actions:[30], eInit:[0.0100], init state:[0 3 1 0 0 0 0 0 0 0 0 0 0 0], end state:[2 3 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 656, score:[2783.64], loss:[1.05434], sequence:[4], random actions:[34], eInit:[0.0100], init state:[ 1 17 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 657, score:[2779.45], loss:[1.00904], sequence:[5], random actions:[29], eInit:[0.0100], init state:[0 5 7 0 0 0 0 0 0 0 0 0 0 0], end state:[2 5 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 658, score:[2766.00], loss:[0.98809], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 2 16 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 16 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 659, score:[2707.45], loss:[1.02859], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6 21  9  1  1  0  1  0  1  1  1  0  0  1], end state:[ 1 21  9  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 660, score:[2770.55], loss:[0.97775], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3 16 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 661, score:[2802.18], loss:[0.84438], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 14 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 662, score:[2738.91], loss:[0.85135], sequence:[3], random actions:[20], eInit:[0.0100], init state:[ 6 19 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 663, score:[2652.73], loss:[1.05476], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 12 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 664, score:[2800.00], loss:[0.88222], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1  4 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 665, score:[2775.45], loss:[0.86863], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2  0 45  0  0  1  0  0  0  0  0  0  0  0], end state:[ 4  0 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 666, score:[2778.00], loss:[0.84802], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1  4 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 667, score:[2716.73], loss:[0.94906], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 6  5 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  5 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 668, score:[2700.00], loss:[1.03417], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5  5 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 669, score:[2759.82], loss:[0.98084], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 2 10 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 10 47  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 670, score:[2717.64], loss:[1.00758], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 4 23  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23  0  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 671, score:[2795.45], loss:[0.92051], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2 17 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 672, score:[2752.36], loss:[0.88716], sequence:[2], random actions:[24], eInit:[0.0100], init state:[6 4 7 0 0 0 0 0 0 0 0 0 0 0], end state:[1 4 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 673, score:[2691.27], loss:[1.02950], sequence:[0], random actions:[25], eInit:[0.0100], init state:[5 2 5 0 0 0 0 0 0 0 0 0 0 0], end state:[0 2 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 674, score:[2706.55], loss:[1.20108], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 0 20 39  1  1  0  0  0  0  0  0  1  0  0], end state:[ 2 20 39  1  1  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 675, score:[2782.91], loss:[1.02584], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0 22 28  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 28  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 676, score:[2794.73], loss:[0.94144], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1  2 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 677, score:[2770.55], loss:[0.95356], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 1  1 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 678, score:[2791.82], loss:[0.99190], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 2 22 58  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 679, score:[2775.82], loss:[0.98105], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 0 16 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 680, score:[2660.36], loss:[1.05988], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  5 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 681, score:[2718.73], loss:[1.09337], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 18 50  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 682, score:[2774.91], loss:[1.05457], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2 21 10  1  1  0  1  0  1  1  1  0  0  1], end state:[ 4 21 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 683, score:[2722.73], loss:[1.11122], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  7 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 684, score:[2757.45], loss:[1.11851], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3 10 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 685, score:[2749.45], loss:[1.07003], sequence:[2], random actions:[40], eInit:[0.0100], init state:[ 2 21 21  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 686, score:[2741.82], loss:[1.08713], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 0 12 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 687, score:[2690.00], loss:[1.09000], sequence:[0], random actions:[30], eInit:[0.0100], init state:[3 6 8 0 0 0 0 0 0 0 0 0 0 0], end state:[5 6 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 688, score:[2700.55], loss:[1.28143], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 13 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 689, score:[2794.55], loss:[1.06128], sequence:[1], random actions:[30], eInit:[0.0100], init state:[0 8 7 1 0 0 0 0 0 0 0 0 0 0], end state:[2 8 7 1 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 690, score:[2721.45], loss:[0.94941], sequence:[0], random actions:[18], eInit:[0.0100], init state:[ 4 22  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22  8  1  1  0  0  0  1  0  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 691, score:[2765.09], loss:[0.97582], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1  5 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  5 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 692, score:[2763.27], loss:[0.95023], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6  1 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 693, score:[2745.09], loss:[1.01513], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 3  5 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 694, score:[2732.73], loss:[0.94549], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 2 15 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 695, score:[2690.73], loss:[1.20465], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 17 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 696, score:[2696.36], loss:[1.10862], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  7 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 697, score:[2654.00], loss:[1.29107], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  6 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 698, score:[2725.82], loss:[1.23394], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2  8 18  1  0  0  0  0  0  0  0  0  0  0], end state:[ 4  8 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 699, score:[2772.55], loss:[1.13126], sequence:[1], random actions:[33], eInit:[0.0100], init state:[1 8 4 1 0 0 0 0 0 0 0 0 0 0], end state:[3 8 4 1 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 700, score:[2763.45], loss:[1.05415], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 4 14 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 701, score:[2702.00], loss:[1.12846], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 17 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 702, score:[2750.73], loss:[1.05354], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 5  1 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  1 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 703, score:[2797.45], loss:[1.07846], sequence:[2], random actions:[16], eInit:[0.0100], init state:[ 6 21 10  1  1  0  1  0  1  1  1  0  0  1], end state:[ 1 21 10  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 704, score:[2763.82], loss:[1.27376], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 4 21  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21  1  0  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 705, score:[2785.09], loss:[1.17774], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 0 12 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 706, score:[2757.09], loss:[1.13210], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 6  1 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 707, score:[2736.55], loss:[1.12067], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 4 10 49  1  1  0  1  0  0  0  0  0  0  0], end state:[ 6 10 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 708, score:[2727.82], loss:[1.12345], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4  7 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 709, score:[2723.82], loss:[1.09902], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  0 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 36  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 710, score:[2727.64], loss:[1.32012], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 3 19  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19  7  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 711, score:[2669.64], loss:[1.37169], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 23  2  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 23  2  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 712, score:[2763.82], loss:[1.28914], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0  7 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 713, score:[2687.64], loss:[1.15505], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4  4 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 714, score:[2720.91], loss:[1.21766], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 18 20  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 715, score:[2708.91], loss:[1.26096], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  6 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 716, score:[2713.27], loss:[1.31289], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 15 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 717, score:[2729.09], loss:[1.19151], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 3  2 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 718, score:[2768.18], loss:[1.13840], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 1 10  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 719, score:[2773.09], loss:[1.02681], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 5  0 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 21  1  0  0  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 720, score:[2754.18], loss:[1.07476], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 5  5 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 16  1  1  0  0  1  1  0  1  1  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 721, score:[2733.09], loss:[1.19914], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  1 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 722, score:[2770.00], loss:[1.14490], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 6 11 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 723, score:[2739.27], loss:[1.10336], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 5 21 16  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 16  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 724, score:[2740.91], loss:[1.18895], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 5 12 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 725, score:[2727.09], loss:[1.16246], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6  1 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 726, score:[2742.73], loss:[1.29757], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 2 22  5  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 727, score:[2746.18], loss:[1.15230], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2 13 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 728, score:[2724.91], loss:[1.08275], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 15 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 729, score:[2758.73], loss:[1.00062], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 0  0 26  1  0  0  0  0  0  0  0  0  0  0], end state:[ 2  0 26  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 730, score:[2686.55], loss:[0.95855], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4 11 33  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 731, score:[2781.82], loss:[0.95475], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 2 19 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 732, score:[2682.00], loss:[0.98335], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 17 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 733, score:[2740.55], loss:[1.15591], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3  5 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 734, score:[2707.64], loss:[1.15536], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 0  4 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 735, score:[2738.00], loss:[1.08060], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2 17  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 736, score:[2736.18], loss:[1.05161], sequence:[2], random actions:[38], eInit:[0.0100], init state:[ 3 21 19  1  1  0  1  0  0  1  1  0  0  1], end state:[ 5 21 19  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 737, score:[2677.27], loss:[1.21022], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 2 22 59  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 59  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 738, score:[2733.64], loss:[1.22797], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6 19 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 739, score:[2758.36], loss:[1.00270], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0  3 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 740, score:[2700.36], loss:[1.04425], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 3 23 49  1  0  0  0  0  0  1  1  0  0  0], end state:[ 5 23 49  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 741, score:[2701.82], loss:[1.22676], sequence:[0], random actions:[39], eInit:[0.0100], init state:[5 5 1 0 0 0 0 0 0 0 0 0 0 0], end state:[0 5 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 742, score:[2770.73], loss:[1.15153], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 21 54  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 21 54  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 743, score:[2746.91], loss:[1.03069], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 5 21  6  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21  6  0  0  0  0  0  0  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 744, score:[2730.36], loss:[1.18976], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 20 12  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 745, score:[2709.82], loss:[1.13602], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5  5 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 50  1  0  1  1  0  0  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 746, score:[2769.27], loss:[1.15267], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 0  5 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 747, score:[2776.91], loss:[1.15004], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 1 23 19  1  0  0  1  0  0  1  1  0  0  1], end state:[ 3 23 19  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 748, score:[2800.00], loss:[0.99502], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 2 19 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 749, score:[2783.27], loss:[0.94952], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 1 16 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 750, score:[2705.09], loss:[1.02439], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 1 22  8  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22  8  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 751, score:[2748.91], loss:[1.17300], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  6 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 15  1  0  0  1  0  0  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 752, score:[2772.00], loss:[1.04348], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 1 18 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 753, score:[2773.27], loss:[1.07762], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 6  9 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 754, score:[2703.45], loss:[1.24862], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4  6 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 755, score:[2760.73], loss:[1.13422], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0  2 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 756, score:[2774.00], loss:[1.12380], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 2  7 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 757, score:[2735.09], loss:[1.16810], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3  9 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 758, score:[2646.18], loss:[1.54880], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 12 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 759, score:[2797.45], loss:[1.29973], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 1 20 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 20 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 760, score:[2726.73], loss:[1.15823], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 3  0 44  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 44  1  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 761, score:[2659.27], loss:[1.45523], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 21 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 45  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 762, score:[2745.27], loss:[1.38769], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 2 12 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 34  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 763, score:[2792.73], loss:[1.43588], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1 13 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 28  0  0  0  0  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 764, score:[2736.00], loss:[1.31269], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 0 16  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 765, score:[2728.55], loss:[1.36095], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 20 42  1  1  0  0  0  0  1  1  1  0  0], end state:[ 5 20 42  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 766, score:[2703.45], loss:[1.40942], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  6 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 767, score:[2717.09], loss:[1.30823], sequence:[0], random actions:[40], eInit:[0.0100], init state:[3 1 5 0 0 1 0 0 0 0 0 0 0 0], end state:[5 1 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 768, score:[2778.36], loss:[1.39281], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 1 17 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 769, score:[2706.36], loss:[1.32238], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 1 18 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 770, score:[2765.64], loss:[1.23481], sequence:[1], random actions:[42], eInit:[0.0100], init state:[ 1 15 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 771, score:[2748.18], loss:[1.19828], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1 10 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 772, score:[2724.55], loss:[1.32866], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5 21 26  1  0  0  1  1  0  1  1  0  0  1], end state:[ 0 21 26  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 773, score:[2736.91], loss:[1.18572], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 16 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 774, score:[2728.55], loss:[1.27010], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3 13 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 775, score:[2755.64], loss:[1.20097], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 15 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 776, score:[2720.00], loss:[1.26340], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4 19 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 777, score:[2784.91], loss:[1.17629], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 3 20 38  1  1  0  0  0  0  0  0  1  0  0], end state:[ 5 20 38  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 778, score:[2780.73], loss:[1.18185], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 3  6 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  6 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 779, score:[2760.36], loss:[1.06325], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 1 12  4  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 780, score:[2761.64], loss:[1.02776], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 4 13 28  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 13 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 781, score:[2781.09], loss:[0.87648], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 1 15 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 782, score:[2685.09], loss:[0.97818], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 23 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 47  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 783, score:[2735.82], loss:[1.13210], sequence:[0], random actions:[34], eInit:[0.0100], init state:[0 1 0 0 0 1 0 0 0 0 0 0 0 0], end state:[2 1 0 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 784, score:[2713.45], loss:[1.10014], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 4  1 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 785, score:[2797.82], loss:[0.97901], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 16 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 786, score:[2763.27], loss:[0.97632], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 0  7 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 787, score:[2632.36], loss:[1.19690], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 10  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 788, score:[2712.00], loss:[1.20172], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 4  8 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 37  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 789, score:[2753.82], loss:[1.16644], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 2 21 15  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 790, score:[2707.45], loss:[1.23953], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  8 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 48  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 791, score:[2714.55], loss:[1.28503], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  7 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 792, score:[2811.09], loss:[1.26105], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 2  6 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 793, score:[2645.09], loss:[1.48338], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 11 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 794, score:[2722.00], loss:[1.44985], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 2  1 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 795, score:[2769.27], loss:[1.26304], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 16 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 796, score:[2734.36], loss:[1.36226], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 0 11 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 797, score:[2694.00], loss:[1.29749], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 1 10 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 798, score:[2740.18], loss:[1.43650], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3  8 47  1  1  0  0  0  0  0  0  0  0  0], end state:[ 5  8 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 799, score:[2779.82], loss:[1.42818], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 3 11 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 800, score:[2729.82], loss:[1.43638], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3 15 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 801, score:[2731.64], loss:[1.29628], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 17 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 802, score:[2775.64], loss:[1.21322], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 10  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 803, score:[2675.82], loss:[1.34584], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 5  0 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 16  1  0  0  1  0  1  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 804, score:[2776.00], loss:[1.54609], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 4 16  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 805, score:[2689.64], loss:[1.50718], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6  4 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 806, score:[2784.36], loss:[1.39551], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 1  3 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 807, score:[2744.91], loss:[1.29723], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 0 13 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 808, score:[2768.36], loss:[1.19081], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 1  3 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 809, score:[2767.64], loss:[1.27608], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 2  0 35  0  0  1  0  0  0  0  0  0  0  0], end state:[ 4  0 35  1  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 810, score:[2712.18], loss:[1.29170], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 21 55  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 55  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 811, score:[2780.00], loss:[1.17574], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2  6 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 812, score:[2705.09], loss:[1.26354], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4  2 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 813, score:[2701.64], loss:[1.31865], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 23 35  1  0  0  1  0  0  1  1  0  0  0], end state:[ 1 23 35  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 814, score:[2690.18], loss:[1.48143], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6 13 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 815, score:[2770.55], loss:[1.18686], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6  9 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 816, score:[2723.27], loss:[1.14923], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 20 50  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 50  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 817, score:[2732.36], loss:[1.24873], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 6 11 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 818, score:[2786.91], loss:[1.12675], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 0 21 47  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 47  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 819, score:[2730.73], loss:[1.31691], sequence:[0], random actions:[42], eInit:[0.0100], init state:[ 1  6 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 820, score:[2749.09], loss:[1.28657], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0 10 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 821, score:[2706.73], loss:[1.37088], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 1  6 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 822, score:[2742.18], loss:[1.40641], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 5 13 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 823, score:[2743.82], loss:[1.29841], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 5  7 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 824, score:[2683.64], loss:[1.58579], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  3 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 825, score:[2762.36], loss:[1.57910], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1 19 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 12  1  0  0  0  0  0  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 826, score:[2737.45], loss:[1.61177], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 3 21 49  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 21 49  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 827, score:[2735.64], loss:[1.70349], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 6 14 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 828, score:[2726.91], loss:[1.61405], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 18  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 829, score:[2750.91], loss:[1.39182], sequence:[1], random actions:[37], eInit:[0.0100], init state:[ 6 23 18  1  0  0  1  0  0  1  1  0  0  1], end state:[ 1 23 18  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 830, score:[2724.55], loss:[1.45100], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6  4 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 831, score:[2779.45], loss:[1.35163], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1 23 21  1  0  0  1  0  0  1  1  0  0  1], end state:[ 3 23 21  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 832, score:[2750.73], loss:[1.32242], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 3 12 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 833, score:[2770.73], loss:[1.25920], sequence:[3], random actions:[20], eInit:[0.0100], init state:[ 5 11 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 834, score:[2764.55], loss:[1.21737], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 1 23 18  1  0  0  1  0  0  1  1  0  0  1], end state:[ 3 23 18  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 835, score:[2727.64], loss:[1.31477], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 6  6 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 836, score:[2661.45], loss:[1.45412], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 18 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 837, score:[2706.73], loss:[1.42056], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  1 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  1 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 838, score:[2764.36], loss:[1.46562], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3  8 22  1  0  0  0  0  0  0  0  0  0  0], end state:[ 5  8 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 839, score:[2811.09], loss:[1.23342], sequence:[2], random actions:[18], eInit:[0.0100], init state:[ 1  7 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 840, score:[2715.09], loss:[1.36266], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4 19 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 841, score:[2720.18], loss:[1.28140], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6 18 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 842, score:[2798.18], loss:[1.12255], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0  3 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 843, score:[2777.64], loss:[1.08406], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 6 22 11  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 11  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 844, score:[2752.55], loss:[1.06344], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 4  7 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 845, score:[2709.27], loss:[1.23261], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 3 14 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 846, score:[2785.27], loss:[1.11456], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1 12 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 20  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 847, score:[2720.91], loss:[1.17718], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4  8 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 38  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 848, score:[2759.45], loss:[1.15719], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 1 20 47  1  1  0  1  0  0  1  1  1  0  0], end state:[ 3 20 47  1  1  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 849, score:[2732.55], loss:[1.16735], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3 20 47  1  1  0  1  0  0  1  1  1  0  0], end state:[ 5 20 47  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 850, score:[2701.09], loss:[1.20880], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  4 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 851, score:[2769.45], loss:[1.17550], sequence:[1], random actions:[22], eInit:[0.0100], init state:[6 3 4 0 0 0 0 0 0 0 0 0 0 0], end state:[1 3 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 852, score:[2750.91], loss:[1.15109], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 6 23  6  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 23  6  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 853, score:[2701.27], loss:[1.21738], sequence:[0], random actions:[27], eInit:[0.0100], init state:[5 9 0 0 0 0 0 0 0 0 0 0 0 0], end state:[0 9 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 854, score:[2765.64], loss:[1.21987], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 6  6 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 855, score:[2756.36], loss:[1.21708], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 6  6 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 856, score:[2732.00], loss:[1.07623], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3  3 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 857, score:[2705.27], loss:[1.35030], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 2  3 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 858, score:[2719.82], loss:[1.24859], sequence:[0], random actions:[29], eInit:[0.0100], init state:[3 5 9 0 0 0 0 0 0 0 0 0 0 0], end state:[5 5 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 859, score:[2767.64], loss:[1.26672], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2  7 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 860, score:[2768.91], loss:[1.23694], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0 15  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 861, score:[2821.27], loss:[1.11432], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 3  0 23  1  0  0  0  0  1  0  0  0  0  0], end state:[ 5  0 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 862, score:[2774.00], loss:[1.09949], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2 22  9  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 863, score:[2771.27], loss:[1.14645], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 1  7 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 864, score:[2755.64], loss:[1.09488], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 0  0 15  1  0  0  0  0  1  0  0  0  0  0], end state:[ 2  0 15  1  0  0  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 865, score:[2795.27], loss:[1.04397], sequence:[7], random actions:[21], eInit:[0.0100], init state:[ 0  6 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  6 34  0  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 866, score:[2770.36], loss:[0.95448], sequence:[8], random actions:[34], eInit:[0.0100], init state:[ 2 21 31  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 21 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 867, score:[2711.45], loss:[1.17817], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 14  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 868, score:[2714.36], loss:[1.17773], sequence:[0], random actions:[23], eInit:[0.0100], init state:[4 7 5 0 0 0 0 0 0 0 0 0 0 0], end state:[6 7 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 869, score:[2784.55], loss:[1.14502], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2 11  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11  8  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 870, score:[2774.91], loss:[1.12459], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0  8 15  1  0  0  0  0  0  0  0  0  0  0], end state:[ 2  8 15  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 871, score:[2822.55], loss:[1.00553], sequence:[3], random actions:[15], eInit:[0.0100], init state:[ 2 19 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 872, score:[2794.73], loss:[0.89857], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 3 16  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 873, score:[2794.55], loss:[0.94158], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 3 17 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17 58  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 874, score:[2657.45], loss:[1.07159], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4  9 31  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 875, score:[2805.82], loss:[0.95409], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0 21 45  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 45  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 876, score:[2712.91], loss:[1.00151], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 6  3 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 877, score:[2707.64], loss:[1.08821], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 18 12  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 878, score:[2714.91], loss:[1.09464], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 18 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 23  0  1  0  0  1  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 879, score:[2753.64], loss:[1.08501], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2  1 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 880, score:[2743.82], loss:[1.13575], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 4 19 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 881, score:[2623.64], loss:[1.14793], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  3 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 882, score:[2780.55], loss:[1.23764], sequence:[1], random actions:[28], eInit:[0.0100], init state:[2 0 4 1 0 0 0 0 0 1 1 0 0 0], end state:[4 0 4 1 0 0 0 0 0 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 883, score:[2673.27], loss:[1.32604], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 2 20  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 884, score:[2694.36], loss:[1.43495], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 15  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15  3  0  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 885, score:[2750.55], loss:[1.39138], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0 15  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 886, score:[2750.73], loss:[1.30033], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 2  6 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 887, score:[2660.36], loss:[1.45763], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 20 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 888, score:[2739.45], loss:[1.41186], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 3 19 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 45  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 889, score:[2715.64], loss:[1.52259], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6 14  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 890, score:[2668.91], loss:[1.56172], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 2 10 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 10 34  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 891, score:[2767.09], loss:[1.49149], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3  7 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 892, score:[2688.91], loss:[1.57537], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 5 12 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 893, score:[2764.00], loss:[1.40106], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 3  0 10  1  0  0  0  0  1  1  1  0  0  0], end state:[ 5  0 10  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 894, score:[2702.36], loss:[1.54380], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4  1 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 895, score:[2764.91], loss:[1.40163], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 4  3 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 896, score:[2698.18], loss:[1.40867], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5 22 40  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 22 40  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 897, score:[2727.82], loss:[1.51103], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 4 19  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 898, score:[2790.73], loss:[1.42862], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0  1 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 899, score:[2759.82], loss:[1.39592], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6 19 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 900, score:[2666.55], loss:[1.26158], sequence:[0], random actions:[26], eInit:[0.0100], init state:[5 5 7 0 0 0 0 0 0 0 0 0 0 0], end state:[0 5 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 901, score:[2704.36], loss:[1.43392], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6  3 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 902, score:[2721.64], loss:[1.34573], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 23  6  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 23  6  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 903, score:[2719.27], loss:[1.33392], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  1 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 904, score:[2734.36], loss:[1.28285], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 0 21 41  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 41  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 905, score:[2691.64], loss:[1.37952], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 2  4 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 906, score:[2719.82], loss:[1.46428], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 6 16  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 907, score:[2705.45], loss:[1.38185], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 0 10 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 908, score:[2758.91], loss:[1.19546], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0  9 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 909, score:[2797.82], loss:[1.03916], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 10 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 910, score:[2729.82], loss:[1.14069], sequence:[0], random actions:[33], eInit:[0.0100], init state:[4 6 7 0 0 0 0 0 0 0 0 0 0 0], end state:[6 6 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 911, score:[2706.36], loss:[1.22777], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  0 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 31  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 912, score:[2780.18], loss:[1.15574], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3  3 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 913, score:[2730.55], loss:[1.21681], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 0 16 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 914, score:[2740.18], loss:[1.14617], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 4  7 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 915, score:[2739.09], loss:[1.18200], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 6  7 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 916, score:[2766.18], loss:[1.17259], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 6 17 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 917, score:[2776.55], loss:[1.00254], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 0  0 13  1  0  0  0  0  1  1  1  0  0  0], end state:[ 2  0 13  1  0  0  0  0  1  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 918, score:[2696.00], loss:[1.17417], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2 16 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 16 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 919, score:[2754.18], loss:[1.12951], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3  4 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 920, score:[2725.27], loss:[1.11668], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6 21 35  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 21 35  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 921, score:[2742.00], loss:[1.15348], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2  2 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 922, score:[2769.64], loss:[1.25431], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 6 15 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 923, score:[2750.91], loss:[1.10462], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 0 15 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 924, score:[2810.00], loss:[0.96593], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 0 10 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 925, score:[2658.55], loss:[1.28761], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 15 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 926, score:[2723.82], loss:[1.21423], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 0 21 23  1  1  0  1  0  0  1  1  0  0  1], end state:[ 2 21 23  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 927, score:[2700.18], loss:[1.27587], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  1 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  1 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 928, score:[2678.91], loss:[1.29905], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5 12 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 929, score:[2658.73], loss:[1.37512], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 19 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 22  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 930, score:[2769.09], loss:[1.33320], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 6 19 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 931, score:[2785.27], loss:[1.19252], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1 18 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 932, score:[2762.36], loss:[1.06550], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 1 21 13  1  1  0  1  0  0  1  1  0  0  1], end state:[ 3 21 13  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 933, score:[2764.00], loss:[0.99480], sequence:[4], random actions:[17], eInit:[0.0100], init state:[ 5 16 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 934, score:[2679.27], loss:[1.23405], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 16 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 935, score:[2652.18], loss:[1.44276], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 13 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 936, score:[2802.73], loss:[1.30946], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1  7 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 937, score:[2714.55], loss:[1.22569], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 3 13  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 938, score:[2782.18], loss:[1.12720], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 16 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 45  0  0  0  0  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 939, score:[2754.91], loss:[1.09933], sequence:[2], random actions:[43], eInit:[0.0100], init state:[ 2 11 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11 26  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 940, score:[2757.64], loss:[1.13160], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1 20 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 20 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 941, score:[2749.09], loss:[1.01853], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 4 15 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 942, score:[2759.09], loss:[1.07433], sequence:[5], random actions:[24], eInit:[0.0100], init state:[4 6 1 0 0 0 0 0 0 0 0 0 0 0], end state:[6 6 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 943, score:[2778.73], loss:[1.21055], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 0 13 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 944, score:[2748.36], loss:[1.09771], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 3 23 52  1  0  0  0  0  0  1  1  0  0  0], end state:[ 5 23 52  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 945, score:[2637.27], loss:[1.31539], sequence:[0], random actions:[25], eInit:[0.0100], init state:[5 4 6 0 0 0 0 0 0 0 0 0 0 0], end state:[0 4 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 946, score:[2751.45], loss:[1.42154], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3 18  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18  6  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 947, score:[2707.82], loss:[1.38048], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 20 55  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 55  1  1  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 948, score:[2773.82], loss:[1.25722], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 11 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 949, score:[2750.36], loss:[1.21933], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 5 21 44  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 44  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 950, score:[2765.82], loss:[1.17143], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 4  4 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 58  0  0  0  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 951, score:[2743.45], loss:[1.15756], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 3  9 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 952, score:[2657.27], loss:[1.21048], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 17 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 953, score:[2801.27], loss:[1.06729], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0 10 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 954, score:[2716.73], loss:[1.09695], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 0  4 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 955, score:[2721.64], loss:[1.16188], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4  7 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 956, score:[2714.18], loss:[1.33779], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 20 48  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 48  0  0  0  0  0  0  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 957, score:[2632.18], loss:[1.43993], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  2 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 958, score:[2727.45], loss:[1.53830], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 15 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 959, score:[2712.91], loss:[1.54740], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 23 36  1  0  0  0  0  0  1  1  0  0  0], end state:[ 0 23 36  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 960, score:[2792.91], loss:[1.35723], sequence:[1], random actions:[24], eInit:[0.0100], init state:[1 5 1 0 0 0 0 0 0 0 0 0 0 0], end state:[3 5 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 961, score:[2755.82], loss:[1.44842], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 5 19  8  1  0  0  1  1  0  0  0  0  0  0], end state:[ 0 19  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 962, score:[2752.91], loss:[1.40420], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 4  9 47  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 963, score:[2760.55], loss:[1.31066], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 2 23 40  1  0  0  1  0  0  1  1  0  0  0], end state:[ 4 23 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 964, score:[2743.27], loss:[1.14957], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 5 17 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 965, score:[2690.36], loss:[1.30376], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4  6 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 966, score:[2773.64], loss:[1.28152], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3  3 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 50  0  1  0  0  1  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 967, score:[2769.82], loss:[1.31900], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 2 22 14  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 968, score:[2712.00], loss:[1.61136], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 3 12  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 969, score:[2759.09], loss:[1.37568], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1 23 37  1  0  0  1  0  0  1  1  0  0  0], end state:[ 3 23 37  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 970, score:[2727.64], loss:[1.36799], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  7 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 971, score:[2774.18], loss:[1.31046], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0  7 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 972, score:[2755.27], loss:[1.30332], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 1 13  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 973, score:[2800.36], loss:[1.21314], sequence:[3], random actions:[28], eInit:[0.0100], init state:[0 8 8 1 0 0 0 0 0 0 0 0 0 0], end state:[2 8 8 1 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 974, score:[2758.91], loss:[1.06264], sequence:[4], random actions:[39], eInit:[0.0100], init state:[0 9 8 0 0 0 0 0 0 0 0 0 0 0], end state:[2 9 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 975, score:[2727.45], loss:[1.09638], sequence:[0], random actions:[31], eInit:[0.0100], init state:[2 4 8 0 0 0 0 0 0 0 0 0 0 0], end state:[4 4 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 976, score:[2725.09], loss:[1.31613], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 2  8 37  1  1  0  1  0  1  0  0  0  0  0], end state:[ 4  8 37  0  1  1  0  0  0  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 977, score:[2765.27], loss:[1.17254], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1  7 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 978, score:[2675.82], loss:[1.22108], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  2 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 28  0  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 979, score:[2718.73], loss:[1.26384], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6  4 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 980, score:[2750.00], loss:[1.17487], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0  7 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 981, score:[2690.55], loss:[1.23363], sequence:[0], random actions:[36], eInit:[0.0100], init state:[3 9 4 0 0 0 0 0 0 0 0 0 0 0], end state:[5 9 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 982, score:[2760.55], loss:[1.19156], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 19 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 983, score:[2778.91], loss:[1.01861], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 19 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 984, score:[2732.18], loss:[1.07881], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 3 12 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 985, score:[2647.64], loss:[1.31017], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5  7 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 986, score:[2706.00], loss:[1.33351], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 3 22  5  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22  5  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 987, score:[2760.18], loss:[1.24705], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 2 23 18  1  0  0  1  0  0  1  1  0  0  1], end state:[ 4 23 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 988, score:[2791.09], loss:[1.30328], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 20 38  1  1  0  0  0  0  0  0  1  0  0], end state:[ 2 20 38  1  0  0  0  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 989, score:[2713.27], loss:[1.22020], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4  4 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 990, score:[2762.91], loss:[1.29006], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  0 50  0  0  1  0  0  0  0  0  0  0  0], end state:[ 3  0 50  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365])
INFO:Reinforcement.Functions:episode: 991, score:[2755.09], loss:[1.20183], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 3 10 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 992, score:[2768.00], loss:[1.22744], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1  0 43  0  0  1  0  0  0  0  0  0  0  0], end state:[ 3  0 43  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 993, score:[2753.27], loss:[1.24432], sequence:[4], random actions:[43], eInit:[0.0100], init state:[ 3 16  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 994, score:[2748.00], loss:[1.24059], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 2 18 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 995, score:[2754.00], loss:[1.18830], sequence:[6], random actions:[35], eInit:[0.0100], init state:[ 1  3 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 996, score:[2768.73], loss:[1.17318], sequence:[7], random actions:[35], eInit:[0.0100], init state:[ 2  0 45  0  0  1  0  0  0  0  0  0  0  0], end state:[ 4  0 45  1  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 997, score:[2765.64], loss:[1.22280], sequence:[8], random actions:[36], eInit:[0.0100], init state:[ 2  7 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 998, score:[2736.73], loss:[1.20481], sequence:[9], random actions:[30], eInit:[0.0100], init state:[ 3 16 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 999, score:[2729.82], loss:[1.33075], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6 18 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1000, score:[2707.09], loss:[1.35064], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 18 48  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365, 998])
INFO:Reinforcement.Functions:episode: 1001, score:[2746.36], loss:[1.52644], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 0 16 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 22  0  1  1  0  1  0  0  1  1  1  1]
INFO:Reinforcement.Functions:episode: 1002, score:[2748.55], loss:[1.42208], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 3  9 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1003, score:[2691.64], loss:[1.45552], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  7 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1004, score:[2753.45], loss:[1.35268], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 6 20 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 20 26  0  0  0  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1005, score:[2746.55], loss:[1.24103], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 4  9 54  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 54  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1006, score:[2768.00], loss:[1.23414], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 0  3 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1007, score:[2702.00], loss:[1.58541], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6  0 12  1  0  0  0  0  1  1  1  0  0  0], end state:[ 1  0 12  1  0  0  0  0  1  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1008, score:[2665.64], loss:[1.60022], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 23 20  1  0  0  0  0  0  1  1  0  0  1], end state:[ 0 23 20  0  0  0  0  1  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1009, score:[2778.73], loss:[1.38913], sequence:[1], random actions:[33], eInit:[0.0100], init state:[2 2 7 0 0 0 0 0 0 0 0 0 0 0], end state:[4 2 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1010, score:[2686.73], loss:[1.53115], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  2 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365, 998])
INFO:Reinforcement.Functions:episode: 1011, score:[2771.45], loss:[1.52313], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6 15 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1012, score:[2708.55], loss:[1.52435], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2  1 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1013, score:[2725.82], loss:[1.61547], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 3  4 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1014, score:[2764.36], loss:[1.52663], sequence:[1], random actions:[18], eInit:[0.0100], init state:[ 3  1 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  1 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1015, score:[2786.36], loss:[1.40330], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1 20 35  1  1  0  0  0  0  0  0  1  0  0], end state:[ 3 20 35  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1016, score:[2723.82], loss:[1.43067], sequence:[0], random actions:[23], eInit:[0.0100], init state:[5 2 9 0 0 0 0 0 0 0 0 0 0 0], end state:[0 2 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1017, score:[2738.18], loss:[1.42359], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 6  6 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1018, score:[2755.27], loss:[1.41730], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 6  1 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1019, score:[2686.00], loss:[1.44355], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 1 16 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 56  0  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1020, score:[2775.09], loss:[1.34338], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 6 19  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365, 998])
INFO:Reinforcement.Functions:episode: 1021, score:[2762.73], loss:[1.28915], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 10 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1022, score:[2756.36], loss:[1.27459], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 2 18  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1023, score:[2731.09], loss:[1.18930], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 1 22 15  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 15  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1024, score:[2701.27], loss:[1.33579], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 20 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1025, score:[2748.18], loss:[1.26481], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 17 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1026, score:[2797.09], loss:[1.12608], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 0 18 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1027, score:[2774.55], loss:[1.09670], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 0 23  2  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 23  2  1  0  0  0  1  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1028, score:[2769.45], loss:[1.11091], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 2 19 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1029, score:[2771.27], loss:[1.03158], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 6 19 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1030, score:[2722.73], loss:[1.11739], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 18 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365, 998])
INFO:Reinforcement.Functions:episode: 1031, score:[2721.64], loss:[1.12979], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 19 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1032, score:[2779.64], loss:[1.08036], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1 14 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1033, score:[2738.18], loss:[1.12490], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 16 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 16 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1034, score:[2788.73], loss:[1.10679], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 0  3 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1035, score:[2781.09], loss:[1.05095], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 1  1 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1036, score:[2738.18], loss:[1.12928], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 0 16 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1037, score:[2793.09], loss:[0.95358], sequence:[6], random actions:[20], eInit:[0.0100], init state:[2 1 8 0 0 1 0 0 0 0 0 0 0 0], end state:[4 1 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1038, score:[2727.45], loss:[1.05910], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 18  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1039, score:[2716.18], loss:[1.09119], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6 15 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1040, score:[2750.73], loss:[1.07107], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 6 13 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365, 998])
INFO:Reinforcement.Functions:episode: 1041, score:[2750.73], loss:[1.08966], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6  9 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1042, score:[2698.91], loss:[1.17994], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 22 34  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 22 34  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1043, score:[2646.91], loss:[1.34614], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 12 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1044, score:[2730.91], loss:[1.40737], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 10 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1045, score:[2781.27], loss:[1.22938], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 4  8 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 54  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1046, score:[2750.36], loss:[1.51480], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 1 18 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1047, score:[2764.00], loss:[1.50286], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 3 15 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 19  0  1  0  0  0  0  0  0  1  0  1]
INFO:Reinforcement.Functions:episode: 1048, score:[2785.64], loss:[1.31936], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 1 18 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1049, score:[2727.82], loss:[1.39866], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3  9 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1050, score:[2686.91], loss:[1.40147], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6  7 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(9, [365, 998])
INFO:Reinforcement.Functions:episode: 1051, score:[2762.91], loss:[1.25547], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 6 15 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1052, score:[2766.55], loss:[1.21616], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 3 10 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 59  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1053, score:[2782.55], loss:[1.20340], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 0 19  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1054, score:[2794.91], loss:[1.12254], sequence:[4], random actions:[28], eInit:[0.0100], init state:[1 3 1 0 0 0 0 0 0 0 0 0 0 0], end state:[3 3 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1055, score:[2747.64], loss:[1.11571], sequence:[5], random actions:[42], eInit:[0.0100], init state:[ 0  5 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1056, score:[2751.09], loss:[1.10814], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 2 14 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1057, score:[2792.91], loss:[1.13107], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 3 18  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18  1  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1058, score:[2806.00], loss:[1.05886], sequence:[8], random actions:[23], eInit:[0.0100], init state:[ 1 22 51  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 51  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1059, score:[2785.45], loss:[1.01400], sequence:[9], random actions:[31], eInit:[0.0100], init state:[ 2  4 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1060, score:[2738.18], loss:[1.06173], sequence:[10], random actions:[29], eInit:[0.0100], init state:[ 3 22  3  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22  3  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(10, [1060])
INFO:Reinforcement.Functions:episode: 1061, score:[2763.27], loss:[1.13220], sequence:[11], random actions:[24], eInit:[0.0100], init state:[ 4 16 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1062, score:[2759.64], loss:[0.99714], sequence:[12], random actions:[38], eInit:[0.0100], init state:[ 4 16  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1063, score:[2742.91], loss:[1.15616], sequence:[13], random actions:[32], eInit:[0.0100], init state:[ 4 14 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1064, score:[2747.09], loss:[1.04458], sequence:[14], random actions:[30], eInit:[0.0100], init state:[ 4 17 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1065, score:[2794.00], loss:[1.02208], sequence:[15], random actions:[32], eInit:[0.0100], init state:[ 2 22  3  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1066, score:[2762.36], loss:[1.10811], sequence:[16], random actions:[35], eInit:[0.0100], init state:[ 1 20 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 20 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1067, score:[2683.64], loss:[1.25304], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 17  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1068, score:[2699.82], loss:[1.16801], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5  1 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  1 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1069, score:[2811.27], loss:[1.13794], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 3 10 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1070, score:[2773.64], loss:[1.00371], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 4 14 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1071, score:[2739.64], loss:[1.14271], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 5 23 49  1  0  0  0  0  0  1  1  0  0  0], end state:[ 0 23 49  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1072, score:[2773.09], loss:[1.18254], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 3 12 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1073, score:[2746.00], loss:[1.14153], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 6  8 49  1  1  0  0  0  0  0  0  0  0  0], end state:[ 1  8 49  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1074, score:[2809.64], loss:[1.06907], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 0 16  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1075, score:[2762.55], loss:[1.02816], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 3 12 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1076, score:[2712.00], loss:[1.10739], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  6 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1077, score:[2735.27], loss:[1.25765], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 21 37  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 21 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1078, score:[2727.64], loss:[1.39574], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 2  3 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1079, score:[2801.09], loss:[1.27752], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 3  3 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1080, score:[2782.00], loss:[1.16284], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 4 14 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1081, score:[2780.91], loss:[1.15695], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 2  5 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  5 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1082, score:[2741.82], loss:[1.26561], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 6  4 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1083, score:[2825.64], loss:[1.06227], sequence:[5], random actions:[16], eInit:[0.0100], init state:[ 0  5 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1084, score:[2705.82], loss:[1.36181], sequence:[0], random actions:[26], eInit:[0.0100], init state:[5 9 3 0 0 0 0 0 0 0 0 0 0 0], end state:[0 9 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1085, score:[2766.18], loss:[1.18066], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 2 11 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11 40  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1086, score:[2683.09], loss:[1.29198], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  7 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 11  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1087, score:[2804.55], loss:[1.24170], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 1  9 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  9 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1088, score:[2750.36], loss:[1.23790], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 4  0 18  1  0  0  0  0  1  0  0  0  0  0], end state:[ 6  0 18  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1089, score:[2814.00], loss:[1.10698], sequence:[3], random actions:[20], eInit:[0.0100], init state:[ 1 12 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1090, score:[2670.55], loss:[1.33613], sequence:[0], random actions:[44], eInit:[0.0100], init state:[ 4 11 48  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1091, score:[2752.18], loss:[1.28732], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 5  4 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  4 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1092, score:[2783.64], loss:[1.20618], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 20 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1093, score:[2736.55], loss:[1.29882], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 3 19 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 27  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1094, score:[2745.45], loss:[1.34524], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 0  5 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1095, score:[2757.27], loss:[1.24122], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 5 23 19  1  0  0  0  0  0  1  1  0  0  1], end state:[ 0 23 19  1  0  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1096, score:[2663.45], loss:[1.30144], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 13 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1097, score:[2779.45], loss:[1.24572], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2  9 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1098, score:[2803.45], loss:[1.19601], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 3 10 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1099, score:[2726.73], loss:[1.38779], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6 16  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1100, score:[2784.55], loss:[1.15000], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 4 19 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1101, score:[2820.18], loss:[1.03302], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 0 15 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1102, score:[2678.36], loss:[1.14463], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 16 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1103, score:[2761.45], loss:[1.17015], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 4 12 43  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1104, score:[2797.82], loss:[1.04244], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 1  0 57  0  0  1  0  0  0  0  0  0  0  0], end state:[ 3  0 57  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1105, score:[2765.45], loss:[1.08630], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 4  5 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 57  0  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1106, score:[2760.55], loss:[1.03337], sequence:[4], random actions:[19], eInit:[0.0100], init state:[ 6  2 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  2 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1107, score:[2792.18], loss:[1.05807], sequence:[5], random actions:[21], eInit:[0.0100], init state:[ 0  9 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1108, score:[2744.00], loss:[1.09602], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 4  4 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1109, score:[2779.45], loss:[0.99707], sequence:[7], random actions:[32], eInit:[0.0100], init state:[ 4 11 43  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1110, score:[2818.18], loss:[0.91304], sequence:[8], random actions:[24], eInit:[0.0100], init state:[1 1 3 0 0 1 0 0 0 0 0 0 0 0], end state:[3 1 3 1 0 0 0 1 0 0 1 1 1 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1111, score:[2784.91], loss:[0.95646], sequence:[9], random actions:[22], eInit:[0.0100], init state:[ 2 22 15  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1112, score:[2673.27], loss:[1.16877], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 14  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1113, score:[2670.55], loss:[1.26207], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 6 12 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1114, score:[2784.73], loss:[1.04282], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1 21 17  1  1  0  1  0  0  1  1  0  0  1], end state:[ 3 21 17  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1115, score:[2795.82], loss:[0.96014], sequence:[2], random actions:[18], eInit:[0.0100], init state:[ 3 12 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1116, score:[2776.36], loss:[0.90016], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 2  9 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1117, score:[2778.00], loss:[0.90858], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 0 17 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1118, score:[2788.00], loss:[0.91188], sequence:[5], random actions:[20], eInit:[0.0100], init state:[ 0  8 26  1  0  0  0  0  0  0  0  0  0  0], end state:[ 2  8 26  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1119, score:[2782.55], loss:[0.88298], sequence:[6], random actions:[34], eInit:[0.0100], init state:[ 2 21  4  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1120, score:[2788.00], loss:[0.99622], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 3 18 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 59  1  0  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1121, score:[2808.18], loss:[0.87081], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 1 19 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1122, score:[2686.55], loss:[0.97029], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 19 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 45  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1123, score:[2773.82], loss:[0.98128], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 3  7 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1124, score:[2778.73], loss:[1.04701], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1 18 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1125, score:[2797.64], loss:[0.92000], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 3 17 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1126, score:[2809.09], loss:[0.79363], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 0 22 14  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 14  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1127, score:[2802.91], loss:[0.82305], sequence:[5], random actions:[27], eInit:[0.0100], init state:[2 8 1 1 0 0 0 0 0 0 0 0 0 0], end state:[4 8 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1128, score:[2803.45], loss:[0.81636], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 2  0 50  0  0  1  0  0  0  0  0  0  0  0], end state:[ 4  0 50  1  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1129, score:[2774.73], loss:[0.82155], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 2 20 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1130, score:[2665.82], loss:[1.02283], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5 11  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1131, score:[2752.55], loss:[1.16647], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 0 20  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 20  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1132, score:[2806.55], loss:[0.88556], sequence:[2], random actions:[26], eInit:[0.0100], init state:[1 3 6 0 0 0 0 0 0 0 0 0 0 0], end state:[3 3 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1133, score:[2762.91], loss:[0.88494], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 2  8 23  1  0  0  0  0  0  0  0  0  0  0], end state:[ 4  8 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1134, score:[2742.00], loss:[0.90741], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 6 10 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1135, score:[2755.82], loss:[0.98427], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 6 15 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1136, score:[2762.55], loss:[1.00770], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 6  9 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1137, score:[2806.18], loss:[0.93669], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 1 22 28  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 28  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1138, score:[2806.73], loss:[0.88640], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 0  1 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1139, score:[2713.27], loss:[1.00421], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 21 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 17  1  1  1  0  1  1  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1140, score:[2696.55], loss:[1.26910], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 12  5  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12  5  0  0  1  0  0  1  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1141, score:[2754.00], loss:[1.15450], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 4  8 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 17  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1142, score:[2772.18], loss:[1.03578], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1 21 26  1  1  0  1  0  0  1  1  0  0  1], end state:[ 3 21 26  1  1  0  0  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1143, score:[2697.64], loss:[1.23544], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6 16 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1144, score:[2785.27], loss:[1.01657], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 2 18  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1145, score:[2734.91], loss:[1.07537], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4  1 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1146, score:[2784.91], loss:[1.10236], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 22 21  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 21  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1147, score:[2696.73], loss:[1.25598], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4  4 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 10  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1148, score:[2744.91], loss:[1.22889], sequence:[1], random actions:[35], eInit:[0.0100], init state:[0 6 9 0 0 0 0 0 0 0 0 0 0 0], end state:[2 6 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1149, score:[2718.18], loss:[1.20727], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  3 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1150, score:[2721.45], loss:[1.35955], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 16  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1151, score:[2812.00], loss:[1.07130], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1  9 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  9 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1152, score:[2781.09], loss:[1.05008], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 2  2 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1153, score:[2733.09], loss:[1.16852], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 6 20 54  1  1  0  1  0  0  1  1  1  0  0], end state:[ 1 20 54  1  0  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1154, score:[2773.82], loss:[0.96216], sequence:[1], random actions:[31], eInit:[0.0100], init state:[1 2 4 0 0 0 0 0 0 0 0 0 0 0], end state:[3 2 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1155, score:[2784.36], loss:[1.06330], sequence:[2], random actions:[24], eInit:[0.0100], init state:[0 4 6 0 0 0 0 0 0 0 0 0 0 0], end state:[2 4 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1156, score:[2689.64], loss:[1.15921], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  7 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1157, score:[2639.82], loss:[1.20294], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  5 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1158, score:[2652.00], loss:[1.27038], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 4 22 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22 41  1  1  0  0  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1159, score:[2759.45], loss:[1.40991], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0  8 58  1  1  0  0  0  0  0  0  0  0  0], end state:[ 2  8 58  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1160, score:[2759.82], loss:[1.42151], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 1 20 32  1  1  0  0  0  0  0  0  1  0  0], end state:[ 3 20 32  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1161, score:[2817.27], loss:[1.08836], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 0  5 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1162, score:[2773.27], loss:[1.14837], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 1 13 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1163, score:[2744.36], loss:[1.10229], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 6  3 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1164, score:[2788.36], loss:[1.02434], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 1 22  6  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22  6  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1165, score:[2703.45], loss:[1.16205], sequence:[0], random actions:[29], eInit:[0.0100], init state:[5 5 6 0 0 0 0 0 0 0 0 0 0 0], end state:[0 5 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1166, score:[2759.45], loss:[1.16814], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 5  7 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1167, score:[2799.09], loss:[1.11082], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0  5 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1168, score:[2761.27], loss:[1.11940], sequence:[3], random actions:[20], eInit:[0.0100], init state:[ 2 17 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1169, score:[2704.18], loss:[1.40295], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 21 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 41  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1170, score:[2754.36], loss:[1.35746], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 2 20 40  1  1  0  0  0  0  1  1  1  0  0], end state:[ 4 20 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1171, score:[2790.91], loss:[1.16965], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1  3 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1172, score:[2780.36], loss:[1.12842], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 0 19 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1173, score:[2748.73], loss:[1.12299], sequence:[4], random actions:[30], eInit:[0.0100], init state:[4 9 9 0 0 0 0 0 0 0 0 0 0 0], end state:[6 9 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1174, score:[2764.55], loss:[1.22366], sequence:[5], random actions:[27], eInit:[0.0100], init state:[0 5 2 0 0 0 0 0 0 0 0 0 0 0], end state:[2 5 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1175, score:[2756.00], loss:[1.21428], sequence:[6], random actions:[39], eInit:[0.0100], init state:[ 6  3 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1176, score:[2791.45], loss:[1.07806], sequence:[7], random actions:[20], eInit:[0.0100], init state:[ 4  2 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1177, score:[2747.45], loss:[1.11137], sequence:[8], random actions:[34], eInit:[0.0100], init state:[ 6  7 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 29  0  0  0  0  1  0  0  0  1  0  1]
INFO:Reinforcement.Functions:episode: 1178, score:[2798.00], loss:[1.09174], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 0  2 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1179, score:[2757.64], loss:[1.15275], sequence:[10], random actions:[39], eInit:[0.0100], init state:[ 0 20 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 20 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1180, score:[2726.55], loss:[1.22628], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 19 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1181, score:[2684.00], loss:[1.12936], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  3 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1182, score:[2756.55], loss:[1.21972], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 4  3 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1183, score:[2738.73], loss:[1.17430], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 6  7 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1184, score:[2721.82], loss:[1.25290], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 2 12 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 57  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1185, score:[2652.73], loss:[1.81414], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 15  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1186, score:[2660.18], loss:[1.90751], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 12 35  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1187, score:[2783.64], loss:[1.36367], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 4 13 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1188, score:[2751.45], loss:[1.34264], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 0 20 52  1  1  0  1  0  0  1  1  1  0  0], end state:[ 2 20 52  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1189, score:[2768.18], loss:[1.29090], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 1 18 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1190, score:[2722.55], loss:[1.42031], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  7 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1191, score:[2788.73], loss:[1.36685], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 1 20 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 20 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1192, score:[2723.64], loss:[1.47801], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 19 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1193, score:[2741.27], loss:[1.43422], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 2 15 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1194, score:[2734.00], loss:[1.39998], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6  0 29  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  0 29  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1195, score:[2812.18], loss:[1.31533], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 1  6 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1196, score:[2788.36], loss:[1.26597], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 6 10 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1197, score:[2796.73], loss:[1.24166], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 2  4 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1198, score:[2803.27], loss:[1.28140], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 6 16 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1199, score:[2758.36], loss:[1.18730], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 3 20 51  1  1  0  1  0  0  1  1  1  0  0], end state:[ 5 20 51  1  0  0  0  0  0  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1200, score:[2658.00], loss:[1.40434], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  7 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1201, score:[2786.91], loss:[1.25989], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  2 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1202, score:[2772.00], loss:[1.29049], sequence:[2], random actions:[40], eInit:[0.0100], init state:[ 1  9 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  9 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1203, score:[2768.73], loss:[1.29245], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 1  0 20  1  0  0  0  0  1  0  0  0  0  0], end state:[ 3  0 20  1  0  0  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1204, score:[2774.91], loss:[1.23244], sequence:[4], random actions:[34], eInit:[0.0100], init state:[ 0 11 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1205, score:[2784.00], loss:[1.13929], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 1 15 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1206, score:[2790.18], loss:[0.96461], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 1 16 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1207, score:[2789.27], loss:[0.92751], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 3 10 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1208, score:[2738.73], loss:[0.97576], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 5 21 40  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 40  1  1  0  1  0  1  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1209, score:[2745.64], loss:[1.02089], sequence:[9], random actions:[18], eInit:[0.0100], init state:[ 6 16 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1210, score:[2795.27], loss:[0.99357], sequence:[10], random actions:[25], eInit:[0.0100], init state:[ 0  7 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1211, score:[2727.27], loss:[1.09143], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 3 13  4  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1212, score:[2792.00], loss:[1.00303], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 2 20 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1213, score:[2766.73], loss:[1.03601], sequence:[2], random actions:[35], eInit:[0.0100], init state:[2 5 4 0 0 0 0 0 0 0 0 0 0 0], end state:[4 5 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1214, score:[2782.36], loss:[1.12382], sequence:[3], random actions:[17], eInit:[0.0100], init state:[ 5 23 49  1  0  0  0  0  0  1  1  0  0  0], end state:[ 0 23 49  1  0  0  0  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1215, score:[2652.91], loss:[1.50449], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 16 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1216, score:[2811.09], loss:[1.19008], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1  4 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1217, score:[2739.45], loss:[1.20353], sequence:[2], random actions:[30], eInit:[0.0100], init state:[6 7 4 0 0 0 0 0 0 0 0 0 0 0], end state:[1 7 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1218, score:[2775.82], loss:[1.06225], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 2  4 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1219, score:[2800.36], loss:[1.09043], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 6 17  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1220, score:[2710.91], loss:[1.29937], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4 18 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 34  0  0  0  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1221, score:[2805.09], loss:[1.14479], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 16 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1222, score:[2778.18], loss:[1.22307], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 4 18 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1223, score:[2731.82], loss:[1.32642], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 23 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 47  0  0  0  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1224, score:[2777.09], loss:[1.40177], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0  5 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1225, score:[2694.00], loss:[1.53392], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 15 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1226, score:[2741.45], loss:[1.42718], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 5 20 19  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1227, score:[2688.55], loss:[1.55432], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 19 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 19  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1228, score:[2769.27], loss:[1.54155], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 1  6 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1229, score:[2773.82], loss:[1.42862], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1  1 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1230, score:[2751.82], loss:[1.50541], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 5  5 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1231, score:[2798.91], loss:[1.48032], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 0 10 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1232, score:[2776.00], loss:[1.43192], sequence:[5], random actions:[15], eInit:[0.0100], init state:[ 3  1 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  1 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1233, score:[2776.55], loss:[1.31144], sequence:[6], random actions:[25], eInit:[0.0100], init state:[ 2 14  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1234, score:[2759.27], loss:[1.45297], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 2  2 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1235, score:[2787.45], loss:[1.40279], sequence:[8], random actions:[21], eInit:[0.0100], init state:[ 4 14 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1236, score:[2701.45], loss:[1.66478], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  3 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1237, score:[2747.27], loss:[1.81182], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 0 23 58  1  0  0  0  0  0  1  1  0  0  0], end state:[ 2 23 58  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1238, score:[2785.45], loss:[1.56877], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 6  8 47  1  1  0  0  0  0  0  0  0  0  0], end state:[ 1  8 47  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1239, score:[2686.36], loss:[1.75218], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4  7 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 31  1  1  1  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1240, score:[2791.09], loss:[1.55232], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4  2 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1241, score:[2645.27], loss:[1.57293], sequence:[0], random actions:[45], eInit:[0.0100], init state:[ 4 23 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 44  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1242, score:[2737.27], loss:[1.69340], sequence:[1], random actions:[21], eInit:[0.0100], init state:[6 4 1 0 0 0 0 0 0 0 0 0 0 0], end state:[1 4 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1243, score:[2799.27], loss:[1.52317], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 1 22 45  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 45  1  0  0  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1244, score:[2779.09], loss:[1.39662], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 0 22 11  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 11  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1245, score:[2698.91], loss:[1.52686], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 15 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1246, score:[2724.91], loss:[1.55794], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6  4 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1247, score:[2756.73], loss:[1.65035], sequence:[1], random actions:[40], eInit:[0.0100], init state:[ 1 20 46  1  1  0  1  0  0  1  1  1  0  0], end state:[ 3 20 46  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1248, score:[2735.82], loss:[1.70414], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 5 23 21  1  0  0  0  0  0  1  1  0  0  1], end state:[ 0 23 21  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1249, score:[2707.82], loss:[1.64601], sequence:[0], random actions:[34], eInit:[0.0100], init state:[6 2 8 0 0 0 0 0 0 0 0 0 0 0], end state:[1 2 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1250, score:[2690.36], loss:[1.87042], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  7 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1251, score:[2789.45], loss:[1.63997], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0  9 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1252, score:[2746.18], loss:[1.68654], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 4  2 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1253, score:[2676.18], loss:[1.76313], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 22 14  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 22 14  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1254, score:[2785.09], loss:[1.79062], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6  9 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1255, score:[2716.73], loss:[1.71144], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3 11 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1256, score:[2750.18], loss:[1.85087], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3 23  3  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 23  3  1  0  0  0  0  0  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1257, score:[2758.00], loss:[1.86730], sequence:[2], random actions:[34], eInit:[0.0100], init state:[2 9 7 0 0 0 0 0 0 0 0 0 0 0], end state:[4 9 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1258, score:[2773.09], loss:[1.71288], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 2  9 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1259, score:[2804.36], loss:[1.68375], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 0 11 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1260, score:[2773.45], loss:[1.51724], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 1  4 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1261, score:[2776.00], loss:[1.49869], sequence:[6], random actions:[19], eInit:[0.0100], init state:[ 4 12 56  1  1  0  1  0  0  0  0  0  0  0], end state:[ 6 12 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1262, score:[2751.82], loss:[1.71875], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 3 12 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1263, score:[2804.36], loss:[1.56362], sequence:[8], random actions:[17], eInit:[0.0100], init state:[ 4 13 26  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 13 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1264, score:[2653.09], loss:[1.91498], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 13 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1265, score:[2769.82], loss:[1.68615], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 1 10 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1266, score:[2764.55], loss:[1.67908], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 1 18 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1267, score:[2704.18], loss:[1.74010], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 12 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1268, score:[2772.91], loss:[1.49949], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3 22 46  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1269, score:[2811.27], loss:[1.44196], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 3  3 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1270, score:[2755.82], loss:[1.43522], sequence:[3], random actions:[31], eInit:[0.0100], init state:[0 9 9 0 0 0 0 0 0 0 0 0 0 0], end state:[2 9 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1271, score:[2759.82], loss:[1.38383], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 2  9 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1272, score:[2727.64], loss:[1.43221], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 23 40  1  0  0  1  0  0  1  1  0  0  0], end state:[ 5 23 40  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1273, score:[2737.27], loss:[1.41319], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 5 11 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1274, score:[2776.73], loss:[1.27990], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 22 17  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1275, score:[2780.36], loss:[1.33647], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 6 10 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1276, score:[2716.55], loss:[1.44879], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6  7 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1277, score:[2766.55], loss:[1.38113], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 5 19 33  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1278, score:[2754.00], loss:[1.37926], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2 23 35  1  0  0  1  0  0  1  1  0  0  0], end state:[ 4 23 35  0  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1279, score:[2732.55], loss:[1.42001], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 1  3 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1280, score:[2734.36], loss:[1.63611], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6 17  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17  0  0  1  1  1  1  0  1  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1281, score:[2734.18], loss:[1.55025], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 17  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1282, score:[2797.45], loss:[1.47545], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3  5 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1283, score:[2689.45], loss:[1.67604], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4  6 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  6 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1284, score:[2780.00], loss:[1.84127], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1  9 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  9 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1285, score:[2750.91], loss:[1.74880], sequence:[2], random actions:[38], eInit:[0.0100], init state:[ 0 21 21  1  1  0  1  0  0  1  1  0  0  1], end state:[ 2 21 21  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1286, score:[2761.64], loss:[1.54296], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 1  3 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1287, score:[2734.36], loss:[1.98966], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6 13  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1288, score:[2707.82], loss:[1.77753], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 11 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1289, score:[2751.09], loss:[1.90736], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 5  7 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1290, score:[2816.55], loss:[1.70073], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0 17 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1291, score:[2770.55], loss:[1.72448], sequence:[3], random actions:[18], eInit:[0.0100], init state:[ 4  2 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1292, score:[2723.64], loss:[1.69213], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 1 22 46  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 46  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1293, score:[2713.09], loss:[1.73872], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 4  7 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1294, score:[2771.09], loss:[1.68846], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 2  6 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1295, score:[2743.64], loss:[1.68078], sequence:[2], random actions:[37], eInit:[0.0100], init state:[ 1  6 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1296, score:[2795.82], loss:[1.65676], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 2  8 49  1  1  0  0  0  0  0  0  0  0  0], end state:[ 4  8 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1297, score:[2739.64], loss:[1.62357], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 4  5 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1298, score:[2771.45], loss:[1.57763], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 4 11  2  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1299, score:[2772.18], loss:[1.58402], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 1 18 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1300, score:[2753.09], loss:[1.50778], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 3 15 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1301, score:[2746.55], loss:[1.55554], sequence:[8], random actions:[29], eInit:[0.0100], init state:[ 3 22 39  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 39  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1302, score:[2724.36], loss:[1.59049], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 17 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 55  0  0  0  0  1  0  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1303, score:[2758.73], loss:[1.60809], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6 17 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1304, score:[2789.64], loss:[1.51471], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 3 11 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1305, score:[2793.82], loss:[1.53621], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 3  0 34  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1306, score:[2805.27], loss:[1.48737], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 3 10 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1307, score:[2744.18], loss:[1.47964], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 0 15 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1308, score:[2713.27], loss:[1.42528], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  1 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1309, score:[2750.73], loss:[1.59898], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3 22 32  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 32  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1310, score:[2728.73], loss:[1.69956], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4 13 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1311, score:[2788.00], loss:[1.64501], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 22 33  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1312, score:[2755.09], loss:[1.60881], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6 21  3  1  1  0  1  0  0  1  1  0  0  1], end state:[ 1 21  3  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1313, score:[2768.18], loss:[1.70861], sequence:[3], random actions:[36], eInit:[0.0100], init state:[0 0 7 1 0 0 0 0 1 1 1 0 0 0], end state:[2 0 7 1 0 0 0 0 1 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 1314, score:[2751.27], loss:[1.85392], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 1 20 39  1  1  0  0  0  0  0  0  1  0  0], end state:[ 3 20 39  1  1  0  0  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1315, score:[2777.27], loss:[1.64475], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 1 14  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1316, score:[2682.73], loss:[1.88343], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  9 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1317, score:[2746.73], loss:[2.02029], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 2 23 17  1  0  0  1  0  0  1  1  0  0  1], end state:[ 4 23 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1318, score:[2784.00], loss:[1.85984], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 1 19 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1319, score:[2642.18], loss:[1.85429], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4 23 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 37  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1320, score:[2752.36], loss:[1.72886], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 2 14 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1321, score:[2674.36], loss:[1.80353], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 23 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 34  1  0  1  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1322, score:[2651.82], loss:[2.00529], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 15 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1323, score:[2722.55], loss:[1.86546], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 2 13 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 33  0  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1324, score:[2800.36], loss:[1.73850], sequence:[1], random actions:[26], eInit:[0.0100], init state:[2 6 6 0 0 0 0 0 0 0 0 0 0 0], end state:[4 6 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1325, score:[2771.82], loss:[1.65647], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 4 11 32  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1326, score:[2773.82], loss:[1.51461], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1 23 56  1  0  0  0  0  0  1  1  0  0  0], end state:[ 3 23 56  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1327, score:[2803.45], loss:[1.48172], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 0  9 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1328, score:[2820.55], loss:[1.39126], sequence:[5], random actions:[16], eInit:[0.0100], init state:[ 2  8 59  1  1  0  0  0  0  0  0  0  0  0], end state:[ 4  8 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1329, score:[2764.91], loss:[1.55465], sequence:[6], random actions:[37], eInit:[0.0100], init state:[ 3  7 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 57  1  1  0  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1330, score:[2756.73], loss:[1.60370], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 6  1 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  1 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1331, score:[2764.18], loss:[1.70421], sequence:[8], random actions:[25], eInit:[0.0100], init state:[ 0  5 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1332, score:[2739.09], loss:[1.86708], sequence:[9], random actions:[29], eInit:[0.0100], init state:[ 6 17 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1333, score:[2709.82], loss:[2.07064], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6 11 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1334, score:[2779.27], loss:[1.75645], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 0 20 38  1  1  0  0  0  0  0  0  1  0  0], end state:[ 2 20 38  1  1  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1335, score:[2697.45], loss:[1.76516], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 19 56  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1336, score:[2778.00], loss:[1.64908], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6 18 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1337, score:[2773.45], loss:[1.65333], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 3  5 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1338, score:[2787.82], loss:[1.69332], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 2 11 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11 47  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1339, score:[2763.82], loss:[1.55553], sequence:[4], random actions:[32], eInit:[0.0100], init state:[2 5 1 0 0 0 0 0 0 0 0 0 0 0], end state:[4 5 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1340, score:[2801.82], loss:[1.46334], sequence:[5], random actions:[29], eInit:[0.0100], init state:[1 0 3 1 0 0 0 0 0 1 1 0 0 0], end state:[3 0 3 1 0 0 0 0 0 1 1 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1341, score:[2802.55], loss:[1.50215], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 0 19 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1342, score:[2685.27], loss:[1.51329], sequence:[0], random actions:[23], eInit:[0.0100], init state:[4 3 9 0 0 0 0 0 0 0 0 0 0 0], end state:[6 3 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1343, score:[2743.82], loss:[1.30630], sequence:[1], random actions:[29], eInit:[0.0100], init state:[4 1 5 0 0 1 0 0 0 0 0 0 0 0], end state:[6 1 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1344, score:[2753.64], loss:[1.41920], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 2 22 29  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 29  0  0  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1345, score:[2795.82], loss:[1.29787], sequence:[3], random actions:[18], eInit:[0.0100], init state:[ 2 21 15  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21 15  0  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1346, score:[2781.27], loss:[1.25079], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2 20  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1347, score:[2659.64], loss:[1.34623], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 22  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22  5  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1348, score:[2752.00], loss:[1.52433], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 1  4 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1349, score:[2734.00], loss:[1.57776], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 0 10 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1350, score:[2802.36], loss:[1.34597], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0  5 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1351, score:[2803.64], loss:[1.23437], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 4  0 25  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  0 25  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1352, score:[2766.00], loss:[1.30834], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 4 16 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1353, score:[2811.64], loss:[1.23317], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 2  1 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1354, score:[2795.27], loss:[1.20491], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 6 22 34  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 34  1  1  0  0  0  0  1  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1355, score:[2651.64], loss:[1.45625], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5 18  3  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1356, score:[2762.73], loss:[1.36608], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 17 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 40  0  1  0  0  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1357, score:[2804.55], loss:[1.22913], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 19 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1358, score:[2707.09], loss:[1.13024], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5  6 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1359, score:[2773.82], loss:[1.30391], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 4  7 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1360, score:[2787.09], loss:[1.36742], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3  4 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1361, score:[2696.36], loss:[1.48871], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 5 12 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1362, score:[2734.91], loss:[1.47228], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 2 11 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11 52  0  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1363, score:[2788.36], loss:[1.59145], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3  0 26  1  0  0  0  0  0  0  0  0  0  0], end state:[ 5  0 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1364, score:[2772.73], loss:[1.32978], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 4 12 30  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 30  1  0  0  0  0  0  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1365, score:[2824.00], loss:[1.09912], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 1  6 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1366, score:[2818.55], loss:[1.11034], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 2  7 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1367, score:[2724.36], loss:[1.17807], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  8 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 45  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1368, score:[2702.18], loss:[1.38987], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 20 54  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 54  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1369, score:[2803.09], loss:[1.37027], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 20 43  1  1  0  0  0  0  1  1  1  0  0], end state:[ 3 20 43  1  1  0  0  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1370, score:[2778.73], loss:[1.21995], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 2 20 56  1  1  0  1  0  0  1  1  0  0  0], end state:[ 4 20 56  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1371, score:[2799.27], loss:[1.29532], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 3 21 17  1  1  0  1  0  0  1  1  0  0  1], end state:[ 5 21 17  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1372, score:[2786.73], loss:[1.29859], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 2  3 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1373, score:[2743.82], loss:[1.19625], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 0 19 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 58  0  0  0  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1374, score:[2759.64], loss:[1.29383], sequence:[6], random actions:[35], eInit:[0.0100], init state:[ 2  8 23  1  0  0  0  0  0  0  0  0  0  0], end state:[ 4  8 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1375, score:[2704.00], loss:[1.49632], sequence:[0], random actions:[42], eInit:[0.0100], init state:[ 5 19 48  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1376, score:[2785.64], loss:[1.32971], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 13  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1377, score:[2727.64], loss:[1.30017], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3 17 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1378, score:[2777.09], loss:[1.25220], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 2 12 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 20  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1379, score:[2712.91], loss:[1.37305], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 16 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1380, score:[2735.45], loss:[1.54918], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 18 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1381, score:[2808.36], loss:[1.29216], sequence:[1], random actions:[29], eInit:[0.0100], init state:[1 0 0 1 0 0 0 0 0 1 1 0 0 0], end state:[3 0 0 1 0 0 0 0 0 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 1382, score:[2797.27], loss:[1.26454], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 2  1 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1383, score:[2779.82], loss:[1.32644], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0  3 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1384, score:[2754.91], loss:[1.44755], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 1  2 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1385, score:[2778.73], loss:[1.50931], sequence:[5], random actions:[35], eInit:[0.0100], init state:[ 3  0 46  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 46  0  0  0  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1386, score:[2706.18], loss:[1.71718], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 21 16  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 16  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1387, score:[2779.09], loss:[1.52305], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3  4 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1388, score:[2764.73], loss:[1.63894], sequence:[2], random actions:[35], eInit:[0.0100], init state:[0 2 0 0 0 0 0 0 0 0 0 0 0 0], end state:[2 2 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1389, score:[2781.09], loss:[1.49674], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 2 16 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 16 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1390, score:[2748.18], loss:[1.57510], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 5 18 57  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1391, score:[2776.73], loss:[1.42457], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 3  0 54  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1392, score:[2790.00], loss:[1.40149], sequence:[6], random actions:[23], eInit:[0.0100], init state:[ 4 15  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1393, score:[2763.27], loss:[1.37431], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 4 16 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1394, score:[2733.82], loss:[1.51451], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5 19 32  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1395, score:[2767.27], loss:[1.55304], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0 23 10  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 23 10  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1396, score:[2785.27], loss:[1.42796], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 3  2 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1397, score:[2720.73], loss:[1.47752], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 16 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1398, score:[2801.64], loss:[1.44233], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 18 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1399, score:[2762.36], loss:[1.41969], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 6 22 11  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 11  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1400, score:[2738.73], loss:[1.52934], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 3  0 11  1  0  0  0  0  1  1  1  0  0  0], end state:[ 5  0 11  0  0  0  0  1  0  0  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1401, score:[2737.09], loss:[1.54582], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 4 20 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 38  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1402, score:[2745.09], loss:[1.71895], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 0  5 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1403, score:[2784.36], loss:[1.54372], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 2  4 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1404, score:[2686.91], loss:[1.75374], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 13 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1405, score:[2762.36], loss:[1.67641], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 21  4  1  1  0  1  0  0  1  1  0  0  1], end state:[ 3 21  4  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1406, score:[2764.00], loss:[1.75399], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 4 12 32  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1407, score:[2758.36], loss:[1.69072], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 3  7 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1408, score:[2788.91], loss:[1.64962], sequence:[4], random actions:[20], eInit:[0.0100], init state:[ 6 12 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1409, score:[2738.36], loss:[1.62745], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 6 17 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1410, score:[2652.91], loss:[1.67256], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2  5 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  5 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1411, score:[2734.18], loss:[1.84006], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6 17 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1412, score:[2763.64], loss:[2.06517], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 3  7 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1413, score:[2732.91], loss:[2.04954], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 6  8 19  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  8 19  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1414, score:[2727.45], loss:[2.07429], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 16 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1415, score:[2763.27], loss:[2.01357], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 19 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1416, score:[2798.18], loss:[1.90461], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 6 20 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 20 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1417, score:[2790.18], loss:[1.90450], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0 22 13  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 13  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1418, score:[2722.55], loss:[1.95491], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 14 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1419, score:[2740.55], loss:[1.97037], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 4 13 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1420, score:[2794.73], loss:[1.83291], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 2 13 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1421, score:[2798.55], loss:[1.92841], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 0 18 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1422, score:[2775.27], loss:[1.80713], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 0  2 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1423, score:[2779.45], loss:[1.89850], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 2 19 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1424, score:[2730.36], loss:[1.83767], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  7 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1425, score:[2804.18], loss:[1.76978], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 19 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1426, score:[2769.09], loss:[1.60775], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 6 21 47  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 21 47  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1427, score:[2728.55], loss:[1.69207], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  4 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  4 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1428, score:[2757.82], loss:[1.78003], sequence:[1], random actions:[26], eInit:[0.0100], init state:[5 6 6 0 0 0 0 0 0 0 0 0 0 0], end state:[0 6 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1429, score:[2766.18], loss:[1.86548], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 4 12 19  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1430, score:[2759.45], loss:[1.85980], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 1 16 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1431, score:[2768.91], loss:[1.80703], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 6  8 16  1  0  0  0  0  0  0  0  0  0  0], end state:[ 1  8 16  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1432, score:[2778.73], loss:[1.69441], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 0  8 41  1  1  0  1  0  1  0  0  0  0  0], end state:[ 2  8 41  1  1  0  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1433, score:[2721.27], loss:[1.87200], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 2 23 21  1  0  0  1  0  0  1  1  0  0  1], end state:[ 4 23 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1434, score:[2791.82], loss:[1.72975], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0  0 42  0  0  1  0  0  0  0  0  0  0  0], end state:[ 2  0 42  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1435, score:[2796.18], loss:[1.70019], sequence:[2], random actions:[24], eInit:[0.0100], init state:[1 9 6 0 0 0 0 0 0 0 0 0 0 0], end state:[3 9 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1436, score:[2798.73], loss:[1.65145], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 0 17 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1437, score:[2787.82], loss:[1.54100], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 2  4 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1438, score:[2792.73], loss:[1.52976], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 1 21 12  1  1  0  1  0  0  1  1  0  0  1], end state:[ 3 21 12  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1439, score:[2779.27], loss:[1.48490], sequence:[6], random actions:[34], eInit:[0.0100], init state:[ 0 18 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1440, score:[2751.82], loss:[1.48137], sequence:[7], random actions:[21], eInit:[0.0100], init state:[ 2 14 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1441, score:[2657.27], loss:[1.64265], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 20 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 20 15  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1442, score:[2772.36], loss:[1.61592], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3 10 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1443, score:[2795.09], loss:[1.42920], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1  4 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1444, score:[2758.73], loss:[1.35162], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 0  3 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  3 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1445, score:[2772.73], loss:[1.34976], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 2 18 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1446, score:[2780.00], loss:[1.27769], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 0 17 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1447, score:[2674.55], loss:[1.29173], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4 23 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 13  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1448, score:[2798.36], loss:[1.24445], sequence:[1], random actions:[33], eInit:[0.0100], init state:[1 5 8 0 0 0 0 0 0 0 0 0 0 0], end state:[3 5 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1449, score:[2796.00], loss:[1.21897], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 1 15 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1450, score:[2763.45], loss:[1.26687], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 2  1 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1451, score:[2709.27], loss:[1.48730], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 12 33  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1452, score:[2786.73], loss:[1.59366], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2  1 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1453, score:[2710.36], loss:[1.58701], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4  9 39  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1454, score:[2709.27], loss:[1.65544], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6  5 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  5 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1455, score:[2760.18], loss:[1.58846], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 3 15  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1456, score:[2812.73], loss:[1.46332], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 1  4 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1457, score:[2636.18], loss:[1.47253], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5  2 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1458, score:[2802.18], loss:[1.62845], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 0 19  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1459, score:[2805.45], loss:[1.42228], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0  9 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1460, score:[2774.55], loss:[1.55805], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 1 17 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1461, score:[2769.82], loss:[1.67918], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 2 15  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1462, score:[2791.27], loss:[1.68017], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 2  3 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1463, score:[2796.73], loss:[1.67968], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 1 19 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1464, score:[2610.18], loss:[2.07638], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 16 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1465, score:[2780.00], loss:[1.95767], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3  7 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1466, score:[2736.00], loss:[1.79821], sequence:[2], random actions:[36], eInit:[0.0100], init state:[3 9 5 0 0 0 0 0 0 0 0 0 0 0], end state:[5 9 5 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1467, score:[2750.91], loss:[1.74015], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 1  0 54  0  0  1  0  0  0  0  0  0  0  0], end state:[ 3  0 54  1  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1468, score:[2689.45], loss:[1.68337], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5  5 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1469, score:[2770.36], loss:[1.78633], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 2 16 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 16 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1470, score:[2761.27], loss:[1.71167], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 0  0 30  0  0  1  0  0  0  0  0  0  0  0], end state:[ 2  0 30  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1471, score:[2794.36], loss:[1.74804], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 2 22 15  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1472, score:[2780.00], loss:[1.64807], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 0 10 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1473, score:[2766.36], loss:[1.63245], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 6 20 31  1  1  0  0  0  0  0  0  1  0  0], end state:[ 1 20 31  0  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1474, score:[2761.09], loss:[1.51493], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 6  7 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1475, score:[2610.36], loss:[1.80809], sequence:[0], random actions:[45], eInit:[0.0100], init state:[ 4 17 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1476, score:[2785.27], loss:[1.71473], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 0 11 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1477, score:[2785.82], loss:[1.65351], sequence:[2], random actions:[28], eInit:[0.0100], init state:[0 1 6 0 0 1 0 0 0 0 0 0 0 0], end state:[2 1 6 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1478, score:[2726.18], loss:[1.64843], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 14  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1479, score:[2728.36], loss:[1.72457], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 19  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1480, score:[2774.55], loss:[1.61983], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1 18  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1481, score:[2706.00], loss:[1.66289], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6 18 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1482, score:[2782.36], loss:[1.51886], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 1  0 15  1  0  0  0  0  1  0  0  0  0  0], end state:[ 3  0 15  1  0  0  0  0  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 1483, score:[2796.00], loss:[1.50058], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 1 15 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1484, score:[2807.09], loss:[1.41138], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 0  4 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1485, score:[2803.64], loss:[1.25882], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 6  9 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1486, score:[2708.00], loss:[1.37092], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4  9 47  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1487, score:[2714.55], loss:[1.42043], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 18 33  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1488, score:[2763.45], loss:[1.29269], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 5 23 57  1  0  0  0  0  0  1  1  0  0  0], end state:[ 0 23 57  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1489, score:[2715.09], loss:[1.40856], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  6 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1490, score:[2751.27], loss:[1.31209], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2  4 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1491, score:[2733.82], loss:[1.35629], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4  5 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1492, score:[2697.64], loss:[1.67776], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 3 19 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 14  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1493, score:[2680.91], loss:[1.79357], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 14 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1494, score:[2773.45], loss:[1.55125], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  9 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  9 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1495, score:[2715.64], loss:[1.83027], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 0  7 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1496, score:[2788.73], loss:[1.69477], sequence:[1], random actions:[15], eInit:[0.0100], init state:[ 1  6 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1497, score:[2747.45], loss:[1.54564], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 5 19 32  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1498, score:[2771.82], loss:[1.64016], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 6 18 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1499, score:[2720.55], loss:[1.63137], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 6  0 47  0  0  1  0  0  0  0  0  0  0  0], end state:[ 1  0 47  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1500, score:[2758.18], loss:[1.82144], sequence:[1], random actions:[31], eInit:[0.0100], init state:[0 7 9 0 0 0 0 0 0 0 0 0 0 0], end state:[2 7 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1501, score:[2768.73], loss:[1.76865], sequence:[2], random actions:[29], eInit:[0.0100], init state:[6 2 4 0 0 0 0 0 0 0 0 0 0 0], end state:[1 2 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1502, score:[2758.00], loss:[1.90193], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 0 16 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1503, score:[2684.18], loss:[2.09131], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 17 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1504, score:[2789.82], loss:[1.93343], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0  7 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1505, score:[2759.09], loss:[2.00802], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 6 11 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1506, score:[2742.18], loss:[2.01203], sequence:[3], random actions:[29], eInit:[0.0100], init state:[6 2 4 0 0 0 0 0 0 0 0 0 0 0], end state:[1 2 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1507, score:[2763.09], loss:[1.86153], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 4  3 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1508, score:[2804.91], loss:[1.84383], sequence:[5], random actions:[20], eInit:[0.0100], init state:[ 6 15 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1509, score:[2753.64], loss:[1.72029], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 6 23 28  1  0  0  1  0  0  1  1  0  0  1], end state:[ 1 23 28  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1510, score:[2807.45], loss:[1.57644], sequence:[7], random actions:[20], eInit:[0.0100], init state:[ 1 12 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1511, score:[2657.82], loss:[1.68626], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  4 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  4 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1512, score:[2798.91], loss:[1.63283], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0 18 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1513, score:[2823.82], loss:[1.44529], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 23 50  1  0  0  0  0  0  1  1  0  0  0], end state:[ 2 23 50  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1514, score:[2750.55], loss:[1.49140], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 5 10 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10 36  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1515, score:[2821.64], loss:[1.37580], sequence:[4], random actions:[19], eInit:[0.0100], init state:[ 0 11 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1516, score:[2795.64], loss:[1.48437], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 0 17 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1517, score:[2805.09], loss:[1.48031], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 1 23 18  1  0  0  1  0  0  1  1  0  0  1], end state:[ 3 23 18  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1518, score:[2827.27], loss:[1.29266], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 0 15 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1519, score:[2653.64], loss:[1.55228], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 18  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18  9  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1520, score:[2810.00], loss:[1.41122], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 0  9 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1521, score:[2749.45], loss:[1.52375], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 6  7 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1522, score:[2775.45], loss:[1.51080], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 0  0 11  1  0  0  0  0  1  1  1  0  0  0], end state:[ 2  0 11  0  0  0  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1523, score:[2802.91], loss:[1.42579], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 1 14 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1524, score:[2718.55], loss:[1.45868], sequence:[0], random actions:[28], eInit:[0.0100], init state:[4 9 0 0 0 0 0 0 0 0 0 0 0 0], end state:[6 9 0 0 0 0 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1525, score:[2657.64], loss:[1.56297], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 14  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1526, score:[2799.82], loss:[1.63485], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0  6 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  6 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1527, score:[2694.73], loss:[1.70088], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 4  0 59  1  0  1  0  0  0  0  0  0  0  0], end state:[ 6  0 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1528, score:[2783.64], loss:[1.66160], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  7 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1529, score:[2772.18], loss:[1.66232], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 3 22 16  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 16  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1530, score:[2780.91], loss:[1.86176], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 0 12 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1531, score:[2702.73], loss:[1.84931], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 2 21 43  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 21 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1532, score:[2725.27], loss:[1.74971], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4  4 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1533, score:[2680.55], loss:[1.96759], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  8 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 40  1  1  0  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1534, score:[2664.00], loss:[2.15902], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4 21 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 25  1  1  0  0  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1535, score:[2763.45], loss:[2.23689], sequence:[1], random actions:[29], eInit:[0.0100], init state:[3 1 3 0 0 1 0 0 0 0 0 0 0 0], end state:[5 1 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1536, score:[2757.64], loss:[2.35673], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 6 23  0  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 23  0  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1537, score:[2649.27], loss:[2.43647], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 16 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1538, score:[2811.45], loss:[2.30421], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1  3 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1539, score:[2746.91], loss:[2.14112], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 4 23  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23  1  1  0  0  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1540, score:[2706.73], loss:[2.22146], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  1 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  1 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1541, score:[2783.45], loss:[2.31507], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1 11 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1542, score:[2734.00], loss:[2.39127], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 0 15 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1543, score:[2783.27], loss:[2.18689], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3 18 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 25  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1544, score:[2737.82], loss:[2.21383], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 6  6 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1545, score:[2806.00], loss:[2.10496], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 1 10 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1546, score:[2710.73], loss:[2.16021], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3  5 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1547, score:[2745.09], loss:[2.12407], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 3  7 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1548, score:[2763.64], loss:[2.24845], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 6 15 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1549, score:[2712.18], loss:[2.47514], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 13 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1550, score:[2656.00], loss:[2.57763], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 15 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1551, score:[2727.64], loss:[2.52351], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 1 14 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1552, score:[2620.91], loss:[2.39989], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4 22 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22 15  0  1  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1553, score:[2738.36], loss:[2.40785], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3  0 38  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 38  0  0  0  1  0  0  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1554, score:[2689.64], loss:[2.45647], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6  4 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1555, score:[2760.18], loss:[2.32407], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 1 15  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1556, score:[2773.82], loss:[2.18933], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2 18 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1557, score:[2752.36], loss:[2.25878], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 0 15 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1558, score:[2676.00], loss:[2.33578], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 16 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1559, score:[2692.91], loss:[2.63762], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6  5 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  5 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1560, score:[2725.27], loss:[2.54074], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4 12  4  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1561, score:[2790.55], loss:[2.55235], sequence:[1], random actions:[27], eInit:[0.0100], init state:[1 7 2 0 0 0 0 0 0 0 0 0 0 0], end state:[3 7 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1562, score:[2652.18], loss:[2.67680], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5  4 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  4 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1563, score:[2782.73], loss:[2.58340], sequence:[1], random actions:[28], eInit:[0.0100], init state:[6 9 3 0 0 0 0 0 0 0 0 0 0 0], end state:[1 9 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1564, score:[2784.91], loss:[2.28192], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 1 15 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1565, score:[2803.82], loss:[2.25257], sequence:[3], random actions:[28], eInit:[0.0100], init state:[1 5 9 0 0 0 0 0 0 0 0 0 0 0], end state:[3 5 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1566, score:[2679.45], loss:[2.41950], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6  2 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  2 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1567, score:[2764.00], loss:[2.30756], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 0  8 21  1  0  0  0  0  0  0  0  0  0  0], end state:[ 2  8 21  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1568, score:[2732.00], loss:[2.44278], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 3 22 53  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 53  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1569, score:[2758.00], loss:[2.23632], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3  3 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1570, score:[2730.91], loss:[2.27847], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 20 43  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 43  1  1  0  0  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1571, score:[2705.64], loss:[2.28474], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3  3 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1572, score:[2761.82], loss:[2.35618], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1  7 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1573, score:[2702.36], loss:[2.35771], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  4 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  4 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1574, score:[2811.82], loss:[2.25983], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 2 10 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 10 13  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1575, score:[2738.00], loss:[2.19547], sequence:[2], random actions:[39], eInit:[0.0100], init state:[ 0 13  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1576, score:[2801.45], loss:[2.10432], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 3 14 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1577, score:[2748.00], loss:[1.90095], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 4  8 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 25  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1578, score:[2673.82], loss:[2.11297], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 18  2  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1579, score:[2761.27], loss:[2.16143], sequence:[1], random actions:[37], eInit:[0.0100], init state:[ 0 23 13  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 23 13  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1580, score:[2792.18], loss:[1.96330], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 3  3 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1581, score:[2696.91], loss:[2.07495], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2  3 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1582, score:[2798.91], loss:[2.22430], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  2 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1583, score:[2786.18], loss:[2.19308], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0  7 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1584, score:[2768.36], loss:[2.15600], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 6 15 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1585, score:[2740.73], loss:[2.17529], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 6  8 48  1  1  0  0  0  0  0  0  0  0  0], end state:[ 1  8 48  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1586, score:[2802.18], loss:[2.07825], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 2 15 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1587, score:[2764.55], loss:[2.09760], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 6  3 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 18  0  0  0  0  0  1  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1588, score:[2794.91], loss:[2.16565], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 0 13 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1589, score:[2686.55], loss:[2.21609], sequence:[0], random actions:[31], eInit:[0.0100], init state:[5 0 7 0 0 0 0 0 0 0 0 0 0 0], end state:[0 0 7 1 0 0 0 0 1 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 1590, score:[2791.82], loss:[2.20719], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2 22 48  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1591, score:[2778.91], loss:[2.25305], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 17  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1592, score:[2789.27], loss:[2.06608], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 3  7 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1593, score:[2759.82], loss:[2.20971], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2 22 24  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1594, score:[2755.27], loss:[2.46518], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 6  6 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1595, score:[2759.82], loss:[2.33830], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 6 12  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1596, score:[2799.27], loss:[2.20566], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 1 17 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1597, score:[2761.82], loss:[2.21664], sequence:[8], random actions:[24], eInit:[0.0100], init state:[ 3 18 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 30  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1598, score:[2819.64], loss:[2.29025], sequence:[9], random actions:[21], eInit:[0.0100], init state:[ 0 14 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1599, score:[2757.45], loss:[1.91758], sequence:[10], random actions:[35], eInit:[0.0100], init state:[ 2 15 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1600, score:[2792.73], loss:[1.85530], sequence:[11], random actions:[34], eInit:[0.0100], init state:[ 0 18  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066])
INFO:Reinforcement.Functions:episode: 1601, score:[2777.82], loss:[1.87581], sequence:[12], random actions:[25], eInit:[0.0100], init state:[ 3 11 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1602, score:[2790.00], loss:[1.90671], sequence:[13], random actions:[20], eInit:[0.0100], init state:[ 0 18 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1603, score:[2799.45], loss:[1.86463], sequence:[14], random actions:[31], eInit:[0.0100], init state:[ 1 21  4  1  1  0  1  0  0  1  1  0  0  1], end state:[ 3 21  4  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1604, score:[2761.64], loss:[1.89399], sequence:[15], random actions:[38], eInit:[0.0100], init state:[ 2 23 10  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 23 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1605, score:[2742.00], loss:[2.01450], sequence:[16], random actions:[29], eInit:[0.0100], init state:[ 4 16 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1606, score:[2721.82], loss:[2.14635], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4 22 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22 30  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1607, score:[2795.27], loss:[2.16937], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 10 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 34  1  0  0  1  0  1  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1608, score:[2803.27], loss:[2.16129], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 2 11 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11 35  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1609, score:[2799.27], loss:[2.10522], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1 16 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1610, score:[2757.09], loss:[2.02980], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 4  4 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1611, score:[2760.00], loss:[2.35471], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 2 17 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1612, score:[2787.64], loss:[2.18666], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 1 12 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1613, score:[2773.27], loss:[2.14106], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 1  2 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1614, score:[2737.45], loss:[2.27481], sequence:[8], random actions:[42], eInit:[0.0100], init state:[ 2 11  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11  2  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1615, score:[2730.55], loss:[2.44161], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 19 26  1  0  0  1  0  0  0  0  0  0  0], end state:[ 0 19 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1616, score:[2750.00], loss:[2.33686], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3 10 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1617, score:[2650.00], loss:[2.70269], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5  6 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1618, score:[2728.91], loss:[2.81274], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 4 19 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1619, score:[2670.00], loss:[2.79563], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  2 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  2 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1620, score:[2772.00], loss:[2.81433], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 4  4 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 26  1  1  0  1  1  0  0  0  1  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1621, score:[2808.36], loss:[2.71601], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 1  7 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1622, score:[2773.27], loss:[2.75213], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 0 18  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1623, score:[2820.00], loss:[2.55201], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 2  4 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1624, score:[2735.27], loss:[2.46298], sequence:[0], random actions:[27], eInit:[0.0100], init state:[5 6 6 0 0 0 0 0 0 0 0 0 0 0], end state:[0 6 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1625, score:[2774.73], loss:[2.56748], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3  4 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1626, score:[2692.18], loss:[2.68727], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 23  5  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 23  5  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1627, score:[2772.36], loss:[2.81632], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 3 17 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1628, score:[2702.91], loss:[2.69227], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5  5 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1629, score:[2758.36], loss:[2.87095], sequence:[1], random actions:[31], eInit:[0.0100], init state:[1 0 3 1 0 0 0 0 0 1 1 0 0 0], end state:[3 0 3 1 0 0 0 0 0 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 1630, score:[2791.27], loss:[2.95131], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 23 42  1  0  0  1  0  0  1  1  0  0  0], end state:[ 2 23 42  0  0  0  0  0  0  1  0  1  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1631, score:[2712.55], loss:[2.99362], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  8 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  8 35  0  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1632, score:[2768.00], loss:[3.04654], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3  8 20  1  0  0  0  0  0  0  0  0  0  0], end state:[ 5  8 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1633, score:[2788.36], loss:[2.94849], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0  5 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1634, score:[2785.45], loss:[2.98936], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 6 23  7  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 23  7  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1635, score:[2746.91], loss:[3.13841], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 2  8 46  1  1  0  0  0  0  0  0  0  0  0], end state:[ 4  8 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1636, score:[2805.27], loss:[3.34338], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 3 14 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1637, score:[2658.55], loss:[3.22137], sequence:[0], random actions:[28], eInit:[0.0100], init state:[4 8 2 0 0 0 0 0 0 0 0 0 0 0], end state:[6 8 2 1 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1638, score:[2728.73], loss:[3.17712], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 2 21  0  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1639, score:[2773.64], loss:[3.26547], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 19 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1640, score:[2752.00], loss:[3.14548], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 2 15 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 15 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1641, score:[2760.55], loss:[3.34063], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 5 10 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1642, score:[2805.09], loss:[3.30052], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 1 22  7  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22  7  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1643, score:[2727.45], loss:[3.32217], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 5 12 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1644, score:[2769.45], loss:[3.31134], sequence:[1], random actions:[25], eInit:[0.0100], init state:[1 1 4 0 0 1 0 0 0 0 0 0 0 0], end state:[3 1 4 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1645, score:[2773.27], loss:[3.28995], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 3  4 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1646, score:[2689.45], loss:[3.57869], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 5  6 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1647, score:[2814.36], loss:[3.45560], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3 15  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1648, score:[2722.18], loss:[3.42507], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6  3 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1649, score:[2762.36], loss:[3.42123], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 6 15 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1650, score:[2750.73], loss:[3.65474], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 4  4 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1651, score:[2693.09], loss:[3.67191], sequence:[0], random actions:[32], eInit:[0.0100], init state:[5 1 9 0 0 0 0 0 0 0 0 0 0 0], end state:[0 1 9 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1652, score:[2742.36], loss:[3.69432], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 5 14 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1653, score:[2762.18], loss:[3.60896], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 10 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1654, score:[2748.55], loss:[3.54281], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 2 21 39  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 21 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1655, score:[2796.55], loss:[3.69736], sequence:[4], random actions:[17], eInit:[0.0100], init state:[ 0  7 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1656, score:[2731.82], loss:[3.63176], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  4 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1657, score:[2786.36], loss:[3.58157], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3  4 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1658, score:[2753.82], loss:[3.45358], sequence:[2], random actions:[23], eInit:[0.0100], init state:[6 3 4 0 0 0 0 0 0 0 0 0 0 0], end state:[1 3 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1659, score:[2799.27], loss:[3.34541], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 3  0 54  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1660, score:[2661.09], loss:[3.55707], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 18 13  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1661, score:[2713.27], loss:[3.94742], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  4 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1662, score:[2805.09], loss:[4.04788], sequence:[1], random actions:[25], eInit:[0.0100], init state:[0 9 2 0 0 0 0 0 0 0 0 0 0 0], end state:[2 9 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1663, score:[2777.09], loss:[3.74857], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 2  0 24  1  0  0  0  0  1  0  0  0  0  0], end state:[ 4  0 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1664, score:[2796.73], loss:[3.51721], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 1 13 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1665, score:[2739.09], loss:[3.55310], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 4 20 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1666, score:[2757.64], loss:[3.41215], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 2  2 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1667, score:[2796.18], loss:[3.50971], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 0 15 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1668, score:[2763.64], loss:[3.46350], sequence:[7], random actions:[19], eInit:[0.0100], init state:[ 4  7 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1669, score:[2806.18], loss:[3.30208], sequence:[8], random actions:[31], eInit:[0.0100], init state:[ 1  3 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1670, score:[2763.64], loss:[3.30754], sequence:[9], random actions:[32], eInit:[0.0100], init state:[ 1  8 55  1  1  0  0  0  0  0  0  0  0  0], end state:[ 3  8 55  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1671, score:[2706.91], loss:[3.35577], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 3  6 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  6 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1672, score:[2725.27], loss:[3.64301], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6 17 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 26  1  1  0  0  1  1  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1673, score:[2802.18], loss:[3.33397], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 0 21 43  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 43  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1674, score:[2770.18], loss:[3.35615], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2  9 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1675, score:[2682.91], loss:[3.42197], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  9 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1676, score:[2682.91], loss:[3.70797], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  8 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 48  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1677, score:[2798.91], loss:[3.75501], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1 15  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1678, score:[2738.91], loss:[3.63727], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 2 20  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1679, score:[2726.36], loss:[3.55648], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  1 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  1 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1680, score:[2766.00], loss:[3.71438], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6 21 36  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 21 36  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1681, score:[2775.64], loss:[4.08778], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3  9 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1682, score:[2768.36], loss:[4.16833], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 1 17 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1683, score:[2730.91], loss:[4.16569], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 2  3 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1684, score:[2742.91], loss:[4.33383], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 6 19 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1685, score:[2754.36], loss:[4.47525], sequence:[2], random actions:[39], eInit:[0.0100], init state:[ 0  9 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1686, score:[2775.45], loss:[4.41107], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 0 17  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1687, score:[2731.09], loss:[4.63035], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 4  1 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1688, score:[2811.09], loss:[4.63955], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0  2 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1689, score:[2741.27], loss:[4.47803], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 4 14 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1690, score:[2743.45], loss:[4.61439], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 1 22 16  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 16  0  0  0  0  0  0  0  0  1  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1691, score:[2751.27], loss:[4.72602], sequence:[4], random actions:[34], eInit:[0.0100], init state:[ 4  2 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1692, score:[2787.09], loss:[4.69213], sequence:[5], random actions:[16], eInit:[0.0100], init state:[ 6  8 45  1  1  0  0  0  0  0  0  0  0  0], end state:[ 1  8 45  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1693, score:[2679.82], loss:[4.61214], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  4 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1694, score:[2696.00], loss:[4.53895], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6 15 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 15 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1695, score:[2714.36], loss:[4.69073], sequence:[0], random actions:[43], eInit:[0.0100], init state:[ 2 10 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 10 50  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1696, score:[2692.00], loss:[4.80454], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5 10 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1697, score:[2728.91], loss:[4.61411], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 21 46  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 46  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1698, score:[2628.55], loss:[4.43997], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  2 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  2 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1699, score:[2765.09], loss:[4.41481], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 6  9 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1700, score:[2800.55], loss:[4.30274], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 0 22 53  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 53  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1701, score:[2743.45], loss:[4.19322], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 4 11 44  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1702, score:[2739.45], loss:[4.30943], sequence:[4], random actions:[32], eInit:[0.0100], init state:[6 6 8 0 0 0 0 0 0 0 0 0 0 0], end state:[1 6 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1703, score:[2764.91], loss:[4.24995], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 0  6 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  6 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1704, score:[2755.82], loss:[4.33719], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 2 14 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1705, score:[2781.82], loss:[4.31463], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 3  5 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1706, score:[2781.09], loss:[4.52751], sequence:[8], random actions:[32], eInit:[0.0100], init state:[ 3 15  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1707, score:[2756.00], loss:[4.39179], sequence:[9], random actions:[36], eInit:[0.0100], init state:[ 1 11 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1708, score:[2795.64], loss:[4.13674], sequence:[10], random actions:[27], eInit:[0.0100], init state:[ 1 15 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1709, score:[2674.36], loss:[4.57700], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  9 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1710, score:[2776.36], loss:[5.82554], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3 16 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1711, score:[2771.82], loss:[5.70167], sequence:[2], random actions:[28], eInit:[0.0100], init state:[2 4 0 0 0 0 0 0 0 0 0 0 0 0], end state:[4 4 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1712, score:[2801.09], loss:[5.34992], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 3 15 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1713, score:[2800.36], loss:[5.09744], sequence:[4], random actions:[22], eInit:[0.0100], init state:[2 6 0 0 0 0 0 0 0 0 0 0 0 0], end state:[4 6 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1714, score:[2790.00], loss:[5.17599], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 2 11 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 11 49  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1715, score:[2772.55], loss:[5.04722], sequence:[6], random actions:[33], eInit:[0.0100], init state:[ 3 16 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1716, score:[2675.09], loss:[5.17680], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5  7 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1717, score:[2676.18], loss:[5.90001], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 5 16 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1718, score:[2787.64], loss:[6.42968], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 3 10 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1719, score:[2772.73], loss:[6.38876], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0 23  0  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 23  0  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1720, score:[2742.36], loss:[6.52952], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 1 11 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1721, score:[2777.64], loss:[6.33634], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 2 20 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1722, score:[2678.91], loss:[5.81445], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5  3 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1723, score:[2731.45], loss:[5.56144], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 0 19 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1724, score:[2771.09], loss:[5.46731], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0  9 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1725, score:[2536.36], loss:[5.60410], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 10 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1726, score:[2722.18], loss:[6.15114], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6 10 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 48  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1727, score:[2756.18], loss:[5.84242], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 0 20 38  1  1  0  0  0  0  0  0  1  0  0], end state:[ 2 20 38  1  1  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1728, score:[2711.64], loss:[5.88571], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 6 10 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1729, score:[2731.45], loss:[5.71363], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5 11 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1730, score:[2701.09], loss:[5.87298], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 0 14  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1731, score:[2689.45], loss:[6.08241], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  0 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 36  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1732, score:[2731.82], loss:[6.43979], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 1  2 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1733, score:[2741.64], loss:[6.30279], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 5 17  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1734, score:[2789.27], loss:[6.02952], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 0 17 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 17 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1735, score:[2700.73], loss:[5.47395], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6  0 37  0  0  1  0  0  0  0  0  0  0  0], end state:[ 1  0 37  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1736, score:[2771.64], loss:[5.27189], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  0 17  1  0  0  0  0  1  0  0  0  0  0], end state:[ 3  0 17  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1737, score:[2829.82], loss:[5.22649], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 1 19 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 56  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1738, score:[2718.73], loss:[5.14001], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6  0 52  0  0  1  0  0  0  0  0  0  0  0], end state:[ 1  0 52  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1739, score:[2744.91], loss:[5.27565], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 2 14 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1740, score:[2763.09], loss:[5.41986], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1  2 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1741, score:[2775.82], loss:[5.33226], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 1 22  5  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22  5  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1742, score:[2728.36], loss:[5.47257], sequence:[0], random actions:[17], eInit:[0.0100], init state:[ 6 11 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1743, score:[2729.09], loss:[5.19100], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 5 10  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1744, score:[2689.09], loss:[5.33315], sequence:[0], random actions:[43], eInit:[0.0100], init state:[ 6  8 43  1  1  0  1  0  0  0  0  0  0  0], end state:[ 1  8 43  1  1  0  1  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1745, score:[2681.45], loss:[5.58096], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4  0 39  1  0  1  0  0  0  0  0  0  0  0], end state:[ 6  0 39  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1746, score:[2700.91], loss:[5.88712], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 14 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 14 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1747, score:[2773.27], loss:[5.77713], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 16 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1748, score:[2787.45], loss:[5.54041], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 23 34  1  0  0  1  0  0  1  1  0  0  0], end state:[ 4 23 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1749, score:[2808.73], loss:[5.36588], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 0 16 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1750, score:[2677.09], loss:[5.32305], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 21  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21  7  0  1  0  1  0  0  0  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1751, score:[2725.82], loss:[5.22844], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 2 14 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1752, score:[2778.91], loss:[5.15730], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 2 17 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1753, score:[2778.55], loss:[5.53519], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 21  5  1  1  0  1  1  0  1  1  0  0  1], end state:[ 2 21  5  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1754, score:[2760.73], loss:[5.61508], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 0  8 27  1  0  0  0  0  0  0  0  0  0  0], end state:[ 2  8 27  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1755, score:[2803.82], loss:[5.45425], sequence:[4], random actions:[28], eInit:[0.0100], init state:[0 8 4 1 0 0 0 0 0 0 0 0 0 0], end state:[2 8 4 1 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1756, score:[2721.27], loss:[4.98802], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 1 23 24  1  0  0  1  0  0  1  1  0  0  1], end state:[ 3 23 24  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1757, score:[2739.27], loss:[4.73460], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0  4 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  4 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1758, score:[2781.27], loss:[4.67144], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 1 13 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1759, score:[2804.18], loss:[4.25054], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 2  2 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1760, score:[2729.82], loss:[4.20185], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3  9 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1761, score:[2757.64], loss:[4.27781], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3 21 10  1  1  0  1  0  1  1  1  0  0  1], end state:[ 5 21 10  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1762, score:[2770.73], loss:[3.96752], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 4  1 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  1 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1763, score:[2683.82], loss:[4.22161], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 0 16 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1764, score:[2758.91], loss:[4.21499], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0 21 46  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 46  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1765, score:[2700.73], loss:[4.77860], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 11  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1766, score:[2686.55], loss:[4.93353], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 18 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 54  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1767, score:[2672.91], loss:[5.06387], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  3 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1768, score:[2722.18], loss:[5.18786], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5  0 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 58  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1769, score:[2744.18], loss:[5.44619], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  2 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  2 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1770, score:[2696.00], loss:[5.70795], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  2 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1771, score:[2714.55], loss:[5.59618], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 0  1 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1772, score:[2616.00], loss:[6.69853], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 18 42  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1773, score:[2732.73], loss:[7.15206], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 1 19 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1774, score:[2819.09], loss:[6.92670], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3 15 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1775, score:[2723.09], loss:[6.56371], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 16 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1776, score:[2765.82], loss:[6.79948], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2  2 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1777, score:[2793.82], loss:[6.52515], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2 20 37  1  1  0  0  0  0  0  0  1  0  0], end state:[ 4 20 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1778, score:[2669.09], loss:[6.68847], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 20 12  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1779, score:[2763.27], loss:[6.48540], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3  2 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1780, score:[2760.00], loss:[6.31910], sequence:[2], random actions:[40], eInit:[0.0100], init state:[ 1 16 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1781, score:[2751.64], loss:[6.26286], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 6 21 26  1  1  0  1  0  0  1  1  0  0  1], end state:[ 1 21 26  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1782, score:[2627.27], loss:[6.03671], sequence:[0], random actions:[34], eInit:[0.0100], init state:[5 5 4 0 0 0 0 0 0 0 0 0 0 0], end state:[0 5 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1783, score:[2695.45], loss:[5.79666], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 2  7 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1784, score:[2708.36], loss:[5.55670], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 20 30  1  1  0  0  0  0  0  0  0  1  0], end state:[ 5 20 30  0  1  0  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1785, score:[2720.55], loss:[5.25063], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  0 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 22  1  0  0  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1786, score:[2761.82], loss:[5.05066], sequence:[1], random actions:[28], eInit:[0.0100], init state:[0 1 7 0 0 1 0 0 0 0 0 0 0 0], end state:[2 1 7 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1787, score:[2752.55], loss:[4.88798], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 5  5 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1788, score:[2722.73], loss:[4.83125], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 16 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1789, score:[2753.82], loss:[4.45323], sequence:[1], random actions:[42], eInit:[0.0100], init state:[ 3 18 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 14  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1790, score:[2765.64], loss:[3.87770], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 1  8 47  1  1  0  0  0  0  0  0  0  0  0], end state:[ 3  8 47  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1791, score:[2678.00], loss:[3.88160], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 20 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 55  0  0  0  0  0  0  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1792, score:[2700.73], loss:[4.17894], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6 17 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1793, score:[2780.91], loss:[3.66036], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 2  1 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1794, score:[2724.00], loss:[3.92005], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5 12 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1795, score:[2741.82], loss:[3.72768], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 16  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 16  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1796, score:[2766.55], loss:[3.46079], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 6 18 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1797, score:[2743.45], loss:[3.57802], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 5 17 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1798, score:[2746.00], loss:[3.46826], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 3  2 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1799, score:[2796.55], loss:[3.80610], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 0 12  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1800, score:[2725.09], loss:[3.76766], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6 10 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1801, score:[2732.73], loss:[3.91375], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 4  3 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1802, score:[2734.00], loss:[3.86638], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 1  4 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1803, score:[2738.55], loss:[4.03209], sequence:[1], random actions:[27], eInit:[0.0100], init state:[1 6 0 0 0 0 0 0 0 0 0 0 0 0], end state:[3 6 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1804, score:[2790.91], loss:[4.09272], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0  1 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1805, score:[2633.27], loss:[4.20988], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4 22 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 22 39  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1806, score:[2790.00], loss:[4.28023], sequence:[1], random actions:[23], eInit:[0.0100], init state:[1 8 4 1 0 0 0 0 0 0 0 0 0 0], end state:[3 8 4 1 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1807, score:[2698.73], loss:[4.53638], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6  0 52  0  0  1  0  0  0  0  0  0  0  0], end state:[ 1  0 52  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1808, score:[2709.64], loss:[4.58519], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4 23 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 42  0  0  0  0  0  0  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1809, score:[2764.91], loss:[4.38600], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 2  4 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1810, score:[2637.45], loss:[4.88145], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6 10 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1811, score:[2801.27], loss:[5.99223], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0 15 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1812, score:[2758.73], loss:[4.54845], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 4  4 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  4 34  0  0  0  0  0  0  0  0  1  0  1]
INFO:Reinforcement.Functions:episode: 1813, score:[2731.09], loss:[4.41164], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 10 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 10 25  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1814, score:[2773.45], loss:[4.42337], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 10 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1815, score:[2816.55], loss:[4.41417], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 3 14 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1816, score:[2675.82], loss:[4.90897], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6 19 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1817, score:[2751.27], loss:[4.69400], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0  8 28  1  0  0  0  0  0  0  0  0  0  0], end state:[ 2  8 28  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1818, score:[2758.73], loss:[4.82398], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 5 16 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1819, score:[2690.00], loss:[4.86633], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 21 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 58  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1820, score:[2743.45], loss:[5.08652], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 0 22 33  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 22 33  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1821, score:[2707.09], loss:[5.42227], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 4 14 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1822, score:[2550.91], loss:[6.23096], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 5  9 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1823, score:[2779.64], loss:[6.50455], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 6 23 27  1  0  0  1  0  0  1  1  0  0  1], end state:[ 1 23 27  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1824, score:[2771.82], loss:[6.50692], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 3  3 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  3 24  0  0  1  0  1  0  1  1  1  1  1]
INFO:Reinforcement.Functions:episode: 1825, score:[2718.55], loss:[6.54834], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 18 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 15  0  0  0  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1826, score:[2733.09], loss:[6.36067], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 1 22  6  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22  6  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1827, score:[2691.09], loss:[6.25097], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 15 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1828, score:[2780.00], loss:[5.89444], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0 18 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1829, score:[2748.00], loss:[5.81235], sequence:[2], random actions:[39], eInit:[0.0100], init state:[ 4 18 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1830, score:[2731.27], loss:[5.73508], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 10  2  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1831, score:[2797.64], loss:[5.89237], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 6 20 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 20 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1832, score:[2786.73], loss:[5.83327], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1  6 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1833, score:[2740.36], loss:[5.50009], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 6 11  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1834, score:[2732.73], loss:[5.44614], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  5 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1835, score:[2793.64], loss:[5.32152], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 6  3 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1836, score:[2808.00], loss:[5.02230], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 2 22 44  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1837, score:[2733.82], loss:[5.08092], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 17 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1838, score:[2721.09], loss:[5.08656], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 20  6  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1839, score:[2746.73], loss:[4.70579], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 2  2 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1840, score:[2724.18], loss:[4.12193], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 20 53  1  1  0  1  0  0  1  1  1  0  0], end state:[ 5 20 53  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1841, score:[2809.09], loss:[3.82923], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3 19 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 48  0  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1842, score:[2683.64], loss:[4.16925], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 0 18 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1843, score:[2743.45], loss:[4.05123], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3 10 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 10 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1844, score:[2767.09], loss:[3.75725], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 0 18  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1845, score:[2736.91], loss:[3.60182], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 3  6 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  6 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1846, score:[2703.09], loss:[4.08321], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 21  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21  1  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1847, score:[2726.73], loss:[4.05547], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 10 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 10 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1848, score:[2737.82], loss:[4.15205], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 3  6 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  6 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1849, score:[2826.91], loss:[4.05572], sequence:[2], random actions:[19], eInit:[0.0100], init state:[3 3 2 0 0 0 0 0 0 0 0 0 0 0], end state:[5 3 2 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1850, score:[2773.45], loss:[4.00386], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 3 16 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1851, score:[2760.73], loss:[3.93369], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 2  1 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1852, score:[2740.00], loss:[4.08843], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 1  3 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1853, score:[2718.55], loss:[4.32782], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 13  0  1  1  0  1  0  0  0  0  0  0  0], end state:[ 6 13  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1854, score:[2757.64], loss:[4.38475], sequence:[1], random actions:[42], eInit:[0.0100], init state:[ 1  8 30  1  1  0  1  1  0  0  0  0  0  0], end state:[ 3  8 30  1  1  0  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1855, score:[2759.45], loss:[4.36978], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 0  6 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  6 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1856, score:[2797.09], loss:[4.31968], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 1  3 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1857, score:[2775.45], loss:[4.25385], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2 23 40  1  0  0  1  0  0  1  1  0  0  0], end state:[ 4 23 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1858, score:[2660.18], loss:[4.37903], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 17 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1859, score:[2676.00], loss:[4.36532], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2 23 23  1  0  0  1  0  0  1  1  0  0  1], end state:[ 4 23 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1860, score:[2732.18], loss:[4.43730], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 3 16 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1861, score:[2783.27], loss:[4.30569], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0 20 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 20 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1862, score:[2783.82], loss:[4.28541], sequence:[2], random actions:[32], eInit:[0.0100], init state:[2 7 8 0 0 0 0 0 0 0 0 0 0 0], end state:[4 7 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1863, score:[2807.45], loss:[4.29577], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 1  1 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1864, score:[2770.91], loss:[4.40516], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 3  8 52  1  1  0  0  0  0  0  0  0  0  0], end state:[ 5  8 52  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1865, score:[2715.45], loss:[4.38780], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 16  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1866, score:[2763.45], loss:[4.41517], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 6  8 30  1  1  0  1  1  0  0  0  0  0  0], end state:[ 1  8 30  1  1  0  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1867, score:[2748.91], loss:[4.54970], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 6 20 37  1  1  0  0  0  0  0  0  1  0  0], end state:[ 1 20 37  1  1  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1868, score:[2770.00], loss:[4.72442], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 6 22  2  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22  2  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1869, score:[2738.55], loss:[4.87119], sequence:[4], random actions:[27], eInit:[0.0100], init state:[4 6 3 0 0 0 0 0 0 0 0 0 0 0], end state:[6 6 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1870, score:[2814.55], loss:[4.58092], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 1  4 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1871, score:[2781.64], loss:[4.65211], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 6 22 14  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 14  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1872, score:[2766.91], loss:[4.94219], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 6  5 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  5 47  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1873, score:[2789.64], loss:[4.60152], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 3 18 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1874, score:[2774.36], loss:[4.87608], sequence:[9], random actions:[35], eInit:[0.0100], init state:[ 3 12 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 12 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1875, score:[2715.09], loss:[4.92600], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 18 12  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1876, score:[2812.55], loss:[4.45701], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 2  5 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  5 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1877, score:[2793.64], loss:[4.27572], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 1 14 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1878, score:[2691.45], loss:[4.38753], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 23 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 23 38  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1879, score:[2782.55], loss:[4.72664], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 4 13 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 13 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1880, score:[2800.91], loss:[4.51934], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0  5 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  5 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1881, score:[2747.09], loss:[4.59259], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 4 10 52  1  1  0  1  0  0  0  0  0  0  0], end state:[ 6 10 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1882, score:[2784.73], loss:[4.53577], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 4 14 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 14 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1883, score:[2769.09], loss:[4.42294], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 0 11 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1884, score:[2826.00], loss:[4.36635], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 1  8 31  1  1  0  1  1  0  0  0  0  0  0], end state:[ 3  8 31  1  1  0  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1885, score:[2669.27], loss:[4.65203], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6  6 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  6 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1886, score:[2744.55], loss:[5.53624], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 1  7 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  7 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1887, score:[2767.45], loss:[4.94760], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 18 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 18 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1888, score:[2714.73], loss:[5.07832], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  0 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  0 51  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1889, score:[2750.00], loss:[5.22615], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 5  8 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 42  1  1  0  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1890, score:[2610.91], loss:[5.06193], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4 18 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1891, score:[2650.18], loss:[5.15253], sequence:[0], random actions:[26], eInit:[0.0100], init state:[5 3 6 0 0 0 0 0 0 0 0 0 0 0], end state:[0 3 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1892, score:[2768.73], loss:[5.61872], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0  2 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1893, score:[2760.00], loss:[5.87442], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 0 13 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1894, score:[2768.18], loss:[5.83151], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 3 20 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 20 21  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1895, score:[2650.91], loss:[5.98985], sequence:[0], random actions:[43], eInit:[0.0100], init state:[ 6  4 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1896, score:[2780.91], loss:[5.91701], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2  2 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1897, score:[2749.09], loss:[6.16290], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 3  4 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1898, score:[2710.91], loss:[6.26747], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 22 42  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 22 42  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1899, score:[2753.09], loss:[6.57390], sequence:[1], random actions:[33], eInit:[0.0100], init state:[6 8 3 1 0 0 0 0 0 0 0 0 0 0], end state:[1 8 3 1 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1900, score:[2804.00], loss:[6.45059], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 3  5 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1901, score:[2650.55], loss:[6.43441], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5  4 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  4 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1902, score:[2711.09], loss:[7.02254], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6  3 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1903, score:[2782.73], loss:[6.77986], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 6 11 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1904, score:[2758.18], loss:[6.78200], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 3 19 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 55  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1905, score:[2706.91], loss:[6.97699], sequence:[0], random actions:[23], eInit:[0.0100], init state:[6 1 0 0 0 1 0 0 0 0 0 0 0 0], end state:[1 1 0 0 0 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1906, score:[2813.45], loss:[6.87573], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1 15 48  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 48  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1907, score:[2781.45], loss:[6.97193], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1 13 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 13 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1908, score:[2778.00], loss:[6.84052], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 6 19  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1909, score:[2769.64], loss:[6.65345], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 6  0 34  0  0  1  0  0  0  0  0  0  0  0], end state:[ 1  0 34  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1910, score:[2775.82], loss:[5.96915], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 0 20 55  1  1  0  1  0  0  1  1  0  0  0], end state:[ 2 20 55  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1911, score:[2758.00], loss:[5.85778], sequence:[6], random actions:[25], eInit:[0.0100], init state:[ 2  4 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1912, score:[2767.45], loss:[5.77591], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 6  9 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1913, score:[2696.91], loss:[5.70296], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 17  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 17  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1914, score:[2715.27], loss:[5.78176], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 1 18 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1915, score:[2699.64], loss:[5.55384], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4 11 40  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1916, score:[2746.00], loss:[5.57865], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 5  3 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  3 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1917, score:[2732.73], loss:[5.56923], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 0  1 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  1 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1918, score:[2597.09], loss:[6.02283], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 23 33  1  0  0  0  0  0  1  1  0  0  0], end state:[ 0 23 33  0  1  0  0  0  0  0  1  1  1  0]
INFO:Reinforcement.Functions:episode: 1919, score:[2777.45], loss:[6.93922], sequence:[1], random actions:[30], eInit:[0.0100], init state:[4 6 8 0 0 0 0 0 0 0 0 0 0 0], end state:[6 6 8 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1920, score:[2805.45], loss:[6.74154], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 0 20  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 20  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1921, score:[2730.18], loss:[6.86839], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5  7 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  7 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1922, score:[2666.18], loss:[6.80563], sequence:[0], random actions:[24], eInit:[0.0100], init state:[3 0 9 1 0 0 0 0 1 1 1 0 0 0], end state:[5 0 9 1 0 0 1 0 1 1 1 0 0 0]
INFO:Reinforcement.Functions:episode: 1923, score:[2776.00], loss:[7.24601], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 1 16  4  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1924, score:[2626.55], loss:[7.59231], sequence:[0], random actions:[43], eInit:[0.0100], init state:[ 4 17 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1925, score:[2745.82], loss:[7.72830], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6 14 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1926, score:[2729.27], loss:[7.50192], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 3  2 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 57  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1927, score:[2624.91], loss:[8.75348], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 2 12 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 15  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1928, score:[2743.09], loss:[8.81995], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 1 10 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1929, score:[2701.27], loss:[8.91036], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 2  6 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 13  0  0  0  0  0  1  1  0  1  1  0]
INFO:Reinforcement.Functions:episode: 1930, score:[2736.00], loss:[9.38996], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 2 12 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 29  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1931, score:[2699.82], loss:[9.81591], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  7 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1932, score:[2733.45], loss:[9.80004], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 2 17  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1933, score:[2779.27], loss:[9.57231], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1 17 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 17 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1934, score:[2769.27], loss:[9.54480], sequence:[2], random actions:[25], eInit:[0.0100], init state:[2 8 4 1 0 0 0 0 0 0 0 0 0 0], end state:[4 8 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1935, score:[2757.45], loss:[9.32409], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 3 18 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 59  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1936, score:[2757.45], loss:[8.63904], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 0  7 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  7 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1937, score:[2799.09], loss:[8.13714], sequence:[5], random actions:[19], eInit:[0.0100], init state:[ 0 13 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1938, score:[2754.73], loss:[8.06984], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 3 16 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1939, score:[2731.27], loss:[7.99579], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2  6 12  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  6 12  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1940, score:[2737.82], loss:[8.10165], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2 21 20  1  1  0  1  0  0  1  1  0  0  1], end state:[ 4 21 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1941, score:[2769.64], loss:[7.92939], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 4  9 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1942, score:[2721.45], loss:[7.68637], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 0 20  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 20  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1943, score:[2803.09], loss:[7.53921], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2  9 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 44  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1944, score:[2772.73], loss:[6.81602], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 12  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1945, score:[2704.36], loss:[5.77512], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 10 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1946, score:[2745.27], loss:[5.81175], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 5 23 57  1  0  0  0  0  0  1  1  0  0  0], end state:[ 0 23 57  1  0  0  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1947, score:[2817.45], loss:[5.39963], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 6 23  4  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 23  4  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1948, score:[2728.18], loss:[5.26711], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 5  5 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  5 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1949, score:[2773.45], loss:[4.99241], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2  8 14  1  0  0  0  0  0  0  0  0  0  0], end state:[ 4  8 14  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1950, score:[2728.00], loss:[5.17277], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6 14 13  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 14 13  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1951, score:[2806.36], loss:[4.93408], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 2 22 17  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1952, score:[2706.73], loss:[4.86870], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 5 13 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1953, score:[2789.45], loss:[4.99495], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3  8 18  1  0  0  0  0  0  0  0  0  0  0], end state:[ 5  8 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1954, score:[2670.55], loss:[5.45012], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6 12 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1955, score:[2674.36], loss:[5.99567], sequence:[0], random actions:[33], eInit:[0.0100], init state:[2 5 7 0 0 0 0 0 0 0 0 0 0 0], end state:[4 5 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1956, score:[2795.09], loss:[5.87130], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1 15 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1957, score:[2717.45], loss:[5.83974], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2  1 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1958, score:[2632.18], loss:[6.12060], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6 17  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1959, score:[2712.55], loss:[6.08163], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 12 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 53  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1960, score:[2752.91], loss:[6.15952], sequence:[1], random actions:[37], eInit:[0.0100], init state:[ 2 22 28  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1961, score:[2757.45], loss:[6.33267], sequence:[2], random actions:[33], eInit:[0.0100], init state:[4 1 3 0 0 1 0 0 0 0 0 0 0 0], end state:[6 1 3 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1962, score:[2746.73], loss:[6.18861], sequence:[3], random actions:[29], eInit:[0.0100], init state:[2 7 1 0 0 0 0 0 0 0 0 0 0 0], end state:[4 7 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1963, score:[2669.27], loss:[6.34983], sequence:[0], random actions:[48], eInit:[0.0100], init state:[ 6  9 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1964, score:[2782.36], loss:[6.66318], sequence:[1], random actions:[40], eInit:[0.0100], init state:[ 1 21 42  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 21 42  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1965, score:[2276.36], loss:[7.21788], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2 23 51  1  0  0  0  0  0  1  1  0  0  0], end state:[ 4 23 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1966, score:[2822.00], loss:[11.38414], sequence:[1], random actions:[20], eInit:[0.0100], init state:[1 3 1 0 0 0 0 0 0 0 0 0 0 0], end state:[3 3 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1967, score:[2772.91], loss:[10.95715], sequence:[2], random actions:[21], eInit:[0.0100], init state:[6 6 9 0 0 0 0 0 0 0 0 0 0 0], end state:[1 6 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1968, score:[2614.00], loss:[10.81901], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 23  7  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 23  7  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1969, score:[2746.18], loss:[10.41741], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 3 20 55  1  1  0  1  0  0  1  1  0  0  0], end state:[ 5 20 55  0  0  1  0  1  0  0  0  1  0  1]
INFO:Reinforcement.Functions:episode: 1970, score:[2722.00], loss:[10.26112], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 2  3 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1971, score:[2711.45], loss:[9.72824], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 4 21 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 39  1  0  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1972, score:[2787.64], loss:[9.31602], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 20  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1973, score:[2774.73], loss:[9.02816], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 2 19 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19 24  0  1  0  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1974, score:[2769.09], loss:[8.80127], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 2 17  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1975, score:[2760.36], loss:[8.63033], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 3  0 55  0  0  1  0  0  0  0  0  0  0  0], end state:[ 5  0 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1976, score:[2742.00], loss:[8.71775], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 6 17 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 17 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1977, score:[2784.55], loss:[8.45963], sequence:[6], random actions:[19], eInit:[0.0100], init state:[ 3 16 37  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 37  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1978, score:[2644.55], loss:[9.22185], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 20 55  1  0  0  0  0  0  0  0  0  0  0], end state:[ 0 20 55  1  1  0  1  0  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1979, score:[2727.82], loss:[9.13702], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 21 10  1  0  0  1  0  0  1  1  0  0  1], end state:[ 0 21 10  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1980, score:[2770.00], loss:[9.13343], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 6 18 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 18 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1981, score:[2804.73], loss:[8.42686], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 0  9 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  9 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1982, score:[2682.91], loss:[7.97065], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 19 35  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1983, score:[2662.18], loss:[6.45992], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4 17 15  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 15  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1984, score:[2634.00], loss:[6.33758], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 15 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15 43  1  0  0  1  1  1  1  1  1  1  1]
INFO:Reinforcement.Functions:episode: 1985, score:[2737.09], loss:[6.55761], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 5 16 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 16 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1986, score:[2683.45], loss:[6.71115], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 17 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1987, score:[2739.45], loss:[7.02348], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 16  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 16  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1988, score:[2778.73], loss:[7.02824], sequence:[2], random actions:[35], eInit:[0.0100], init state:[1 2 6 0 0 0 0 0 0 0 0 0 0 0], end state:[3 2 6 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1989, score:[2707.27], loss:[7.03517], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 14 18  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 14 18  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1990, score:[2766.91], loss:[7.12798], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0 18 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 1991, score:[2773.64], loss:[7.19687], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 2 20 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 20 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1992, score:[2802.73], loss:[7.20652], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 1 21 48  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 21 48  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1993, score:[2786.36], loss:[7.09609], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 1 18  6  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18  6  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1994, score:[2657.09], loss:[7.59430], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4 18  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1995, score:[2764.18], loss:[7.30614], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 21 35  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 35  1  1  0  1  1  1  1  1  1  0  1]
INFO:Reinforcement.Functions:episode: 1996, score:[2756.18], loss:[7.47573], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 4 16 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 16 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1997, score:[2786.36], loss:[7.03247], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 3 11 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 11 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1998, score:[2778.73], loss:[6.94832], sequence:[4], random actions:[37], eInit:[0.0100], init state:[ 1 15 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1999, score:[2648.00], loss:[7.05849], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  8 46  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 46  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2000, score:[2668.73], loss:[8.46220], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 18 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 43  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2001, score:[2709.27], loss:[8.11909], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  8 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  8 39  1  1  0  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2002, score:[2690.36], loss:[7.86688], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 1 20 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 20 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2003, score:[2782.00], loss:[7.61948], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 3 18 56  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 18 56  1  1  0  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2004, score:[2748.91], loss:[7.17523], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1 22 34  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 34  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2005, score:[2772.91], loss:[6.96666], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 2  5 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  5 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2006, score:[2685.09], loss:[7.02480], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  7 57  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  7 57  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2007, score:[2796.18], loss:[6.99394], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 3 15 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2008, score:[2754.36], loss:[6.72258], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 5 18 45  1  1  0  1  0  0  0  0  1  0  0], end state:[ 0 18 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2009, score:[2752.73], loss:[6.52982], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 1 22 46  1  0  0  0  0  0  1  1  0  0  1], end state:[ 3 22 46  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2010, score:[2662.36], loss:[6.72799], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6 13  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2011, score:[2718.00], loss:[6.68358], sequence:[0], random actions:[13], eInit:[0.0100], init state:[5 5 9 0 0 0 0 0 0 0 0 0 0 0], end state:[0 5 9 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2012, score:[2685.27], loss:[6.76162], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 0  8 28  1  0  0  0  0  0  0  0  0  0  0], end state:[ 2  8 28  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2013, score:[2772.18], loss:[6.55796], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 18 14  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 14  0  0  0  0  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2014, score:[2740.00], loss:[6.33576], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2 23 46  1  0  0  0  0  0  1  1  0  0  0], end state:[ 4 23 46  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2015, score:[2781.64], loss:[6.38907], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 0 12 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2016, score:[2787.82], loss:[6.08965], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 1  0 44  0  0  1  0  0  0  0  0  0  0  0], end state:[ 3  0 44  0  0  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2017, score:[2715.27], loss:[5.12582], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3  9 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2018, score:[2668.55], loss:[5.27642], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 19 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 19 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2019, score:[2778.73], loss:[5.22591], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 4 11  4  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 11  4  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2020, score:[2716.91], loss:[5.23509], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3 22 31  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 31  0  0  0  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2021, score:[2723.64], loss:[5.34086], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6 13 29  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 13 29  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2022, score:[2713.64], loss:[5.29731], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 2 17  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 17  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2023, score:[2649.82], loss:[5.41343], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 12 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 44  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2024, score:[2569.09], loss:[6.47787], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 11 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 11 47  0  0  0  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 2025, score:[2616.91], loss:[7.73236], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 17 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2026, score:[2674.36], loss:[9.03371], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6  7 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  7 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2027, score:[2748.55], loss:[8.97352], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 20 50  1  1  0  1  0  0  1  1  1  0  0], end state:[ 3 20 50  1  0  0  0  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2028, score:[2778.91], loss:[8.75443], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1 15 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 15 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2029, score:[2781.09], loss:[8.41512], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 0  2 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 49  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2030, score:[2751.64], loss:[8.46131], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 6  3 43  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 43  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2031, score:[2808.00], loss:[8.30420], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 1 11 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 11 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2032, score:[2797.64], loss:[8.57572], sequence:[6], random actions:[30], eInit:[0.0100], init state:[3 9 4 0 0 0 0 0 0 0 0 0 0 0], end state:[5 9 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2033, score:[2794.91], loss:[8.55706], sequence:[7], random actions:[30], eInit:[0.0100], init state:[ 3 16 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 16 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2034, score:[2818.73], loss:[8.23670], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 3 15 11  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 11  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2035, score:[2736.36], loss:[7.43476], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 6  9 58  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  9 58  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2036, score:[2699.45], loss:[6.98621], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 6 11  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2037, score:[2812.91], loss:[7.05762], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 3  9 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  9 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2038, score:[2717.09], loss:[6.93624], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4  5 28  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 28  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2039, score:[2764.55], loss:[7.06612], sequence:[1], random actions:[20], eInit:[0.0100], init state:[2 4 0 0 0 0 0 0 0 0 0 0 0 0], end state:[4 4 0 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2040, score:[2744.36], loss:[7.36044], sequence:[2], random actions:[18], eInit:[0.0100], init state:[ 5 15  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2041, score:[2689.64], loss:[6.38779], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 5 12 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2042, score:[2795.45], loss:[5.69894], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 11 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2043, score:[2828.91], loss:[4.03083], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 1  1 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2044, score:[2786.00], loss:[3.96420], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 1 18 19  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18 19  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2045, score:[2735.09], loss:[3.99706], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 0  2 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2  2 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2046, score:[2731.27], loss:[4.06840], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 2 14 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 14 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2047, score:[2755.64], loss:[4.42789], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3 19  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19  7  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2048, score:[2763.64], loss:[4.64834], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2  4 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  4 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2049, score:[2777.82], loss:[4.61126], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 2  1 47  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  1 47  0  0  0  0  1  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2050, score:[2784.00], loss:[4.76157], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 2  2 10  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  2 10  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2051, score:[2786.73], loss:[4.94136], sequence:[5], random actions:[38], eInit:[0.0100], init state:[ 4  3 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2052, score:[2657.82], loss:[5.09060], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6  2 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  2 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2053, score:[2816.18], loss:[4.93393], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 1  1 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  1 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2054, score:[2720.91], loss:[5.14722], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 0 18 40  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 18 40  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2055, score:[2780.91], loss:[5.19550], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  4 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2056, score:[2754.18], loss:[4.87551], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 1  6 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  6 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2057, score:[2644.73], loss:[6.13067], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3  5 55  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 55  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2058, score:[2814.91], loss:[6.28962], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3  2 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  2 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2059, score:[2794.36], loss:[6.21321], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 19  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2060, score:[2745.82], loss:[6.36931], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 4 12 35  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 35  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2061, score:[2798.00], loss:[6.53358], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 2 22 36  1  0  0  0  0  0  1  1  0  0  1], end state:[ 4 22 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2062, score:[2744.73], loss:[6.42999], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 4 21 44  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 21 44  0  0  0  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2063, score:[2747.27], loss:[6.42265], sequence:[6], random actions:[33], eInit:[0.0100], init state:[ 3  4 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  4 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2064, score:[2760.18], loss:[6.33554], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 4  3 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  3 41  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2065, score:[2789.64], loss:[6.29430], sequence:[8], random actions:[36], eInit:[0.0100], init state:[ 1 10 20  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 10 20  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2066, score:[2762.36], loss:[5.87932], sequence:[9], random actions:[35], eInit:[0.0100], init state:[ 2 10 49  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 10 49  1  1  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2067, score:[2605.82], loss:[6.16304], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 4  2 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  2 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2068, score:[2772.36], loss:[6.34231], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 3 15  1  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15  1  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2069, score:[2828.73], loss:[6.02027], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 1 14 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 14 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2070, score:[2812.36], loss:[6.17484], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 3  5 50  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 50  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2071, score:[2733.45], loss:[6.24064], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  9 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  9 32  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2072, score:[2784.55], loss:[6.30559], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 15 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2073, score:[2646.36], loss:[6.57302], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 18 23  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 18 23  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2074, score:[2761.27], loss:[6.07327], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 0 21 36  1  0  0  0  0  0  1  1  0  0  1], end state:[ 2 21 36  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2075, score:[2799.09], loss:[4.77087], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0 14 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 14 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2076, score:[2726.36], loss:[4.85247], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 2 13 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 13 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2077, score:[2747.64], loss:[5.11718], sequence:[1], random actions:[43], eInit:[0.0100], init state:[ 6 22 20  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 20  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2078, score:[2778.91], loss:[4.96455], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 19  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 19  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2079, score:[2753.27], loss:[5.15866], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 5 15  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 15  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2080, score:[2758.55], loss:[5.08057], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 4 12 33  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2081, score:[2746.18], loss:[5.16973], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 4 20 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2082, score:[2794.36], loss:[5.16232], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 1  3 42  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  3 42  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2083, score:[2803.45], loss:[5.14415], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 4 15  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 15  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2084, score:[2619.45], loss:[5.34902], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 12 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2085, score:[2751.09], loss:[5.38096], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0 12 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 12 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2086, score:[2696.91], loss:[5.66088], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6  4 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  4 33  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2087, score:[2687.09], loss:[5.99440], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6  3 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1  3 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2088, score:[2764.36], loss:[6.16079], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 19 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 19 30  1  0  0  0  0  1  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2089, score:[2742.55], loss:[6.01542], sequence:[2], random actions:[41], eInit:[0.0100], init state:[ 0 21 16  1  1  0  1  0  0  1  1  0  0  1], end state:[ 2 21 16  1  1  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2090, score:[2821.09], loss:[5.92191], sequence:[3], random actions:[30], eInit:[0.0100], init state:[0 4 1 0 0 0 0 0 0 0 0 0 0 0], end state:[2 4 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2091, score:[2707.09], loss:[5.85184], sequence:[0], random actions:[31], eInit:[0.0100], init state:[3 4 7 0 0 0 0 0 0 0 0 0 0 0], end state:[5 4 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2092, score:[2756.55], loss:[6.13768], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3  7 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  7 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2093, score:[2733.45], loss:[6.31399], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6 22 58  1  0  0  0  0  0  1  1  0  0  1], end state:[ 1 22 58  1  0  0  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2094, score:[2769.09], loss:[6.10357], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 2  7 51  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 51  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2095, score:[2822.00], loss:[5.72071], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 0 10 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 10 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2096, score:[2812.00], loss:[5.58148], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 0 13 30  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 13 30  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2097, score:[2674.18], loss:[5.66777], sequence:[0], random actions:[31], eInit:[0.0100], init state:[4 5 4 0 0 0 0 0 0 0 0 0 0 0], end state:[6 5 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2098, score:[2777.09], loss:[5.79164], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 3 15 24  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 15 24  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2099, score:[2793.82], loss:[5.55968], sequence:[2], random actions:[37], eInit:[0.0100], init state:[ 2  3 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  3 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2100, score:[2782.55], loss:[5.46387], sequence:[3], random actions:[39], eInit:[0.0100], init state:[ 1 18  9  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 18  9  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2101, score:[2759.45], loss:[5.19495], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 0  8 57  1  1  0  0  0  0  0  0  0  0  0], end state:[ 2  8 57  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2102, score:[2775.27], loss:[5.00078], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 3 20  4  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 20  4  1  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2103, score:[2747.45], loss:[4.80494], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 6 11 52  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 11 52  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2104, score:[2763.82], loss:[4.52910], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 5 10 16  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 10 16  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2105, score:[2770.00], loss:[4.60407], sequence:[8], random actions:[34], eInit:[0.0100], init state:[ 0 11 25  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 11 25  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2106, score:[2761.45], loss:[4.52618], sequence:[9], random actions:[41], eInit:[0.0100], init state:[ 2  7 26  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  7 26  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2107, score:[2596.00], loss:[4.52868], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  9 56  1  0  0  0  0  0  0  0  0  0  0], end state:[ 6  9 56  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2108, score:[2752.36], loss:[4.95242], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 1 12 31  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12 31  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2109, score:[2741.45], loss:[5.00155], sequence:[2], random actions:[28], eInit:[0.0100], init state:[6 7 7 0 0 0 0 0 0 0 0 0 0 0], end state:[1 7 7 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2110, score:[2745.09], loss:[5.12453], sequence:[3], random actions:[30], eInit:[0.0100], init state:[5 7 4 0 0 0 0 0 0 0 0 0 0 0], end state:[0 7 4 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2111, score:[2807.64], loss:[4.87795], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 0 15 39  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 15 39  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2112, score:[2681.64], loss:[5.48384], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6 20  3  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 20  3  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2113, score:[2832.91], loss:[5.53439], sequence:[1], random actions:[17], eInit:[0.0100], init state:[ 1  4 34  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3  4 34  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2114, score:[2742.91], loss:[5.30282], sequence:[2], random actions:[14], eInit:[0.0100], init state:[ 3 19 33  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 19 33  1  0  0  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2115, score:[2620.18], loss:[5.27921], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 17  8  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 17  8  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2116, score:[2758.18], loss:[5.37445], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 3 13 54  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13 54  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2117, score:[2745.27], loss:[5.13595], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 3 13  5  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5 13  5  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2118, score:[2800.00], loss:[5.07763], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 2 12 32  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4 12 32  1  1  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2119, score:[2760.18], loss:[5.11627], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 4 17 22  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 17 22  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2120, score:[2676.73], loss:[5.10453], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5 13 21  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 13 21  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2121, score:[2795.09], loss:[5.34491], sequence:[1], random actions:[31], eInit:[0.0100], init state:[1 2 1 0 0 0 0 0 0 0 0 0 0 0], end state:[3 2 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2122, score:[2783.27], loss:[5.03229], sequence:[2], random actions:[40], eInit:[0.0100], init state:[ 3  5 17  0  0  0  0  0  0  0  0  0  0  0], end state:[ 5  5 17  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2123, score:[2608.36], loss:[5.18203], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  5 38  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6  5 38  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2124, score:[2741.64], loss:[5.22481], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 5 12 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0 12 45  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2125, score:[2811.27], loss:[4.84947], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1 12  7  0  0  0  0  0  0  0  0  0  0  0], end state:[ 3 12  7  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2126, score:[2791.27], loss:[4.44098], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 3 21  4  1  1  0  1  0  0  1  1  0  0  1], end state:[ 5 21  4  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2127, score:[2679.64], loss:[4.48557], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5  6 27  0  0  0  0  0  0  0  0  0  0  0], end state:[ 0  6 27  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2128, score:[2814.91], loss:[4.24127], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 0 19 53  0  0  0  0  0  0  0  0  0  0  0], end state:[ 2 19 53  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2129, score:[2718.00], loss:[4.59344], sequence:[0], random actions:[43], eInit:[0.0100], init state:[ 6 16 59  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 16 59  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2130, score:[2701.64], loss:[5.17579], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 6 19  0  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 19  0  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-41-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-41-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-41-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-41-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2833.0909090909117, [515]) , maxSequence:(16, [1066, 1605])
INFO:Reinforcement.Functions:episode: 2131, score:[2740.00], loss:[5.39023], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 5 23 34  1  0  0  0  0  0  1  1  0  0  0], end state:[ 0 23 34  1  0  0  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2132, score:[2769.09], loss:[5.30760], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 6 12 36  0  0  0  0  0  0  0  0  0  0  0], end state:[ 1 12 36  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2133, score:[2620.36], loss:[5.12152], sequence:[0], random actions:[42], eInit:[0.0100], init state:[ 3 22 37  1  0  0  0  0  0  1  1  0  0  1], end state:[ 5 22 37  1  0  0  1  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2134, score:[2794.18], loss:[5.18542], sequence:[1], random actions:[25], eInit:[0.0100], init state:[1 6 1 0 0 0 0 0 0 0 0 0 0 0], end state:[3 6 1 0 0 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2135, score:[2723.45], loss:[5.13780], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 12  2  1  1  0  0  0  0  0  0  0  0  0], end state:[ 6 12  2  0  0  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2136, score:[2782.91], loss:[5.09854], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 4 20 41  0  0  0  0  0  0  0  0  0  0  0], end state:[ 6 20 41  1  0  0  0  0  0  0  1  1  0  1]
INFO:Reinforcement.Functions:episode: 2137, score:[2731.27], loss:[5.00216], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 2  9 45  0  0  0  0  0  0  0  0  0  0  0], end state:[ 4  9 45  1  0  0  0  0  0  0  0  0  0  0]

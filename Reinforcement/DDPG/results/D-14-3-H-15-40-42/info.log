INFO:Reinforcement.Functions:settings:[{'minGameScore': 2736, u'TAU': 0.001, u'minGameScoreRatio': 0.95, u'batchSize': 256, u'nGamesPerSave': 10, u'nEpochs': 1, u'minGameSequence': 500, u'nModelBackups': 3, u'gameMinutesLength': 2880, u'dequeSize': 50000, u'learningRate': 0.001, u'gamma': 0.95, u'trainSetSize': 128}]
INFO:Reinforcement.Functions:args:[{'random': True, 'gpuFrac': 0.3, 'sequential': False, 'gpuNum': 0, 'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json'}]
INFO:Reinforcement.Functions:results:[{'loss': [], 'score': []}]
INFO:Reinforcement.Functions:Actor:[{'epsilon_decay': 0.99, 'epsilon': 1.0, 'curBackupIdx': 0, 'epsilon_min': 0.01, 'TAU': 0.001, 'nBackups': 3, 'k': 26, 'actionDim': 8}]
INFO:Reinforcement.Functions:Critic:[{'TAU': 0.001, 'nBackups': 3, 'curBackupIdx': 0, 'actionDim': 8}]
INFO:Reinforcement.Functions:policy:[{'numOfDevices': 8, 'stateDim': (1, 11), 'seqLen': 1, 'policyJSON': {u'10': [{u'days': u'weekdays', u'times': [[u'21:00', u'23:29']]}, {u'days': [5], u'times': [[u'21:00', u'23:29']]}], u'6': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:14'], [u'20:40', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'weekdays': [0, 1, 2, 3, 6], u'Devices': [u'Room light1', u'Room light2', u'Room light3 (backdoor)', u'Kitchen light', u'Toilets light', u'Bathroom light', u'Living room light1', u'Living room light2'], u'days': [u'Monday', u'Tuesday', u'Wednesday', u'Thursday', u'Friday', u'Saturday', u'Sunday'], u'1': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:59'], [u'20:30', u'21:29']]}, {u'days': [4], u'times': [[u'10:00', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'0': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:29'], [u'08:00', u'08:59'], [u'20:30', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:59'], [u'09:30', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'23:59']]}], u'3': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:44'], [u'20:45', u'21:29'], [u'23:15', u'23:44']]}, {u'days': [4], u'times': [[u'10:00', u'10:59'], [u'12:45', u'13:14']]}, {u'days': [5], u'times': [[u'18:00', u'19:59'], [u'21:00', u'23:14']]}], u'2': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:30', u'01:09']]}, {u'days': [4], u'times': [[u'00:30', u'01:09']]}], u'5': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:05', u'00:24'], [u'08:35', u'08:42'], [u'21:09', u'21:11']]}, {u'days': [4], u'times': [[u'00:05', u'00:24'], [u'10:18', u'10:29']]}, {u'days': [5], u'times': [[u'19:09', u'19:09'], [u'21:34', u'21:34']]}], u'4': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:34'], [u'21:05', u'21:08']]}, {u'days': [4], u'times': [[u'10:10', u'10:17']]}, {u'days': [5], u'times': [[u'19:05', u'19:08'], [u'21:20', u'21:33']]}], u'7': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:14'], [u'20:40', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'Time format': u'%H:%M', u'9': [{u'days': u'weekdays', u'times': [[u'09:00', u'09:00'], [u'20:30', u'20:30']]}, {u'days': [4], u'times': [[u'13:29', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:00']]}], u'8': [{u'days': u'weekdays', u'times': [[u'20:31', u'20:54']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'weekend': [4, 5]}}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 11)             0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 512)            6144      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            131328    
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 8)              2056      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 8)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 139,528
INFO:Reinforcement.Functions:Trainable params: 139,528
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 11)        0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)                 (None, 1, 512)       6144        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 8)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)                 (None, 1, 256)       131328      dense_4[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)                 (None, 256)          2304        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_5[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_6[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 1)         257         activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_7[0][0]                    
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 140,033
INFO:Reinforcement.Functions:Trainable params: 140,033
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[1583.50], loss:[32.14671], sequence:[0], random actions:[136], eInit:[1.0000], init state:[ 6 23 50  1  0  0  0  0  0  1  1], end state:[ 1 23 50  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2, score:[1915.00], loss:[27.22025], sequence:[0], random actions:[118], eInit:[0.9900], init state:[ 3 18  0  0  0  0  0  0  0  0  0], end state:[ 5 18  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 3, score:[2108.50], loss:[19.45449], sequence:[0], random actions:[115], eInit:[0.9801], init state:[ 6 14 21  0  0  0  0  0  0  0  0], end state:[ 1 14 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 4, score:[2246.50], loss:[16.02469], sequence:[0], random actions:[110], eInit:[0.9703], init state:[ 2 21 55  1  0  0  0  0  0  1  1], end state:[ 4 21 55  1  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 5, score:[2354.75], loss:[13.26809], sequence:[0], random actions:[126], eInit:[0.9606], init state:[ 3 11 46  0  0  0  0  0  0  0  0], end state:[ 5 11 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 6, score:[2367.00], loss:[11.12721], sequence:[0], random actions:[103], eInit:[0.9510], init state:[ 0 19 26  0  0  0  0  0  0  0  0], end state:[ 2 19 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 7, score:[2463.25], loss:[9.88206], sequence:[0], random actions:[122], eInit:[0.9415], init state:[ 1 20 13  0  0  0  0  0  0  0  0], end state:[ 3 20 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 8, score:[2489.75], loss:[8.59993], sequence:[0], random actions:[119], eInit:[0.9321], init state:[ 6 21 43  1  0  0  0  0  0  1  1], end state:[ 1 21 43  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 9, score:[2410.50], loss:[8.35708], sequence:[0], random actions:[115], eInit:[0.9227], init state:[ 3 15 47  0  0  0  0  0  0  0  0], end state:[ 5 15 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 10, score:[2490.50], loss:[7.67972], sequence:[0], random actions:[112], eInit:[0.9135], init state:[ 3 16 14  0  0  0  0  0  0  0  0], end state:[ 5 16 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2490.5, [10]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
INFO:Reinforcement.Functions:episode: 11, score:[2430.75], loss:[8.75429], sequence:[0], random actions:[111], eInit:[0.9044], init state:[ 5 23 32  1  0  0  0  0  0  1  1], end state:[ 0 23 32  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 12, score:[2454.75], loss:[8.77815], sequence:[0], random actions:[118], eInit:[0.8953], init state:[ 6 19  9  0  0  0  0  0  0  0  0], end state:[ 1 19  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 13, score:[2299.75], loss:[8.58349], sequence:[0], random actions:[112], eInit:[0.8864], init state:[ 5  1 25  0  0  0  0  0  0  0  0], end state:[ 0  1 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 14, score:[2451.75], loss:[8.48172], sequence:[0], random actions:[100], eInit:[0.8775], init state:[ 3 21 11  1  1  0  1  0  1  1  1], end state:[ 5 21 11  1  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 15, score:[2538.75], loss:[7.60605], sequence:[0], random actions:[101], eInit:[0.8687], init state:[ 1 22 32  1  0  0  0  0  0  1  1], end state:[ 3 22 32  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 16, score:[2574.50], loss:[7.04099], sequence:[0], random actions:[110], eInit:[0.8601], init state:[ 1  0 37  0  0  1  0  0  0  0  0], end state:[ 3  0 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 17, score:[2362.25], loss:[7.32515], sequence:[0], random actions:[100], eInit:[0.8515], init state:[4 9 1 0 0 0 0 0 0 0 0], end state:[6 9 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 18, score:[2563.00], loss:[6.81755], sequence:[0], random actions:[107], eInit:[0.8429], init state:[0 1 9 0 0 1 0 0 0 0 0], end state:[2 1 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 19, score:[2539.25], loss:[6.44176], sequence:[0], random actions:[103], eInit:[0.8345], init state:[ 3  5 20  0  0  0  0  0  0  0  0], end state:[ 5  5 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 20, score:[2414.75], loss:[6.37182], sequence:[0], random actions:[103], eInit:[0.8262], init state:[ 4 21 50  0  0  0  0  0  0  0  0], end state:[ 6 21 50  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2574.5, [16]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])
INFO:Reinforcement.Functions:episode: 21, score:[2567.75], loss:[5.96742], sequence:[0], random actions:[106], eInit:[0.8179], init state:[ 3 16 32  0  0  0  0  0  0  0  0], end state:[ 5 16 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 22, score:[2551.00], loss:[5.20915], sequence:[0], random actions:[115], eInit:[0.8097], init state:[ 3  4 31  0  0  0  0  0  0  0  0], end state:[ 5  4 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 23, score:[2540.00], loss:[5.13592], sequence:[0], random actions:[113], eInit:[0.8016], init state:[ 2 22 43  1  0  0  0  0  0  1  1], end state:[ 4 22 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 24, score:[2586.25], loss:[4.81224], sequence:[0], random actions:[111], eInit:[0.7936], init state:[ 6 23 31  1  0  0  1  0  0  1  1], end state:[ 1 23 31  1  0  1  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 25, score:[2607.50], loss:[4.43520], sequence:[0], random actions:[92], eInit:[0.7857], init state:[ 3 12 56  0  0  0  0  0  0  0  0], end state:[ 5 12 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 26, score:[2613.25], loss:[4.33889], sequence:[0], random actions:[89], eInit:[0.7778], init state:[ 1 15 56  0  0  0  0  0  0  0  0], end state:[ 3 15 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 27, score:[2566.75], loss:[4.11597], sequence:[0], random actions:[88], eInit:[0.7700], init state:[ 6  2 11  0  0  0  0  0  0  0  0], end state:[ 1  2 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 28, score:[2596.50], loss:[4.15483], sequence:[0], random actions:[113], eInit:[0.7623], init state:[ 1  3 26  0  0  0  0  0  0  0  0], end state:[ 3  3 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 29, score:[2622.75], loss:[3.81401], sequence:[0], random actions:[108], eInit:[0.7547], init state:[ 1 20 54  1  1  0  1  0  0  1  1], end state:[ 3 20 54  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 30, score:[2530.75], loss:[3.74935], sequence:[0], random actions:[103], eInit:[0.7472], init state:[ 6  1 45  0  0  0  0  0  0  0  0], end state:[ 1  1 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2622.75, [29]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])
INFO:Reinforcement.Functions:episode: 31, score:[2596.75], loss:[3.44982], sequence:[0], random actions:[99], eInit:[0.7397], init state:[ 2 10 20  0  0  0  0  0  0  0  0], end state:[ 4 10 20  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 32, score:[2543.00], loss:[3.69666], sequence:[0], random actions:[95], eInit:[0.7323], init state:[ 6  5 51  0  0  0  0  0  0  0  0], end state:[ 1  5 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 33, score:[2622.00], loss:[3.75571], sequence:[0], random actions:[103], eInit:[0.7250], init state:[0 7 5 0 0 0 0 0 0 0 0], end state:[2 7 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 34, score:[2667.25], loss:[3.51735], sequence:[0], random actions:[83], eInit:[0.7177], init state:[ 0  3 31  0  0  0  0  0  0  0  0], end state:[ 2  3 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 35, score:[2651.75], loss:[3.51450], sequence:[0], random actions:[77], eInit:[0.7106], init state:[ 0 17 19  0  0  0  0  0  0  0  0], end state:[ 2 17 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 36, score:[2630.00], loss:[3.30051], sequence:[0], random actions:[91], eInit:[0.7034], init state:[ 1 15 26  0  0  0  0  0  0  0  0], end state:[ 3 15 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 37, score:[2487.75], loss:[3.43735], sequence:[0], random actions:[90], eInit:[0.6964], init state:[ 3 22 53  1  0  0  0  0  0  1  1], end state:[ 5 22 53  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 38, score:[2674.00], loss:[3.40259], sequence:[0], random actions:[73], eInit:[0.6894], init state:[ 1 20 53  1  1  0  1  0  0  1  1], end state:[ 3 20 53  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 39, score:[2623.50], loss:[3.36650], sequence:[0], random actions:[100], eInit:[0.6826], init state:[ 1 18 31  0  0  0  0  0  0  0  0], end state:[ 3 18 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 40, score:[2428.75], loss:[3.51899], sequence:[0], random actions:[102], eInit:[0.6757], init state:[ 5 13 39  0  0  0  0  0  0  0  0], end state:[ 0 13 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2674.0, [38]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40])
INFO:Reinforcement.Functions:episode: 41, score:[2551.50], loss:[3.50222], sequence:[0], random actions:[71], eInit:[0.6690], init state:[ 5 17 55  0  0  0  0  0  0  0  0], end state:[ 0 17 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 42, score:[2687.50], loss:[3.13203], sequence:[0], random actions:[80], eInit:[0.6623], init state:[ 0  5 48  0  0  0  0  0  0  0  0], end state:[ 2  5 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 43, score:[2499.25], loss:[3.36336], sequence:[0], random actions:[91], eInit:[0.6557], init state:[ 3  4 41  0  0  0  0  0  0  0  0], end state:[ 5  4 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 44, score:[2650.00], loss:[3.24548], sequence:[0], random actions:[102], eInit:[0.6491], init state:[ 0 10 24  0  0  0  0  0  0  0  0], end state:[ 2 10 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 45, score:[2511.50], loss:[3.27978], sequence:[0], random actions:[93], eInit:[0.6426], init state:[ 3 22 38  1  0  0  0  0  0  1  1], end state:[ 5 22 38  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 46, score:[2675.75], loss:[3.14349], sequence:[0], random actions:[88], eInit:[0.6362], init state:[ 0 22 44  1  0  0  0  0  0  1  1], end state:[ 2 22 44  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 47, score:[2580.75], loss:[3.28788], sequence:[0], random actions:[75], eInit:[0.6298], init state:[ 4 12 18  1  1  0  0  0  0  0  0], end state:[ 6 12 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 48, score:[2504.75], loss:[3.42280], sequence:[0], random actions:[101], eInit:[0.6235], init state:[ 5  5 50  0  0  0  0  0  0  0  0], end state:[ 0  5 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 49, score:[2646.00], loss:[3.34672], sequence:[0], random actions:[81], eInit:[0.6173], init state:[ 6 19 59  0  0  0  0  0  0  0  0], end state:[ 1 19 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 50, score:[2502.00], loss:[3.18469], sequence:[0], random actions:[89], eInit:[0.6111], init state:[ 4  1 55  0  0  0  0  0  0  0  0], end state:[ 6  1 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2687.5, [42]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])
INFO:Reinforcement.Functions:episode: 51, score:[2633.25], loss:[2.91723], sequence:[0], random actions:[84], eInit:[0.6050], init state:[ 4  2 45  0  0  0  0  0  0  0  0], end state:[ 6  2 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 52, score:[2552.50], loss:[3.07122], sequence:[0], random actions:[85], eInit:[0.5990], init state:[ 5  3 11  0  0  0  0  0  0  0  0], end state:[ 0  3 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 53, score:[2624.25], loss:[3.22813], sequence:[0], random actions:[93], eInit:[0.5930], init state:[ 6  7 54  0  0  0  0  0  0  0  0], end state:[ 1  7 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 54, score:[2636.50], loss:[2.99007], sequence:[0], random actions:[87], eInit:[0.5870], init state:[ 6  3 40  0  0  0  0  0  0  0  0], end state:[ 1  3 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 55, score:[2662.75], loss:[3.20108], sequence:[0], random actions:[83], eInit:[0.5812], init state:[ 0 20 36  1  1  0  0  0  0  0  0], end state:[ 2 20 36  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 56, score:[2598.00], loss:[2.95850], sequence:[0], random actions:[73], eInit:[0.5754], init state:[ 4 20 37  0  0  0  0  0  0  0  0], end state:[ 6 20 37  0  1  0  1  0  0  0  1]
INFO:Reinforcement.Functions:episode: 57, score:[2634.75], loss:[3.02063], sequence:[0], random actions:[82], eInit:[0.5696], init state:[ 2  0 38  0  0  1  0  0  0  0  0], end state:[ 4  0 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 58, score:[2699.75], loss:[2.90233], sequence:[0], random actions:[76], eInit:[0.5639], init state:[ 1 10 21  0  0  0  0  0  0  0  0], end state:[ 3 10 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 59, score:[2565.25], loss:[3.02975], sequence:[0], random actions:[71], eInit:[0.5583], init state:[ 5 17 58  0  0  0  0  0  0  0  0], end state:[ 0 17 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 60, score:[2607.75], loss:[3.05616], sequence:[0], random actions:[94], eInit:[0.5527], init state:[ 2 21 32  1  0  0  0  0  0  1  1], end state:[ 4 21 32  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2699.75, [58]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60])
INFO:Reinforcement.Functions:episode: 61, score:[2659.75], loss:[3.61155], sequence:[0], random actions:[78], eInit:[0.5472], init state:[ 0 17 41  0  0  0  0  0  0  0  0], end state:[ 2 17 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 62, score:[2656.00], loss:[3.16707], sequence:[0], random actions:[76], eInit:[0.5417], init state:[ 6  1 18  0  0  0  0  0  0  0  0], end state:[ 1  1 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 63, score:[2678.75], loss:[3.08080], sequence:[0], random actions:[78], eInit:[0.5363], init state:[ 0  6 22  0  0  0  0  0  0  0  0], end state:[ 2  6 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 64, score:[2639.50], loss:[3.07951], sequence:[0], random actions:[85], eInit:[0.5309], init state:[ 6 10 55  0  0  0  0  0  0  0  0], end state:[ 1 10 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 65, score:[2604.75], loss:[3.26560], sequence:[0], random actions:[70], eInit:[0.5256], init state:[ 4 20  7  0  0  0  0  0  0  0  0], end state:[ 6 20  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 66, score:[2644.75], loss:[2.98974], sequence:[0], random actions:[74], eInit:[0.5203], init state:[ 3 15 55  0  0  0  0  0  0  0  0], end state:[ 5 15 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 67, score:[2728.75], loss:[2.60987], sequence:[0], random actions:[65], eInit:[0.5151], init state:[1 3 9 0 0 0 0 0 0 0 0], end state:[3 3 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 68, score:[2725.50], loss:[2.47536], sequence:[0], random actions:[68], eInit:[0.5100], init state:[0 9 8 0 0 0 0 0 0 0 0], end state:[2 9 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 69, score:[2671.75], loss:[2.53014], sequence:[0], random actions:[67], eInit:[0.5049], init state:[ 4 16  0  0  0  0  0  0  0  0  0], end state:[ 6 16  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 70, score:[2717.75], loss:[2.32018], sequence:[0], random actions:[80], eInit:[0.4998], init state:[ 0  9 51  0  0  0  0  0  0  0  0], end state:[ 2  9 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2728.75, [67]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70])
INFO:Reinforcement.Functions:episode: 71, score:[2650.50], loss:[2.35605], sequence:[0], random actions:[68], eInit:[0.4948], init state:[ 5  6 52  0  0  0  0  0  0  0  0], end state:[ 0  6 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 72, score:[2714.00], loss:[2.14347], sequence:[0], random actions:[84], eInit:[0.4899], init state:[ 1  1 27  0  0  0  0  0  0  0  0], end state:[ 3  1 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 73, score:[2671.50], loss:[2.21664], sequence:[0], random actions:[65], eInit:[0.4850], init state:[ 5  0 48  0  0  0  0  0  0  0  0], end state:[ 0  0 48  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 74, score:[2638.75], loss:[2.52151], sequence:[0], random actions:[81], eInit:[0.4801], init state:[ 6 17  5  0  0  0  0  0  0  0  0], end state:[ 1 17  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 75, score:[2728.75], loss:[2.21638], sequence:[0], random actions:[64], eInit:[0.4753], init state:[ 1 15  9  0  0  0  0  0  0  0  0], end state:[ 3 15  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 76, score:[2556.75], loss:[2.48459], sequence:[0], random actions:[71], eInit:[0.4706], init state:[ 3  8 41  1  1  0  1  0  1  0  0], end state:[ 5  8 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 77, score:[2689.75], loss:[2.26495], sequence:[0], random actions:[55], eInit:[0.4659], init state:[ 4 20 11  0  0  0  0  0  0  0  0], end state:[ 6 20 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 78, score:[2685.00], loss:[2.06992], sequence:[0], random actions:[66], eInit:[0.4612], init state:[ 4 20 31  0  0  0  0  0  0  0  0], end state:[ 6 20 31  1  1  0  1  0  0  0  1]
INFO:Reinforcement.Functions:episode: 79, score:[2700.75], loss:[1.85054], sequence:[0], random actions:[77], eInit:[0.4566], init state:[ 2 12 46  0  0  0  0  0  0  0  0], end state:[ 4 12 46  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 80, score:[2685.00], loss:[2.24532], sequence:[0], random actions:[70], eInit:[0.4520], init state:[ 4  5 32  0  0  0  0  0  0  0  0], end state:[ 6  5 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2728.75, [67, 75]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80])
INFO:Reinforcement.Functions:episode: 81, score:[2694.25], loss:[2.22034], sequence:[0], random actions:[73], eInit:[0.4475], init state:[ 0 19 34  0  0  0  0  0  0  0  0], end state:[ 2 19 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 82, score:[2656.25], loss:[2.36192], sequence:[0], random actions:[58], eInit:[0.4430], init state:[3 6 2 0 0 0 0 0 0 0 0], end state:[5 6 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 83, score:[2712.50], loss:[2.14118], sequence:[0], random actions:[76], eInit:[0.4386], init state:[1 9 4 0 0 0 0 0 0 0 0], end state:[3 9 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 84, score:[2746.75], loss:[2.04389], sequence:[1], random actions:[67], eInit:[0.4342], init state:[ 1 13 15  0  0  0  0  0  0  0  0], end state:[ 3 13 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 85, score:[2665.75], loss:[2.08435], sequence:[0], random actions:[68], eInit:[0.4299], init state:[ 2 23 31  1  0  0  1  0  0  1  1], end state:[ 4 23 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 86, score:[2703.00], loss:[2.26277], sequence:[0], random actions:[73], eInit:[0.4256], init state:[ 1  5 47  0  0  0  0  0  0  0  0], end state:[ 3  5 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 87, score:[2768.00], loss:[2.04074], sequence:[1], random actions:[51], eInit:[0.4213], init state:[ 1  5 57  0  0  0  0  0  0  0  0], end state:[ 3  5 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 88, score:[2717.50], loss:[1.97168], sequence:[0], random actions:[65], eInit:[0.4171], init state:[ 2  7 47  0  0  0  0  0  0  0  0], end state:[ 4  7 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 89, score:[2713.50], loss:[2.03669], sequence:[0], random actions:[72], eInit:[0.4129], init state:[ 0  6 48  0  0  0  0  0  0  0  0], end state:[ 2  6 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 90, score:[2634.50], loss:[2.01205], sequence:[0], random actions:[66], eInit:[0.4088], init state:[ 4 13 37  0  0  0  0  0  0  0  0], end state:[ 6 13 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2768.0, [87]) , maxSequence:(1, [84, 87])
INFO:Reinforcement.Functions:episode: 91, score:[2675.25], loss:[2.07419], sequence:[0], random actions:[58], eInit:[0.4047], init state:[ 4 11  1  1  1  0  0  0  0  0  0], end state:[ 6 11  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 92, score:[2736.25], loss:[1.83068], sequence:[1], random actions:[56], eInit:[0.4007], init state:[ 2  1 39  0  0  0  0  0  0  0  0], end state:[ 4  1 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 93, score:[2756.25], loss:[1.81726], sequence:[2], random actions:[59], eInit:[0.3967], init state:[1 9 2 0 0 0 0 0 0 0 0], end state:[3 9 2 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 94, score:[2737.00], loss:[1.71757], sequence:[3], random actions:[70], eInit:[0.3927], init state:[ 0  9 23  0  0  0  0  0  0  0  0], end state:[ 2  9 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 95, score:[2735.25], loss:[1.70543], sequence:[0], random actions:[70], eInit:[0.3888], init state:[ 0  8 54  1  1  0  0  0  0  0  0], end state:[ 2  8 54  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 96, score:[2711.75], loss:[1.57776], sequence:[0], random actions:[72], eInit:[0.3849], init state:[ 4 17 32  0  0  0  0  0  0  0  0], end state:[ 6 17 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 97, score:[2705.25], loss:[1.70648], sequence:[0], random actions:[73], eInit:[0.3810], init state:[ 0  0 16  1  0  0  0  0  1  0  0], end state:[ 2  0 16  1  0  0  0  0  1  0  1]
INFO:Reinforcement.Functions:episode: 98, score:[2624.00], loss:[1.73696], sequence:[0], random actions:[60], eInit:[0.3772], init state:[ 5 10 18  0  0  0  0  0  0  0  0], end state:[ 0 10 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 99, score:[2635.75], loss:[1.82618], sequence:[0], random actions:[62], eInit:[0.3735], init state:[ 5 19 23  1  0  0  1  0  0  0  0], end state:[ 0 19 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 100, score:[2672.00], loss:[1.68232], sequence:[0], random actions:[69], eInit:[0.3697], init state:[ 6  5 31  0  0  0  0  0  0  0  0], end state:[ 1  5 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2768.0, [87]) , maxSequence:(3, [94])
INFO:Reinforcement.Functions:episode: 101, score:[2670.75], loss:[1.83532], sequence:[0], random actions:[53], eInit:[0.3660], init state:[ 4  7 55  0  0  0  0  0  0  0  0], end state:[ 6  7 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 102, score:[2686.50], loss:[1.73845], sequence:[0], random actions:[66], eInit:[0.3624], init state:[ 3 15 38  0  0  0  0  0  0  0  0], end state:[ 5 15 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 103, score:[2684.00], loss:[1.82080], sequence:[0], random actions:[63], eInit:[0.3587], init state:[ 0  9 14  0  0  0  0  0  0  0  0], end state:[ 2  9 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 104, score:[2662.25], loss:[1.82712], sequence:[0], random actions:[69], eInit:[0.3552], init state:[ 6 13 56  0  0  0  0  0  0  0  0], end state:[ 1 13 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 105, score:[2746.75], loss:[1.71874], sequence:[1], random actions:[59], eInit:[0.3516], init state:[ 3 16 36  0  0  0  0  0  0  0  0], end state:[ 5 16 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 106, score:[2708.50], loss:[1.72055], sequence:[0], random actions:[57], eInit:[0.3481], init state:[ 3  5 51  0  0  0  0  0  0  0  0], end state:[ 5  5 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 107, score:[2741.25], loss:[1.58365], sequence:[1], random actions:[64], eInit:[0.3446], init state:[ 0  0 25  1  0  0  0  0  0  0  0], end state:[ 2  0 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 108, score:[2692.50], loss:[1.80347], sequence:[0], random actions:[57], eInit:[0.3412], init state:[ 6 18 51  0  0  0  0  0  0  0  0], end state:[ 1 18 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 109, score:[2671.00], loss:[1.80172], sequence:[0], random actions:[62], eInit:[0.3378], init state:[ 5 22 45  1  0  0  1  0  0  1  1], end state:[ 0 22 45  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 110, score:[2734.00], loss:[1.60482], sequence:[0], random actions:[57], eInit:[0.3344], init state:[ 1 17  2  0  0  0  0  0  0  0  0], end state:[ 3 17  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2768.0, [87]) , maxSequence:(3, [94])
INFO:Reinforcement.Functions:episode: 111, score:[2680.00], loss:[1.54566], sequence:[0], random actions:[54], eInit:[0.3310], init state:[ 4 18  3  0  0  0  0  0  0  0  0], end state:[ 6 18  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 112, score:[2755.00], loss:[1.53250], sequence:[1], random actions:[56], eInit:[0.3277], init state:[2 2 2 0 0 0 0 0 0 0 0], end state:[4 2 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 113, score:[2734.50], loss:[1.65225], sequence:[0], random actions:[37], eInit:[0.3244], init state:[ 3 14 27  0  0  0  0  0  0  0  0], end state:[ 5 14 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 114, score:[2700.00], loss:[1.71964], sequence:[0], random actions:[55], eInit:[0.3212], init state:[ 3  6 26  0  0  0  0  0  0  0  0], end state:[ 5  6 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 115, score:[2694.25], loss:[1.73748], sequence:[0], random actions:[57], eInit:[0.3180], init state:[ 3 14 43  0  0  0  0  0  0  0  0], end state:[ 5 14 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 116, score:[2758.00], loss:[1.42795], sequence:[1], random actions:[51], eInit:[0.3148], init state:[ 0 20 56  1  1  0  1  0  0  1  1], end state:[ 2 20 56  1  1  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 117, score:[2686.50], loss:[1.58092], sequence:[0], random actions:[63], eInit:[0.3117], init state:[ 6  3 16  0  0  0  0  0  0  0  0], end state:[ 1  3 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 118, score:[2672.25], loss:[1.54330], sequence:[0], random actions:[55], eInit:[0.3085], init state:[ 5 12 55  0  0  0  0  0  0  0  0], end state:[ 0 12 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 119, score:[2681.50], loss:[1.55749], sequence:[0], random actions:[67], eInit:[0.3055], init state:[ 4 14 39  0  0  0  0  0  0  0  0], end state:[ 6 14 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 120, score:[2681.75], loss:[1.66452], sequence:[0], random actions:[74], eInit:[0.3024], init state:[ 3 20  9  0  0  0  0  0  0  0  0], end state:[ 5 20  9  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2768.0, [87]) , maxSequence:(3, [94])
INFO:Reinforcement.Functions:episode: 121, score:[2722.50], loss:[1.42312], sequence:[0], random actions:[60], eInit:[0.2994], init state:[ 1 10 19  0  0  0  0  0  0  0  0], end state:[ 3 10 19  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 122, score:[2775.50], loss:[1.43589], sequence:[1], random actions:[43], eInit:[0.2964], init state:[ 0 16  7  0  0  0  0  0  0  0  0], end state:[ 2 16  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 123, score:[2682.75], loss:[1.58809], sequence:[0], random actions:[47], eInit:[0.2934], init state:[ 5 20  6  1  0  0  0  0  0  0  0], end state:[ 0 20  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 124, score:[2733.75], loss:[1.42944], sequence:[0], random actions:[57], eInit:[0.2905], init state:[ 6 21 13  1  1  0  1  0  0  1  1], end state:[ 1 21 13  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 125, score:[2742.25], loss:[1.35758], sequence:[1], random actions:[50], eInit:[0.2876], init state:[ 0 16 50  0  0  0  0  0  0  0  0], end state:[ 2 16 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 126, score:[2744.75], loss:[1.35263], sequence:[2], random actions:[46], eInit:[0.2847], init state:[ 3  9 19  0  0  0  0  0  0  0  0], end state:[ 5  9 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 127, score:[2706.75], loss:[1.36710], sequence:[0], random actions:[63], eInit:[0.2819], init state:[ 6 17 41  0  0  0  0  0  0  0  0], end state:[ 1 17 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 128, score:[2659.50], loss:[1.39197], sequence:[0], random actions:[55], eInit:[0.2790], init state:[ 5  6 10  0  0  0  0  0  0  0  0], end state:[ 0  6 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 129, score:[2699.50], loss:[1.49985], sequence:[0], random actions:[46], eInit:[0.2763], init state:[ 4 23 21  0  0  0  0  0  0  0  0], end state:[ 6 23 21  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 130, score:[2714.25], loss:[1.34500], sequence:[0], random actions:[55], eInit:[0.2735], init state:[ 2 11 21  0  0  0  0  0  0  0  0], end state:[ 4 11 21  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2775.5, [122]) , maxSequence:(3, [94])
INFO:Reinforcement.Functions:episode: 131, score:[2688.75], loss:[1.50395], sequence:[0], random actions:[47], eInit:[0.2708], init state:[3 7 1 0 0 0 0 0 0 0 0], end state:[5 7 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 132, score:[2686.50], loss:[1.44102], sequence:[0], random actions:[51], eInit:[0.2680], init state:[ 4 21 41  0  0  0  0  0  0  0  0], end state:[ 6 21 41  1  1  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 133, score:[2648.50], loss:[1.58033], sequence:[0], random actions:[56], eInit:[0.2654], init state:[3 7 1 0 0 0 0 0 0 0 0], end state:[5 7 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 134, score:[2737.00], loss:[1.46276], sequence:[1], random actions:[50], eInit:[0.2627], init state:[ 4 20  1  0  0  0  0  0  0  0  0], end state:[ 6 20  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 135, score:[2726.00], loss:[1.32848], sequence:[0], random actions:[50], eInit:[0.2601], init state:[ 2 11 37  0  0  0  0  0  0  0  0], end state:[ 4 11 37  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 136, score:[2712.50], loss:[1.50838], sequence:[0], random actions:[38], eInit:[0.2575], init state:[ 4 22 43  0  0  0  0  0  0  0  0], end state:[ 6 22 43  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 137, score:[2740.75], loss:[1.32258], sequence:[1], random actions:[49], eInit:[0.2549], init state:[ 0 13 49  0  0  0  0  0  0  0  0], end state:[ 2 13 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 138, score:[2738.75], loss:[1.29630], sequence:[2], random actions:[46], eInit:[0.2524], init state:[ 6  2 33  0  0  0  0  0  0  0  0], end state:[ 1  2 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 139, score:[2707.25], loss:[1.20817], sequence:[0], random actions:[59], eInit:[0.2498], init state:[ 2 10 40  0  0  0  0  0  0  0  0], end state:[ 4 10 40  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 140, score:[2763.50], loss:[1.24754], sequence:[1], random actions:[48], eInit:[0.2473], init state:[ 1 22  2  1  0  0  0  0  0  1  1], end state:[ 3 22  2  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2775.5, [122]) , maxSequence:(3, [94])
INFO:Reinforcement.Functions:episode: 141, score:[2723.00], loss:[1.29613], sequence:[0], random actions:[60], eInit:[0.2449], init state:[ 2  9 53  0  0  0  0  0  0  0  0], end state:[ 4  9 53  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 142, score:[2726.00], loss:[1.15577], sequence:[0], random actions:[42], eInit:[0.2424], init state:[6 4 9 0 0 0 0 0 0 0 0], end state:[1 4 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 143, score:[2744.00], loss:[1.20866], sequence:[1], random actions:[56], eInit:[0.2400], init state:[ 3  6 34  0  0  0  0  0  0  0  0], end state:[ 5  6 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 144, score:[2740.25], loss:[1.16299], sequence:[2], random actions:[57], eInit:[0.2376], init state:[ 0  6 12  0  0  0  0  0  0  0  0], end state:[ 2  6 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 145, score:[2721.50], loss:[1.37676], sequence:[0], random actions:[54], eInit:[0.2352], init state:[ 5 22 13  1  0  0  1  0  0  1  1], end state:[ 0 22 13  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 146, score:[2742.75], loss:[1.20989], sequence:[1], random actions:[49], eInit:[0.2329], init state:[ 6  7 48  0  0  0  0  0  0  0  0], end state:[ 1  7 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 147, score:[2768.00], loss:[1.15394], sequence:[2], random actions:[58], eInit:[0.2305], init state:[ 1 11 53  0  0  0  0  0  0  0  0], end state:[ 3 11 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 148, score:[2739.75], loss:[1.15721], sequence:[3], random actions:[56], eInit:[0.2282], init state:[ 0 17 46  0  0  0  0  0  0  0  0], end state:[ 2 17 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 149, score:[2691.00], loss:[1.22386], sequence:[0], random actions:[50], eInit:[0.2259], init state:[ 5 21 57  1  0  0  1  0  0  1  1], end state:[ 0 21 57  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 150, score:[2713.00], loss:[1.29263], sequence:[0], random actions:[34], eInit:[0.2237], init state:[ 2 18 33  0  0  0  0  0  0  0  0], end state:[ 4 18 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2775.5, [122]) , maxSequence:(3, [94, 148])
INFO:Reinforcement.Functions:episode: 151, score:[2768.75], loss:[1.10607], sequence:[1], random actions:[45], eInit:[0.2215], init state:[ 2 10 42  0  0  0  0  0  0  0  0], end state:[ 4 10 42  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 152, score:[2782.75], loss:[1.09188], sequence:[2], random actions:[46], eInit:[0.2192], init state:[1 0 7 1 0 0 0 0 1 1 1], end state:[3 0 7 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 153, score:[2734.00], loss:[0.97613], sequence:[0], random actions:[43], eInit:[0.2170], init state:[ 6 22 58  1  0  0  0  0  0  1  1], end state:[ 1 22 58  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 154, score:[2795.25], loss:[1.03913], sequence:[1], random actions:[39], eInit:[0.2149], init state:[ 1 11 39  0  0  0  0  0  0  0  0], end state:[ 3 11 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 155, score:[2692.75], loss:[0.97419], sequence:[0], random actions:[66], eInit:[0.2127], init state:[ 4 16 49  0  0  0  0  0  0  0  0], end state:[ 6 16 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 156, score:[2726.25], loss:[0.97346], sequence:[0], random actions:[40], eInit:[0.2106], init state:[ 4  1 50  0  0  0  0  0  0  0  0], end state:[ 6  1 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 157, score:[2791.50], loss:[1.04579], sequence:[1], random actions:[42], eInit:[0.2085], init state:[ 0  8 29  1  0  0  0  0  0  0  0], end state:[ 2  8 29  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 158, score:[2711.00], loss:[1.08340], sequence:[0], random actions:[49], eInit:[0.2064], init state:[ 6  3 41  0  0  0  0  0  0  0  0], end state:[ 1  3 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 159, score:[2671.00], loss:[1.35686], sequence:[0], random actions:[45], eInit:[0.2043], init state:[ 3 13 44  0  0  0  0  0  0  0  0], end state:[ 5 13 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 160, score:[2741.25], loss:[1.16248], sequence:[1], random actions:[37], eInit:[0.2023], init state:[ 1 10 11  0  0  0  0  0  0  0  0], end state:[ 3 10 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2795.25, [154]) , maxSequence:(3, [94, 148])
INFO:Reinforcement.Functions:episode: 161, score:[2723.75], loss:[1.19504], sequence:[0], random actions:[43], eInit:[0.2003], init state:[ 5  1 46  0  0  0  0  0  0  0  0], end state:[ 0  1 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 162, score:[2760.50], loss:[1.19384], sequence:[1], random actions:[32], eInit:[0.1983], init state:[ 5 11 32  0  0  0  0  0  0  0  0], end state:[ 0 11 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 163, score:[2734.00], loss:[1.21742], sequence:[0], random actions:[51], eInit:[0.1963], init state:[ 3  5 18  0  0  0  0  0  0  0  0], end state:[ 5  5 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 164, score:[2730.25], loss:[1.20228], sequence:[0], random actions:[47], eInit:[0.1943], init state:[ 5  9 53  0  0  0  0  0  0  0  0], end state:[ 0  9 53  0  0  0  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 165, score:[2727.25], loss:[1.24803], sequence:[0], random actions:[42], eInit:[0.1924], init state:[ 5  4 35  0  0  0  0  0  0  0  0], end state:[ 0  4 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 166, score:[2784.25], loss:[1.14389], sequence:[1], random actions:[33], eInit:[0.1905], init state:[ 5  2 46  0  0  0  0  0  0  0  0], end state:[ 0  2 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 167, score:[2737.00], loss:[1.30834], sequence:[2], random actions:[49], eInit:[0.1886], init state:[ 4 19 11  0  0  0  0  0  0  0  0], end state:[ 6 19 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 168, score:[2700.50], loss:[1.45049], sequence:[0], random actions:[53], eInit:[0.1867], init state:[ 4 21  5  0  0  0  0  0  0  0  0], end state:[ 6 21  5  1  1  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 169, score:[2692.75], loss:[1.48163], sequence:[0], random actions:[32], eInit:[0.1848], init state:[ 4 10 36  1  1  0  1  0  0  0  0], end state:[ 6 10 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 170, score:[2649.25], loss:[1.53632], sequence:[0], random actions:[47], eInit:[0.1830], init state:[ 3 12 11  0  0  0  0  0  0  0  0], end state:[ 5 12 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2795.25, [154]) , maxSequence:(3, [94, 148])
INFO:Reinforcement.Functions:episode: 171, score:[2734.00], loss:[1.41746], sequence:[0], random actions:[45], eInit:[0.1811], init state:[ 3  7 45  0  0  0  0  0  0  0  0], end state:[ 5  7 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 172, score:[2742.25], loss:[1.30553], sequence:[1], random actions:[51], eInit:[0.1793], init state:[ 1 15 49  0  0  0  0  0  0  0  0], end state:[ 3 15 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 173, score:[2723.25], loss:[1.31565], sequence:[0], random actions:[49], eInit:[0.1775], init state:[ 5  4 16  0  0  0  0  0  0  0  0], end state:[ 0  4 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 174, score:[2745.75], loss:[1.36117], sequence:[1], random actions:[42], eInit:[0.1757], init state:[ 2  6 44  0  0  0  0  0  0  0  0], end state:[ 4  6 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 175, score:[2773.25], loss:[1.35940], sequence:[2], random actions:[31], eInit:[0.1740], init state:[ 4  5 30  0  0  0  0  0  0  0  0], end state:[ 6  5 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 176, score:[2758.50], loss:[1.28743], sequence:[3], random actions:[43], eInit:[0.1722], init state:[ 4 14  3  0  0  0  0  0  0  0  0], end state:[ 6 14  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 177, score:[2755.00], loss:[1.32150], sequence:[4], random actions:[38], eInit:[0.1705], init state:[0 3 1 0 0 0 0 0 0 0 0], end state:[2 3 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 178, score:[2738.50], loss:[1.28985], sequence:[5], random actions:[53], eInit:[0.1688], init state:[ 1 19 52  0  0  0  0  0  0  0  0], end state:[ 3 19 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 179, score:[2729.00], loss:[1.15075], sequence:[0], random actions:[45], eInit:[0.1671], init state:[ 2 17  7  0  0  0  0  0  0  0  0], end state:[ 4 17  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 180, score:[2681.00], loss:[1.23420], sequence:[0], random actions:[38], eInit:[0.1655], init state:[ 4 18 21  0  0  0  0  0  0  0  0], end state:[ 6 18 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2795.25, [154]) , maxSequence:(5, [178])
INFO:Reinforcement.Functions:episode: 181, score:[2667.00], loss:[1.45048], sequence:[0], random actions:[42], eInit:[0.1638], init state:[ 4  9 40  1  0  0  0  0  0  0  0], end state:[ 6  9 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 182, score:[2780.00], loss:[1.14671], sequence:[1], random actions:[33], eInit:[0.1622], init state:[ 2  0 52  0  0  1  0  0  0  0  0], end state:[ 4  0 52  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 183, score:[2723.25], loss:[1.28376], sequence:[0], random actions:[46], eInit:[0.1605], init state:[ 1 15  5  0  0  0  0  0  0  0  0], end state:[ 3 15  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 184, score:[2703.75], loss:[1.31259], sequence:[0], random actions:[35], eInit:[0.1589], init state:[ 6  5 13  0  0  0  0  0  0  0  0], end state:[ 1  5 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 185, score:[2746.50], loss:[1.28755], sequence:[1], random actions:[33], eInit:[0.1574], init state:[0 0 0 1 0 0 0 0 0 1 1], end state:[2 0 0 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 186, score:[2758.25], loss:[1.20034], sequence:[2], random actions:[38], eInit:[0.1558], init state:[ 4  7 28  0  0  0  0  0  0  0  0], end state:[ 6  7 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 187, score:[2683.75], loss:[1.24658], sequence:[0], random actions:[32], eInit:[0.1542], init state:[ 5 14  6  0  0  0  0  0  0  0  0], end state:[ 0 14  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 188, score:[2770.00], loss:[1.14607], sequence:[1], random actions:[39], eInit:[0.1527], init state:[6 1 8 0 0 1 0 0 0 0 0], end state:[1 1 8 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 189, score:[2757.00], loss:[1.12518], sequence:[2], random actions:[31], eInit:[0.1512], init state:[ 5  2 53  0  0  0  0  0  0  0  0], end state:[ 0  2 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 190, score:[2728.00], loss:[1.24712], sequence:[0], random actions:[44], eInit:[0.1496], init state:[ 3 16 20  0  0  0  0  0  0  0  0], end state:[ 5 16 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2795.25, [154]) , maxSequence:(5, [178])
INFO:Reinforcement.Functions:episode: 191, score:[2761.50], loss:[1.10702], sequence:[1], random actions:[42], eInit:[0.1481], init state:[ 1  6 21  0  0  0  0  0  0  0  0], end state:[ 3  6 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 192, score:[2754.25], loss:[1.14095], sequence:[2], random actions:[47], eInit:[0.1467], init state:[ 1 13 10  0  0  0  0  0  0  0  0], end state:[ 3 13 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 193, score:[2781.25], loss:[1.16296], sequence:[3], random actions:[38], eInit:[0.1452], init state:[ 1 18 23  0  0  0  0  0  0  0  0], end state:[ 3 18 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 194, score:[2689.50], loss:[1.24195], sequence:[0], random actions:[51], eInit:[0.1437], init state:[ 4 10 48  1  1  0  1  0  0  0  0], end state:[ 6 10 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 195, score:[2772.00], loss:[1.13578], sequence:[1], random actions:[29], eInit:[0.1423], init state:[ 4 21  2  0  0  0  0  0  0  0  0], end state:[ 6 21  2  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 196, score:[2773.25], loss:[1.09451], sequence:[2], random actions:[34], eInit:[0.1409], init state:[ 4  1 42  0  0  0  0  0  0  0  0], end state:[ 6  1 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 197, score:[2812.50], loss:[1.04079], sequence:[3], random actions:[33], eInit:[0.1395], init state:[ 1  1 30  0  0  0  0  0  0  0  0], end state:[ 3  1 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 198, score:[2753.00], loss:[1.11189], sequence:[4], random actions:[35], eInit:[0.1381], init state:[ 6  4 39  0  0  0  0  0  0  0  0], end state:[ 1  4 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 199, score:[2760.50], loss:[1.14228], sequence:[5], random actions:[39], eInit:[0.1367], init state:[ 1  0 45  0  0  1  0  0  0  0  0], end state:[ 3  0 45  0  0  1  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 200, score:[2752.50], loss:[1.16099], sequence:[6], random actions:[45], eInit:[0.1353], init state:[ 3  3 30  0  0  0  0  0  0  0  0], end state:[ 5  3 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(6, [200])
INFO:Reinforcement.Functions:episode: 201, score:[2778.75], loss:[1.14903], sequence:[7], random actions:[38], eInit:[0.1340], init state:[ 0 16 41  0  0  0  0  0  0  0  0], end state:[ 2 16 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 202, score:[2691.50], loss:[1.11303], sequence:[0], random actions:[31], eInit:[0.1326], init state:[ 4  0 19  1  0  0  0  0  1  0  0], end state:[ 6  0 19  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 203, score:[2791.75], loss:[1.01779], sequence:[1], random actions:[32], eInit:[0.1313], init state:[ 0  0 48  0  0  1  0  0  0  0  0], end state:[ 2  0 48  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 204, score:[2757.00], loss:[1.08639], sequence:[2], random actions:[39], eInit:[0.1300], init state:[ 1  8 12  1  0  0  0  0  0  0  0], end state:[ 3  8 12  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 205, score:[2653.00], loss:[1.20645], sequence:[0], random actions:[57], eInit:[0.1287], init state:[ 2 11 43  0  0  0  0  0  0  0  0], end state:[ 4 11 43  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 206, score:[2756.75], loss:[1.16032], sequence:[1], random actions:[30], eInit:[0.1274], init state:[ 0 19 56  0  0  0  0  0  0  0  0], end state:[ 2 19 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 207, score:[2668.25], loss:[1.05307], sequence:[0], random actions:[37], eInit:[0.1261], init state:[ 4  5 21  0  0  0  0  0  0  0  0], end state:[ 6  5 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 208, score:[2762.50], loss:[1.17224], sequence:[1], random actions:[37], eInit:[0.1249], init state:[ 6 16 27  0  0  0  0  0  0  0  0], end state:[ 1 16 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 209, score:[2755.50], loss:[1.11553], sequence:[2], random actions:[42], eInit:[0.1236], init state:[ 3 12 14  0  0  0  0  0  0  0  0], end state:[ 5 12 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 210, score:[2782.50], loss:[1.03142], sequence:[3], random actions:[32], eInit:[0.1224], init state:[1 3 2 0 0 0 0 0 0 0 0], end state:[3 3 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(7, [201])
INFO:Reinforcement.Functions:episode: 211, score:[2748.50], loss:[1.07203], sequence:[4], random actions:[36], eInit:[0.1212], init state:[ 3 14 31  0  0  0  0  0  0  0  0], end state:[ 5 14 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 212, score:[2794.00], loss:[0.91331], sequence:[5], random actions:[41], eInit:[0.1200], init state:[ 1 16  3  0  0  0  0  0  0  0  0], end state:[ 3 16  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 213, score:[2761.50], loss:[1.05161], sequence:[6], random actions:[37], eInit:[0.1188], init state:[ 6  8 38  1  1  0  1  0  1  0  0], end state:[ 1  8 38  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 214, score:[2771.50], loss:[1.02425], sequence:[7], random actions:[38], eInit:[0.1176], init state:[ 6  2 43  0  0  0  0  0  0  0  0], end state:[ 1  2 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 215, score:[2740.25], loss:[1.13692], sequence:[8], random actions:[36], eInit:[0.1164], init state:[ 6 11 36  0  0  0  0  0  0  0  0], end state:[ 1 11 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 216, score:[2729.00], loss:[1.26587], sequence:[0], random actions:[34], eInit:[0.1152], init state:[ 5 20 51  1  0  0  0  0  0  0  0], end state:[ 0 20 51  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 217, score:[2805.50], loss:[1.04994], sequence:[1], random actions:[27], eInit:[0.1141], init state:[ 0 14 52  0  0  0  0  0  0  0  0], end state:[ 2 14 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 218, score:[2759.00], loss:[1.05555], sequence:[2], random actions:[45], eInit:[0.1129], init state:[ 6 14 36  0  0  0  0  0  0  0  0], end state:[ 1 14 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 219, score:[2680.25], loss:[1.08165], sequence:[0], random actions:[35], eInit:[0.1118], init state:[ 2 14 29  0  0  0  0  0  0  0  0], end state:[ 4 14 29  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 220, score:[2802.25], loss:[1.17469], sequence:[1], random actions:[29], eInit:[0.1107], init state:[ 2  2 22  0  0  0  0  0  0  0  0], end state:[ 4  2 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(8, [215])
INFO:Reinforcement.Functions:episode: 221, score:[2764.00], loss:[1.02375], sequence:[2], random actions:[41], eInit:[0.1096], init state:[ 6 19 26  0  0  0  0  0  0  0  0], end state:[ 1 19 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 222, score:[2742.50], loss:[1.01832], sequence:[3], random actions:[40], eInit:[0.1085], init state:[ 5  5 40  0  0  0  0  0  0  0  0], end state:[ 0  5 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 223, score:[2701.50], loss:[1.15685], sequence:[0], random actions:[34], eInit:[0.1074], init state:[ 3  4 25  0  0  0  0  0  0  0  0], end state:[ 5  4 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 224, score:[2722.50], loss:[1.19895], sequence:[0], random actions:[27], eInit:[0.1063], init state:[ 4 12 42  1  1  0  0  0  0  0  0], end state:[ 6 12 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 225, score:[2763.25], loss:[1.00151], sequence:[1], random actions:[30], eInit:[0.1053], init state:[ 2 18 13  0  0  0  0  0  0  0  0], end state:[ 4 18 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 226, score:[2666.50], loss:[1.17923], sequence:[0], random actions:[48], eInit:[0.1042], init state:[ 4 13 31  0  0  0  0  0  0  0  0], end state:[ 6 13 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 227, score:[2689.25], loss:[1.15403], sequence:[0], random actions:[29], eInit:[0.1032], init state:[ 3 10 58  0  0  0  0  0  0  0  0], end state:[ 5 10 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 228, score:[2700.25], loss:[1.28370], sequence:[0], random actions:[47], eInit:[0.1021], init state:[ 6 20  8  0  0  0  0  0  0  0  0], end state:[ 1 20  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 229, score:[2725.75], loss:[1.14819], sequence:[0], random actions:[37], eInit:[0.1011], init state:[ 4 19 42  0  0  0  0  0  0  0  0], end state:[ 6 19 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 230, score:[2760.75], loss:[1.02112], sequence:[1], random actions:[31], eInit:[0.1001], init state:[ 3 21 47  1  0  0  0  0  0  1  1], end state:[ 5 21 47  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(8, [215])
INFO:Reinforcement.Functions:episode: 231, score:[2729.75], loss:[1.07555], sequence:[0], random actions:[39], eInit:[0.0991], init state:[ 2  1 37  0  0  0  0  0  0  0  0], end state:[ 4  1 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 232, score:[2785.50], loss:[1.03530], sequence:[1], random actions:[33], eInit:[0.0981], init state:[ 0 13  0  0  0  0  0  0  0  0  0], end state:[ 2 13  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 233, score:[2769.25], loss:[0.93063], sequence:[2], random actions:[30], eInit:[0.0971], init state:[ 1 19 57  0  0  0  0  0  0  0  0], end state:[ 3 19 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 234, score:[2703.00], loss:[1.04429], sequence:[0], random actions:[38], eInit:[0.0962], init state:[4 6 6 0 0 0 0 0 0 0 0], end state:[6 6 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 235, score:[2776.25], loss:[1.09916], sequence:[1], random actions:[33], eInit:[0.0952], init state:[ 1 12 51  0  0  0  0  0  0  0  0], end state:[ 3 12 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 236, score:[2746.00], loss:[1.12379], sequence:[2], random actions:[31], eInit:[0.0942], init state:[ 6 11 59  0  0  0  0  0  0  0  0], end state:[ 1 11 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 237, score:[2735.25], loss:[1.06636], sequence:[0], random actions:[30], eInit:[0.0933], init state:[ 5 23 57  1  0  0  0  0  0  1  1], end state:[ 0 23 57  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 238, score:[2674.00], loss:[1.15651], sequence:[0], random actions:[32], eInit:[0.0924], init state:[ 4 23 23  0  0  0  0  0  0  0  0], end state:[ 6 23 23  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 239, score:[2781.50], loss:[1.12762], sequence:[1], random actions:[37], eInit:[0.0914], init state:[ 1 15  1  0  0  0  0  0  0  0  0], end state:[ 3 15  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 240, score:[2746.00], loss:[1.19973], sequence:[2], random actions:[31], eInit:[0.0905], init state:[ 5  7 34  0  0  0  0  0  0  0  0], end state:[ 0  7 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(8, [215])
INFO:Reinforcement.Functions:episode: 241, score:[2761.00], loss:[1.16166], sequence:[3], random actions:[31], eInit:[0.0896], init state:[ 2  6 33  0  0  0  0  0  0  0  0], end state:[ 4  6 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 242, score:[2697.75], loss:[1.24727], sequence:[0], random actions:[46], eInit:[0.0887], init state:[ 4 20  6  0  0  0  0  0  0  0  0], end state:[ 6 20  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 243, score:[2755.25], loss:[1.27229], sequence:[1], random actions:[40], eInit:[0.0878], init state:[ 6  8 12  1  0  0  0  0  0  0  0], end state:[ 1  8 12  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 244, score:[2719.00], loss:[1.16688], sequence:[0], random actions:[36], eInit:[0.0870], init state:[ 5  5 34  0  0  0  0  0  0  0  0], end state:[ 0  5 34  0  0  0  1  0  1  1  0]
INFO:Reinforcement.Functions:episode: 245, score:[2763.25], loss:[1.18924], sequence:[1], random actions:[29], eInit:[0.0861], init state:[ 6  6 14  0  0  0  0  0  0  0  0], end state:[ 1  6 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 246, score:[2690.25], loss:[1.27645], sequence:[0], random actions:[39], eInit:[0.0852], init state:[4 1 9 0 0 1 0 0 0 0 0], end state:[6 1 9 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 247, score:[2722.75], loss:[1.25815], sequence:[0], random actions:[36], eInit:[0.0844], init state:[4 7 5 0 0 0 0 0 0 0 0], end state:[6 7 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 248, score:[2739.25], loss:[1.22552], sequence:[1], random actions:[38], eInit:[0.0835], init state:[ 6 13 13  0  0  0  0  0  0  0  0], end state:[ 1 13 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 249, score:[2744.00], loss:[1.18136], sequence:[2], random actions:[33], eInit:[0.0827], init state:[ 3 17 40  0  0  0  0  0  0  0  0], end state:[ 5 17 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 250, score:[2793.00], loss:[1.06643], sequence:[3], random actions:[25], eInit:[0.0819], init state:[ 0  4 58  0  0  0  0  0  0  0  0], end state:[ 2  4 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(8, [215])
INFO:Reinforcement.Functions:episode: 251, score:[2769.75], loss:[1.04302], sequence:[4], random actions:[39], eInit:[0.0811], init state:[ 4 16  3  0  0  0  0  0  0  0  0], end state:[ 6 16  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 252, score:[2769.75], loss:[1.04344], sequence:[5], random actions:[35], eInit:[0.0802], init state:[ 6  4 58  0  0  0  0  0  0  0  0], end state:[ 1  4 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 253, score:[2745.50], loss:[1.16192], sequence:[6], random actions:[32], eInit:[0.0794], init state:[ 3 15 49  0  0  0  0  0  0  0  0], end state:[ 5 15 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 254, score:[2751.50], loss:[1.16810], sequence:[7], random actions:[39], eInit:[0.0787], init state:[ 6  9 29  0  0  0  0  0  0  0  0], end state:[ 1  9 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 255, score:[2803.25], loss:[1.04672], sequence:[8], random actions:[26], eInit:[0.0779], init state:[ 1  7 53  0  0  0  0  0  0  0  0], end state:[ 3  7 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 256, score:[2752.50], loss:[1.07209], sequence:[9], random actions:[38], eInit:[0.0771], init state:[ 5 22  3  1  0  0  1  0  0  1  1], end state:[ 0 22  3  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 257, score:[2778.25], loss:[1.04021], sequence:[10], random actions:[23], eInit:[0.0763], init state:[ 1 11 19  0  0  0  0  0  0  0  0], end state:[ 3 11 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 258, score:[2782.50], loss:[1.03111], sequence:[11], random actions:[30], eInit:[0.0756], init state:[ 6  3 47  0  0  0  0  0  0  0  0], end state:[ 1  3 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 259, score:[2716.00], loss:[1.12432], sequence:[0], random actions:[25], eInit:[0.0748], init state:[ 5  2 13  0  0  0  0  0  0  0  0], end state:[ 0  2 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 260, score:[2769.00], loss:[1.12150], sequence:[1], random actions:[21], eInit:[0.0740], init state:[ 3 10 11  0  0  0  0  0  0  0  0], end state:[ 5 10 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(11, [258])
INFO:Reinforcement.Functions:episode: 261, score:[2673.00], loss:[1.28579], sequence:[0], random actions:[40], eInit:[0.0733], init state:[ 4 10 28  1  1  0  1  0  1  0  0], end state:[ 6 10 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 262, score:[2726.75], loss:[1.26475], sequence:[0], random actions:[25], eInit:[0.0726], init state:[ 2 12 26  0  0  0  0  0  0  0  0], end state:[ 4 12 26  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 263, score:[2787.00], loss:[1.13418], sequence:[1], random actions:[28], eInit:[0.0718], init state:[ 2  7 36  0  0  0  0  0  0  0  0], end state:[ 4  7 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 264, score:[2740.00], loss:[1.11115], sequence:[2], random actions:[44], eInit:[0.0711], init state:[ 4  2 13  0  0  0  0  0  0  0  0], end state:[ 6  2 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 265, score:[2736.25], loss:[1.19420], sequence:[3], random actions:[25], eInit:[0.0704], init state:[ 5 23 53  1  0  0  0  0  0  1  1], end state:[ 0 23 53  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 266, score:[2701.25], loss:[1.32560], sequence:[0], random actions:[36], eInit:[0.0697], init state:[ 4 12  9  1  1  0  0  0  0  0  0], end state:[ 6 12  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 267, score:[2715.75], loss:[1.32134], sequence:[0], random actions:[37], eInit:[0.0690], init state:[ 3 23 51  1  0  0  0  0  0  1  1], end state:[ 5 23 51  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 268, score:[2697.75], loss:[1.30116], sequence:[0], random actions:[34], eInit:[0.0683], init state:[ 6  1 43  0  0  0  0  0  0  0  0], end state:[ 1  1 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 269, score:[2754.25], loss:[1.24132], sequence:[1], random actions:[30], eInit:[0.0676], init state:[ 5 23 12  1  0  0  1  0  0  1  1], end state:[ 0 23 12  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 270, score:[2703.50], loss:[1.37175], sequence:[0], random actions:[36], eInit:[0.0670], init state:[ 3 19 25  0  0  0  0  0  0  0  0], end state:[ 5 19 25  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(11, [258])
INFO:Reinforcement.Functions:episode: 271, score:[2780.50], loss:[1.42226], sequence:[1], random actions:[35], eInit:[0.0663], init state:[ 5 20 17  1  0  0  0  0  0  0  0], end state:[ 0 20 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 272, score:[2784.00], loss:[1.25347], sequence:[2], random actions:[28], eInit:[0.0656], init state:[ 1 17 29  0  0  0  0  0  0  0  0], end state:[ 3 17 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 273, score:[2744.00], loss:[1.32231], sequence:[3], random actions:[33], eInit:[0.0650], init state:[ 3 14 33  0  0  0  0  0  0  0  0], end state:[ 5 14 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 274, score:[2795.25], loss:[1.16152], sequence:[4], random actions:[29], eInit:[0.0643], init state:[ 1  3 32  0  0  0  0  0  0  0  0], end state:[ 3  3 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 275, score:[2706.50], loss:[1.41278], sequence:[0], random actions:[33], eInit:[0.0637], init state:[ 2 12 40  0  0  0  0  0  0  0  0], end state:[ 4 12 40  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 276, score:[2780.50], loss:[1.16341], sequence:[1], random actions:[37], eInit:[0.0630], init state:[ 0 20  5  0  0  0  0  0  0  0  0], end state:[ 2 20  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 277, score:[2769.25], loss:[1.12705], sequence:[2], random actions:[25], eInit:[0.0624], init state:[ 3 19 29  0  0  0  0  0  0  0  0], end state:[ 5 19 29  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 278, score:[2757.00], loss:[1.11661], sequence:[3], random actions:[33], eInit:[0.0618], init state:[ 2 16 36  0  0  0  0  0  0  0  0], end state:[ 4 16 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 279, score:[2750.25], loss:[1.14345], sequence:[4], random actions:[37], eInit:[0.0612], init state:[ 2 15 21  0  0  0  0  0  0  0  0], end state:[ 4 15 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 280, score:[2771.00], loss:[1.23985], sequence:[5], random actions:[20], eInit:[0.0606], init state:[ 5  1 28  0  0  0  0  0  0  0  0], end state:[ 0  1 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(11, [258])
INFO:Reinforcement.Functions:episode: 281, score:[2696.50], loss:[1.37915], sequence:[0], random actions:[25], eInit:[0.0600], init state:[ 3 22  8  1  0  0  0  0  0  1  1], end state:[ 5 22  8  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 282, score:[2768.75], loss:[1.29233], sequence:[1], random actions:[36], eInit:[0.0594], init state:[ 6 16 38  0  0  0  0  0  0  0  0], end state:[ 1 16 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 283, score:[2735.00], loss:[1.26791], sequence:[0], random actions:[40], eInit:[0.0588], init state:[ 3  1 33  0  0  0  0  0  0  0  0], end state:[ 5  1 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 284, score:[2745.75], loss:[1.29096], sequence:[1], random actions:[33], eInit:[0.0582], init state:[ 6 20 11  0  0  0  0  0  0  0  0], end state:[ 1 20 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 285, score:[2752.50], loss:[1.14282], sequence:[2], random actions:[35], eInit:[0.0576], init state:[ 1  0 32  0  0  1  0  0  0  0  0], end state:[ 3  0 32  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 286, score:[2772.75], loss:[1.36327], sequence:[3], random actions:[35], eInit:[0.0570], init state:[ 1 15  9  0  0  0  0  0  0  0  0], end state:[ 3 15  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 287, score:[2732.75], loss:[1.33510], sequence:[0], random actions:[31], eInit:[0.0565], init state:[ 3  9 26  0  0  0  0  0  0  0  0], end state:[ 5  9 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 288, score:[2779.50], loss:[1.38708], sequence:[1], random actions:[46], eInit:[0.0559], init state:[ 0 21  6  1  1  0  1  1  0  1  1], end state:[ 2 21  6  1  1  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 289, score:[2712.00], loss:[1.22244], sequence:[0], random actions:[35], eInit:[0.0553], init state:[ 3 21 48  1  0  0  0  0  0  1  1], end state:[ 5 21 48  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 290, score:[2702.75], loss:[1.24921], sequence:[0], random actions:[34], eInit:[0.0548], init state:[ 5  5 52  0  0  0  0  0  0  0  0], end state:[ 0  5 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(11, [258])
INFO:Reinforcement.Functions:episode: 291, score:[2808.00], loss:[1.10812], sequence:[1], random actions:[31], eInit:[0.0542], init state:[ 0 14 40  0  0  0  0  0  0  0  0], end state:[ 2 14 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 292, score:[2780.00], loss:[1.06123], sequence:[2], random actions:[26], eInit:[0.0537], init state:[ 2 16  5  0  0  0  0  0  0  0  0], end state:[ 4 16  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 293, score:[2736.50], loss:[1.03587], sequence:[3], random actions:[31], eInit:[0.0531], init state:[ 5  0 35  0  0  0  0  0  0  0  0], end state:[ 0  0 35  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 294, score:[2712.25], loss:[1.16132], sequence:[0], random actions:[32], eInit:[0.0526], init state:[ 4 14 25  0  0  0  0  0  0  0  0], end state:[ 6 14 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 295, score:[2757.75], loss:[1.29195], sequence:[1], random actions:[38], eInit:[0.0521], init state:[ 0  5 51  0  0  0  0  0  0  0  0], end state:[ 2  5 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 296, score:[2726.50], loss:[1.25630], sequence:[0], random actions:[35], eInit:[0.0516], init state:[ 5  9 47  0  0  0  0  0  0  0  0], end state:[ 0  9 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 297, score:[2810.75], loss:[1.03644], sequence:[1], random actions:[28], eInit:[0.0511], init state:[ 0 23 37  1  0  0  1  0  0  1  1], end state:[ 2 23 37  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 298, score:[2736.50], loss:[1.09129], sequence:[2], random actions:[34], eInit:[0.0505], init state:[ 4 22  0  0  0  0  0  0  0  0  0], end state:[ 6 22  0  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 299, score:[2730.50], loss:[1.17917], sequence:[0], random actions:[37], eInit:[0.0500], init state:[ 3  5 15  0  0  0  0  0  0  0  0], end state:[ 5  5 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 300, score:[2790.25], loss:[1.13954], sequence:[1], random actions:[35], eInit:[0.0495], init state:[ 1  8 21  1  0  0  0  0  0  0  0], end state:[ 3  8 21  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(11, [258])
INFO:Reinforcement.Functions:episode: 301, score:[2737.25], loss:[1.06824], sequence:[2], random actions:[22], eInit:[0.0490], init state:[ 5  1 10  0  0  0  0  0  0  0  0], end state:[ 0  1 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 302, score:[2719.50], loss:[1.23308], sequence:[0], random actions:[27], eInit:[0.0486], init state:[ 5 22  8  1  0  0  1  0  0  1  1], end state:[ 0 22  8  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 303, score:[2759.50], loss:[1.16808], sequence:[1], random actions:[28], eInit:[0.0481], init state:[ 4  7 16  0  0  0  0  0  0  0  0], end state:[ 6  7 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 304, score:[2790.25], loss:[1.14685], sequence:[2], random actions:[27], eInit:[0.0476], init state:[ 5  2 42  0  0  0  0  0  0  0  0], end state:[ 0  2 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 305, score:[2770.25], loss:[1.13219], sequence:[3], random actions:[30], eInit:[0.0471], init state:[ 3 20 34  1  1  0  0  0  0  0  0], end state:[ 5 20 34  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 306, score:[2752.00], loss:[1.07426], sequence:[4], random actions:[31], eInit:[0.0466], init state:[ 6 10 28  0  0  0  0  0  0  0  0], end state:[ 1 10 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 307, score:[2751.50], loss:[1.13252], sequence:[5], random actions:[30], eInit:[0.0462], init state:[ 5 11 21  0  0  0  0  0  0  0  0], end state:[ 0 11 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 308, score:[2803.50], loss:[1.14300], sequence:[6], random actions:[31], eInit:[0.0457], init state:[ 6  6 45  0  0  0  0  0  0  0  0], end state:[ 1  6 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 309, score:[2755.50], loss:[1.07445], sequence:[7], random actions:[40], eInit:[0.0453], init state:[ 3  8 18  1  0  0  0  0  0  0  0], end state:[ 5  8 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 310, score:[2781.25], loss:[1.01038], sequence:[8], random actions:[30], eInit:[0.0448], init state:[ 6  0 30  0  0  1  0  0  0  0  0], end state:[ 1  0 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2812.5, [197]) , maxSequence:(11, [258])
INFO:Reinforcement.Functions:episode: 311, score:[2756.75], loss:[1.01220], sequence:[9], random actions:[35], eInit:[0.0444], init state:[3 9 0 0 0 0 0 0 0 0 0], end state:[5 9 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 312, score:[2782.50], loss:[0.95757], sequence:[10], random actions:[33], eInit:[0.0439], init state:[ 6  1 24  0  0  0  0  0  0  0  0], end state:[ 1  1 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 313, score:[2807.50], loss:[0.95106], sequence:[11], random actions:[22], eInit:[0.0435], init state:[ 1 21 34  1  0  0  0  0  0  1  1], end state:[ 3 21 34  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 314, score:[2781.00], loss:[0.88196], sequence:[12], random actions:[24], eInit:[0.0430], init state:[5 6 2 0 0 0 0 0 0 0 0], end state:[0 6 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 315, score:[2742.25], loss:[0.91531], sequence:[13], random actions:[37], eInit:[0.0426], init state:[ 2 15 10  0  0  0  0  0  0  0  0], end state:[ 4 15 10  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 316, score:[2799.00], loss:[0.87764], sequence:[14], random actions:[32], eInit:[0.0422], init state:[2 2 1 0 0 0 0 0 0 0 0], end state:[4 2 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 317, score:[2807.25], loss:[0.80712], sequence:[15], random actions:[35], eInit:[0.0418], init state:[ 1  4 29  0  0  0  0  0  0  0  0], end state:[ 3  4 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 318, score:[2815.75], loss:[0.72525], sequence:[16], random actions:[24], eInit:[0.0413], init state:[ 1 10 46  0  0  0  0  0  0  0  0], end state:[ 3 10 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 319, score:[2788.75], loss:[0.76834], sequence:[17], random actions:[28], eInit:[0.0409], init state:[ 0 22 12  1  0  0  0  0  0  1  1], end state:[ 2 22 12  1  0  1  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 320, score:[2698.50], loss:[0.86857], sequence:[0], random actions:[27], eInit:[0.0405], init state:[ 4  9 55  1  0  0  0  0  0  0  0], end state:[ 6  9 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2815.75, [318]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 321, score:[2771.00], loss:[0.87108], sequence:[1], random actions:[32], eInit:[0.0401], init state:[ 2 23 22  1  0  0  1  0  0  1  1], end state:[ 4 23 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 322, score:[2739.00], loss:[0.86304], sequence:[2], random actions:[28], eInit:[0.0397], init state:[ 5 12 25  0  0  0  0  0  0  0  0], end state:[ 0 12 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 323, score:[2729.25], loss:[0.84596], sequence:[0], random actions:[34], eInit:[0.0393], init state:[ 2 23  5  1  0  0  0  0  0  1  1], end state:[ 4 23  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 324, score:[2795.00], loss:[0.83300], sequence:[1], random actions:[32], eInit:[0.0389], init state:[1 0 8 1 0 0 0 0 1 1 1], end state:[3 0 8 1 0 0 0 0 1 1 1]
INFO:Reinforcement.Functions:episode: 325, score:[2770.00], loss:[0.80199], sequence:[2], random actions:[26], eInit:[0.0385], init state:[ 3  1 50  0  0  0  0  0  0  0  0], end state:[ 5  1 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 326, score:[2787.75], loss:[0.84274], sequence:[3], random actions:[23], eInit:[0.0381], init state:[ 0  1 54  0  0  0  0  0  0  0  0], end state:[ 2  1 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 327, score:[2793.25], loss:[0.93631], sequence:[4], random actions:[29], eInit:[0.0378], init state:[2 4 7 0 0 0 0 0 0 0 0], end state:[4 4 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 328, score:[2783.00], loss:[0.79866], sequence:[5], random actions:[32], eInit:[0.0374], init state:[ 0 19  3  0  0  0  0  0  0  0  0], end state:[ 2 19  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 329, score:[2781.00], loss:[0.74957], sequence:[6], random actions:[32], eInit:[0.0370], init state:[ 2 17 56  0  0  0  0  0  0  0  0], end state:[ 4 17 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 330, score:[2795.75], loss:[0.76249], sequence:[7], random actions:[22], eInit:[0.0366], init state:[ 0 22 52  1  0  0  0  0  0  1  1], end state:[ 2 22 52  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2815.75, [318]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 331, score:[2769.00], loss:[0.74605], sequence:[8], random actions:[31], eInit:[0.0363], init state:[3 3 8 0 0 0 0 0 0 0 0], end state:[5 3 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 332, score:[2817.50], loss:[0.71066], sequence:[9], random actions:[29], eInit:[0.0359], init state:[ 0 14 31  0  0  0  0  0  0  0  0], end state:[ 2 14 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 333, score:[2822.00], loss:[0.70087], sequence:[10], random actions:[25], eInit:[0.0356], init state:[ 1 13 42  0  0  0  0  0  0  0  0], end state:[ 3 13 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 334, score:[2745.25], loss:[0.78468], sequence:[11], random actions:[33], eInit:[0.0352], init state:[ 3  4 39  0  0  0  0  0  0  0  0], end state:[ 5  4 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 335, score:[2777.75], loss:[0.77980], sequence:[12], random actions:[36], eInit:[0.0348], init state:[ 2  5 24  0  0  0  0  0  0  0  0], end state:[ 4  5 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 336, score:[2795.25], loss:[0.73745], sequence:[13], random actions:[26], eInit:[0.0345], init state:[ 0  9 38  0  0  0  0  0  0  0  0], end state:[ 2  9 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 337, score:[2684.50], loss:[0.87697], sequence:[0], random actions:[28], eInit:[0.0342], init state:[ 6  4 57  0  0  0  0  0  0  0  0], end state:[ 1  4 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 338, score:[2677.25], loss:[0.95953], sequence:[0], random actions:[31], eInit:[0.0338], init state:[5 6 9 0 0 0 0 0 0 0 0], end state:[0 6 9 0 0 0 0 1 0 0 0]
INFO:Reinforcement.Functions:episode: 339, score:[2809.25], loss:[0.84762], sequence:[1], random actions:[29], eInit:[0.0335], init state:[ 0  3 10  0  0  0  0  0  0  0  0], end state:[ 2  3 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 340, score:[2800.00], loss:[0.75902], sequence:[2], random actions:[35], eInit:[0.0331], init state:[ 1 12 46  0  0  0  0  0  0  0  0], end state:[ 3 12 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2822.0, [333]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 341, score:[2717.25], loss:[0.80872], sequence:[0], random actions:[29], eInit:[0.0328], init state:[ 4  3 58  0  0  0  0  0  0  0  0], end state:[ 6  3 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 342, score:[2770.00], loss:[0.86886], sequence:[1], random actions:[39], eInit:[0.0325], init state:[ 1 10  9  0  0  0  0  0  0  0  0], end state:[ 3 10  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 343, score:[2778.75], loss:[0.84625], sequence:[2], random actions:[26], eInit:[0.0322], init state:[ 1  6 53  0  0  0  0  0  0  0  0], end state:[ 3  6 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 344, score:[2776.25], loss:[0.83723], sequence:[3], random actions:[32], eInit:[0.0318], init state:[ 2 19 38  0  0  0  0  0  0  0  0], end state:[ 4 19 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 345, score:[2747.00], loss:[0.92898], sequence:[4], random actions:[31], eInit:[0.0315], init state:[ 6  7 29  0  0  0  0  0  0  0  0], end state:[ 1  7 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 346, score:[2805.50], loss:[0.78905], sequence:[5], random actions:[33], eInit:[0.0312], init state:[ 1 17 20  0  0  0  0  0  0  0  0], end state:[ 3 17 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 347, score:[2710.75], loss:[0.86988], sequence:[0], random actions:[33], eInit:[0.0309], init state:[ 4  7 33  0  0  0  0  0  0  0  0], end state:[ 6  7 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 348, score:[2717.00], loss:[1.01377], sequence:[0], random actions:[41], eInit:[0.0306], init state:[ 2 15 40  0  0  0  0  0  0  0  0], end state:[ 4 15 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 349, score:[2783.00], loss:[0.97092], sequence:[1], random actions:[32], eInit:[0.0303], init state:[ 0  1 11  0  0  0  0  0  0  0  0], end state:[ 2  1 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 350, score:[2695.25], loss:[1.09945], sequence:[0], random actions:[30], eInit:[0.0300], init state:[ 5  7 35  0  0  0  0  0  0  0  0], end state:[ 0  7 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2822.0, [333]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 351, score:[2776.75], loss:[0.97554], sequence:[1], random actions:[26], eInit:[0.0297], init state:[ 4 14 54  0  0  0  0  0  0  0  0], end state:[ 6 14 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 352, score:[2740.00], loss:[0.87958], sequence:[2], random actions:[31], eInit:[0.0294], init state:[ 4  6 59  0  0  0  0  0  0  0  0], end state:[ 6  6 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 353, score:[2714.25], loss:[1.10841], sequence:[0], random actions:[29], eInit:[0.0291], init state:[ 5 18 22  1  1  0  1  0  0  0  0], end state:[ 0 18 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 354, score:[2738.00], loss:[1.12953], sequence:[1], random actions:[30], eInit:[0.0288], init state:[ 6  3 41  0  0  0  0  0  0  0  0], end state:[ 1  3 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 355, score:[2765.50], loss:[1.10376], sequence:[2], random actions:[23], eInit:[0.0285], init state:[ 5 17 40  0  0  0  0  0  0  0  0], end state:[ 0 17 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 356, score:[2755.50], loss:[1.06111], sequence:[3], random actions:[44], eInit:[0.0282], init state:[ 1 23 42  1  0  0  1  0  0  1  1], end state:[ 3 23 42  1  0  0  0  0  1  1  1]
INFO:Reinforcement.Functions:episode: 357, score:[2799.00], loss:[0.98892], sequence:[4], random actions:[34], eInit:[0.0279], init state:[ 6 21 15  1  1  0  1  0  0  1  1], end state:[ 1 21 15  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 358, score:[2703.00], loss:[1.14199], sequence:[0], random actions:[22], eInit:[0.0277], init state:[ 5 10 45  0  0  0  0  0  0  0  0], end state:[ 0 10 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 359, score:[2750.25], loss:[1.14615], sequence:[1], random actions:[27], eInit:[0.0274], init state:[ 5 15  6  0  0  0  0  0  0  0  0], end state:[ 0 15  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 360, score:[2734.50], loss:[1.25004], sequence:[0], random actions:[31], eInit:[0.0271], init state:[ 3 20 22  0  0  0  0  0  0  0  0], end state:[ 5 20 22  1  0  0  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2822.0, [333]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 361, score:[2771.00], loss:[1.22489], sequence:[1], random actions:[27], eInit:[0.0268], init state:[ 1 17 44  0  0  0  0  0  0  0  0], end state:[ 3 17 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 362, score:[2677.25], loss:[1.39131], sequence:[0], random actions:[37], eInit:[0.0266], init state:[ 5  8 54  0  0  0  0  0  0  0  0], end state:[ 0  8 54  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 363, score:[2748.00], loss:[1.35272], sequence:[1], random actions:[40], eInit:[0.0263], init state:[ 6 19 58  0  0  0  0  0  0  0  0], end state:[ 1 19 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 364, score:[2814.00], loss:[1.15963], sequence:[2], random actions:[22], eInit:[0.0260], init state:[ 1 23 54  1  0  0  0  0  0  1  1], end state:[ 3 23 54  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 365, score:[2770.25], loss:[1.08516], sequence:[3], random actions:[26], eInit:[0.0258], init state:[ 6 10 41  0  0  0  0  0  0  0  0], end state:[ 1 10 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 366, score:[2752.00], loss:[1.13175], sequence:[4], random actions:[24], eInit:[0.0255], init state:[ 5 22  6  1  0  0  1  0  0  1  1], end state:[ 0 22  6  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 367, score:[2723.00], loss:[1.21743], sequence:[0], random actions:[35], eInit:[0.0253], init state:[ 4  1 33  0  0  0  0  0  0  0  0], end state:[ 6  1 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 368, score:[2809.25], loss:[1.12004], sequence:[1], random actions:[24], eInit:[0.0250], init state:[ 0  1 26  0  0  0  0  0  0  0  0], end state:[ 2  1 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 369, score:[2780.50], loss:[1.07354], sequence:[2], random actions:[31], eInit:[0.0248], init state:[ 0 14 21  0  0  0  0  0  0  0  0], end state:[ 2 14 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 370, score:[2759.25], loss:[1.01382], sequence:[3], random actions:[28], eInit:[0.0245], init state:[ 2 21 32  1  0  0  0  0  0  1  1], end state:[ 4 21 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2822.0, [333]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 371, score:[2743.00], loss:[1.13263], sequence:[4], random actions:[36], eInit:[0.0243], init state:[ 2 16 49  0  0  0  0  0  0  0  0], end state:[ 4 16 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 372, score:[2760.75], loss:[1.11505], sequence:[5], random actions:[31], eInit:[0.0240], init state:[ 1 11 10  0  0  0  0  0  0  0  0], end state:[ 3 11 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 373, score:[2748.00], loss:[1.12245], sequence:[6], random actions:[25], eInit:[0.0238], init state:[ 6 16  4  0  0  0  0  0  0  0  0], end state:[ 1 16  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 374, score:[2805.50], loss:[0.98317], sequence:[7], random actions:[20], eInit:[0.0235], init state:[ 2  7 29  0  0  0  0  0  0  0  0], end state:[ 4  7 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 375, score:[2792.25], loss:[0.91376], sequence:[8], random actions:[24], eInit:[0.0233], init state:[ 2 19 47  0  0  0  0  0  0  0  0], end state:[ 4 19 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 376, score:[2773.50], loss:[0.78942], sequence:[9], random actions:[25], eInit:[0.0231], init state:[ 2 20 40  1  1  0  0  0  0  1  1], end state:[ 4 20 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 377, score:[2776.75], loss:[0.88877], sequence:[10], random actions:[30], eInit:[0.0228], init state:[ 0 19  5  0  0  0  0  0  0  0  0], end state:[ 2 19  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 378, score:[2746.75], loss:[0.97155], sequence:[11], random actions:[28], eInit:[0.0226], init state:[ 3 11  6  0  0  0  0  0  0  0  0], end state:[ 5 11  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 379, score:[2633.00], loss:[0.95434], sequence:[0], random actions:[33], eInit:[0.0224], init state:[ 5  7 52  0  0  0  0  0  0  0  0], end state:[ 0  7 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 380, score:[2812.25], loss:[0.83325], sequence:[1], random actions:[23], eInit:[0.0222], init state:[ 6 15 58  0  0  0  0  0  0  0  0], end state:[ 1 15 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2822.0, [333]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 381, score:[2744.50], loss:[0.89955], sequence:[2], random actions:[32], eInit:[0.0219], init state:[5 3 3 0 0 0 0 0 0 0 0], end state:[0 3 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 382, score:[2774.50], loss:[1.06224], sequence:[3], random actions:[26], eInit:[0.0217], init state:[ 6 12 53  0  0  0  0  0  0  0  0], end state:[ 1 12 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 383, score:[2790.50], loss:[1.08549], sequence:[4], random actions:[22], eInit:[0.0215], init state:[4 5 7 0 0 0 0 0 0 0 0], end state:[6 5 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 384, score:[2803.00], loss:[0.96027], sequence:[5], random actions:[27], eInit:[0.0213], init state:[ 0 22 42  1  0  0  0  0  0  1  1], end state:[ 2 22 42  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 385, score:[2787.50], loss:[0.89079], sequence:[6], random actions:[26], eInit:[0.0211], init state:[ 2 19  0  0  0  0  0  0  0  0  0], end state:[ 4 19  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 386, score:[2825.00], loss:[0.85740], sequence:[7], random actions:[23], eInit:[0.0209], init state:[0 3 0 0 0 0 0 0 0 0 0], end state:[2 3 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 387, score:[2792.00], loss:[0.84804], sequence:[8], random actions:[30], eInit:[0.0207], init state:[ 1 22  6  1  0  0  0  0  0  1  1], end state:[ 3 22  6  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 388, score:[2780.00], loss:[0.81738], sequence:[9], random actions:[22], eInit:[0.0205], init state:[ 3  5 29  0  0  0  0  0  0  0  0], end state:[ 5  5 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 389, score:[2726.75], loss:[0.87094], sequence:[0], random actions:[37], eInit:[0.0203], init state:[ 0  7 17  0  0  0  0  0  0  0  0], end state:[ 2  7 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 390, score:[2791.50], loss:[0.69416], sequence:[1], random actions:[21], eInit:[0.0200], init state:[ 3  1 28  0  0  0  0  0  0  0  0], end state:[ 5  1 28  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2825.0, [386]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 391, score:[2784.00], loss:[0.80157], sequence:[2], random actions:[28], eInit:[0.0198], init state:[ 6 23  7  1  0  0  0  0  0  1  1], end state:[ 1 23  7  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 392, score:[2838.50], loss:[0.69213], sequence:[3], random actions:[19], eInit:[0.0196], init state:[ 1 17 33  0  0  0  0  0  0  0  0], end state:[ 3 17 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 393, score:[2733.75], loss:[0.87721], sequence:[0], random actions:[25], eInit:[0.0195], init state:[ 6  8 17  1  0  0  0  0  0  0  0], end state:[ 1  8 17  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 394, score:[2763.00], loss:[0.88410], sequence:[1], random actions:[33], eInit:[0.0193], init state:[ 3 14  9  0  0  0  0  0  0  0  0], end state:[ 5 14  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 395, score:[2727.75], loss:[0.88935], sequence:[0], random actions:[41], eInit:[0.0191], init state:[0 9 6 0 0 0 0 0 0 0 0], end state:[2 9 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 396, score:[2769.50], loss:[0.86337], sequence:[1], random actions:[34], eInit:[0.0189], init state:[ 2 16 44  0  0  0  0  0  0  0  0], end state:[ 4 16 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 397, score:[2776.75], loss:[0.90054], sequence:[2], random actions:[32], eInit:[0.0187], init state:[ 3  9 32  0  0  0  0  0  0  0  0], end state:[ 5  9 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 398, score:[2793.00], loss:[0.83954], sequence:[3], random actions:[29], eInit:[0.0185], init state:[ 0  2 54  0  0  0  0  0  0  0  0], end state:[ 2  2 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 399, score:[2821.25], loss:[0.80112], sequence:[4], random actions:[25], eInit:[0.0183], init state:[ 0 15 46  0  0  0  0  0  0  0  0], end state:[ 2 15 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 400, score:[2759.75], loss:[0.80178], sequence:[5], random actions:[28], eInit:[0.0181], init state:[ 3 12 10  0  0  0  0  0  0  0  0], end state:[ 5 12 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 401, score:[2788.75], loss:[0.76608], sequence:[6], random actions:[29], eInit:[0.0180], init state:[ 2 12 46  0  0  0  0  0  0  0  0], end state:[ 4 12 46  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 402, score:[2618.25], loss:[1.02562], sequence:[0], random actions:[32], eInit:[0.0178], init state:[ 5  7 54  0  0  0  0  0  0  0  0], end state:[ 0  7 54  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 403, score:[2733.75], loss:[1.02853], sequence:[0], random actions:[24], eInit:[0.0176], init state:[ 4 10 25  1  1  0  1  0  1  0  0], end state:[ 6 10 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 404, score:[2738.75], loss:[1.00897], sequence:[1], random actions:[27], eInit:[0.0174], init state:[ 6 18 18  0  0  0  0  0  0  0  0], end state:[ 1 18 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 405, score:[2761.00], loss:[1.02369], sequence:[2], random actions:[29], eInit:[0.0172], init state:[ 3  7 53  0  0  0  0  0  0  0  0], end state:[ 5  7 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 406, score:[2800.25], loss:[0.93892], sequence:[3], random actions:[35], eInit:[0.0171], init state:[ 0 18 19  0  0  0  0  0  0  0  0], end state:[ 2 18 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 407, score:[2712.25], loss:[0.97518], sequence:[0], random actions:[28], eInit:[0.0169], init state:[ 4 13 21  1  1  0  0  0  0  0  0], end state:[ 6 13 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 408, score:[2772.25], loss:[1.03900], sequence:[1], random actions:[17], eInit:[0.0167], init state:[ 6  3 52  0  0  0  0  0  0  0  0], end state:[ 1  3 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 409, score:[2742.75], loss:[0.99832], sequence:[2], random actions:[27], eInit:[0.0166], init state:[ 3 21 59  1  0  0  0  0  0  1  1], end state:[ 5 21 59  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 410, score:[2810.25], loss:[0.89806], sequence:[3], random actions:[31], eInit:[0.0164], init state:[ 0 20 36  1  1  0  0  0  0  0  0], end state:[ 2 20 36  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 411, score:[2821.75], loss:[0.77746], sequence:[4], random actions:[24], eInit:[0.0162], init state:[ 3 13 57  0  0  0  0  0  0  0  0], end state:[ 5 13 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 412, score:[2705.75], loss:[0.94495], sequence:[0], random actions:[32], eInit:[0.0161], init state:[6 5 7 0 0 0 0 0 0 0 0], end state:[1 5 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 413, score:[2689.75], loss:[0.94533], sequence:[0], random actions:[40], eInit:[0.0159], init state:[ 4 11 26  1  1  0  0  0  0  0  0], end state:[ 6 11 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 414, score:[2704.25], loss:[0.99317], sequence:[0], random actions:[25], eInit:[0.0158], init state:[ 4 10 59  1  1  0  1  0  0  0  0], end state:[ 6 10 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 415, score:[2785.75], loss:[0.90630], sequence:[1], random actions:[22], eInit:[0.0156], init state:[ 3 19 37  0  0  0  0  0  0  0  0], end state:[ 5 19 37  1  0  0  1  0  0  0  1]
INFO:Reinforcement.Functions:episode: 416, score:[2821.25], loss:[0.88255], sequence:[2], random actions:[26], eInit:[0.0154], init state:[ 1 11 34  0  0  0  0  0  0  0  0], end state:[ 3 11 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 417, score:[2762.75], loss:[0.90403], sequence:[3], random actions:[30], eInit:[0.0153], init state:[ 2  5 45  0  0  0  0  0  0  0  0], end state:[ 4  5 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 418, score:[2756.25], loss:[1.00504], sequence:[4], random actions:[24], eInit:[0.0151], init state:[ 2 20 54  1  1  0  1  0  0  1  1], end state:[ 4 20 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 419, score:[2742.00], loss:[0.92086], sequence:[5], random actions:[32], eInit:[0.0150], init state:[ 3 20 37  1  1  0  0  0  0  0  0], end state:[ 5 20 37  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 420, score:[2750.25], loss:[0.98931], sequence:[6], random actions:[19], eInit:[0.0148], init state:[6 1 6 0 0 1 0 0 0 0 0], end state:[1 1 6 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 421, score:[2760.50], loss:[0.99330], sequence:[7], random actions:[31], eInit:[0.0147], init state:[ 6  8 26  1  0  0  0  0  0  0  0], end state:[ 1  8 26  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 422, score:[2770.50], loss:[1.06892], sequence:[8], random actions:[27], eInit:[0.0145], init state:[ 3 10 21  0  0  0  0  0  0  0  0], end state:[ 5 10 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 423, score:[2737.50], loss:[1.07858], sequence:[9], random actions:[28], eInit:[0.0144], init state:[ 4  8 52  0  0  0  0  0  0  0  0], end state:[ 6  8 52  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 424, score:[2762.25], loss:[1.13033], sequence:[10], random actions:[24], eInit:[0.0142], init state:[ 4 10 42  1  1  0  1  0  0  0  0], end state:[ 6 10 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 425, score:[2791.25], loss:[1.04881], sequence:[11], random actions:[33], eInit:[0.0141], init state:[0 9 6 0 0 0 0 0 0 0 0], end state:[2 9 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 426, score:[2788.75], loss:[0.98873], sequence:[12], random actions:[25], eInit:[0.0140], init state:[ 2 10 36  0  0  0  0  0  0  0  0], end state:[ 4 10 36  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 427, score:[2677.25], loss:[1.24814], sequence:[0], random actions:[28], eInit:[0.0138], init state:[3 6 1 0 0 0 0 0 0 0 0], end state:[5 6 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 428, score:[2801.25], loss:[1.01239], sequence:[1], random actions:[24], eInit:[0.0137], init state:[ 0 19 13  0  0  0  0  0  0  0  0], end state:[ 2 19 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 429, score:[2774.50], loss:[0.93143], sequence:[2], random actions:[27], eInit:[0.0135], init state:[ 2 19  1  0  0  0  0  0  0  0  0], end state:[ 4 19  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 430, score:[2715.50], loss:[1.07577], sequence:[0], random actions:[32], eInit:[0.0134], init state:[ 3  6 18  0  0  0  0  0  0  0  0], end state:[ 5  6 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 431, score:[2761.75], loss:[1.07725], sequence:[1], random actions:[31], eInit:[0.0133], init state:[ 2 19 10  0  0  0  0  0  0  0  0], end state:[ 4 19 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 432, score:[2713.25], loss:[1.08853], sequence:[0], random actions:[32], eInit:[0.0131], init state:[ 3 19  8  0  0  0  0  0  0  0  0], end state:[ 5 19  8  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 433, score:[2682.00], loss:[1.22360], sequence:[0], random actions:[42], eInit:[0.0130], init state:[ 6  4 40  0  0  0  0  0  0  0  0], end state:[ 1  4 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 434, score:[2751.75], loss:[1.20935], sequence:[1], random actions:[28], eInit:[0.0129], init state:[ 6 23 53  1  0  0  0  0  0  1  1], end state:[ 1 23 53  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 435, score:[2803.25], loss:[1.06432], sequence:[2], random actions:[26], eInit:[0.0128], init state:[ 3 18 52  0  0  0  0  0  0  0  0], end state:[ 5 18 52  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 436, score:[2772.00], loss:[0.95866], sequence:[3], random actions:[27], eInit:[0.0126], init state:[1 3 9 0 0 0 0 0 0 0 0], end state:[3 3 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 437, score:[2719.75], loss:[1.05219], sequence:[0], random actions:[24], eInit:[0.0125], init state:[5 3 6 0 0 0 0 0 0 0 0], end state:[0 3 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 438, score:[2819.75], loss:[0.92796], sequence:[1], random actions:[23], eInit:[0.0124], init state:[ 1 21 45  1  0  0  0  0  0  1  1], end state:[ 3 21 45  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 439, score:[2743.75], loss:[0.99796], sequence:[2], random actions:[26], eInit:[0.0123], init state:[ 6  4 17  0  0  0  0  0  0  0  0], end state:[ 1  4 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 440, score:[2742.50], loss:[0.98736], sequence:[3], random actions:[33], eInit:[0.0121], init state:[ 6 16  2  0  0  0  0  0  0  0  0], end state:[ 1 16  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 441, score:[2767.25], loss:[1.03583], sequence:[4], random actions:[30], eInit:[0.0120], init state:[ 3 17 19  0  0  0  0  0  0  0  0], end state:[ 5 17 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 442, score:[2749.25], loss:[1.08894], sequence:[5], random actions:[30], eInit:[0.0119], init state:[ 2  1 50  0  0  0  0  0  0  0  0], end state:[ 4  1 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 443, score:[2694.25], loss:[1.28058], sequence:[0], random actions:[29], eInit:[0.0118], init state:[ 5 15 49  0  0  0  0  0  0  0  0], end state:[ 0 15 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 444, score:[2760.00], loss:[1.05208], sequence:[1], random actions:[32], eInit:[0.0117], init state:[ 5  7 15  0  0  0  0  0  0  0  0], end state:[ 0  7 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 445, score:[2795.75], loss:[0.99486], sequence:[2], random actions:[31], eInit:[0.0115], init state:[ 0 14 18  0  0  0  0  0  0  0  0], end state:[ 2 14 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 446, score:[2774.25], loss:[0.94937], sequence:[3], random actions:[25], eInit:[0.0114], init state:[ 6 16 23  0  0  0  0  0  0  0  0], end state:[ 1 16 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 447, score:[2757.00], loss:[1.04863], sequence:[4], random actions:[36], eInit:[0.0113], init state:[ 2  7 30  0  0  0  0  0  0  0  0], end state:[ 4  7 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 448, score:[2799.75], loss:[0.92370], sequence:[5], random actions:[22], eInit:[0.0112], init state:[ 2  5 22  0  0  0  0  0  0  0  0], end state:[ 4  5 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 449, score:[2761.25], loss:[1.05162], sequence:[6], random actions:[29], eInit:[0.0111], init state:[ 6  8 15  1  0  0  0  0  0  0  0], end state:[ 1  8 15  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 450, score:[2759.00], loss:[1.01987], sequence:[7], random actions:[35], eInit:[0.0110], init state:[ 0 11 40  0  0  0  0  0  0  0  0], end state:[ 2 11 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 451, score:[2732.00], loss:[1.11603], sequence:[0], random actions:[23], eInit:[0.0109], init state:[ 3 21 17  1  1  0  1  0  0  1  1], end state:[ 5 21 17  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 452, score:[2765.75], loss:[1.09047], sequence:[1], random actions:[29], eInit:[0.0108], init state:[ 2 14 42  0  0  0  0  0  0  0  0], end state:[ 4 14 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 453, score:[2730.25], loss:[1.14991], sequence:[0], random actions:[26], eInit:[0.0106], init state:[ 4 15  2  0  0  0  0  0  0  0  0], end state:[ 6 15  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 454, score:[2662.25], loss:[1.29957], sequence:[0], random actions:[31], eInit:[0.0105], init state:[ 5 12 24  0  0  0  0  0  0  0  0], end state:[ 0 12 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 455, score:[2750.00], loss:[1.19235], sequence:[1], random actions:[35], eInit:[0.0104], init state:[ 6  8 32  1  1  0  1  1  0  0  0], end state:[ 1  8 32  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 456, score:[2793.00], loss:[1.12121], sequence:[2], random actions:[26], eInit:[0.0103], init state:[ 6 10 51  0  0  0  0  0  0  0  0], end state:[ 1 10 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 457, score:[2786.50], loss:[1.03231], sequence:[3], random actions:[26], eInit:[0.0102], init state:[ 2 13 31  0  0  0  0  0  0  0  0], end state:[ 4 13 31  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 458, score:[2772.25], loss:[0.99918], sequence:[4], random actions:[23], eInit:[0.0101], init state:[ 3  7 42  0  0  0  0  0  0  0  0], end state:[ 5  7 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 459, score:[2762.50], loss:[1.01973], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 1  4 34  0  0  0  0  0  0  0  0], end state:[ 3  4 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 460, score:[2740.25], loss:[1.06826], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 4 17 27  0  0  0  0  0  0  0  0], end state:[ 6 17 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 461, score:[2802.00], loss:[0.92778], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 6 16 31  0  0  0  0  0  0  0  0], end state:[ 1 16 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 462, score:[2760.75], loss:[1.07113], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 2 20 59  1  1  0  1  0  0  1  1], end state:[ 4 20 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 463, score:[2774.00], loss:[1.12388], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 1 14 33  0  0  0  0  0  0  0  0], end state:[ 3 14 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 464, score:[2718.00], loss:[1.08037], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 16 10  0  0  0  0  0  0  0  0], end state:[ 0 16 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 465, score:[2747.00], loss:[1.09055], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 5 13 49  0  0  0  0  0  0  0  0], end state:[ 0 13 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 466, score:[2750.50], loss:[1.21792], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 1 20 19  0  0  0  0  0  0  0  0], end state:[ 3 20 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 467, score:[2746.75], loss:[1.08212], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0  3 37  0  0  0  0  0  0  0  0], end state:[ 2  3 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 468, score:[2662.25], loss:[1.29199], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4 18 17  0  0  0  0  0  0  0  0], end state:[ 6 18 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 469, score:[2791.00], loss:[1.16180], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 6  5 58  0  0  0  0  0  0  0  0], end state:[ 1  5 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 470, score:[2797.50], loss:[1.09790], sequence:[2], random actions:[37], eInit:[0.0100], init state:[2 7 9 0 0 0 0 0 0 0 0], end state:[4 7 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 471, score:[2706.00], loss:[1.02559], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  2 24  0  0  0  0  0  0  0  0], end state:[ 0  2 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 472, score:[2799.00], loss:[1.01362], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0 17 30  0  0  0  0  0  0  0  0], end state:[ 2 17 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 473, score:[2809.25], loss:[0.95845], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 13 41  0  0  0  0  0  0  0  0], end state:[ 2 13 41  1  0  1  0  1  1  1  0]
INFO:Reinforcement.Functions:episode: 474, score:[2743.00], loss:[1.01558], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 4 23  0  0  0  0  0  0  0  0  0], end state:[ 6 23  0  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 475, score:[2807.50], loss:[0.96471], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 1 17 45  0  0  0  0  0  0  0  0], end state:[ 3 17 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 476, score:[2752.75], loss:[1.05118], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 6 15 36  0  0  0  0  0  0  0  0], end state:[ 1 15 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 477, score:[2678.25], loss:[1.14188], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5  1 36  0  0  0  0  0  0  0  0], end state:[ 0  1 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 478, score:[2781.25], loss:[1.07906], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0  0 46  0  0  1  0  0  0  0  0], end state:[ 2  0 46  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 479, score:[2635.50], loss:[1.19298], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 21 39  0  0  0  0  0  0  0  0], end state:[ 6 21 39  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 480, score:[2681.00], loss:[1.31020], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 12 37  0  0  0  0  0  0  0  0], end state:[ 0 12 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 481, score:[2706.00], loss:[1.28710], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5  7 30  0  0  0  0  0  0  0  0], end state:[ 0  7 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 482, score:[2783.00], loss:[1.13380], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0  6 19  0  0  0  0  0  0  0  0], end state:[ 2  6 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 483, score:[2721.25], loss:[1.22847], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 21 47  1  0  0  0  0  0  1  1], end state:[ 4 21 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 484, score:[2807.00], loss:[1.12323], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0 22 41  1  0  0  0  0  0  1  1], end state:[ 2 22 41  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 485, score:[2679.25], loss:[1.21820], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 19 16  0  0  0  0  0  0  0  0], end state:[ 5 19 16  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 486, score:[2811.75], loss:[0.99133], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 1  1 48  0  0  0  0  0  0  0  0], end state:[ 3  1 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 487, score:[2647.50], loss:[1.23101], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  0 57  0  0  0  0  0  0  0  0], end state:[ 0  0 57  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 488, score:[2784.25], loss:[1.38612], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 6  8 18  1  0  0  0  0  0  0  0], end state:[ 1  8 18  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 489, score:[2708.75], loss:[1.37362], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  5 35  0  0  0  0  0  0  0  0], end state:[ 6  5 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 490, score:[2707.25], loss:[1.42102], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  0 55  1  0  1  0  0  0  0  0], end state:[ 6  0 55  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 491, score:[2717.75], loss:[1.35688], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 16  4  0  0  0  0  0  0  0  0], end state:[ 4 16  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 492, score:[2740.25], loss:[1.51387], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 6  5 21  0  0  0  0  0  0  0  0], end state:[ 1  5 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 493, score:[2779.00], loss:[1.41455], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 5 15 17  0  0  0  0  0  0  0  0], end state:[ 0 15 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 494, score:[2758.50], loss:[1.29850], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 3  0 48  0  0  1  0  0  0  0  0], end state:[ 5  0 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 495, score:[2811.00], loss:[1.15594], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 2  0 51  0  0  1  0  0  0  0  0], end state:[ 4  0 51  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 496, score:[2706.25], loss:[1.36856], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5  4 51  0  0  0  0  0  0  0  0], end state:[ 0  4 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 497, score:[2801.00], loss:[1.10204], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 0  4 41  0  0  0  0  0  0  0  0], end state:[ 2  4 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 498, score:[2815.25], loss:[0.97939], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 0 22 33  1  0  0  0  0  0  1  1], end state:[ 2 22 33  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 499, score:[2769.75], loss:[0.98618], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 6 18 32  0  0  0  0  0  0  0  0], end state:[ 1 18 32  0  1  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 500, score:[2749.25], loss:[1.00633], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 6 14 51  0  0  0  0  0  0  0  0], end state:[ 1 14 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 501, score:[2740.75], loss:[1.10876], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 5  7 17  0  0  0  0  0  0  0  0], end state:[ 0  7 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 502, score:[2818.25], loss:[0.98639], sequence:[6], random actions:[23], eInit:[0.0100], init state:[ 1  6 38  0  0  0  0  0  0  0  0], end state:[ 3  6 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 503, score:[2682.00], loss:[1.22468], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 15  2  0  0  0  0  0  0  0  0], end state:[ 5 15  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 504, score:[2780.75], loss:[1.05961], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 6  9 27  0  0  0  0  0  0  0  0], end state:[ 1  9 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 505, score:[2720.25], loss:[1.01551], sequence:[0], random actions:[31], eInit:[0.0100], init state:[4 4 1 0 0 0 0 0 0 0 0], end state:[6 4 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 506, score:[2784.75], loss:[1.09831], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 6 22 45  1  0  0  0  0  0  1  1], end state:[ 1 22 45  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 507, score:[2653.50], loss:[1.12282], sequence:[0], random actions:[45], eInit:[0.0100], init state:[ 3 20 44  1  1  0  0  0  0  1  1], end state:[ 5 20 44  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 508, score:[2756.25], loss:[1.16937], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 2 22 26  1  0  0  0  0  0  1  1], end state:[ 4 22 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 509, score:[2807.75], loss:[1.09480], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1 10 14  0  0  0  0  0  0  0  0], end state:[ 3 10 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 510, score:[2747.50], loss:[1.01527], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 3 19 54  0  0  0  0  0  0  0  0], end state:[ 5 19 54  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 511, score:[2725.25], loss:[1.08665], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  1 58  0  0  0  0  0  0  0  0], end state:[ 0  1 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 512, score:[2745.50], loss:[1.19405], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 3 15 54  0  0  0  0  0  0  0  0], end state:[ 5 15 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 513, score:[2821.25], loss:[0.85713], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0 22 41  1  0  0  0  0  0  1  1], end state:[ 2 22 41  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 514, score:[2767.00], loss:[0.90879], sequence:[3], random actions:[38], eInit:[0.0100], init state:[ 2 15 16  0  0  0  0  0  0  0  0], end state:[ 4 15 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 515, score:[2738.25], loss:[0.93875], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 6 12  1  0  0  0  0  0  0  0  0], end state:[ 1 12  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 516, score:[2789.25], loss:[0.84011], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 1 14 52  0  0  0  0  0  0  0  0], end state:[ 3 14 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 517, score:[2708.75], loss:[0.99349], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 2 22 35  1  0  0  0  0  0  1  1], end state:[ 4 22 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 518, score:[2818.75], loss:[0.81844], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2  3 27  0  0  0  0  0  0  0  0], end state:[ 4  3 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 519, score:[2686.75], loss:[0.98120], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  4 47  0  0  0  0  0  0  0  0], end state:[ 0  4 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 520, score:[2744.75], loss:[1.04439], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3 16 16  0  0  0  0  0  0  0  0], end state:[ 5 16 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 521, score:[2775.75], loss:[0.90551], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 6  2 19  0  0  0  0  0  0  0  0], end state:[ 1  2 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 522, score:[2783.50], loss:[0.81782], sequence:[3], random actions:[24], eInit:[0.0100], init state:[3 4 2 0 0 0 0 0 0 0 0], end state:[5 4 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 523, score:[2774.75], loss:[0.79331], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 1  1 12  0  0  0  0  0  0  0  0], end state:[ 3  1 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 524, score:[2748.50], loss:[0.89794], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 3 14 42  0  0  0  0  0  0  0  0], end state:[ 5 14 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 525, score:[2724.75], loss:[1.09962], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6  3 31  0  0  0  0  0  0  0  0], end state:[ 1  3 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 526, score:[2805.25], loss:[0.90521], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0  4 27  0  0  0  0  0  0  0  0], end state:[ 2  4 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 527, score:[2743.00], loss:[0.99433], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 4 12 21  1  1  0  0  0  0  0  0], end state:[ 6 12 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 528, score:[2818.00], loss:[0.99344], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 1 20  4  0  0  0  0  0  0  0  0], end state:[ 3 20  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 529, score:[2794.50], loss:[0.77779], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 6 11 35  0  0  0  0  0  0  0  0], end state:[ 1 11 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 530, score:[2693.75], loss:[0.90445], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 22  6  1  0  0  1  0  0  1  1], end state:[ 0 22  6  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 531, score:[2695.75], loss:[1.02332], sequence:[0], random actions:[38], eInit:[0.0100], init state:[3 0 9 1 0 0 0 0 1 1 1], end state:[5 0 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 532, score:[2751.50], loss:[1.00610], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3  9 49  0  0  0  0  0  0  0  0], end state:[ 5  9 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 533, score:[2771.00], loss:[0.93829], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 5 17 24  0  0  0  0  0  0  0  0], end state:[ 0 17 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 534, score:[2802.25], loss:[0.87062], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 0 19 32  0  0  0  0  0  0  0  0], end state:[ 2 19 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 535, score:[2822.25], loss:[0.87348], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 1 17 23  0  0  0  0  0  0  0  0], end state:[ 3 17 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 536, score:[2799.00], loss:[0.86256], sequence:[5], random actions:[18], eInit:[0.0100], init state:[ 4 20  5  0  0  0  0  0  0  0  0], end state:[ 6 20  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 537, score:[2796.25], loss:[0.78630], sequence:[6], random actions:[36], eInit:[0.0100], init state:[ 2 11 30  0  0  0  0  0  0  0  0], end state:[ 4 11 30  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 538, score:[2815.50], loss:[0.76446], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 1  4 18  0  0  0  0  0  0  0  0], end state:[ 3  4 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 539, score:[2723.75], loss:[0.90569], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6  6 26  0  0  0  0  0  0  0  0], end state:[ 1  6 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 540, score:[2790.00], loss:[0.79769], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 6  3 14  0  0  0  0  0  0  0  0], end state:[ 1  3 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 541, score:[2778.00], loss:[0.77152], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 1  2 45  0  0  0  0  0  0  0  0], end state:[ 3  2 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 542, score:[2724.00], loss:[0.80384], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 12 35  0  0  0  0  0  0  0  0], end state:[ 5 12 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 543, score:[2759.00], loss:[0.78984], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 3  2 44  0  0  0  0  0  0  0  0], end state:[ 5  2 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 544, score:[2732.75], loss:[0.99761], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 13  2  0  0  0  0  0  0  0  0], end state:[ 0 13  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 545, score:[2799.75], loss:[0.78699], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 1 18 22  0  0  0  0  0  0  0  0], end state:[ 3 18 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 546, score:[2741.00], loss:[0.86878], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 4 18 31  0  0  0  0  0  0  0  0], end state:[ 6 18 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 547, score:[2791.25], loss:[0.87600], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 0 17 53  0  0  0  0  0  0  0  0], end state:[ 2 17 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 548, score:[2791.25], loss:[0.73413], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 1  7 26  0  0  0  0  0  0  0  0], end state:[ 3  7 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 549, score:[2721.00], loss:[0.86348], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 21 59  0  0  0  0  0  0  0  0], end state:[ 6 21 59  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 550, score:[2802.50], loss:[0.90711], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 0 19 15  0  0  0  0  0  0  0  0], end state:[ 2 19 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 551, score:[2761.00], loss:[0.94669], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 0  1 43  0  0  0  0  0  0  0  0], end state:[ 2  1 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 552, score:[2828.75], loss:[0.88513], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 0  5 36  0  0  0  0  0  0  0  0], end state:[ 2  5 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 553, score:[2718.00], loss:[0.90809], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  2 15  0  0  0  0  0  0  0  0], end state:[ 0  2 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 554, score:[2758.75], loss:[1.03490], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 5 23 51  1  0  0  0  0  0  1  1], end state:[ 0 23 51  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 555, score:[2646.75], loss:[1.10467], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  7 19  0  0  0  0  0  0  0  0], end state:[ 6  7 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 556, score:[2720.50], loss:[1.12649], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 5 12 24  0  0  0  0  0  0  0  0], end state:[ 0 12 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 557, score:[2800.75], loss:[1.05717], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 18 37  0  0  0  0  0  0  0  0], end state:[ 2 18 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 558, score:[2733.75], loss:[0.98177], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3  2 14  0  0  0  0  0  0  0  0], end state:[ 5  2 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 559, score:[2752.75], loss:[1.09584], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3 23 29  1  0  0  1  0  0  1  1], end state:[ 5 23 29  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 560, score:[2715.00], loss:[1.12141], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3  7 56  0  0  0  0  0  0  0  0], end state:[ 5  7 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 561, score:[2768.25], loss:[1.05501], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1 23 20  1  0  0  1  0  0  1  1], end state:[ 3 23 20  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 562, score:[2785.75], loss:[0.89828], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0 22 12  1  0  0  0  0  0  1  1], end state:[ 2 22 12  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 563, score:[2786.00], loss:[1.07700], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0 22 10  1  0  0  0  0  0  1  1], end state:[ 2 22 10  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 564, score:[2785.50], loss:[1.01120], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 1 10 12  0  0  0  0  0  0  0  0], end state:[ 3 10 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 565, score:[2794.75], loss:[0.95549], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 0 14 36  0  0  0  0  0  0  0  0], end state:[ 2 14 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 566, score:[2705.75], loss:[1.33734], sequence:[0], random actions:[17], eInit:[0.0100], init state:[ 3 15 21  0  0  0  0  0  0  0  0], end state:[ 5 15 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 567, score:[2720.75], loss:[1.33408], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 10  4  1  1  0  1  0  0  0  0], end state:[ 6 10  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 568, score:[2786.75], loss:[1.13479], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 2  0 29  1  0  0  0  0  0  0  0], end state:[ 4  0 29  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 569, score:[2812.00], loss:[1.06200], sequence:[2], random actions:[29], eInit:[0.0100], init state:[1 0 4 1 0 0 0 0 0 1 1], end state:[3 0 4 0 0 0 0 0 1 1 0]
INFO:Reinforcement.Functions:episode: 570, score:[2772.25], loss:[1.05128], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 4 16 38  0  0  0  0  0  0  0  0], end state:[ 6 16 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 571, score:[2798.50], loss:[1.03146], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 6  5 47  0  0  0  0  0  0  0  0], end state:[ 1  5 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 572, score:[2731.00], loss:[1.01244], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6 16 51  0  0  0  0  0  0  0  0], end state:[ 1 16 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 573, score:[2764.25], loss:[0.94847], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3  4 30  0  0  0  0  0  0  0  0], end state:[ 5  4 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 574, score:[2714.50], loss:[1.00506], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 3 22 15  1  0  0  0  0  0  1  1], end state:[ 5 22 15  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 575, score:[2790.50], loss:[0.95176], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 6  9 25  0  0  0  0  0  0  0  0], end state:[ 1  9 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 576, score:[2727.50], loss:[1.10483], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 5  6 37  0  0  0  0  0  0  0  0], end state:[ 0  6 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 577, score:[2801.25], loss:[0.93163], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2  8 53  1  1  0  0  0  0  0  0], end state:[ 4  8 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 578, score:[2779.75], loss:[0.90648], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 2 13 36  0  0  0  0  0  0  0  0], end state:[ 4 13 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 579, score:[2807.75], loss:[0.96470], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 2  5 14  0  0  0  0  0  0  0  0], end state:[ 4  5 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 580, score:[2768.00], loss:[0.99804], sequence:[4], random actions:[26], eInit:[0.0100], init state:[3 7 4 0 0 0 0 0 0 0 0], end state:[5 7 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 581, score:[2765.75], loss:[1.07240], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 6 19 35  0  0  0  0  0  0  0  0], end state:[ 1 19 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 582, score:[2784.75], loss:[1.05556], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 6 14 18  0  0  0  0  0  0  0  0], end state:[ 1 14 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 583, score:[2803.00], loss:[1.09353], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 0 22 54  1  0  0  0  0  0  1  1], end state:[ 2 22 54  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 584, score:[2748.75], loss:[1.07504], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 3 19 46  0  0  0  0  0  0  0  0], end state:[ 5 19 46  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 585, score:[2809.75], loss:[0.92155], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 1  1 26  0  0  0  0  0  0  0  0], end state:[ 3  1 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 586, score:[2667.00], loss:[1.03610], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4  2 39  0  0  0  0  0  0  0  0], end state:[ 6  2 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 587, score:[2738.00], loss:[1.21341], sequence:[1], random actions:[40], eInit:[0.0100], init state:[ 4 21 41  0  0  0  0  0  0  0  0], end state:[ 6 21 41  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 588, score:[2811.50], loss:[1.01306], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 13 21  0  0  0  0  0  0  0  0], end state:[ 2 13 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 589, score:[2724.25], loss:[1.06294], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 3 20 55  1  1  0  1  0  0  1  1], end state:[ 5 20 55  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 590, score:[2742.50], loss:[1.20190], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 2  1 35  0  0  0  0  0  0  0  0], end state:[ 4  1 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 591, score:[2795.50], loss:[1.14314], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 0 14 44  0  0  0  0  0  0  0  0], end state:[ 2 14 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 592, score:[2761.50], loss:[1.09035], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 5 13  7  0  0  0  0  0  0  0  0], end state:[ 0 13  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 593, score:[2782.00], loss:[0.98064], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 4 14 40  0  0  0  0  0  0  0  0], end state:[ 6 14 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 594, score:[2818.25], loss:[0.88046], sequence:[5], random actions:[23], eInit:[0.0100], init state:[ 1 15 15  0  0  0  0  0  0  0  0], end state:[ 3 15 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 595, score:[2795.00], loss:[0.88170], sequence:[6], random actions:[29], eInit:[0.0100], init state:[1 0 8 1 0 0 0 0 1 1 1], end state:[3 0 8 1 0 0 0 0 1 1 1]
INFO:Reinforcement.Functions:episode: 596, score:[2678.75], loss:[1.18398], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 14 13  0  0  0  0  0  0  0  0], end state:[ 0 14 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 597, score:[2769.50], loss:[1.14001], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6  4 12  0  0  0  0  0  0  0  0], end state:[ 1  4 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 598, score:[2797.00], loss:[1.05648], sequence:[2], random actions:[36], eInit:[0.0100], init state:[1 7 3 0 0 0 0 0 0 0 0], end state:[3 7 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 599, score:[2760.50], loss:[0.99346], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 4  7 49  0  0  0  0  0  0  0  0], end state:[ 6  7 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 600, score:[2778.50], loss:[1.01021], sequence:[4], random actions:[37], eInit:[0.0100], init state:[ 2 21 52  1  0  0  0  0  0  1  1], end state:[ 4 21 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 601, score:[2793.50], loss:[0.95804], sequence:[5], random actions:[23], eInit:[0.0100], init state:[ 4 10 55  1  1  0  1  0  0  0  0], end state:[ 6 10 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 602, score:[2779.75], loss:[0.97828], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 0 23 30  1  0  0  1  0  0  1  1], end state:[ 2 23 30  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 603, score:[2806.50], loss:[1.01135], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 1  7 41  0  0  0  0  0  0  0  0], end state:[ 3  7 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 604, score:[2809.50], loss:[0.81374], sequence:[8], random actions:[30], eInit:[0.0100], init state:[ 3 15  0  0  0  0  0  0  0  0  0], end state:[ 5 15  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 605, score:[2752.75], loss:[0.87337], sequence:[9], random actions:[39], eInit:[0.0100], init state:[ 4 20  0  0  0  0  0  0  0  0  0], end state:[ 6 20  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 606, score:[2795.75], loss:[0.86589], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 1 20 28  0  0  0  0  0  0  0  0], end state:[ 3 20 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 607, score:[2795.25], loss:[0.88800], sequence:[11], random actions:[28], eInit:[0.0100], init state:[ 1  1 33  0  0  0  0  0  0  0  0], end state:[ 3  1 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 608, score:[2745.00], loss:[0.93480], sequence:[12], random actions:[26], eInit:[0.0100], init state:[ 3 15  9  0  0  0  0  0  0  0  0], end state:[ 5 15  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 609, score:[2751.75], loss:[0.97159], sequence:[13], random actions:[28], eInit:[0.0100], init state:[ 6  2 23  0  0  0  0  0  0  0  0], end state:[ 1  2 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 610, score:[2732.50], loss:[0.97437], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4  1 50  0  0  0  0  0  0  0  0], end state:[ 6  1 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2838.5, [392]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 611, score:[2741.25], loss:[0.92529], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 5 23 46  1  0  0  0  0  0  1  1], end state:[ 0 23 46  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 612, score:[2829.00], loss:[0.91277], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 1  3 47  0  0  0  0  0  0  0  0], end state:[ 3  3 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 613, score:[2740.75], loss:[0.78964], sequence:[3], random actions:[27], eInit:[0.0100], init state:[4 1 5 0 0 1 0 0 0 0 0], end state:[6 1 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 614, score:[2761.50], loss:[0.83986], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 4 16  8  0  0  0  0  0  0  0  0], end state:[ 6 16  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 615, score:[2780.75], loss:[0.75673], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 0  8 14  1  0  0  0  0  0  0  0], end state:[ 2  8 14  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 616, score:[2707.00], loss:[1.00215], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 14 12  0  0  0  0  0  0  0  0], end state:[ 5 14 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 617, score:[2839.00], loss:[0.70641], sequence:[1], random actions:[17], eInit:[0.0100], init state:[ 1  0 55  0  0  1  0  0  0  0  0], end state:[ 3  0 55  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 618, score:[2804.00], loss:[0.69308], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 3 16 23  0  0  0  0  0  0  0  0], end state:[ 5 16 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 619, score:[2767.25], loss:[0.73032], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 5  8 52  0  0  0  0  0  0  0  0], end state:[ 0  8 52  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 620, score:[2717.75], loss:[0.82858], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 14 50  0  0  0  0  0  0  0  0], end state:[ 6 14 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 621, score:[2779.50], loss:[0.94068], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 6 20 36  1  1  0  0  0  0  0  0], end state:[ 1 20 36  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 622, score:[2775.00], loss:[0.79438], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0  3 33  0  0  0  0  0  0  0  0], end state:[ 2  3 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 623, score:[2796.75], loss:[0.72169], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 3 11 39  0  0  0  0  0  0  0  0], end state:[ 5 11 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 624, score:[2769.00], loss:[0.82665], sequence:[4], random actions:[37], eInit:[0.0100], init state:[ 5 22 19  1  0  0  1  0  0  1  1], end state:[ 0 22 19  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 625, score:[2778.25], loss:[0.82807], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 4  7 19  0  0  0  0  0  0  0  0], end state:[ 6  7 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 626, score:[2699.50], loss:[1.03636], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3 16 22  0  0  0  0  0  0  0  0], end state:[ 5 16 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 627, score:[2754.75], loss:[0.95515], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 5  9 46  0  0  0  0  0  0  0  0], end state:[ 0  9 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 628, score:[2787.00], loss:[0.91516], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 10 36  0  0  0  0  0  0  0  0], end state:[ 4 10 36  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 629, score:[2804.75], loss:[0.84348], sequence:[3], random actions:[27], eInit:[0.0100], init state:[1 9 2 0 0 0 0 0 0 0 0], end state:[3 9 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 630, score:[2775.25], loss:[0.94012], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 3 13 18  0  0  0  0  0  0  0  0], end state:[ 5 13 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 631, score:[2733.25], loss:[1.15646], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2  7 32  0  0  0  0  0  0  0  0], end state:[ 4  7 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 632, score:[2779.25], loss:[1.01773], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0  1 59  0  0  0  0  0  0  0  0], end state:[ 2  1 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 633, score:[2687.25], loss:[1.02610], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 23 55  0  0  0  0  0  0  0  0], end state:[ 6 23 55  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 634, score:[2731.75], loss:[1.16779], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2 11 45  0  0  0  0  0  0  0  0], end state:[ 4 11 45  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 635, score:[2743.00], loss:[1.11269], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 5  5 22  0  0  0  0  0  0  0  0], end state:[ 0  5 22  0  1  1  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 636, score:[2774.50], loss:[0.95785], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 2  5 41  0  0  0  0  0  0  0  0], end state:[ 4  5 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 637, score:[2751.75], loss:[1.01382], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 4  0 24  1  0  0  0  0  1  0  0], end state:[ 6  0 24  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 638, score:[2807.00], loss:[0.95659], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 0 17 39  0  0  0  0  0  0  0  0], end state:[ 2 17 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 639, score:[2681.50], loss:[1.30703], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 15 43  0  0  0  0  0  0  0  0], end state:[ 1 15 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 640, score:[2764.50], loss:[1.02825], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 1 16 37  0  0  0  0  0  0  0  0], end state:[ 3 16 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 641, score:[2772.50], loss:[1.04004], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 4 16  5  0  0  0  0  0  0  0  0], end state:[ 6 16  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 642, score:[2795.50], loss:[0.92804], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 3 10 52  0  0  0  0  0  0  0  0], end state:[ 5 10 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 643, score:[2746.50], loss:[0.93536], sequence:[4], random actions:[31], eInit:[0.0100], init state:[3 5 8 0 0 0 0 0 0 0 0], end state:[5 5 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 644, score:[2787.50], loss:[1.08842], sequence:[5], random actions:[18], eInit:[0.0100], init state:[ 0  5 13  0  0  0  0  0  0  0  0], end state:[ 2  5 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 645, score:[2784.75], loss:[0.94395], sequence:[6], random actions:[29], eInit:[0.0100], init state:[0 9 5 0 0 0 0 0 0 0 0], end state:[2 9 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 646, score:[2757.75], loss:[1.09939], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 6  0 48  0  0  1  0  0  0  0  0], end state:[ 1  0 48  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 647, score:[2728.50], loss:[1.14724], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5 10 48  0  0  0  0  0  0  0  0], end state:[ 0 10 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 648, score:[2759.75], loss:[0.99201], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 11  2  0  0  0  0  0  0  0  0], end state:[ 3 11  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 649, score:[2775.00], loss:[0.99070], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 3  2 41  0  0  0  0  0  0  0  0], end state:[ 5  2 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 650, score:[2804.75], loss:[0.95040], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 2 17 52  0  0  0  0  0  0  0  0], end state:[ 4 17 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 651, score:[2754.75], loss:[0.88726], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 4  2 57  0  0  0  0  0  0  0  0], end state:[ 6  2 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 652, score:[2793.25], loss:[0.87198], sequence:[5], random actions:[38], eInit:[0.0100], init state:[ 1  9 32  0  0  0  0  0  0  0  0], end state:[ 3  9 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 653, score:[2801.00], loss:[0.78615], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 0  1 34  0  0  0  0  0  0  0  0], end state:[ 2  1 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 654, score:[2821.25], loss:[0.72219], sequence:[7], random actions:[22], eInit:[0.0100], init state:[ 0  1 19  0  0  0  0  0  0  0  0], end state:[ 2  1 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 655, score:[2758.00], loss:[0.80406], sequence:[8], random actions:[29], eInit:[0.0100], init state:[ 6  3 27  0  0  0  0  0  0  0  0], end state:[ 1  3 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 656, score:[2828.75], loss:[0.74984], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 3 17  0  0  0  0  0  0  0  0  0], end state:[ 5 17  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 657, score:[2780.25], loss:[0.79157], sequence:[10], random actions:[35], eInit:[0.0100], init state:[ 0  2 51  0  0  0  0  0  0  0  0], end state:[ 2  2 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 658, score:[2811.25], loss:[0.80222], sequence:[11], random actions:[26], eInit:[0.0100], init state:[ 0  4 49  0  0  0  0  0  0  0  0], end state:[ 2  4 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 659, score:[2832.00], loss:[0.68333], sequence:[12], random actions:[21], eInit:[0.0100], init state:[ 0 22 28  1  0  0  0  0  0  1  1], end state:[ 2 22 28  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 660, score:[2705.75], loss:[0.78156], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 2 23 50  1  0  0  0  0  0  1  1], end state:[ 4 23 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 661, score:[2724.25], loss:[1.12149], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 12 42  0  0  0  0  0  0  0  0], end state:[ 0 12 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 662, score:[2819.00], loss:[0.88290], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 0 18 28  0  0  0  0  0  0  0  0], end state:[ 2 18 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 663, score:[2738.00], loss:[1.00407], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 5 12 24  0  0  0  0  0  0  0  0], end state:[ 0 12 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 664, score:[2743.75], loss:[0.92913], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 4 11 26  1  1  0  0  0  0  0  0], end state:[ 6 11 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 665, score:[2768.25], loss:[0.88943], sequence:[4], random actions:[34], eInit:[0.0100], init state:[ 6 13  3  0  0  0  0  0  0  0  0], end state:[ 1 13  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 666, score:[2783.75], loss:[0.75711], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 0  3 31  0  0  0  0  0  0  0  0], end state:[ 2  3 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 667, score:[2755.25], loss:[0.83954], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 4 15 51  0  0  0  0  0  0  0  0], end state:[ 6 15 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 668, score:[2750.50], loss:[0.92987], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 5  5 53  0  0  0  0  0  0  0  0], end state:[ 0  5 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 669, score:[2771.25], loss:[0.97483], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 5  3 26  0  0  0  0  0  0  0  0], end state:[ 0  3 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 670, score:[2791.75], loss:[0.95645], sequence:[9], random actions:[28], eInit:[0.0100], init state:[ 6  6 12  0  0  0  0  0  0  0  0], end state:[ 1  6 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 671, score:[2775.50], loss:[0.91322], sequence:[10], random actions:[32], eInit:[0.0100], init state:[ 4 17 56  0  0  0  0  0  0  0  0], end state:[ 6 17 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 672, score:[2816.75], loss:[0.81290], sequence:[11], random actions:[26], eInit:[0.0100], init state:[ 0  4 31  0  0  0  0  0  0  0  0], end state:[ 2  4 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 673, score:[2735.50], loss:[0.87970], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2 13  7  0  0  0  0  0  0  0  0], end state:[ 4 13  7  0  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 674, score:[2817.25], loss:[1.15605], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 5 20 38  1  0  0  0  0  0  0  0], end state:[ 0 20 38  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 675, score:[2773.75], loss:[0.97888], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3 23 32  1  0  0  1  0  0  1  1], end state:[ 5 23 32  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 676, score:[2787.50], loss:[0.99929], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 6 23  1  1  0  0  0  0  0  1  1], end state:[ 1 23  1  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 677, score:[2784.00], loss:[0.92840], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 1 12  7  0  0  0  0  0  0  0  0], end state:[ 3 12  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 678, score:[2754.50], loss:[0.97043], sequence:[5], random actions:[38], eInit:[0.0100], init state:[5 0 1 0 0 0 0 0 0 0 0], end state:[0 0 1 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 679, score:[2778.25], loss:[1.03210], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 4 13 50  0  0  0  0  0  0  0  0], end state:[ 6 13 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 680, score:[2775.50], loss:[1.02496], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 0  6 16  0  0  0  0  0  0  0  0], end state:[ 2  6 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 681, score:[2752.75], loss:[1.02301], sequence:[8], random actions:[36], eInit:[0.0100], init state:[ 6 10 50  0  0  0  0  0  0  0  0], end state:[ 1 10 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 682, score:[2776.25], loss:[1.05042], sequence:[9], random actions:[24], eInit:[0.0100], init state:[ 6 11 24  0  0  0  0  0  0  0  0], end state:[ 1 11 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 683, score:[2800.25], loss:[0.95248], sequence:[10], random actions:[33], eInit:[0.0100], init state:[ 5 23 43  1  0  0  0  0  0  1  1], end state:[ 0 23 43  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 684, score:[2749.00], loss:[1.06356], sequence:[11], random actions:[33], eInit:[0.0100], init state:[ 3  9 10  0  0  0  0  0  0  0  0], end state:[ 5  9 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 685, score:[2778.00], loss:[1.01632], sequence:[12], random actions:[32], eInit:[0.0100], init state:[ 6 18  2  0  0  0  0  0  0  0  0], end state:[ 1 18  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 686, score:[2782.50], loss:[0.92293], sequence:[13], random actions:[29], eInit:[0.0100], init state:[ 0  4 30  0  0  0  0  0  0  0  0], end state:[ 2  4 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 687, score:[2725.75], loss:[1.07052], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 22  6  1  0  0  0  0  0  1  1], end state:[ 4 22  6  1  0  0  1  0  0  0  1]
INFO:Reinforcement.Functions:episode: 688, score:[2808.25], loss:[1.11790], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 17 20  0  0  0  0  0  0  0  0], end state:[ 2 17 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 689, score:[2664.00], loss:[1.21946], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4  6 10  0  0  0  0  0  0  0  0], end state:[ 6  6 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 690, score:[2774.00], loss:[1.12509], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 5  5 23  0  0  0  0  0  0  0  0], end state:[ 0  5 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 691, score:[2785.50], loss:[1.06859], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1 21  8  1  1  0  1  1  0  1  1], end state:[ 3 21  8  1  1  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 692, score:[2728.75], loss:[1.15942], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5  9 15  0  0  0  0  0  0  0  0], end state:[ 0  9 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 693, score:[2765.25], loss:[1.32455], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 5 21 36  1  0  0  1  0  0  1  1], end state:[ 0 21 36  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 694, score:[2768.50], loss:[1.29643], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 5 14 18  0  0  0  0  0  0  0  0], end state:[ 0 14 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 695, score:[2750.00], loss:[1.13199], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 0  3 11  0  0  0  0  0  0  0  0], end state:[ 2  3 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 696, score:[2784.50], loss:[1.15571], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 5 20 19  1  0  0  0  0  0  0  0], end state:[ 0 20 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 697, score:[2790.00], loss:[1.01258], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 0  0 13  1  0  0  0  0  1  1  1], end state:[ 2  0 13  1  0  0  0  0  1  1  1]
INFO:Reinforcement.Functions:episode: 698, score:[2799.75], loss:[0.94361], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 2 10 18  0  0  0  0  0  0  0  0], end state:[ 4 10 18  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 699, score:[2809.25], loss:[0.90984], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 1 20 34  1  1  0  0  0  0  0  0], end state:[ 3 20 34  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 700, score:[2747.25], loss:[1.07477], sequence:[8], random actions:[25], eInit:[0.0100], init state:[ 3  8 33  1  1  0  1  1  0  0  0], end state:[ 5  8 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 701, score:[2794.25], loss:[1.07479], sequence:[9], random actions:[22], eInit:[0.0100], init state:[ 1  4 21  0  0  0  0  0  0  0  0], end state:[ 3  4 21  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 702, score:[2767.25], loss:[1.01386], sequence:[10], random actions:[30], eInit:[0.0100], init state:[ 6 16 43  0  0  0  0  0  0  0  0], end state:[ 1 16 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 703, score:[2788.50], loss:[0.90656], sequence:[11], random actions:[24], eInit:[0.0100], init state:[ 0 16  8  0  0  0  0  0  0  0  0], end state:[ 2 16  8  0  0  1  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 704, score:[2718.00], loss:[1.03222], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 14 40  0  0  0  0  0  0  0  0], end state:[ 0 14 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 705, score:[2813.50], loss:[1.02235], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0  2 34  0  0  0  0  0  0  0  0], end state:[ 2  2 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 706, score:[2718.25], loss:[1.11342], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 11 42  0  0  0  0  0  0  0  0], end state:[ 1 11 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 707, score:[2803.25], loss:[0.97440], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 10 45  0  0  0  0  0  0  0  0], end state:[ 3 10 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 708, score:[2801.25], loss:[0.84649], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 23 16  1  0  0  1  0  0  1  1], end state:[ 3 23 16  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 709, score:[2816.50], loss:[0.76121], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 2  5 25  0  0  0  0  0  0  0  0], end state:[ 4  5 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 710, score:[2811.50], loss:[0.84210], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 6 10  2  0  0  0  0  0  0  0  0], end state:[ 1 10  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 711, score:[2726.00], loss:[1.14294], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 11 56  0  0  0  0  0  0  0  0], end state:[ 0 11 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 712, score:[2783.25], loss:[0.90565], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 10 31  0  0  0  0  0  0  0  0], end state:[ 3 10 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 713, score:[2808.25], loss:[0.86800], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 1 21 46  1  0  0  0  0  0  1  1], end state:[ 3 21 46  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 714, score:[2815.50], loss:[0.84296], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 6 21 55  1  0  0  0  0  0  1  1], end state:[ 1 21 55  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 715, score:[2687.75], loss:[0.90830], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 2 21 52  1  0  0  0  0  0  1  1], end state:[ 4 21 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 716, score:[2727.25], loss:[1.12415], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3  0 44  0  0  1  0  0  0  0  0], end state:[ 5  0 44  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 717, score:[2791.50], loss:[1.15873], sequence:[1], random actions:[33], eInit:[0.0100], init state:[0 5 9 0 0 0 0 0 0 0 0], end state:[2 5 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 718, score:[2783.25], loss:[1.06816], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2  3 47  0  0  0  0  0  0  0  0], end state:[ 4  3 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 719, score:[2824.50], loss:[0.94434], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 6 18 37  0  0  0  0  0  0  0  0], end state:[ 1 18 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 720, score:[2741.25], loss:[0.95698], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 4 15 45  0  0  0  0  0  0  0  0], end state:[ 6 15 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 721, score:[2617.25], loss:[1.22304], sequence:[0], random actions:[33], eInit:[0.0100], init state:[5 9 5 0 0 0 0 0 0 0 0], end state:[0 9 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 722, score:[2823.00], loss:[1.07786], sequence:[1], random actions:[21], eInit:[0.0100], init state:[0 2 7 0 0 0 0 0 0 0 0], end state:[2 2 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 723, score:[2801.00], loss:[0.88531], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 0 23 34  1  0  0  1  0  0  1  1], end state:[ 2 23 34  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 724, score:[2790.00], loss:[0.81990], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 0  2 12  0  0  0  0  0  0  0  0], end state:[ 2  2 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 725, score:[2804.75], loss:[0.87970], sequence:[4], random actions:[25], eInit:[0.0100], init state:[6 6 4 0 0 0 0 0 0 0 0], end state:[1 6 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 726, score:[2765.25], loss:[0.98609], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 2 13 45  0  0  0  0  0  0  0  0], end state:[ 4 13 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 727, score:[2735.25], loss:[1.23867], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 10 11  1  1  0  1  1  0  0  0], end state:[ 6 10 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 728, score:[2771.00], loss:[1.12049], sequence:[1], random actions:[35], eInit:[0.0100], init state:[1 2 1 0 0 0 0 0 0 0 0], end state:[3 2 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 729, score:[2756.75], loss:[1.24183], sequence:[2], random actions:[37], eInit:[0.0100], init state:[ 5 16 41  0  0  0  0  0  0  0  0], end state:[ 0 16 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 730, score:[2807.50], loss:[1.03444], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 2  7 39  0  0  0  0  0  0  0  0], end state:[ 4  7 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 731, score:[2678.25], loss:[1.33748], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5 11 56  0  0  0  0  0  0  0  0], end state:[ 0 11 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 732, score:[2792.00], loss:[1.27071], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6  1 11  0  0  0  0  0  0  0  0], end state:[ 1  1 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 733, score:[2796.25], loss:[1.09185], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1  8 53  1  1  0  0  0  0  0  0], end state:[ 3  8 53  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 734, score:[2764.25], loss:[1.14988], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 3 19 53  0  0  0  0  0  0  0  0], end state:[ 5 19 53  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 735, score:[2805.25], loss:[1.14672], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 1 23 59  1  0  0  0  0  0  1  1], end state:[ 3 23 59  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 736, score:[2812.00], loss:[0.99647], sequence:[5], random actions:[18], eInit:[0.0100], init state:[ 3  6 57  0  0  0  0  0  0  0  0], end state:[ 5  6 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 737, score:[2776.00], loss:[0.96560], sequence:[6], random actions:[28], eInit:[0.0100], init state:[3 4 3 0 0 0 0 0 0 0 0], end state:[5 4 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 738, score:[2784.75], loss:[1.09366], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 5  3 32  0  0  0  0  0  0  0  0], end state:[ 0  3 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 739, score:[2737.25], loss:[1.11921], sequence:[8], random actions:[33], eInit:[0.0100], init state:[ 4  0 35  1  0  1  0  0  0  0  0], end state:[ 6  0 35  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 740, score:[2757.50], loss:[1.20437], sequence:[9], random actions:[35], eInit:[0.0100], init state:[ 4 17  0  0  0  0  0  0  0  0  0], end state:[ 6 17  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 741, score:[2766.50], loss:[1.28394], sequence:[10], random actions:[29], eInit:[0.0100], init state:[ 2 18 29  0  0  0  0  0  0  0  0], end state:[ 4 18 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 742, score:[2796.50], loss:[1.07361], sequence:[11], random actions:[33], eInit:[0.0100], init state:[ 1 21  4  1  1  0  1  0  0  1  1], end state:[ 3 21  4  1  1  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 743, score:[2701.75], loss:[1.42125], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 16 32  0  0  0  0  0  0  0  0], end state:[ 0 16 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 744, score:[2733.00], loss:[1.47325], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 18  4  0  0  0  0  0  0  0  0], end state:[ 4 18  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 745, score:[2713.00], loss:[1.57067], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  4 11  0  0  0  0  0  0  0  0], end state:[ 0  4 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 746, score:[2705.25], loss:[1.60908], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6 17 23  0  0  0  0  0  0  0  0], end state:[ 1 17 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 747, score:[2791.00], loss:[1.26841], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0  9 19  0  0  0  0  0  0  0  0], end state:[ 2  9 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 748, score:[2789.25], loss:[1.15718], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3  4 13  0  0  0  0  0  0  0  0], end state:[ 5  4 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 749, score:[2716.50], loss:[1.28688], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 13 29  0  0  0  0  0  0  0  0], end state:[ 0 13 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 750, score:[2715.00], loss:[1.37465], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 13  0  0  0  0  0  0  0  0  0], end state:[ 0 13  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 751, score:[2790.25], loss:[1.32251], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 3 11 38  0  0  0  0  0  0  0  0], end state:[ 5 11 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 752, score:[2811.25], loss:[1.19459], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 4 11 49  1  1  0  0  0  0  0  0], end state:[ 6 11 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 753, score:[2808.50], loss:[1.18436], sequence:[3], random actions:[28], eInit:[0.0100], init state:[1 2 0 0 0 0 0 0 0 0 0], end state:[3 2 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 754, score:[2802.75], loss:[1.12058], sequence:[4], random actions:[20], eInit:[0.0100], init state:[ 1 21  7  1  1  0  1  1  0  1  1], end state:[ 3 21  7  1  1  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 755, score:[2768.00], loss:[1.13376], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 2  7 49  0  0  0  0  0  0  0  0], end state:[ 4  7 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 756, score:[2731.50], loss:[1.27223], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 12 32  0  0  0  0  0  0  0  0], end state:[ 0 12 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 757, score:[2738.75], loss:[1.27485], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 5 15 13  0  0  0  0  0  0  0  0], end state:[ 0 15 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 758, score:[2828.25], loss:[1.14176], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 1  1 15  0  0  0  0  0  0  0  0], end state:[ 3  1 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 759, score:[2767.00], loss:[1.23370], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 5 10 35  0  0  0  0  0  0  0  0], end state:[ 0 10 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 760, score:[2701.00], loss:[1.36336], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 3  0 22  1  0  0  0  0  1  0  0], end state:[ 5  0 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 761, score:[2762.50], loss:[1.52884], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 5  6 12  0  0  0  0  0  0  0  0], end state:[ 0  6 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 762, score:[2797.75], loss:[1.28293], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 6  9 28  0  0  0  0  0  0  0  0], end state:[ 1  9 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 763, score:[2739.00], loss:[1.31297], sequence:[3], random actions:[38], eInit:[0.0100], init state:[ 3 18 32  0  0  0  0  0  0  0  0], end state:[ 5 18 32  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 764, score:[2784.75], loss:[1.17205], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 2 18 51  0  0  0  0  0  0  0  0], end state:[ 4 18 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 765, score:[2756.75], loss:[1.13197], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 3 22 17  1  0  0  0  0  0  1  1], end state:[ 5 22 17  1  0  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 766, score:[2754.50], loss:[1.36222], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 6 17 38  0  0  0  0  0  0  0  0], end state:[ 1 17 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 767, score:[2770.00], loss:[1.30991], sequence:[7], random actions:[34], eInit:[0.0100], init state:[ 6  6 22  0  0  0  0  0  0  0  0], end state:[ 1  6 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 768, score:[2755.50], loss:[1.20657], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 4  2 38  0  0  0  0  0  0  0  0], end state:[ 6  2 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 769, score:[2810.25], loss:[1.16077], sequence:[9], random actions:[19], eInit:[0.0100], init state:[ 3 10 29  0  0  0  0  0  0  0  0], end state:[ 5 10 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 770, score:[2730.75], loss:[1.17607], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4  3 59  0  0  0  0  0  0  0  0], end state:[ 6  3 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 771, score:[2767.50], loss:[1.17734], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 12 18  0  0  0  0  0  0  0  0], end state:[ 2 12 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 772, score:[2780.75], loss:[1.09489], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1 18 10  0  0  0  0  0  0  0  0], end state:[ 3 18 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 773, score:[2796.25], loss:[1.12522], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 3 10  7  0  0  0  0  0  0  0  0], end state:[ 5 10  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 774, score:[2768.25], loss:[1.22044], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 2  4 35  0  0  0  0  0  0  0  0], end state:[ 4  4 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 775, score:[2774.00], loss:[1.36499], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 2 23 26  1  0  0  1  0  0  1  1], end state:[ 4 23 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 776, score:[2777.75], loss:[1.30506], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 2 22 44  1  0  0  0  0  0  1  1], end state:[ 4 22 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 777, score:[2769.25], loss:[1.37137], sequence:[7], random actions:[17], eInit:[0.0100], init state:[ 3 14 39  0  0  0  0  0  0  0  0], end state:[ 5 14 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 778, score:[2779.75], loss:[1.30242], sequence:[8], random actions:[31], eInit:[0.0100], init state:[ 0 18 13  0  0  0  0  0  0  0  0], end state:[ 2 18 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 779, score:[2730.50], loss:[1.39432], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 6  1 32  0  0  0  0  0  0  0  0], end state:[ 1  1 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 780, score:[2706.50], loss:[1.27236], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 18 34  0  0  0  0  0  0  0  0], end state:[ 5 18 34  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 781, score:[2756.50], loss:[1.31180], sequence:[1], random actions:[18], eInit:[0.0100], init state:[ 6  2 27  0  0  0  0  0  0  0  0], end state:[ 1  2 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 782, score:[2744.25], loss:[1.33338], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 3  1 23  0  0  0  0  0  0  0  0], end state:[ 5  1 23  1  1  1  0  0  1  1  0]
INFO:Reinforcement.Functions:episode: 783, score:[2784.00], loss:[1.26986], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 0  9 23  0  0  0  0  0  0  0  0], end state:[ 2  9 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 784, score:[2656.50], loss:[1.47726], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 15 27  0  0  0  0  0  0  0  0], end state:[ 0 15 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 785, score:[2824.50], loss:[1.22064], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1 13 51  0  0  0  0  0  0  0  0], end state:[ 3 13 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 786, score:[2807.25], loss:[1.10038], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1  6 14  0  0  0  0  0  0  0  0], end state:[ 3  6 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 787, score:[2731.00], loss:[1.20707], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 21 51  1  0  0  0  0  0  1  1], end state:[ 5 21 51  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 788, score:[2795.75], loss:[1.13735], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 13 18  0  0  0  0  0  0  0  0], end state:[ 4 13 18  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 789, score:[2759.25], loss:[1.22752], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 4  8 31  0  0  0  0  0  0  0  0], end state:[ 6  8 31  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 790, score:[2785.75], loss:[1.21612], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 2  9 36  0  0  0  0  0  0  0  0], end state:[ 4  9 36  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 791, score:[2779.50], loss:[1.11683], sequence:[4], random actions:[19], eInit:[0.0100], init state:[ 4  5 32  0  0  0  0  0  0  0  0], end state:[ 6  5 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 792, score:[2720.50], loss:[1.16124], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 21 30  1  0  0  1  1  0  1  1], end state:[ 0 21 30  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 793, score:[2755.75], loss:[1.31739], sequence:[1], random actions:[31], eInit:[0.0100], init state:[4 4 7 0 0 0 0 0 0 0 0], end state:[6 4 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 794, score:[2701.50], loss:[1.44121], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6  5 49  0  0  0  0  0  0  0  0], end state:[ 1  5 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 795, score:[2742.00], loss:[1.41209], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 3  9 34  0  0  0  0  0  0  0  0], end state:[ 5  9 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 796, score:[2749.75], loss:[1.64656], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 5 19 51  1  0  0  1  0  0  0  0], end state:[ 0 19 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 797, score:[2760.75], loss:[1.56190], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 3 14 25  0  0  0  0  0  0  0  0], end state:[ 5 14 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 798, score:[2760.00], loss:[1.44831], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 6 18  1  0  0  0  0  0  0  0  0], end state:[ 1 18  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 799, score:[2743.50], loss:[1.51565], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 3 18 53  0  0  0  0  0  0  0  0], end state:[ 5 18 53  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 800, score:[2701.25], loss:[1.62228], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 13 33  0  0  0  0  0  0  0  0], end state:[ 0 13 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 801, score:[2803.25], loss:[1.44706], sequence:[1], random actions:[19], eInit:[0.0100], init state:[1 7 3 0 0 0 0 0 0 0 0], end state:[3 7 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 802, score:[2770.50], loss:[1.34793], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 16 27  0  0  0  0  0  0  0  0], end state:[ 2 16 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 803, score:[2755.50], loss:[1.35033], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 6 22 14  1  0  0  0  0  0  1  1], end state:[ 1 22 14  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 804, score:[2723.50], loss:[1.43618], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4  9 30  1  0  0  0  0  0  0  0], end state:[ 6  9 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 805, score:[2789.00], loss:[1.42860], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 5 18 43  1  1  0  1  0  0  0  0], end state:[ 0 18 43  0  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 806, score:[2752.25], loss:[1.36825], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 4 23 21  0  0  0  0  0  0  0  0], end state:[ 6 23 21  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 807, score:[2804.75], loss:[1.42754], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 0 20  4  0  0  0  0  0  0  0  0], end state:[ 2 20  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 808, score:[2789.50], loss:[1.31593], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 5  5 37  0  0  0  0  0  0  0  0], end state:[ 0  5 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 809, score:[2774.75], loss:[1.43901], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 2 13 13  0  0  0  0  0  0  0  0], end state:[ 4 13 13  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 810, score:[2742.00], loss:[1.51522], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 4 11 24  1  1  0  0  0  0  0  0], end state:[ 6 11 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 811, score:[2772.75], loss:[1.49060], sequence:[7], random actions:[35], eInit:[0.0100], init state:[ 1 21 27  1  1  0  1  0  0  1  1], end state:[ 3 21 27  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 812, score:[2744.00], loss:[1.41244], sequence:[8], random actions:[43], eInit:[0.0100], init state:[ 6  6 58  0  0  0  0  0  0  0  0], end state:[ 1  6 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 813, score:[2791.25], loss:[1.31273], sequence:[9], random actions:[29], eInit:[0.0100], init state:[ 0 16 34  0  0  0  0  0  0  0  0], end state:[ 2 16 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 814, score:[2808.75], loss:[1.13696], sequence:[10], random actions:[24], eInit:[0.0100], init state:[ 2  1 37  0  0  0  0  0  0  0  0], end state:[ 4  1 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 815, score:[2813.50], loss:[1.00316], sequence:[11], random actions:[28], eInit:[0.0100], init state:[ 2  2 31  0  0  0  0  0  0  0  0], end state:[ 4  2 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 816, score:[2721.25], loss:[1.12727], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 10 34  1  1  0  1  0  0  0  0], end state:[ 6 10 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 817, score:[2701.75], loss:[1.47798], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  9 59  0  0  0  0  0  0  0  0], end state:[ 0  9 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 818, score:[2804.75], loss:[1.35379], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 6 19 14  0  0  0  0  0  0  0  0], end state:[ 1 19 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 819, score:[2675.25], loss:[1.37482], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3  8 10  1  0  0  0  0  0  0  0], end state:[ 5  8 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 820, score:[2711.75], loss:[1.42939], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 21 55  1  0  0  0  0  0  1  1], end state:[ 5 21 55  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 821, score:[2786.00], loss:[1.37250], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 4  0 52  1  0  1  0  0  0  0  0], end state:[ 6  0 52  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 822, score:[2744.75], loss:[1.36818], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 4  0 34  1  0  1  0  0  0  0  0], end state:[ 6  0 34  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 823, score:[2784.75], loss:[1.29174], sequence:[3], random actions:[24], eInit:[0.0100], init state:[2 5 1 0 0 0 0 0 0 0 0], end state:[4 5 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 824, score:[2793.50], loss:[1.20199], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 2  8 58  1  1  0  0  0  0  0  0], end state:[ 4  8 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 825, score:[2740.25], loss:[1.33915], sequence:[5], random actions:[37], eInit:[0.0100], init state:[ 5 10 13  0  0  0  0  0  0  0  0], end state:[ 0 10 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 826, score:[2740.25], loss:[1.39050], sequence:[6], random actions:[29], eInit:[0.0100], init state:[2 0 1 1 0 0 0 0 0 1 1], end state:[4 0 1 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 827, score:[2786.00], loss:[1.44101], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 1  5 32  0  0  0  0  0  0  0  0], end state:[ 3  5 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 828, score:[2768.25], loss:[1.16358], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 2 17 54  0  0  0  0  0  0  0  0], end state:[ 4 17 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 829, score:[2747.00], loss:[1.28246], sequence:[9], random actions:[31], eInit:[0.0100], init state:[ 4 15 31  0  0  0  0  0  0  0  0], end state:[ 6 15 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 830, score:[2775.50], loss:[1.16253], sequence:[10], random actions:[25], eInit:[0.0100], init state:[ 5  5 36  0  0  0  0  0  0  0  0], end state:[ 0  5 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 831, score:[2740.75], loss:[1.83844], sequence:[11], random actions:[36], eInit:[0.0100], init state:[ 0 20  0  0  0  0  0  0  0  0  0], end state:[ 2 20  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 832, score:[2776.50], loss:[1.53366], sequence:[12], random actions:[29], eInit:[0.0100], init state:[ 0  1 12  0  0  0  0  0  0  0  0], end state:[ 2  1 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 833, score:[2775.75], loss:[1.34946], sequence:[13], random actions:[25], eInit:[0.0100], init state:[ 6  8 59  1  1  0  0  0  0  0  0], end state:[ 1  8 59  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 834, score:[2789.00], loss:[1.26995], sequence:[14], random actions:[29], eInit:[0.0100], init state:[ 6  2 44  0  0  0  0  0  0  0  0], end state:[ 1  2 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 835, score:[2721.50], loss:[1.28445], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6 13  3  0  0  0  0  0  0  0  0], end state:[ 1 13  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 836, score:[2820.75], loss:[1.10299], sequence:[1], random actions:[28], eInit:[0.0100], init state:[1 5 4 0 0 0 0 0 0 0 0], end state:[3 5 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 837, score:[2776.25], loss:[1.06114], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 2  4 59  0  0  0  0  0  0  0  0], end state:[ 4  4 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 838, score:[2797.50], loss:[0.99026], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1  6 20  0  0  0  0  0  0  0  0], end state:[ 3  6 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 839, score:[2828.00], loss:[0.79480], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 6 23 27  1  0  0  1  0  0  1  1], end state:[ 1 23 27  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 840, score:[2764.00], loss:[0.88472], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 2  7 14  0  0  0  0  0  0  0  0], end state:[ 4  7 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 841, score:[2708.25], loss:[1.03464], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 10 14  0  0  0  0  0  0  0  0], end state:[ 0 10 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 842, score:[2781.25], loss:[1.06366], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 1 13 28  0  0  0  0  0  0  0  0], end state:[ 3 13 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 843, score:[2791.75], loss:[0.88946], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 0  6 28  0  0  0  0  0  0  0  0], end state:[ 2  6 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 844, score:[2733.75], loss:[0.93591], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  2 44  0  0  0  0  0  0  0  0], end state:[ 0  2 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 845, score:[2811.50], loss:[0.93344], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2 10 15  0  0  0  0  0  0  0  0], end state:[ 4 10 15  0  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 846, score:[2780.75], loss:[1.03394], sequence:[2], random actions:[31], eInit:[0.0100], init state:[6 4 2 0 0 0 0 0 0 0 0], end state:[1 4 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 847, score:[2688.00], loss:[1.59106], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 4  6 29  0  0  0  0  0  0  0  0], end state:[ 6  6 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 848, score:[2826.75], loss:[1.39909], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 6  4 31  0  0  0  0  0  0  0  0], end state:[ 1  4 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 849, score:[2792.00], loss:[1.31117], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 6 14  7  0  0  0  0  0  0  0  0], end state:[ 1 14  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 850, score:[2823.50], loss:[1.09628], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1 13 44  0  0  0  0  0  0  0  0], end state:[ 3 13 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 851, score:[2767.25], loss:[1.19281], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 2 19 52  0  0  0  0  0  0  0  0], end state:[ 4 19 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 852, score:[2732.50], loss:[1.49923], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6 14 54  0  0  0  0  0  0  0  0], end state:[ 1 14 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 853, score:[2824.50], loss:[1.13722], sequence:[1], random actions:[16], eInit:[0.0100], init state:[ 6 19 53  0  0  0  0  0  0  0  0], end state:[ 1 19 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 854, score:[2808.50], loss:[1.03283], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2  8 19  1  0  0  0  0  0  0  0], end state:[ 4  8 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 855, score:[2716.50], loss:[1.27176], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 4 16 14  0  0  0  0  0  0  0  0], end state:[ 6 16 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 856, score:[2733.75], loss:[1.31095], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 23  9  1  0  0  0  0  0  1  1], end state:[ 5 23  9  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 857, score:[2771.50], loss:[1.46793], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 3 21 53  1  0  0  0  0  0  1  1], end state:[ 5 21 53  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 858, score:[2756.75], loss:[1.45644], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3 19 32  0  0  0  0  0  0  0  0], end state:[ 5 19 32  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 859, score:[2801.75], loss:[1.34035], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 0 15 44  0  0  0  0  0  0  0  0], end state:[ 2 15 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 860, score:[2752.25], loss:[1.20934], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 2 10 52  0  0  0  0  0  0  0  0], end state:[ 4 10 52  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 861, score:[2743.25], loss:[1.43410], sequence:[5], random actions:[38], eInit:[0.0100], init state:[ 3 10 27  0  0  0  0  0  0  0  0], end state:[ 5 10 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 862, score:[2714.25], loss:[1.87818], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 5 23  1  1  0  0  1  0  0  1  1], end state:[ 0 23  1  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 863, score:[2781.00], loss:[1.66139], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 6  9 32  0  0  0  0  0  0  0  0], end state:[ 1  9 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 864, score:[2792.50], loss:[1.46262], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 2 14 38  0  0  0  0  0  0  0  0], end state:[ 4 14 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 865, score:[2780.50], loss:[1.41939], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 2  1 41  0  0  0  0  0  0  0  0], end state:[ 4  1 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 866, score:[2758.75], loss:[1.64396], sequence:[4], random actions:[34], eInit:[0.0100], init state:[ 6 16 13  0  0  0  0  0  0  0  0], end state:[ 1 16 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 867, score:[2798.00], loss:[1.49965], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 2 19 31  0  0  0  0  0  0  0  0], end state:[ 4 19 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 868, score:[2809.50], loss:[1.42914], sequence:[6], random actions:[24], eInit:[0.0100], init state:[ 1  3 50  0  0  0  0  0  0  0  0], end state:[ 3  3 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 869, score:[2737.75], loss:[1.60355], sequence:[7], random actions:[36], eInit:[0.0100], init state:[ 5  6 39  0  0  0  0  0  0  0  0], end state:[ 0  6 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 870, score:[2783.00], loss:[1.59421], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 2  9 42  0  0  0  0  0  0  0  0], end state:[ 4  9 42  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 871, score:[2785.00], loss:[1.55707], sequence:[9], random actions:[29], eInit:[0.0100], init state:[ 2 11  7  0  0  0  0  0  0  0  0], end state:[ 4 11  7  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 872, score:[2800.00], loss:[1.41490], sequence:[10], random actions:[27], eInit:[0.0100], init state:[ 2 11 57  0  0  0  0  0  0  0  0], end state:[ 4 11 57  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 873, score:[2810.50], loss:[1.36055], sequence:[11], random actions:[31], eInit:[0.0100], init state:[ 0 13  9  0  0  0  0  0  0  0  0], end state:[ 2 13  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 874, score:[2688.00], loss:[1.59147], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  8 42  0  0  0  0  0  0  0  0], end state:[ 0  8 42  0  1  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 875, score:[2695.25], loss:[1.66541], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6 11 39  0  0  0  0  0  0  0  0], end state:[ 1 11 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 876, score:[2807.25], loss:[1.52943], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 6 23 55  1  0  0  0  0  0  1  1], end state:[ 1 23 55  1  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 877, score:[2741.25], loss:[1.57335], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 6  4 58  0  0  0  0  0  0  0  0], end state:[ 1  4 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 878, score:[2700.25], loss:[1.72735], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 2 13 32  0  0  0  0  0  0  0  0], end state:[ 4 13 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 879, score:[2671.75], loss:[1.79454], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3  4 13  0  0  0  0  0  0  0  0], end state:[ 5  4 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 880, score:[2803.25], loss:[1.61394], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1  8 51  1  1  0  0  0  0  0  0], end state:[ 3  8 51  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 881, score:[2707.75], loss:[1.61945], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 20 13  0  0  0  0  0  0  0  0], end state:[ 6 20 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 882, score:[2775.50], loss:[1.43978], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 6  3 18  0  0  0  0  0  0  0  0], end state:[ 1  3 18  0  0  1  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 883, score:[2716.50], loss:[1.58100], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4  3 20  0  0  0  0  0  0  0  0], end state:[ 6  3 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 884, score:[2785.50], loss:[1.50484], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 6 15  7  0  0  0  0  0  0  0  0], end state:[ 1 15  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 885, score:[2737.50], loss:[1.49177], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2 15 18  0  0  0  0  0  0  0  0], end state:[ 4 15 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 886, score:[2706.50], loss:[1.74119], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 12  0  1  1  0  0  0  0  0  0], end state:[ 6 12  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 887, score:[2748.00], loss:[1.85822], sequence:[1], random actions:[21], eInit:[0.0100], init state:[5 3 4 0 0 0 0 0 0 0 0], end state:[0 3 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 888, score:[2745.50], loss:[1.80623], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 4 16 28  0  0  0  0  0  0  0  0], end state:[ 6 16 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 889, score:[2798.50], loss:[1.72263], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 0 16 18  0  0  0  0  0  0  0  0], end state:[ 2 16 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 890, score:[2749.75], loss:[1.68706], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 3 21 33  1  0  0  0  0  0  1  1], end state:[ 5 21 33  0  0  1  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2839.0, [617]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 891, score:[2828.00], loss:[1.76454], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 1 20 40  1  1  0  0  0  0  1  1], end state:[ 3 20 40  1  1  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 892, score:[2840.00], loss:[1.50665], sequence:[6], random actions:[17], eInit:[0.0100], init state:[ 3 10  2  0  0  0  0  0  0  0  0], end state:[ 5 10  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 893, score:[2802.75], loss:[1.41953], sequence:[7], random actions:[28], eInit:[0.0100], init state:[ 2  6 15  0  0  0  0  0  0  0  0], end state:[ 4  6 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 894, score:[2797.75], loss:[1.38210], sequence:[8], random actions:[29], eInit:[0.0100], init state:[ 3  2 24  0  0  0  0  0  0  0  0], end state:[ 5  2 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 895, score:[2746.50], loss:[1.71342], sequence:[9], random actions:[31], eInit:[0.0100], init state:[ 1 17 15  0  0  0  0  0  0  0  0], end state:[ 3 17 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 896, score:[2722.75], loss:[1.78803], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  0 37  0  0  1  0  0  0  0  0], end state:[ 1  0 37  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 897, score:[2793.75], loss:[1.72603], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 3 17 30  0  0  0  0  0  0  0  0], end state:[ 5 17 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 898, score:[2729.00], loss:[1.66873], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6  4 33  0  0  0  0  0  0  0  0], end state:[ 1  4 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 899, score:[2771.25], loss:[1.77960], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 6 20 25  0  0  0  0  0  0  0  0], end state:[ 1 20 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 900, score:[2749.00], loss:[1.43110], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 5 22 23  1  0  0  1  0  0  1  1], end state:[ 0 22 23  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 901, score:[2763.00], loss:[1.42995], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 3 23 30  1  0  0  1  0  0  1  1], end state:[ 5 23 30  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 902, score:[2820.50], loss:[1.38406], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 6 18 46  0  0  0  0  0  0  0  0], end state:[ 1 18 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 903, score:[2742.75], loss:[1.28149], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 0 11 58  0  0  0  0  0  0  0  0], end state:[ 2 11 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 904, score:[2821.25], loss:[1.17707], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 6 15 49  0  0  0  0  0  0  0  0], end state:[ 1 15 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 905, score:[2745.75], loss:[1.14380], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 5  3 55  0  0  0  0  0  0  0  0], end state:[ 0  3 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 906, score:[2752.25], loss:[1.23733], sequence:[8], random actions:[24], eInit:[0.0100], init state:[ 5  6 36  0  0  0  0  0  0  0  0], end state:[ 0  6 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 907, score:[2816.00], loss:[1.10134], sequence:[9], random actions:[30], eInit:[0.0100], init state:[ 1 22 46  1  0  0  0  0  0  1  1], end state:[ 3 22 46  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 908, score:[2793.25], loss:[1.13726], sequence:[10], random actions:[17], eInit:[0.0100], init state:[ 4 11 28  1  1  0  0  0  0  0  0], end state:[ 6 11 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 909, score:[2696.75], loss:[1.20127], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 16 44  0  0  0  0  0  0  0  0], end state:[ 0 16 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 910, score:[2796.00], loss:[1.22831], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 3  3 46  0  0  0  0  0  0  0  0], end state:[ 5  3 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 911, score:[2806.00], loss:[1.19837], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 6 17 32  0  0  0  0  0  0  0  0], end state:[ 1 17 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 912, score:[2766.50], loss:[1.14671], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 2 16 19  0  0  0  0  0  0  0  0], end state:[ 4 16 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 913, score:[2753.75], loss:[1.30649], sequence:[4], random actions:[42], eInit:[0.0100], init state:[ 6  9 57  0  0  0  0  0  0  0  0], end state:[ 1  9 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 914, score:[2778.50], loss:[1.46468], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 3 10 50  0  0  0  0  0  0  0  0], end state:[ 5 10 50  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 915, score:[2767.50], loss:[1.34937], sequence:[6], random actions:[33], eInit:[0.0100], init state:[ 5 21  6  1  0  0  1  0  0  1  1], end state:[ 0 21  6  1  1  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 916, score:[2787.00], loss:[1.29589], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 1 13 15  0  0  0  0  0  0  0  0], end state:[ 3 13 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 917, score:[2762.75], loss:[1.17869], sequence:[8], random actions:[21], eInit:[0.0100], init state:[ 5 13 36  0  0  0  0  0  0  0  0], end state:[ 0 13 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 918, score:[2738.50], loss:[1.19345], sequence:[9], random actions:[28], eInit:[0.0100], init state:[ 5 19 11  1  0  0  1  0  0  0  0], end state:[ 0 19 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 919, score:[2787.75], loss:[1.23298], sequence:[10], random actions:[26], eInit:[0.0100], init state:[ 6 16 21  0  0  0  0  0  0  0  0], end state:[ 1 16 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 920, score:[2766.75], loss:[1.12989], sequence:[11], random actions:[29], eInit:[0.0100], init state:[ 6  7 15  0  0  0  0  0  0  0  0], end state:[ 1  7 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(17, [319])
INFO:Reinforcement.Functions:episode: 921, score:[2799.50], loss:[1.04635], sequence:[12], random actions:[23], eInit:[0.0100], init state:[2 4 6 0 0 0 0 0 0 0 0], end state:[4 4 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 922, score:[2839.50], loss:[0.92638], sequence:[13], random actions:[18], eInit:[0.0100], init state:[ 0 15 48  0  0  0  0  0  0  0  0], end state:[ 2 15 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 923, score:[2785.75], loss:[0.96503], sequence:[14], random actions:[30], eInit:[0.0100], init state:[ 3 10  2  0  0  0  0  0  0  0  0], end state:[ 5 10  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 924, score:[2832.50], loss:[0.88221], sequence:[15], random actions:[23], eInit:[0.0100], init state:[ 0 13 41  0  0  0  0  0  0  0  0], end state:[ 2 13 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 925, score:[2790.25], loss:[0.93586], sequence:[16], random actions:[32], eInit:[0.0100], init state:[ 2  1 42  0  0  0  0  0  0  0  0], end state:[ 4  1 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 926, score:[2740.25], loss:[1.12889], sequence:[17], random actions:[35], eInit:[0.0100], init state:[ 0  4 13  0  0  0  0  0  0  0  0], end state:[ 2  4 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 927, score:[2813.00], loss:[0.98252], sequence:[18], random actions:[18], eInit:[0.0100], init state:[ 2 22 11  1  0  0  0  0  0  1  1], end state:[ 4 22 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 928, score:[2781.50], loss:[0.98425], sequence:[19], random actions:[28], eInit:[0.0100], init state:[ 3  7 47  0  0  0  0  0  0  0  0], end state:[ 5  7 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 929, score:[2804.25], loss:[0.91397], sequence:[20], random actions:[33], eInit:[0.0100], init state:[ 1 11  0  0  0  0  0  0  0  0  0], end state:[ 3 11  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 930, score:[2791.25], loss:[0.91710], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 2 19 59  0  0  0  0  0  0  0  0], end state:[ 4 19 59  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 931, score:[2695.50], loss:[1.15009], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4 13 12  1  1  0  1  0  0  0  0], end state:[ 6 13 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 932, score:[2781.50], loss:[1.24492], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 3 19  8  0  0  0  0  0  0  0  0], end state:[ 5 19  8  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 933, score:[2810.00], loss:[1.05750], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 0  9 23  0  0  0  0  0  0  0  0], end state:[ 2  9 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 934, score:[2815.75], loss:[1.02324], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 3 22 58  1  0  0  0  0  0  1  1], end state:[ 5 22 58  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 935, score:[2755.00], loss:[1.09717], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 2 12 49  0  0  0  0  0  0  0  0], end state:[ 4 12 49  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 936, score:[2789.25], loss:[1.09602], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 0 18 57  0  0  0  0  0  0  0  0], end state:[ 2 18 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 937, score:[2753.75], loss:[1.05883], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 4  9 45  1  0  0  0  0  0  0  0], end state:[ 6  9 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 938, score:[2818.50], loss:[1.04524], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 3  6 56  0  0  0  0  0  0  0  0], end state:[ 5  6 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 939, score:[2784.00], loss:[1.17769], sequence:[8], random actions:[25], eInit:[0.0100], init state:[ 1  0 18  1  0  0  0  0  1  0  0], end state:[ 3  0 18  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 940, score:[2770.00], loss:[1.16445], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 2  8 31  1  1  0  1  1  0  0  0], end state:[ 4  8 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 941, score:[2766.75], loss:[1.26203], sequence:[10], random actions:[44], eInit:[0.0100], init state:[ 0  6 33  0  0  0  0  0  0  0  0], end state:[ 2  6 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 942, score:[2748.75], loss:[1.30442], sequence:[11], random actions:[29], eInit:[0.0100], init state:[ 6 18 30  0  0  0  0  0  0  0  0], end state:[ 1 18 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 943, score:[2768.25], loss:[1.39505], sequence:[12], random actions:[26], eInit:[0.0100], init state:[ 6 20 11  0  0  0  0  0  0  0  0], end state:[ 1 20 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 944, score:[2745.25], loss:[1.15481], sequence:[13], random actions:[31], eInit:[0.0100], init state:[ 3  4 25  0  0  0  0  0  0  0  0], end state:[ 5  4 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 945, score:[2775.00], loss:[1.17127], sequence:[14], random actions:[28], eInit:[0.0100], init state:[ 6  4 39  0  0  0  0  0  0  0  0], end state:[ 1  4 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 946, score:[2729.75], loss:[1.26298], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 4 22 30  0  0  0  0  0  0  0  0], end state:[ 6 22 30  0  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 947, score:[2761.75], loss:[1.38788], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 5 13 33  0  0  0  0  0  0  0  0], end state:[ 0 13 33  0  1  1  1  1  1  1  1]
INFO:Reinforcement.Functions:episode: 948, score:[2794.75], loss:[1.13654], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 10 51  0  0  0  0  0  0  0  0], end state:[ 2 10 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 949, score:[2773.00], loss:[1.08115], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 5 19 29  1  0  0  1  0  0  0  0], end state:[ 0 19 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 950, score:[2746.00], loss:[1.08206], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 4 14 51  0  0  0  0  0  0  0  0], end state:[ 6 14 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 951, score:[2804.25], loss:[1.06530], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 0 14 32  0  0  0  0  0  0  0  0], end state:[ 2 14 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 952, score:[2772.75], loss:[1.05208], sequence:[6], random actions:[24], eInit:[0.0100], init state:[ 3 13 51  0  0  0  0  0  0  0  0], end state:[ 5 13 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 953, score:[2756.50], loss:[1.22347], sequence:[7], random actions:[34], eInit:[0.0100], init state:[ 6 12  5  0  0  0  0  0  0  0  0], end state:[ 1 12  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 954, score:[2812.75], loss:[1.00400], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 1 10 32  0  0  0  0  0  0  0  0], end state:[ 3 10 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 955, score:[2758.00], loss:[1.16531], sequence:[9], random actions:[24], eInit:[0.0100], init state:[ 5  8 20  0  0  0  0  0  0  0  0], end state:[ 0  8 20  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 956, score:[2805.25], loss:[1.14906], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 6 16 35  0  0  0  0  0  0  0  0], end state:[ 1 16 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 957, score:[2820.75], loss:[1.08270], sequence:[11], random actions:[34], eInit:[0.0100], init state:[ 6 23 49  1  0  0  0  0  0  1  1], end state:[ 1 23 49  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 958, score:[2784.75], loss:[1.03016], sequence:[12], random actions:[27], eInit:[0.0100], init state:[ 6  2 28  0  0  0  0  0  0  0  0], end state:[ 1  2 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 959, score:[2752.75], loss:[1.07868], sequence:[13], random actions:[26], eInit:[0.0100], init state:[ 3 19 43  0  0  0  0  0  0  0  0], end state:[ 5 19 43  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 960, score:[2799.00], loss:[1.08809], sequence:[14], random actions:[33], eInit:[0.0100], init state:[ 0 14 48  0  0  0  0  0  0  0  0], end state:[ 2 14 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 961, score:[2751.50], loss:[1.10102], sequence:[15], random actions:[24], eInit:[0.0100], init state:[ 2 13 21  0  0  0  0  0  0  0  0], end state:[ 4 13 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 962, score:[2766.50], loss:[1.17170], sequence:[16], random actions:[37], eInit:[0.0100], init state:[ 1  1 43  0  0  0  0  0  0  0  0], end state:[ 3  1 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 963, score:[2708.00], loss:[1.55382], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 3 19 26  0  0  0  0  0  0  0  0], end state:[ 5 19 26  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 964, score:[2796.50], loss:[1.35737], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3 17 44  0  0  0  0  0  0  0  0], end state:[ 5 17 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 965, score:[2754.00], loss:[1.27716], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 5  6 49  0  0  0  0  0  0  0  0], end state:[ 0  6 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 966, score:[2812.50], loss:[1.13373], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 4 16 57  0  0  0  0  0  0  0  0], end state:[ 6 16 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 967, score:[2784.50], loss:[1.18749], sequence:[4], random actions:[18], eInit:[0.0100], init state:[ 3  9 33  0  0  0  0  0  0  0  0], end state:[ 5  9 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 968, score:[2742.00], loss:[1.19454], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 6  6 24  0  0  0  0  0  0  0  0], end state:[ 1  6 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 969, score:[2789.50], loss:[1.19678], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 4 19 21  0  0  0  0  0  0  0  0], end state:[ 6 19 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 970, score:[2797.50], loss:[1.05808], sequence:[7], random actions:[32], eInit:[0.0100], init state:[ 0 16 27  0  0  0  0  0  0  0  0], end state:[ 2 16 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 971, score:[2814.50], loss:[0.98259], sequence:[8], random actions:[23], eInit:[0.0100], init state:[ 1  6 11  0  0  0  0  0  0  0  0], end state:[ 3  6 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 972, score:[2783.50], loss:[1.01486], sequence:[9], random actions:[32], eInit:[0.0100], init state:[ 6 17 21  0  0  0  0  0  0  0  0], end state:[ 1 17 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 973, score:[2813.75], loss:[1.01351], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 2  4 35  0  0  0  0  0  0  0  0], end state:[ 4  4 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 974, score:[2803.50], loss:[0.97925], sequence:[11], random actions:[31], eInit:[0.0100], init state:[ 0 11 27  0  0  0  0  0  0  0  0], end state:[ 2 11 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 975, score:[2747.75], loss:[1.14913], sequence:[12], random actions:[20], eInit:[0.0100], init state:[ 5 11  9  0  0  0  0  0  0  0  0], end state:[ 0 11  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 976, score:[2689.75], loss:[1.30702], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4  2 53  0  0  0  0  0  0  0  0], end state:[ 6  2 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 977, score:[2810.75], loss:[1.33018], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0 19  4  0  0  0  0  0  0  0  0], end state:[ 2 19  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 978, score:[2714.50], loss:[1.37009], sequence:[0], random actions:[28], eInit:[0.0100], init state:[5 6 7 0 0 0 0 0 0 0 0], end state:[0 6 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 979, score:[2756.75], loss:[1.46823], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2 11 51  0  0  0  0  0  0  0  0], end state:[ 4 11 51  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 980, score:[2744.50], loss:[1.53113], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 5 13 50  0  0  0  0  0  0  0  0], end state:[ 0 13 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 981, score:[2702.50], loss:[1.85385], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6  8 11  1  0  0  0  0  0  0  0], end state:[ 1  8 11  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 982, score:[2770.75], loss:[1.61480], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 5 10 21  0  0  0  0  0  0  0  0], end state:[ 0 10 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 983, score:[2656.00], loss:[1.67803], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4  8 54  0  0  0  0  0  0  0  0], end state:[ 6  8 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 984, score:[2766.00], loss:[1.59005], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 6 20 26  0  0  0  0  0  0  0  0], end state:[ 1 20 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 985, score:[2788.75], loss:[1.58136], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 1  8 30  1  1  0  1  1  0  0  0], end state:[ 3  8 30  1  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 986, score:[2725.25], loss:[1.59966], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 16 55  0  0  0  0  0  0  0  0], end state:[ 6 16 55  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 987, score:[2786.25], loss:[1.49204], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3  7 59  0  0  0  0  0  0  0  0], end state:[ 5  7 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 988, score:[2781.00], loss:[1.44393], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 5 23 58  1  0  0  0  0  0  1  1], end state:[ 0 23 58  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 989, score:[2718.25], loss:[1.57764], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 6  9 40  0  0  0  0  0  0  0  0], end state:[ 1  9 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 990, score:[2783.50], loss:[1.49213], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 2 23  4  1  0  0  0  0  0  1  1], end state:[ 4 23  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 991, score:[2785.50], loss:[1.57379], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 18  8  0  0  0  0  0  0  0  0], end state:[ 2 18  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 992, score:[2747.00], loss:[1.61337], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 5 14 32  0  0  0  0  0  0  0  0], end state:[ 0 14 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 993, score:[2791.00], loss:[1.51113], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 6 17 30  0  0  0  0  0  0  0  0], end state:[ 1 17 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 994, score:[2734.25], loss:[1.57730], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 17 52  0  0  0  0  0  0  0  0], end state:[ 0 17 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 995, score:[2779.50], loss:[1.56175], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 22 17  1  0  0  0  0  0  1  1], end state:[ 3 22 17  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 996, score:[2780.25], loss:[1.25344], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 6  8 33  1  1  0  1  1  0  0  0], end state:[ 1  8 33  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 997, score:[2785.50], loss:[1.21316], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 0 13 31  0  0  0  0  0  0  0  0], end state:[ 2 13 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 998, score:[2780.25], loss:[1.10505], sequence:[4], random actions:[37], eInit:[0.0100], init state:[ 1  1 42  0  0  0  0  0  0  0  0], end state:[ 3  1 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 999, score:[2753.75], loss:[1.25906], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 5 21 23  1  0  0  1  1  0  1  1], end state:[ 0 21 23  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1000, score:[2803.25], loss:[1.11233], sequence:[6], random actions:[29], eInit:[0.0100], init state:[2 8 5 1 0 0 0 0 0 0 0], end state:[4 8 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1001, score:[2770.00], loss:[1.11944], sequence:[7], random actions:[37], eInit:[0.0100], init state:[ 1  8 46  1  1  0  0  0  0  0  0], end state:[ 3  8 46  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1002, score:[2803.25], loss:[0.97583], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 0  5 41  0  0  0  0  0  0  0  0], end state:[ 2  5 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1003, score:[2830.25], loss:[0.90430], sequence:[9], random actions:[19], eInit:[0.0100], init state:[ 2  1 22  0  0  0  0  0  0  0  0], end state:[ 4  1 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1004, score:[2716.25], loss:[1.26298], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 15  9  0  0  0  0  0  0  0  0], end state:[ 0 15  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1005, score:[2744.50], loss:[1.24145], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3 16 38  0  0  0  0  0  0  0  0], end state:[ 5 16 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1006, score:[2739.75], loss:[1.31713], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 6  2 25  0  0  0  0  0  0  0  0], end state:[ 1  2 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1007, score:[2819.50], loss:[1.10116], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 2 14 59  0  0  0  0  0  0  0  0], end state:[ 4 14 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1008, score:[2815.25], loss:[1.01463], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 0 16 28  0  0  0  0  0  0  0  0], end state:[ 2 16 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1009, score:[2821.00], loss:[0.89701], sequence:[5], random actions:[23], eInit:[0.0100], init state:[ 2 21 16  1  1  0  1  0  0  1  1], end state:[ 4 21 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1010, score:[2785.75], loss:[0.99487], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 3 12 59  0  0  0  0  0  0  0  0], end state:[ 5 12 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1011, score:[2729.25], loss:[1.11204], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 13 37  0  0  0  0  0  0  0  0], end state:[ 6 13 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1012, score:[2774.50], loss:[1.11158], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 2  4 53  0  0  0  0  0  0  0  0], end state:[ 4  4 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1013, score:[2796.00], loss:[1.08711], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 6 20 28  0  0  0  0  0  0  0  0], end state:[ 1 20 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1014, score:[2669.75], loss:[1.33274], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3 21 21  1  1  0  1  0  0  1  1], end state:[ 5 21 21  1  0  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 1015, score:[2727.75], loss:[1.28720], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 22 16  1  0  0  0  0  0  1  1], end state:[ 5 22 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1016, score:[2789.75], loss:[1.67829], sequence:[1], random actions:[16], eInit:[0.0100], init state:[ 2  4 29  0  0  0  0  0  0  0  0], end state:[ 4  4 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1017, score:[2761.75], loss:[1.83563], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 1 18 46  0  0  0  0  0  0  0  0], end state:[ 3 18 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1018, score:[2803.25], loss:[1.61150], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 1  9 20  0  0  0  0  0  0  0  0], end state:[ 3  9 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1019, score:[2644.75], loss:[1.89318], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  8 15  0  0  0  0  0  0  0  0], end state:[ 6  8 15  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1020, score:[2790.00], loss:[1.73506], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4  6 20  0  0  0  0  0  0  0  0], end state:[ 6  6 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1021, score:[2724.50], loss:[1.73094], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 3 11 52  0  0  0  0  0  0  0  0], end state:[ 5 11 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1022, score:[2742.75], loss:[1.64052], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 4 20 15  0  0  0  0  0  0  0  0], end state:[ 6 20 15  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1023, score:[2683.00], loss:[1.86118], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4 19 32  0  0  0  0  0  0  0  0], end state:[ 6 19 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1024, score:[2777.50], loss:[1.79152], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0  1 12  0  0  0  0  0  0  0  0], end state:[ 2  1 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1025, score:[2794.75], loss:[1.68487], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 10 14  0  0  0  0  0  0  0  0], end state:[ 3 10 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1026, score:[2710.25], loss:[1.85206], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6 16 22  0  0  0  0  0  0  0  0], end state:[ 1 16 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1027, score:[2709.25], loss:[1.75031], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5  1 30  0  0  0  0  0  0  0  0], end state:[ 0  1 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1028, score:[2753.75], loss:[1.88321], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  2 36  0  0  0  0  0  0  0  0], end state:[ 3  2 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1029, score:[2724.00], loss:[1.78524], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4  6 31  0  0  0  0  0  0  0  0], end state:[ 6  6 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1030, score:[2796.75], loss:[1.72929], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 17 34  0  0  0  0  0  0  0  0], end state:[ 3 17 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1031, score:[2776.75], loss:[1.56022], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 1 14 41  0  0  0  0  0  0  0  0], end state:[ 3 14 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1032, score:[2746.25], loss:[1.59351], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 5 21 29  1  0  0  1  1  0  1  1], end state:[ 0 21 29  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1033, score:[2743.25], loss:[1.60350], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 5  0 16  0  0  0  0  0  0  0  0], end state:[ 0  0 16  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1034, score:[2748.50], loss:[1.54493], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 4  6 32  0  0  0  0  0  0  0  0], end state:[ 6  6 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1035, score:[2774.00], loss:[1.51746], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 4 18  6  0  0  0  0  0  0  0  0], end state:[ 6 18  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1036, score:[2750.00], loss:[1.40394], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 3  7 17  0  0  0  0  0  0  0  0], end state:[ 5  7 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1037, score:[2684.25], loss:[1.50698], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 10 27  0  0  0  0  0  0  0  0], end state:[ 0 10 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1038, score:[2705.75], loss:[1.43194], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4 18  8  0  0  0  0  0  0  0  0], end state:[ 6 18  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1039, score:[2703.75], loss:[1.62629], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  4 42  0  0  0  0  0  0  0  0], end state:[ 0  4 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1040, score:[2805.00], loss:[1.63939], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  0 20  1  0  0  0  0  1  0  0], end state:[ 3  0 20  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1041, score:[2797.25], loss:[1.49904], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3  2 23  0  0  0  0  0  0  0  0], end state:[ 5  2 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1042, score:[2810.25], loss:[1.37720], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 0  2 33  0  0  0  0  0  0  0  0], end state:[ 2  2 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1043, score:[2821.50], loss:[1.25846], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 0  6 46  0  0  0  0  0  0  0  0], end state:[ 2  6 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1044, score:[2733.50], loss:[1.36012], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 17 15  0  0  0  0  0  0  0  0], end state:[ 6 17 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1045, score:[2761.25], loss:[1.44476], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 5 10 34  0  0  0  0  0  0  0  0], end state:[ 0 10 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1046, score:[2754.25], loss:[1.60241], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 2 10 16  0  0  0  0  0  0  0  0], end state:[ 4 10 16  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1047, score:[2809.50], loss:[1.45776], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 4  7 54  0  0  0  0  0  0  0  0], end state:[ 6  7 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1048, score:[2789.25], loss:[1.38507], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 4 21 35  0  0  0  0  0  0  0  0], end state:[ 6 21 35  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1049, score:[2737.00], loss:[1.57324], sequence:[5], random actions:[33], eInit:[0.0100], init state:[1 7 7 0 0 0 0 0 0 0 0], end state:[3 7 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1050, score:[2790.50], loss:[1.35952], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 0  3 26  0  0  0  0  0  0  0  0], end state:[ 2  3 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1051, score:[2769.00], loss:[1.37818], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 1  3 21  0  0  0  0  0  0  0  0], end state:[ 3  3 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1052, score:[2734.25], loss:[1.40068], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 10  7  0  0  0  0  0  0  0  0], end state:[ 0 10  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1053, score:[2753.50], loss:[1.84157], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 4  0 51  1  0  1  0  0  0  0  0], end state:[ 6  0 51  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1054, score:[2759.75], loss:[1.75137], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 2 11 41  0  0  0  0  0  0  0  0], end state:[ 4 11 41  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1055, score:[2724.00], loss:[1.74566], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6  5 28  0  0  0  0  0  0  0  0], end state:[ 1  5 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1056, score:[2722.75], loss:[1.59852], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 2  2 40  0  0  0  0  0  0  0  0], end state:[ 4  2 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1057, score:[2742.75], loss:[1.73317], sequence:[1], random actions:[32], eInit:[0.0100], init state:[6 4 4 0 0 0 0 0 0 0 0], end state:[1 4 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1058, score:[2796.50], loss:[1.61974], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 0 10 17  0  0  0  0  0  0  0  0], end state:[ 2 10 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1059, score:[2733.00], loss:[1.58137], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  3 16  0  0  0  0  0  0  0  0], end state:[ 6  3 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1060, score:[2720.25], loss:[1.68844], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5  9 11  0  0  0  0  0  0  0  0], end state:[ 0  9 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1061, score:[2760.25], loss:[1.71663], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3 12  3  0  0  0  0  0  0  0  0], end state:[ 5 12  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1062, score:[2771.25], loss:[1.60299], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 4 14 54  0  0  0  0  0  0  0  0], end state:[ 6 14 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1063, score:[2735.75], loss:[1.67830], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 4 10 28  1  1  0  1  0  1  0  0], end state:[ 6 10 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1064, score:[2721.50], loss:[1.84194], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 1 19 57  0  0  0  0  0  0  0  0], end state:[ 3 19 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1065, score:[2803.25], loss:[1.69353], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1 15 34  0  0  0  0  0  0  0  0], end state:[ 3 15 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1066, score:[2779.75], loss:[1.62583], sequence:[2], random actions:[17], eInit:[0.0100], init state:[ 4  7 18  0  0  0  0  0  0  0  0], end state:[ 6  7 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1067, score:[2759.25], loss:[1.56085], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 4  9 12  0  0  0  0  0  0  0  0], end state:[ 6  9 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1068, score:[2776.50], loss:[1.70459], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 2  7 32  0  0  0  0  0  0  0  0], end state:[ 4  7 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1069, score:[2768.75], loss:[1.95556], sequence:[5], random actions:[22], eInit:[0.0100], init state:[ 3  7 22  0  0  0  0  0  0  0  0], end state:[ 5  7 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1070, score:[2796.25], loss:[1.66576], sequence:[6], random actions:[23], eInit:[0.0100], init state:[ 2  8 52  1  1  0  0  0  0  0  0], end state:[ 4  8 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1071, score:[2750.50], loss:[1.53703], sequence:[7], random actions:[20], eInit:[0.0100], init state:[ 3 19  2  0  0  0  0  0  0  0  0], end state:[ 5 19  2  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1072, score:[2825.00], loss:[1.43721], sequence:[8], random actions:[18], eInit:[0.0100], init state:[0 2 7 0 0 0 0 0 0 0 0], end state:[2 2 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1073, score:[2763.00], loss:[1.35785], sequence:[9], random actions:[32], eInit:[0.0100], init state:[ 1 14 58  0  0  0  0  0  0  0  0], end state:[ 3 14 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1074, score:[2778.00], loss:[1.42422], sequence:[10], random actions:[25], eInit:[0.0100], init state:[ 2 14  1  0  0  0  0  0  0  0  0], end state:[ 4 14  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1075, score:[2787.00], loss:[1.35084], sequence:[11], random actions:[31], eInit:[0.0100], init state:[ 1  0 36  0  0  1  0  0  0  0  0], end state:[ 3  0 36  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1076, score:[2744.25], loss:[1.37270], sequence:[12], random actions:[29], eInit:[0.0100], init state:[ 2 22 30  1  0  0  0  0  0  1  1], end state:[ 4 22 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1077, score:[2679.00], loss:[1.68576], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 10  7  0  0  0  0  0  0  0  0], end state:[ 0 10  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1078, score:[2762.50], loss:[1.49399], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0  3 53  0  0  0  0  0  0  0  0], end state:[ 2  3 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1079, score:[2696.75], loss:[1.62872], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5 21 54  1  0  0  1  0  0  1  1], end state:[ 0 21 54  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1080, score:[2758.75], loss:[1.74005], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3 17 15  0  0  0  0  0  0  0  0], end state:[ 5 17 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1081, score:[2796.75], loss:[1.47798], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 1 12 35  0  0  0  0  0  0  0  0], end state:[ 3 12 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1082, score:[2755.25], loss:[1.34130], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 3  3 30  0  0  0  0  0  0  0  0], end state:[ 5  3 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1083, score:[2724.75], loss:[1.41642], sequence:[0], random actions:[27], eInit:[0.0100], init state:[5 3 9 0 0 0 0 0 0 0 0], end state:[0 3 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1084, score:[2655.25], loss:[1.74122], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  6 59  0  0  0  0  0  0  0  0], end state:[ 0  6 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1085, score:[2654.50], loss:[1.84071], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 18 50  0  0  0  0  0  0  0  0], end state:[ 5 18 50  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1086, score:[2756.50], loss:[1.72485], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 4  0 37  1  0  1  0  0  0  0  0], end state:[ 6  0 37  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1087, score:[2788.50], loss:[1.71610], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 6 14 18  0  0  0  0  0  0  0  0], end state:[ 1 14 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1088, score:[2717.75], loss:[1.54607], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  3 15  0  0  0  0  0  0  0  0], end state:[ 0  3 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1089, score:[2783.75], loss:[1.58746], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  7 42  0  0  0  0  0  0  0  0], end state:[ 3  7 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1090, score:[2739.00], loss:[1.55093], sequence:[2], random actions:[28], eInit:[0.0100], init state:[5 3 4 0 0 0 0 0 0 0 0], end state:[0 3 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1091, score:[2775.50], loss:[1.66238], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 4  6 21  0  0  0  0  0  0  0  0], end state:[ 6  6 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1092, score:[2777.00], loss:[1.73965], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 5 19 58  1  0  0  1  0  0  0  0], end state:[ 0 19 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1093, score:[2726.75], loss:[2.05961], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6  1 30  0  0  0  0  0  0  0  0], end state:[ 1  1 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1094, score:[2752.50], loss:[2.00001], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 21 47  1  0  0  0  0  0  1  1], end state:[ 3 21 47  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1095, score:[2778.50], loss:[1.78598], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 1 10  4  0  0  0  0  0  0  0  0], end state:[ 3 10  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1096, score:[2732.25], loss:[1.69894], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4 23 53  0  0  0  0  0  0  0  0], end state:[ 6 23 53  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1097, score:[2747.25], loss:[1.67837], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 20 11  0  0  0  0  0  0  0  0], end state:[ 4 20 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1098, score:[2772.75], loss:[1.57827], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 1 23 36  1  0  0  1  0  0  1  1], end state:[ 3 23 36  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1099, score:[2760.25], loss:[1.72185], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 6 16  5  0  0  0  0  0  0  0  0], end state:[ 1 16  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1100, score:[2742.00], loss:[1.66718], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 6  9 56  0  0  0  0  0  0  0  0], end state:[ 1  9 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1101, score:[2754.50], loss:[1.59239], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 0  4 36  0  0  0  0  0  0  0  0], end state:[ 2  4 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1102, score:[2791.50], loss:[1.44849], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 0  8 48  1  1  0  0  0  0  0  0], end state:[ 2  8 48  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1103, score:[2744.00], loss:[1.49043], sequence:[7], random actions:[37], eInit:[0.0100], init state:[2 7 0 0 0 0 0 0 0 0 0], end state:[4 7 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1104, score:[2793.50], loss:[1.29888], sequence:[8], random actions:[25], eInit:[0.0100], init state:[ 0 12 44  0  0  0  0  0  0  0  0], end state:[ 2 12 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1105, score:[2759.00], loss:[1.30287], sequence:[9], random actions:[31], eInit:[0.0100], init state:[ 2 17 12  0  0  0  0  0  0  0  0], end state:[ 4 17 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1106, score:[2727.50], loss:[1.54767], sequence:[0], random actions:[33], eInit:[0.0100], init state:[5 7 0 0 0 0 0 0 0 0 0], end state:[0 7 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1107, score:[2790.50], loss:[1.59073], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2  8 35  1  1  0  1  0  1  0  0], end state:[ 4  8 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1108, score:[2800.25], loss:[1.58263], sequence:[2], random actions:[39], eInit:[0.0100], init state:[ 0  3 52  0  0  0  0  0  0  0  0], end state:[ 2  3 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1109, score:[2729.25], loss:[1.52494], sequence:[0], random actions:[22], eInit:[0.0100], init state:[5 8 3 0 0 0 0 0 0 0 0], end state:[0 8 3 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1110, score:[2709.25], loss:[1.57181], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5 17 23  0  0  0  0  0  0  0  0], end state:[ 0 17 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1111, score:[2634.00], loss:[1.91610], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 23  2  1  0  0  0  0  0  1  1], end state:[ 5 23  2  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1112, score:[2711.25], loss:[1.91353], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 16 59  0  0  0  0  0  0  0  0], end state:[ 6 16 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1113, score:[2712.75], loss:[1.93536], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3 17  1  0  0  0  0  0  0  0  0], end state:[ 5 17  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1114, score:[2776.50], loss:[1.65772], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 22 21  1  0  0  0  0  0  1  1], end state:[ 3 22 21  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1115, score:[2717.00], loss:[1.71141], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 21 20  1  1  0  1  0  0  1  1], end state:[ 5 21 20  1  0  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 1116, score:[2809.25], loss:[1.63235], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 16 13  0  0  0  0  0  0  0  0], end state:[ 3 16 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1117, score:[2764.25], loss:[1.67067], sequence:[2], random actions:[49], eInit:[0.0100], init state:[ 0  5 53  0  0  0  0  0  0  0  0], end state:[ 2  5 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1118, score:[2810.75], loss:[1.44752], sequence:[3], random actions:[24], eInit:[0.0100], init state:[1 0 7 1 0 0 0 0 1 1 1], end state:[3 0 7 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 1119, score:[2712.25], loss:[1.57889], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 0  1 58  0  0  0  0  0  0  0  0], end state:[ 2  1 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1120, score:[2760.50], loss:[1.59604], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 12 17  0  0  0  0  0  0  0  0], end state:[ 3 12 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1121, score:[2764.00], loss:[1.62971], sequence:[2], random actions:[37], eInit:[0.0100], init state:[1 8 5 1 0 0 0 0 0 0 0], end state:[3 8 5 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1122, score:[2711.50], loss:[2.08254], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 16 42  0  0  0  0  0  0  0  0], end state:[ 0 16 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1123, score:[2808.75], loss:[1.68732], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1 11  5  0  0  0  0  0  0  0  0], end state:[ 3 11  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1124, score:[2772.25], loss:[1.65010], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 6 11 44  0  0  0  0  0  0  0  0], end state:[ 1 11 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1125, score:[2717.50], loss:[1.74777], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  4 20  0  0  0  0  0  0  0  0], end state:[ 6  4 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1126, score:[2765.75], loss:[1.74786], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 10 11  0  0  0  0  0  0  0  0], end state:[ 3 10 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1127, score:[2789.25], loss:[1.78056], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0 10 28  0  0  0  0  0  0  0  0], end state:[ 2 10 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1128, score:[2638.75], loss:[2.24501], sequence:[0], random actions:[31], eInit:[0.0100], init state:[4 7 1 0 0 0 0 0 0 0 0], end state:[6 7 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1129, score:[2798.75], loss:[2.01805], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 19  0  0  0  0  0  0  0  0  0], end state:[ 3 19  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1130, score:[2719.25], loss:[2.08894], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 10 19  0  0  0  0  0  0  0  0], end state:[ 4 10 19  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1131, score:[2670.75], loss:[2.12424], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3  6 25  0  0  0  0  0  0  0  0], end state:[ 5  6 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1132, score:[2754.75], loss:[2.17761], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 15 21  0  0  0  0  0  0  0  0], end state:[ 3 15 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1133, score:[2695.50], loss:[1.96076], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  0 43  1  0  1  0  0  0  0  0], end state:[ 6  0 43  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1134, score:[2693.25], loss:[2.26215], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6 18 42  0  0  0  0  0  0  0  0], end state:[ 1 18 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1135, score:[2712.50], loss:[2.11501], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 2 13 32  0  0  0  0  0  0  0  0], end state:[ 4 13 32  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1136, score:[2717.25], loss:[2.44952], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4 20 29  0  0  0  0  0  0  0  0], end state:[ 6 20 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1137, score:[2753.75], loss:[2.40099], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0 22 38  1  0  0  0  0  0  1  1], end state:[ 2 22 38  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1138, score:[2803.00], loss:[2.13902], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 20  4  0  0  0  0  0  0  0  0], end state:[ 2 20  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1139, score:[2738.50], loss:[2.14423], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 5 13 12  0  0  0  0  0  0  0  0], end state:[ 0 13 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1140, score:[2779.75], loss:[2.30158], sequence:[4], random actions:[34], eInit:[0.0100], init state:[ 0 15  1  0  0  0  0  0  0  0  0], end state:[ 2 15  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1141, score:[2749.75], loss:[2.27450], sequence:[5], random actions:[22], eInit:[0.0100], init state:[ 2 23 18  1  0  0  1  0  0  1  1], end state:[ 4 23 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1142, score:[2749.00], loss:[2.30366], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 0  0 39  0  0  1  0  0  0  0  0], end state:[ 2  0 39  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1143, score:[2714.25], loss:[2.57644], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 19 50  1  0  0  1  0  0  0  0], end state:[ 0 19 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1144, score:[2767.00], loss:[2.20043], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 6 22 52  1  0  0  0  0  0  1  1], end state:[ 1 22 52  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1145, score:[2747.50], loss:[2.23019], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 4 19 15  0  0  0  0  0  0  0  0], end state:[ 6 19 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1146, score:[2763.75], loss:[2.14239], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 1 10 15  0  0  0  0  0  0  0  0], end state:[ 3 10 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1147, score:[2755.25], loss:[2.15977], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 1  0 30  0  0  1  0  0  0  0  0], end state:[ 3  0 30  1  0  0  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1148, score:[2735.75], loss:[2.25719], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 6  9 14  0  0  0  0  0  0  0  0], end state:[ 1  9 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1149, score:[2803.75], loss:[1.96580], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 1 18 40  0  0  0  0  0  0  0  0], end state:[ 3 18 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1150, score:[2700.75], loss:[2.10807], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 16 44  0  0  0  0  0  0  0  0], end state:[ 0 16 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1151, score:[2766.00], loss:[1.97659], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 0 17 29  0  0  0  0  0  0  0  0], end state:[ 2 17 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1152, score:[2792.50], loss:[1.86819], sequence:[2], random actions:[26], eInit:[0.0100], init state:[2 3 7 0 0 0 0 0 0 0 0], end state:[4 3 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1153, score:[2692.25], loss:[1.84954], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3 22 31  1  0  0  0  0  0  1  1], end state:[ 5 22 31  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1154, score:[2636.75], loss:[2.28257], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 10 18  0  0  0  0  0  0  0  0], end state:[ 0 10 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1155, score:[2751.75], loss:[2.15019], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 2  7 58  0  0  0  0  0  0  0  0], end state:[ 4  7 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1156, score:[2766.25], loss:[1.88702], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 1 22 37  1  0  0  0  0  0  1  1], end state:[ 3 22 37  1  1  0  1  1  1  0  1]
INFO:Reinforcement.Functions:episode: 1157, score:[2812.25], loss:[1.64092], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 2  7 57  0  0  0  0  0  0  0  0], end state:[ 4  7 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1158, score:[2767.75], loss:[1.56369], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 1 19 57  0  0  0  0  0  0  0  0], end state:[ 3 19 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1159, score:[2803.50], loss:[1.38337], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 0 20 27  0  0  0  0  0  0  0  0], end state:[ 2 20 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1160, score:[2779.75], loss:[1.43748], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 6 18  1  0  0  0  0  0  0  0  0], end state:[ 1 18  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1161, score:[2665.25], loss:[1.83151], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5 16 40  0  0  0  0  0  0  0  0], end state:[ 0 16 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1162, score:[2779.50], loss:[1.60190], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 2  1 32  0  0  0  0  0  0  0  0], end state:[ 4  1 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1163, score:[2784.00], loss:[1.47361], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 1 11 36  0  0  0  0  0  0  0  0], end state:[ 3 11 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1164, score:[2788.00], loss:[1.53285], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 1 17 30  0  0  0  0  0  0  0  0], end state:[ 3 17 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1165, score:[2760.25], loss:[1.37959], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 6 22 34  1  0  0  0  0  0  1  1], end state:[ 1 22 34  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1166, score:[2713.50], loss:[1.56306], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 2 18 18  0  0  0  0  0  0  0  0], end state:[ 4 18 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1167, score:[2638.25], loss:[1.89540], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4  2 52  0  0  0  0  0  0  0  0], end state:[ 6  2 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1168, score:[2723.25], loss:[2.14233], sequence:[0], random actions:[18], eInit:[0.0100], init state:[ 6 17 33  0  0  0  0  0  0  0  0], end state:[ 1 17 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1169, score:[2781.25], loss:[1.81741], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 6 11  1  0  0  0  0  0  0  0  0], end state:[ 1 11  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1170, score:[2738.75], loss:[1.85184], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 3  9 49  0  0  0  0  0  0  0  0], end state:[ 5  9 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1171, score:[2741.25], loss:[1.75648], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 2 21 12  1  1  0  1  0  0  1  1], end state:[ 4 21 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1172, score:[2694.00], loss:[1.84199], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 10 22  1  1  0  1  0  1  0  0], end state:[ 6 10 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1173, score:[2799.25], loss:[1.75086], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 10 17  0  0  0  0  0  0  0  0], end state:[ 4 10 17  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1174, score:[2826.75], loss:[1.64223], sequence:[2], random actions:[18], eInit:[0.0100], init state:[ 3 12 10  0  0  0  0  0  0  0  0], end state:[ 5 12 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1175, score:[2770.50], loss:[1.53951], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 2  5 44  0  0  0  0  0  0  0  0], end state:[ 4  5 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1176, score:[2774.75], loss:[1.49670], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 1 15 32  0  0  0  0  0  0  0  0], end state:[ 3 15 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1177, score:[2776.75], loss:[1.51551], sequence:[5], random actions:[46], eInit:[0.0100], init state:[ 0  8 50  1  1  0  0  0  0  0  0], end state:[ 2  8 50  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1178, score:[2809.00], loss:[1.49812], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 0  7 11  0  0  0  0  0  0  0  0], end state:[ 2  7 11  1  1  1  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1179, score:[2779.25], loss:[1.52706], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 6 16  8  0  0  0  0  0  0  0  0], end state:[ 1 16  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1180, score:[2770.75], loss:[1.60917], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 5  5 53  0  0  0  0  0  0  0  0], end state:[ 0  5 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1181, score:[2707.50], loss:[1.82592], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  9 17  0  0  0  0  0  0  0  0], end state:[ 0  9 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1182, score:[2801.25], loss:[1.80351], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 19  7  0  0  0  0  0  0  0  0], end state:[ 2 19  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1183, score:[2759.75], loss:[1.70747], sequence:[2], random actions:[36], eInit:[0.0100], init state:[5 0 4 0 0 0 0 0 0 0 0], end state:[0 0 4 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 1184, score:[2714.50], loss:[1.78640], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6  3 53  0  0  0  0  0  0  0  0], end state:[ 1  3 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1185, score:[2801.50], loss:[1.58048], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  2 38  0  0  0  0  0  0  0  0], end state:[ 3  2 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1186, score:[2764.25], loss:[1.45684], sequence:[2], random actions:[30], eInit:[0.0100], init state:[2 7 6 0 0 0 0 0 0 0 0], end state:[4 7 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1187, score:[2726.50], loss:[1.53336], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6  4 43  0  0  0  0  0  0  0  0], end state:[ 1  4 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1188, score:[2694.75], loss:[1.88426], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 5 16 35  0  0  0  0  0  0  0  0], end state:[ 0 16 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1189, score:[2705.00], loss:[1.75609], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3  8 27  1  0  0  0  0  0  0  0], end state:[ 5  8 27  1  1  1  0  0  1  1  1]
INFO:Reinforcement.Functions:episode: 1190, score:[2773.00], loss:[1.82063], sequence:[1], random actions:[24], eInit:[0.0100], init state:[3 6 6 0 0 0 0 0 0 0 0], end state:[5 6 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1191, score:[2781.75], loss:[1.81103], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 6 14 11  0  0  0  0  0  0  0  0], end state:[ 1 14 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1192, score:[2761.00], loss:[1.81591], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 5 23 14  1  0  0  1  0  0  1  1], end state:[ 0 23 14  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1193, score:[2815.25], loss:[1.68309], sequence:[4], random actions:[19], eInit:[0.0100], init state:[ 1 12 56  0  0  0  0  0  0  0  0], end state:[ 3 12 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1194, score:[2731.25], loss:[1.63301], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 10 23  1  1  0  1  0  1  0  0], end state:[ 6 10 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1195, score:[2800.00], loss:[1.70576], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0 21 14  1  1  0  1  0  0  1  1], end state:[ 2 21 14  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1196, score:[2724.75], loss:[1.89568], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4  0 59  1  0  1  0  0  0  0  0], end state:[ 6  0 59  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1197, score:[2774.25], loss:[2.15884], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3  3 55  0  0  0  0  0  0  0  0], end state:[ 5  3 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1198, score:[2746.00], loss:[1.97793], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 4 17 16  0  0  0  0  0  0  0  0], end state:[ 6 17 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1199, score:[2703.25], loss:[2.08747], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6 14  3  0  0  0  0  0  0  0  0], end state:[ 1 14  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1200, score:[2723.25], loss:[1.95841], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3 14 33  0  0  0  0  0  0  0  0], end state:[ 5 14 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1201, score:[2786.75], loss:[1.93603], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 10 28  0  0  0  0  0  0  0  0], end state:[ 2 10 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1202, score:[2766.50], loss:[1.93341], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 6 13  9  0  0  0  0  0  0  0  0], end state:[ 1 13  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1203, score:[2790.50], loss:[1.80441], sequence:[3], random actions:[18], eInit:[0.0100], init state:[ 6 16 57  0  0  0  0  0  0  0  0], end state:[ 1 16 57  0  1  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1204, score:[2793.50], loss:[1.82280], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 1 18  2  0  0  0  0  0  0  0  0], end state:[ 3 18  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1205, score:[2770.25], loss:[1.71933], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 0 12  4  0  0  0  0  0  0  0  0], end state:[ 2 12  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1206, score:[2788.75], loss:[1.45912], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 3  6 50  0  0  0  0  0  0  0  0], end state:[ 5  6 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1207, score:[2776.25], loss:[1.59034], sequence:[7], random actions:[30], eInit:[0.0100], init state:[ 1 12 51  0  0  0  0  0  0  0  0], end state:[ 3 12 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1208, score:[2826.50], loss:[1.35751], sequence:[8], random actions:[24], eInit:[0.0100], init state:[ 0 22 40  1  0  0  0  0  0  1  1], end state:[ 2 22 40  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1209, score:[2647.75], loss:[1.72754], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5 20  6  1  0  0  0  0  0  0  0], end state:[ 0 20  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1210, score:[2729.25], loss:[1.65469], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  1 27  0  0  0  0  0  0  0  0], end state:[ 0  1 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1211, score:[2687.50], loss:[1.86296], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  0 46  0  0  0  0  0  0  0  0], end state:[ 0  0 46  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1212, score:[2772.75], loss:[1.72222], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3 16 58  0  0  0  0  0  0  0  0], end state:[ 5 16 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1213, score:[2571.75], loss:[2.27695], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 3 19 16  0  0  0  0  0  0  0  0], end state:[ 5 19 16  1  1  0  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1214, score:[2778.75], loss:[2.07861], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 11 46  0  0  0  0  0  0  0  0], end state:[ 3 11 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1215, score:[2770.25], loss:[1.96966], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 19 50  0  0  0  0  0  0  0  0], end state:[ 2 19 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1216, score:[2744.75], loss:[1.90932], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 6  3 14  0  0  0  0  0  0  0  0], end state:[ 1  3 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1217, score:[2733.00], loss:[1.68567], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  0 45  0  0  0  0  0  0  0  0], end state:[ 0  0 45  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1218, score:[2701.75], loss:[1.86561], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 18 42  0  0  0  0  0  0  0  0], end state:[ 6 18 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1219, score:[2714.50], loss:[2.01804], sequence:[0], random actions:[42], eInit:[0.0100], init state:[ 3 19 38  0  0  0  0  0  0  0  0], end state:[ 5 19 38  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1220, score:[2785.25], loss:[1.93832], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 16 55  0  0  0  0  0  0  0  0], end state:[ 2 16 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1221, score:[2777.00], loss:[1.83730], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 4 23 11  0  0  0  0  0  0  0  0], end state:[ 6 23 11  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1222, score:[2783.00], loss:[1.84015], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 6  9 54  0  0  0  0  0  0  0  0], end state:[ 1  9 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1223, score:[2687.00], loss:[2.28471], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 3 17 52  0  0  0  0  0  0  0  0], end state:[ 5 17 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1224, score:[2798.75], loss:[2.04740], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1 10 55  0  0  0  0  0  0  0  0], end state:[ 3 10 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1225, score:[2795.00], loss:[2.21717], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 3 18  8  0  0  0  0  0  0  0  0], end state:[ 5 18  8  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1226, score:[2805.50], loss:[2.24110], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 0  1 48  0  0  0  0  0  0  0  0], end state:[ 2  1 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1227, score:[2739.75], loss:[2.40453], sequence:[4], random actions:[37], eInit:[0.0100], init state:[ 3  7 48  0  0  0  0  0  0  0  0], end state:[ 5  7 48  0  0  1  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1228, score:[2708.75], loss:[2.46655], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  4 58  0  0  0  0  0  0  0  0], end state:[ 6  4 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1229, score:[2741.25], loss:[2.50150], sequence:[1], random actions:[36], eInit:[0.0100], init state:[2 6 5 0 0 0 0 0 0 0 0], end state:[4 6 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1230, score:[2778.50], loss:[2.27305], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 1 17 20  0  0  0  0  0  0  0  0], end state:[ 3 17 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1231, score:[2696.75], loss:[2.47078], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 13 47  0  0  0  0  0  0  0  0], end state:[ 0 13 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1232, score:[2790.00], loss:[2.31498], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3 16 17  0  0  0  0  0  0  0  0], end state:[ 5 16 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1233, score:[2782.75], loss:[2.27896], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1 18 32  0  0  0  0  0  0  0  0], end state:[ 3 18 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1234, score:[2808.00], loss:[2.24874], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 3 21 58  1  0  0  0  0  0  1  1], end state:[ 5 21 58  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1235, score:[2804.75], loss:[2.23113], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 0  4 36  0  0  0  0  0  0  0  0], end state:[ 2  4 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1236, score:[2782.75], loss:[2.13666], sequence:[5], random actions:[19], eInit:[0.0100], init state:[ 6  3 13  0  0  0  0  0  0  0  0], end state:[ 1  3 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1237, score:[2812.00], loss:[1.97965], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 0 18 59  0  0  0  0  0  0  0  0], end state:[ 2 18 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1238, score:[2768.00], loss:[2.00308], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 5 14  1  0  0  0  0  0  0  0  0], end state:[ 0 14  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1239, score:[2813.25], loss:[1.93251], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 0 12 21  0  0  0  0  0  0  0  0], end state:[ 2 12 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1240, score:[2791.25], loss:[1.68623], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 1  6 15  0  0  0  0  0  0  0  0], end state:[ 3  6 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1241, score:[2793.50], loss:[1.55602], sequence:[10], random actions:[28], eInit:[0.0100], init state:[ 1 11 54  0  0  0  0  0  0  0  0], end state:[ 3 11 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1242, score:[2748.25], loss:[1.58640], sequence:[11], random actions:[31], eInit:[0.0100], init state:[ 2 22 45  1  0  0  0  0  0  1  1], end state:[ 4 22 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1243, score:[2683.00], loss:[1.85493], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6 14 58  0  0  0  0  0  0  0  0], end state:[ 1 14 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1244, score:[2782.75], loss:[1.63232], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  0 57  0  0  1  0  0  0  0  0], end state:[ 3  0 57  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1245, score:[2793.75], loss:[1.48808], sequence:[2], random actions:[29], eInit:[0.0100], init state:[2 5 7 0 0 0 0 0 0 0 0], end state:[4 5 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1246, score:[2743.75], loss:[1.56888], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 3 15 11  0  0  0  0  0  0  0  0], end state:[ 5 15 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1247, score:[2722.25], loss:[1.67756], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 5  6 36  0  0  0  0  0  0  0  0], end state:[ 0  6 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1248, score:[2785.00], loss:[1.64942], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 2  9 57  0  0  0  0  0  0  0  0], end state:[ 4  9 57  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1249, score:[2766.00], loss:[1.64977], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 6 14 51  0  0  0  0  0  0  0  0], end state:[ 1 14 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1250, score:[2758.25], loss:[1.63963], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 6  5 40  0  0  0  0  0  0  0  0], end state:[ 1  5 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1251, score:[2701.50], loss:[2.13757], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 0  6 30  0  0  0  0  0  0  0  0], end state:[ 2  6 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1252, score:[2687.50], loss:[2.13700], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 4  2 16  0  0  0  0  0  0  0  0], end state:[ 6  2 16  0  0  0  1  1  1  1  0]
INFO:Reinforcement.Functions:episode: 1253, score:[2659.00], loss:[2.24029], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  2 25  0  0  0  0  0  0  0  0], end state:[ 1  2 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1254, score:[2729.25], loss:[2.32810], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 1 22 51  1  0  0  0  0  0  1  1], end state:[ 3 22 51  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1255, score:[2759.75], loss:[2.21420], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 6  1 10  0  0  0  0  0  0  0  0], end state:[ 1  1 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1256, score:[2734.00], loss:[2.28700], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6 10 12  0  0  0  0  0  0  0  0], end state:[ 1 10 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1257, score:[2747.75], loss:[2.14269], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 6 17 47  0  0  0  0  0  0  0  0], end state:[ 1 17 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1258, score:[2698.25], loss:[2.26141], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 1  3 53  0  0  0  0  0  0  0  0], end state:[ 3  3 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1259, score:[2759.00], loss:[2.37937], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2 15 44  0  0  0  0  0  0  0  0], end state:[ 4 15 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1260, score:[2788.25], loss:[2.02317], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 0 20 48  1  1  0  1  0  0  1  1], end state:[ 2 20 48  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1261, score:[2709.75], loss:[2.01519], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4  4 26  0  0  0  0  0  0  0  0], end state:[ 6  4 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1262, score:[2717.75], loss:[2.29400], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 19 43  0  0  0  0  0  0  0  0], end state:[ 5 19 43  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1263, score:[2744.50], loss:[2.26572], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 2 14  6  0  0  0  0  0  0  0  0], end state:[ 4 14  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1264, score:[2782.75], loss:[2.19957], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 0 21 54  1  0  0  0  0  0  1  1], end state:[ 2 21 54  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1265, score:[2787.75], loss:[2.02416], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 0  1 10  0  0  0  0  0  0  0  0], end state:[ 2  1 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1266, score:[2749.25], loss:[1.96913], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 0  1 59  0  0  0  0  0  0  0  0], end state:[ 2  1 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1267, score:[2823.50], loss:[1.81953], sequence:[5], random actions:[17], eInit:[0.0100], init state:[ 0 23 43  1  0  0  1  0  0  1  1], end state:[ 2 23 43  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1268, score:[2770.50], loss:[1.77170], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 0  2 14  0  0  0  0  0  0  0  0], end state:[ 2  2 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1269, score:[2734.25], loss:[1.97396], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  2 38  0  0  0  0  0  0  0  0], end state:[ 6  2 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1270, score:[2797.00], loss:[1.90646], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 4 14 43  0  0  0  0  0  0  0  0], end state:[ 6 14 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1271, score:[2789.50], loss:[1.77039], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1  5 42  0  0  0  0  0  0  0  0], end state:[ 3  5 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1272, score:[2812.25], loss:[1.53825], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 0  7 22  0  0  0  0  0  0  0  0], end state:[ 2  7 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1273, score:[2732.00], loss:[1.76882], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 22 29  1  0  0  0  0  0  1  1], end state:[ 5 22 29  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1274, score:[2732.50], loss:[1.88041], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4  7 19  0  0  0  0  0  0  0  0], end state:[ 6  7 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1275, score:[2782.75], loss:[1.84424], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 4 17 16  0  0  0  0  0  0  0  0], end state:[ 6 17 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1276, score:[2730.50], loss:[1.89744], sequence:[0], random actions:[29], eInit:[0.0100], init state:[3 6 4 0 0 0 0 0 0 0 0], end state:[5 6 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1277, score:[2778.25], loss:[1.85117], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3 15 11  0  0  0  0  0  0  0  0], end state:[ 5 15 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1278, score:[2780.50], loss:[1.71696], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 22 57  1  0  0  0  0  0  1  1], end state:[ 2 22 57  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1279, score:[2774.25], loss:[1.71689], sequence:[3], random actions:[27], eInit:[0.0100], init state:[0 1 2 0 0 1 0 0 0 0 0], end state:[2 1 2 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1280, score:[2681.75], loss:[1.87187], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 18 11  0  0  0  0  0  0  0  0], end state:[ 6 18 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1281, score:[2782.75], loss:[1.61517], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0 23 42  1  0  0  1  0  0  1  1], end state:[ 2 23 42  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1282, score:[2671.25], loss:[2.14953], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 23 21  1  0  0  0  0  0  1  1], end state:[ 0 23 21  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1283, score:[2740.50], loss:[2.22378], sequence:[1], random actions:[42], eInit:[0.0100], init state:[ 2  8 48  1  1  0  0  0  0  0  0], end state:[ 4  8 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1284, score:[2771.50], loss:[2.10577], sequence:[2], random actions:[32], eInit:[0.0100], init state:[4 8 7 0 0 0 0 0 0 0 0], end state:[6 8 7 1 1 1 1 1 1 0 1]
INFO:Reinforcement.Functions:episode: 1285, score:[2766.75], loss:[2.16377], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 4 12 21  1  1  0  0  0  0  0  0], end state:[ 6 12 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1286, score:[2793.00], loss:[2.07924], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 1 23 42  1  0  0  1  0  0  1  1], end state:[ 3 23 42  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1287, score:[2715.50], loss:[2.26093], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 2 18 53  0  0  0  0  0  0  0  0], end state:[ 4 18 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1288, score:[2700.00], loss:[2.61196], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 22 57  1  0  0  0  0  0  1  1], end state:[ 5 22 57  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1289, score:[2672.00], loss:[2.70637], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6  7 34  0  0  0  0  0  0  0  0], end state:[ 1  7 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1290, score:[2779.50], loss:[2.32294], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 18 10  0  0  0  0  0  0  0  0], end state:[ 2 18 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1291, score:[2760.25], loss:[2.28998], sequence:[2], random actions:[41], eInit:[0.0100], init state:[ 2  8 21  1  0  0  0  0  0  0  0], end state:[ 4  8 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1292, score:[2743.75], loss:[2.18154], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 2 11 20  0  0  0  0  0  0  0  0], end state:[ 4 11 20  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1293, score:[2769.50], loss:[2.23282], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 3 12  6  0  0  0  0  0  0  0  0], end state:[ 5 12  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1294, score:[2711.25], loss:[2.55003], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 18  3  0  0  0  0  0  0  0  0], end state:[ 6 18  3  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1295, score:[2764.75], loss:[2.34377], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3  7 38  0  0  0  0  0  0  0  0], end state:[ 5  7 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1296, score:[2762.25], loss:[2.49485], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 1 15 47  0  0  0  0  0  0  0  0], end state:[ 3 15 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1297, score:[2764.00], loss:[2.42818], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 4 16 11  0  0  0  0  0  0  0  0], end state:[ 6 16 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1298, score:[2771.25], loss:[2.23266], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2  7 16  0  0  0  0  0  0  0  0], end state:[ 4  7 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1299, score:[2777.50], loss:[2.27188], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 3 21 53  1  0  0  0  0  0  1  1], end state:[ 5 21 53  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1300, score:[2663.50], loss:[2.43046], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 20 44  1  0  0  0  0  0  0  0], end state:[ 0 20 44  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1301, score:[2783.25], loss:[2.14314], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 4 14 50  0  0  0  0  0  0  0  0], end state:[ 6 14 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1302, score:[2739.25], loss:[2.19245], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 6  9 43  0  0  0  0  0  0  0  0], end state:[ 1  9 43  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1303, score:[2718.25], loss:[2.33226], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 22 31  0  0  0  0  0  0  0  0], end state:[ 6 22 31  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1304, score:[2732.75], loss:[2.48817], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4 23 57  0  0  0  0  0  0  0  0], end state:[ 6 23 57  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1305, score:[2775.75], loss:[2.25303], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 4 16 18  0  0  0  0  0  0  0  0], end state:[ 6 16 18  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1306, score:[2784.50], loss:[2.22236], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 4 21 52  0  0  0  0  0  0  0  0], end state:[ 6 21 52  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1307, score:[2760.25], loss:[2.09502], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 2  0 10  1  0  0  0  0  1  1  1], end state:[ 4  0 10  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1308, score:[2750.00], loss:[2.15974], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2 13 27  0  0  0  0  0  0  0  0], end state:[ 4 13 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1309, score:[2780.50], loss:[2.24999], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 6 22 36  1  0  0  0  0  0  1  1], end state:[ 1 22 36  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1310, score:[2755.75], loss:[2.19740], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 5  5 31  0  0  0  0  0  0  0  0], end state:[ 0  5 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1311, score:[2788.00], loss:[2.17177], sequence:[7], random actions:[30], eInit:[0.0100], init state:[ 0 15 42  0  0  0  0  0  0  0  0], end state:[ 2 15 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1312, score:[2766.25], loss:[1.97911], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 2  2 15  0  0  0  0  0  0  0  0], end state:[ 4  2 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1313, score:[2722.75], loss:[2.16946], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 14 30  0  0  0  0  0  0  0  0], end state:[ 0 14 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1314, score:[2713.00], loss:[2.35206], sequence:[0], random actions:[29], eInit:[0.0100], init state:[3 6 6 0 0 0 0 0 0 0 0], end state:[5 6 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1315, score:[2795.50], loss:[2.43502], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1  2 30  0  0  0  0  0  0  0  0], end state:[ 3  2 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1316, score:[2746.50], loss:[2.44074], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 4 23 26  0  0  0  0  0  0  0  0], end state:[ 6 23 26  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1317, score:[2724.00], loss:[2.39128], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6 12  7  0  0  0  0  0  0  0  0], end state:[ 1 12  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1318, score:[2710.25], loss:[2.31003], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2 13 49  0  0  0  0  0  0  0  0], end state:[ 4 13 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1319, score:[2776.00], loss:[2.39293], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 4  7 14  0  0  0  0  0  0  0  0], end state:[ 6  7 14  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1320, score:[2775.25], loss:[2.06829], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 6 21 49  1  0  0  0  0  0  1  1], end state:[ 1 21 49  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1321, score:[2763.25], loss:[2.01769], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 0 18 51  0  0  0  0  0  0  0  0], end state:[ 2 18 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1322, score:[2755.00], loss:[2.10979], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 2 12 11  0  0  0  0  0  0  0  0], end state:[ 4 12 11  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1323, score:[2733.75], loss:[2.52821], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 16 46  0  0  0  0  0  0  0  0], end state:[ 6 16 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1324, score:[2740.50], loss:[2.52406], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 6 19 48  0  0  0  0  0  0  0  0], end state:[ 1 19 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1325, score:[2744.50], loss:[2.49671], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 3 13 25  0  0  0  0  0  0  0  0], end state:[ 5 13 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1326, score:[2778.25], loss:[2.73940], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0  5 48  0  0  0  0  0  0  0  0], end state:[ 2  5 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1327, score:[2776.75], loss:[2.49351], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 6 19  4  0  0  0  0  0  0  0  0], end state:[ 1 19  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1328, score:[2733.25], loss:[2.49810], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 2 17 14  0  0  0  0  0  0  0  0], end state:[ 4 17 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1329, score:[2750.50], loss:[2.58063], sequence:[1], random actions:[37], eInit:[0.0100], init state:[ 2  4 56  0  0  0  0  0  0  0  0], end state:[ 4  4 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1330, score:[2793.50], loss:[2.52988], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 6 17 46  0  0  0  0  0  0  0  0], end state:[ 1 17 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1331, score:[2707.75], loss:[2.48255], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 5 14 38  0  0  0  0  0  0  0  0], end state:[ 0 14 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1332, score:[2788.75], loss:[2.34776], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0  1 55  0  0  0  0  0  0  0  0], end state:[ 2  1 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1333, score:[2714.50], loss:[2.54375], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 2 10  5  0  0  0  0  0  0  0  0], end state:[ 4 10  5  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1334, score:[2651.50], loss:[2.34013], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 2 21 56  1  0  0  0  0  0  1  1], end state:[ 4 21 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1335, score:[2815.75], loss:[2.43770], sequence:[1], random actions:[30], eInit:[0.0100], init state:[0 7 1 0 0 0 0 0 0 0 0], end state:[2 7 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1336, score:[2785.75], loss:[2.13485], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2  0 18  1  0  0  0  0  1  0  0], end state:[ 4  0 18  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1337, score:[2753.75], loss:[2.36418], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 6  1 32  0  0  0  0  0  0  0  0], end state:[ 1  1 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1338, score:[2732.00], loss:[2.11975], sequence:[0], random actions:[28], eInit:[0.0100], init state:[3 5 0 0 0 0 0 0 0 0 0], end state:[5 5 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1339, score:[2687.50], loss:[2.29276], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 20 25  0  0  0  0  0  0  0  0], end state:[ 6 20 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1340, score:[2759.50], loss:[2.33521], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 6  7 23  0  0  0  0  0  0  0  0], end state:[ 1  7 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1341, score:[2656.00], loss:[2.38018], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4  3 47  0  0  0  0  0  0  0  0], end state:[ 6  3 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1342, score:[2745.25], loss:[2.21074], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1  6 57  0  0  0  0  0  0  0  0], end state:[ 3  6 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1343, score:[2723.75], loss:[2.16522], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 19  3  0  0  0  0  0  0  0  0], end state:[ 6 19  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1344, score:[2771.50], loss:[2.25195], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 3  8 10  1  0  0  0  0  0  0  0], end state:[ 5  8 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1345, score:[2789.50], loss:[2.09852], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 12 23  0  0  0  0  0  0  0  0], end state:[ 3 12 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1346, score:[2702.00], loss:[2.03716], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 6 17 35  0  0  0  0  0  0  0  0], end state:[ 1 17 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1347, score:[2751.25], loss:[2.22735], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 6 11  0  0  0  0  0  0  0  0  0], end state:[ 1 11  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1348, score:[2712.25], loss:[2.16126], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 1  2 21  0  0  0  0  0  0  0  0], end state:[ 3  2 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1349, score:[2791.00], loss:[1.92254], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 10  3  0  0  0  0  0  0  0  0], end state:[ 2 10  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1350, score:[2794.50], loss:[1.84501], sequence:[2], random actions:[11], eInit:[0.0100], init state:[ 3 12 46  0  0  0  0  0  0  0  0], end state:[ 5 12 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1351, score:[2655.25], loss:[1.94055], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 22 16  0  0  0  0  0  0  0  0], end state:[ 6 22 16  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1352, score:[2640.75], loss:[2.30880], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 10 10  1  1  0  1  1  0  0  0], end state:[ 6 10 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1353, score:[2726.75], loss:[2.61612], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6 18 55  0  0  0  0  0  0  0  0], end state:[ 1 18 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1354, score:[2740.25], loss:[2.56583], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 18 44  0  0  0  0  0  0  0  0], end state:[ 2 18 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1355, score:[2651.25], loss:[2.57733], sequence:[0], random actions:[33], eInit:[0.0100], init state:[6 8 9 1 0 0 0 0 0 0 0], end state:[1 8 9 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1356, score:[2721.75], loss:[2.44816], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 2 16  0  0  0  0  0  0  0  0  0], end state:[ 4 16  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1357, score:[2768.75], loss:[2.41974], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 0  1 40  0  0  0  0  0  0  0  0], end state:[ 2  1 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1358, score:[2686.75], loss:[2.51092], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3  6 16  0  0  0  0  0  0  0  0], end state:[ 5  6 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1359, score:[2756.50], loss:[2.37470], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0  8 56  1  1  0  0  0  0  0  0], end state:[ 2  8 56  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1360, score:[2626.00], loss:[2.49136], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 23 12  0  0  0  0  0  0  0  0], end state:[ 6 23 12  0  0  0  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1361, score:[2684.25], loss:[2.84093], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6  0 50  0  0  1  0  0  0  0  0], end state:[ 1  0 50  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1362, score:[2682.50], loss:[2.80101], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6 12 58  0  0  0  0  0  0  0  0], end state:[ 1 12 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1363, score:[2686.75], loss:[2.73282], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 4  3 39  0  0  0  0  0  0  0  0], end state:[ 6  3 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1364, score:[2698.00], loss:[3.03886], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3  8 38  1  1  0  1  0  1  0  0], end state:[ 5  8 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1365, score:[2724.00], loss:[2.95594], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 11  5  1  1  0  0  0  0  0  0], end state:[ 6 11  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1366, score:[2609.50], loss:[3.13772], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  0 57  0  0  0  0  0  0  0  0], end state:[ 0  0 57  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1367, score:[2732.25], loss:[3.24039], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 20 18  0  0  0  0  0  0  0  0], end state:[ 5 20 18  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1368, score:[2684.25], loss:[3.26715], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 2 23 25  1  0  0  1  0  0  1  1], end state:[ 4 23 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1369, score:[2546.25], loss:[3.24662], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 2 13 36  0  0  0  0  0  0  0  0], end state:[ 4 13 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1370, score:[2735.25], loss:[3.31184], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 1  0 15  1  0  0  0  0  1  0  0], end state:[ 3  0 15  1  0  0  0  0  1  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1371, score:[2635.50], loss:[3.45609], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 20  1  0  0  0  0  0  0  0  0], end state:[ 1 20  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1372, score:[2777.25], loss:[3.05658], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0 19 31  0  0  0  0  0  0  0  0], end state:[ 2 19 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1373, score:[2619.50], loss:[3.18713], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 12 49  0  0  0  0  0  0  0  0], end state:[ 0 12 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1374, score:[2759.50], loss:[3.00792], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 20  6  0  0  0  0  0  0  0  0], end state:[ 2 20  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1375, score:[2785.50], loss:[2.88978], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 1 15 25  0  0  0  0  0  0  0  0], end state:[ 3 15 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1376, score:[2756.50], loss:[3.05905], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 1 10 40  0  0  0  0  0  0  0  0], end state:[ 3 10 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1377, score:[2712.00], loss:[3.40723], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 19 21  1  0  0  1  0  0  0  0], end state:[ 0 19 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1378, score:[2695.75], loss:[3.13106], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 3 20 17  0  0  0  0  0  0  0  0], end state:[ 5 20 17  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1379, score:[2746.75], loss:[2.89105], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 2  9 41  0  0  0  0  0  0  0  0], end state:[ 4  9 41  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1380, score:[2791.75], loss:[2.68900], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0  7 18  0  0  0  0  0  0  0  0], end state:[ 2  7 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1381, score:[2764.00], loss:[2.56075], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 2  0 12  1  0  0  0  0  1  1  1], end state:[ 4  0 12  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1382, score:[2656.25], loss:[2.94635], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  3 50  0  0  0  0  0  0  0  0], end state:[ 6  3 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1383, score:[2602.50], loss:[3.27836], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 16 33  0  0  0  0  0  0  0  0], end state:[ 0 16 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1384, score:[2683.00], loss:[3.07266], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 20 23  0  0  0  0  0  0  0  0], end state:[ 5 20 23  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1385, score:[2814.75], loss:[2.71976], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 0  0 50  0  0  1  0  0  0  0  0], end state:[ 2  0 50  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1386, score:[2714.25], loss:[2.53929], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 5 12 13  0  0  0  0  0  0  0  0], end state:[ 0 12 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1387, score:[2624.25], loss:[2.49081], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4  3 28  0  0  0  0  0  0  0  0], end state:[ 6  3 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1388, score:[2739.00], loss:[2.70587], sequence:[1], random actions:[35], eInit:[0.0100], init state:[6 5 4 0 0 0 0 0 0 0 0], end state:[1 5 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1389, score:[2753.00], loss:[2.28674], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 15 52  0  0  0  0  0  0  0  0], end state:[ 4 15 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1390, score:[2774.25], loss:[2.43980], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 0 10 35  0  0  0  0  0  0  0  0], end state:[ 2 10 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1391, score:[2646.75], loss:[2.29535], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 5 20 20  1  0  0  0  0  0  0  0], end state:[ 0 20 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1392, score:[2780.50], loss:[2.19123], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 2  4 26  0  0  0  0  0  0  0  0], end state:[ 4  4 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1393, score:[2787.75], loss:[2.15388], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1  6 47  0  0  0  0  0  0  0  0], end state:[ 3  6 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1394, score:[2702.00], loss:[2.19744], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5  2 48  0  0  0  0  0  0  0  0], end state:[ 0  2 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1395, score:[2769.00], loss:[2.26412], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0  0 11  1  0  0  0  0  1  1  1], end state:[ 2  0 11  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1396, score:[2701.75], loss:[2.12499], sequence:[0], random actions:[42], eInit:[0.0100], init state:[ 3 12 37  0  0  0  0  0  0  0  0], end state:[ 5 12 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1397, score:[2772.25], loss:[1.99227], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 1 16 10  0  0  0  0  0  0  0  0], end state:[ 3 16 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1398, score:[2782.25], loss:[1.89882], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 14 20  0  0  0  0  0  0  0  0], end state:[ 4 14 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1399, score:[2665.75], loss:[1.99560], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 15 12  0  0  0  0  0  0  0  0], end state:[ 0 15 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1400, score:[2747.00], loss:[1.74457], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 5 19 53  1  0  0  1  0  0  0  0], end state:[ 0 19 53  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1401, score:[2732.75], loss:[1.77578], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 10  5  0  0  0  0  0  0  0  0], end state:[ 0 10  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1402, score:[2678.25], loss:[1.88028], sequence:[0], random actions:[36], eInit:[0.0100], init state:[3 0 5 1 0 0 0 0 1 1 1], end state:[5 0 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1403, score:[2742.50], loss:[2.04775], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 2 18 16  0  0  0  0  0  0  0  0], end state:[ 4 18 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1404, score:[2703.25], loss:[2.08069], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 16 31  0  0  0  0  0  0  0  0], end state:[ 0 16 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1405, score:[2708.75], loss:[2.14144], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 0 13 10  0  0  0  0  0  0  0  0], end state:[ 2 13 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1406, score:[2692.75], loss:[2.21268], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3  2 36  0  0  0  0  0  0  0  0], end state:[ 5  2 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1407, score:[2799.50], loss:[2.23813], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0  2 42  0  0  0  0  0  0  0  0], end state:[ 2  2 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1408, score:[2767.50], loss:[2.08256], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 0 21 33  1  0  0  0  0  0  1  1], end state:[ 2 21 33  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1409, score:[2796.00], loss:[1.96035], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1 11 31  0  0  0  0  0  0  0  0], end state:[ 3 11 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1410, score:[2733.75], loss:[2.12450], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 0 10  7  0  0  0  0  0  0  0  0], end state:[ 2 10  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1411, score:[2703.00], loss:[2.24803], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 13 44  0  0  0  0  0  0  0  0], end state:[ 6 13 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1412, score:[2776.25], loss:[2.38435], sequence:[1], random actions:[17], eInit:[0.0100], init state:[ 0 12 33  0  0  0  0  0  0  0  0], end state:[ 2 12 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1413, score:[2773.50], loss:[2.24609], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2  8 53  1  1  0  0  0  0  0  0], end state:[ 4  8 53  0  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1414, score:[2760.00], loss:[2.29856], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 3 13 41  0  0  0  0  0  0  0  0], end state:[ 5 13 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1415, score:[2696.50], loss:[2.37819], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5  8 14  0  0  0  0  0  0  0  0], end state:[ 0  8 14  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1416, score:[2655.25], loss:[2.59606], sequence:[0], random actions:[48], eInit:[0.0100], init state:[ 2 20 16  0  0  0  0  0  0  0  0], end state:[ 4 20 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1417, score:[2731.25], loss:[2.45325], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 12 39  0  0  0  0  0  0  0  0], end state:[ 5 12 39  0  0  1  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1418, score:[2743.25], loss:[2.61090], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 3 12  6  0  0  0  0  0  0  0  0], end state:[ 5 12  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1419, score:[2777.25], loss:[2.40217], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1 19 36  0  0  0  0  0  0  0  0], end state:[ 3 19 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1420, score:[2737.25], loss:[2.40578], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 6 22 57  1  0  0  0  0  0  1  1], end state:[ 1 22 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1421, score:[2785.50], loss:[2.38797], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 1  1 37  0  0  0  0  0  0  0  0], end state:[ 3  1 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1422, score:[2670.75], loss:[2.31102], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 4 10  0  1  1  0  1  0  0  0  0], end state:[ 6 10  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1423, score:[2803.50], loss:[2.04283], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 1 16 37  0  0  0  0  0  0  0  0], end state:[ 3 16 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1424, score:[2726.75], loss:[2.13880], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 2 19 12  0  0  0  0  0  0  0  0], end state:[ 4 19 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1425, score:[2757.75], loss:[2.05542], sequence:[1], random actions:[26], eInit:[0.0100], init state:[2 1 9 0 0 1 0 0 0 0 0], end state:[4 1 9 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1426, score:[2735.75], loss:[2.22393], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 10  2  0  0  0  0  0  0  0  0], end state:[ 5 10  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1427, score:[2743.00], loss:[2.23893], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3  8 13  1  0  0  0  0  0  0  0], end state:[ 5  8 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1428, score:[2677.00], loss:[2.39456], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6 18 32  0  0  0  0  0  0  0  0], end state:[ 1 18 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1429, score:[2752.75], loss:[2.21985], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 5  1 40  0  0  0  0  0  0  0  0], end state:[ 0  1 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1430, score:[2705.25], loss:[2.45347], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6  5 25  0  0  0  0  0  0  0  0], end state:[ 1  5 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1431, score:[2679.00], loss:[2.45191], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  6 35  0  0  0  0  0  0  0  0], end state:[ 1  6 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1432, score:[2740.50], loss:[2.28696], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 5 21 11  1  0  0  1  0  0  1  1], end state:[ 0 21 11  1  1  0  1  0  1  1  1]
INFO:Reinforcement.Functions:episode: 1433, score:[2722.25], loss:[2.52856], sequence:[0], random actions:[30], eInit:[0.0100], init state:[3 3 4 0 0 0 0 0 0 0 0], end state:[5 3 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1434, score:[2733.75], loss:[2.47324], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 11  3  0  0  0  0  0  0  0  0], end state:[ 0 11  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1435, score:[2776.25], loss:[2.33086], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1 20  6  0  0  0  0  0  0  0  0], end state:[ 3 20  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1436, score:[2691.00], loss:[2.41157], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 20 57  0  0  0  0  0  0  0  0], end state:[ 6 20 57  1  1  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1437, score:[2787.50], loss:[2.44439], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 0  1 37  0  0  0  0  0  0  0  0], end state:[ 2  1 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1438, score:[2814.75], loss:[2.29017], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 1  4 37  0  0  0  0  0  0  0  0], end state:[ 3  4 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1439, score:[2753.75], loss:[2.26518], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 2 19 54  0  0  0  0  0  0  0  0], end state:[ 4 19 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1440, score:[2756.50], loss:[2.27610], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 6  2 11  0  0  0  0  0  0  0  0], end state:[ 1  2 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1441, score:[2722.50], loss:[2.33339], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  3 36  0  0  0  0  0  0  0  0], end state:[ 0  3 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1442, score:[2750.25], loss:[2.65263], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 16 51  0  0  0  0  0  0  0  0], end state:[ 2 16 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1443, score:[2719.75], loss:[2.72417], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  8 51  0  0  0  0  0  0  0  0], end state:[ 0  8 51  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1444, score:[2767.50], loss:[2.79061], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 3 15 10  0  0  0  0  0  0  0  0], end state:[ 5 15 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1445, score:[2790.50], loss:[2.57846], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 3 15 55  0  0  0  0  0  0  0  0], end state:[ 5 15 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1446, score:[2771.50], loss:[2.43826], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1  6 28  0  0  0  0  0  0  0  0], end state:[ 3  6 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1447, score:[2754.50], loss:[2.65301], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 0 19 35  0  0  0  0  0  0  0  0], end state:[ 2 19 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1448, score:[2673.00], loss:[2.42623], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4  1 19  0  0  0  0  0  0  0  0], end state:[ 6  1 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1449, score:[2733.50], loss:[2.68602], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 16 45  0  0  0  0  0  0  0  0], end state:[ 5 16 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1450, score:[2671.00], loss:[2.58340], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6 11 13  0  0  0  0  0  0  0  0], end state:[ 1 11 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1451, score:[2738.75], loss:[2.38260], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 4 12 34  1  1  0  0  0  0  0  0], end state:[ 6 12 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1452, score:[2783.25], loss:[2.35944], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 6 18 31  0  0  0  0  0  0  0  0], end state:[ 1 18 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1453, score:[2734.25], loss:[2.74385], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 1  2 27  0  0  0  0  0  0  0  0], end state:[ 3  2 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1454, score:[2650.25], loss:[2.60352], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4 22  9  0  0  0  0  0  0  0  0], end state:[ 6 22  9  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1455, score:[2702.00], loss:[2.70695], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 20  4  0  0  0  0  0  0  0  0], end state:[ 6 20  4  0  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1456, score:[2794.00], loss:[2.62401], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 1 13 59  0  0  0  0  0  0  0  0], end state:[ 3 13 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1457, score:[2646.75], loss:[2.81775], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 4 12 21  1  1  0  0  0  0  0  0], end state:[ 6 12 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1458, score:[2770.00], loss:[2.94224], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 14 37  0  0  0  0  0  0  0  0], end state:[ 2 14 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1459, score:[2759.50], loss:[2.85137], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 13 36  0  0  0  0  0  0  0  0], end state:[ 2 13 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1460, score:[2770.50], loss:[2.73092], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 2  5 12  0  0  0  0  0  0  0  0], end state:[ 4  5 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1461, score:[2699.25], loss:[3.03672], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3  7 21  0  0  0  0  0  0  0  0], end state:[ 5  7 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1462, score:[2701.00], loss:[2.91451], sequence:[0], random actions:[18], eInit:[0.0100], init state:[ 6  3 51  0  0  0  0  0  0  0  0], end state:[ 1  3 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1463, score:[2670.50], loss:[2.93066], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 15  8  0  0  0  0  0  0  0  0], end state:[ 0 15  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1464, score:[2642.75], loss:[3.07467], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 14 45  0  0  0  0  0  0  0  0], end state:[ 0 14 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1465, score:[2721.50], loss:[3.00809], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 20 54  0  0  0  0  0  0  0  0], end state:[ 6 20 54  0  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1466, score:[2761.50], loss:[2.99656], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 13 20  0  0  0  0  0  0  0  0], end state:[ 3 13 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1467, score:[2789.25], loss:[2.79345], sequence:[2], random actions:[28], eInit:[0.0100], init state:[4 7 0 0 0 0 0 0 0 0 0], end state:[6 7 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1468, score:[2769.75], loss:[2.86826], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 0 11  4  0  0  0  0  0  0  0  0], end state:[ 2 11  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1469, score:[2823.75], loss:[2.56356], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 1 19 37  0  0  0  0  0  0  0  0], end state:[ 3 19 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1470, score:[2803.50], loss:[2.27795], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 1 18 35  0  0  0  0  0  0  0  0], end state:[ 3 18 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1471, score:[2749.00], loss:[2.33122], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 3  6 51  0  0  0  0  0  0  0  0], end state:[ 5  6 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1472, score:[2784.25], loss:[2.33903], sequence:[7], random actions:[28], eInit:[0.0100], init state:[ 0 15 41  0  0  0  0  0  0  0  0], end state:[ 2 15 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1473, score:[2747.00], loss:[2.36859], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 1  8 14  1  0  0  0  0  0  0  0], end state:[ 3  8 14  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1474, score:[2780.00], loss:[2.41048], sequence:[9], random actions:[22], eInit:[0.0100], init state:[ 3 16 58  0  0  0  0  0  0  0  0], end state:[ 5 16 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1475, score:[2732.00], loss:[2.41806], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 14 29  0  0  0  0  0  0  0  0], end state:[ 6 14 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1476, score:[2773.00], loss:[2.52909], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3 11 14  0  0  0  0  0  0  0  0], end state:[ 5 11 14  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1477, score:[2732.00], loss:[2.48846], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6 13  1  0  0  0  0  0  0  0  0], end state:[ 1 13  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1478, score:[2797.00], loss:[2.19374], sequence:[1], random actions:[18], eInit:[0.0100], init state:[ 6 22 10  1  0  0  0  0  0  1  1], end state:[ 1 22 10  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1479, score:[2723.00], loss:[2.30628], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 23 44  1  0  0  0  0  0  1  1], end state:[ 0 23 44  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1480, score:[2713.25], loss:[2.38938], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 15 30  0  0  0  0  0  0  0  0], end state:[ 5 15 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1481, score:[2822.25], loss:[2.31438], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 1  1 18  0  0  0  0  0  0  0  0], end state:[ 3  1 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1482, score:[2740.75], loss:[2.03968], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 5  0 37  0  0  0  0  0  0  0  0], end state:[ 0  0 37  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1483, score:[2796.75], loss:[2.00489], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 1 10 58  0  0  0  0  0  0  0  0], end state:[ 3 10 58  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1484, score:[2764.00], loss:[2.16100], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 1 18 15  0  0  0  0  0  0  0  0], end state:[ 3 18 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1485, score:[2751.25], loss:[2.00036], sequence:[5], random actions:[24], eInit:[0.0100], init state:[5 1 7 0 0 0 0 0 0 0 0], end state:[0 1 7 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1486, score:[2759.25], loss:[2.16173], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 4  5 39  0  0  0  0  0  0  0  0], end state:[ 6  5 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1487, score:[2745.25], loss:[2.20196], sequence:[7], random actions:[35], eInit:[0.0100], init state:[ 0 21 48  1  0  0  0  0  0  1  1], end state:[ 2 21 48  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1488, score:[2783.75], loss:[2.49315], sequence:[8], random actions:[29], eInit:[0.0100], init state:[ 6 17 37  0  0  0  0  0  0  0  0], end state:[ 1 17 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1489, score:[2786.75], loss:[2.41544], sequence:[9], random actions:[39], eInit:[0.0100], init state:[ 0 22 26  1  0  0  0  0  0  1  1], end state:[ 2 22 26  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1490, score:[2785.75], loss:[2.37605], sequence:[10], random actions:[26], eInit:[0.0100], init state:[ 0  9 24  0  0  0  0  0  0  0  0], end state:[ 2  9 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1491, score:[2759.25], loss:[2.21302], sequence:[11], random actions:[34], eInit:[0.0100], init state:[ 0  4 11  0  0  0  0  0  0  0  0], end state:[ 2  4 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1492, score:[2747.25], loss:[2.43129], sequence:[12], random actions:[36], eInit:[0.0100], init state:[ 3  9 11  0  0  0  0  0  0  0  0], end state:[ 5  9 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1493, score:[2724.75], loss:[2.31964], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  0 20  0  0  0  0  0  0  0  0], end state:[ 0  0 20  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1494, score:[2731.50], loss:[2.37845], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5  4 17  0  0  0  0  0  0  0  0], end state:[ 0  4 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1495, score:[2790.25], loss:[2.30863], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 21 29  1  1  0  1  0  0  1  1], end state:[ 2 21 29  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1496, score:[2764.25], loss:[2.22895], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 6 17 35  0  0  0  0  0  0  0  0], end state:[ 1 17 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1497, score:[2768.50], loss:[2.14350], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1  9 11  0  0  0  0  0  0  0  0], end state:[ 3  9 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1498, score:[2755.25], loss:[2.36635], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 6 18 21  0  0  0  0  0  0  0  0], end state:[ 1 18 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1499, score:[2725.75], loss:[2.37271], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 3 11 46  0  0  0  0  0  0  0  0], end state:[ 5 11 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1500, score:[2676.75], loss:[2.58658], sequence:[0], random actions:[24], eInit:[0.0100], init state:[5 4 4 0 0 0 0 0 0 0 0], end state:[0 4 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1501, score:[2805.50], loss:[2.34783], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1  5 21  0  0  0  0  0  0  0  0], end state:[ 3  5 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1502, score:[2763.50], loss:[2.39111], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 2 15 35  0  0  0  0  0  0  0  0], end state:[ 4 15 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1503, score:[2699.50], loss:[2.36096], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 2 11 12  0  0  0  0  0  0  0  0], end state:[ 4 11 12  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1504, score:[2787.25], loss:[2.44615], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 18 50  0  0  0  0  0  0  0  0], end state:[ 3 18 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1505, score:[2770.25], loss:[2.13009], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 2 15 25  0  0  0  0  0  0  0  0], end state:[ 4 15 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1506, score:[2681.50], loss:[2.45494], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 4  9 43  1  0  0  0  0  0  0  0], end state:[ 6  9 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1507, score:[2683.25], loss:[2.50272], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 16 28  0  0  0  0  0  0  0  0], end state:[ 0 16 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1508, score:[2766.75], loss:[2.23455], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 5  2 43  0  0  0  0  0  0  0  0], end state:[ 0  2 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1509, score:[2678.25], loss:[2.27423], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 2  8 20  1  0  0  0  0  0  0  0], end state:[ 4  8 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1510, score:[2807.00], loss:[2.27523], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 2 17 25  0  0  0  0  0  0  0  0], end state:[ 4 17 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1511, score:[2719.00], loss:[2.31345], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6  6 29  0  0  0  0  0  0  0  0], end state:[ 1  6 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1512, score:[2827.75], loss:[2.21629], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 1 14 56  0  0  0  0  0  0  0  0], end state:[ 3 14 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1513, score:[2788.00], loss:[2.16578], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2 12  3  0  0  0  0  0  0  0  0], end state:[ 4 12  3  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1514, score:[2727.75], loss:[2.60798], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4 18  2  0  0  0  0  0  0  0  0], end state:[ 6 18  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1515, score:[2714.00], loss:[2.61511], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 22 53  1  0  0  1  0  0  1  1], end state:[ 0 22 53  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1516, score:[2751.75], loss:[2.62453], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 4 20 49  0  0  0  0  0  0  0  0], end state:[ 6 20 49  1  1  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1517, score:[2704.50], loss:[2.41738], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 2 16  2  0  0  0  0  0  0  0  0], end state:[ 4 16  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1518, score:[2746.75], loss:[2.58845], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 6 14 27  0  0  0  0  0  0  0  0], end state:[ 1 14 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1519, score:[2725.75], loss:[2.68813], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4  5 26  0  0  0  0  0  0  0  0], end state:[ 6  5 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1520, score:[2748.00], loss:[2.63064], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 3 17 29  0  0  0  0  0  0  0  0], end state:[ 5 17 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1521, score:[2690.25], loss:[2.68307], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 17 42  0  0  0  0  0  0  0  0], end state:[ 0 17 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1522, score:[2770.00], loss:[2.82921], sequence:[1], random actions:[25], eInit:[0.0100], init state:[0 2 3 0 0 0 0 0 0 0 0], end state:[2 2 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1523, score:[2818.25], loss:[2.48779], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 1 11  3  0  0  0  0  0  0  0  0], end state:[ 3 11  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1524, score:[2692.25], loss:[2.51900], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 2 14 31  0  0  0  0  0  0  0  0], end state:[ 4 14 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1525, score:[2689.75], loss:[2.82649], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 2 20 12  0  0  0  0  0  0  0  0], end state:[ 4 20 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1526, score:[2770.50], loss:[2.82952], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 4 20 10  0  0  0  0  0  0  0  0], end state:[ 6 20 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1527, score:[2653.25], loss:[2.87261], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 3  8 54  1  1  0  0  0  0  0  0], end state:[ 5  8 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1528, score:[2784.25], loss:[2.70699], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0 10 39  0  0  0  0  0  0  0  0], end state:[ 2 10 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1529, score:[2733.00], loss:[2.73032], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 22 52  1  0  0  0  0  0  1  1], end state:[ 4 22 52  0  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1530, score:[2666.00], loss:[3.09164], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4 22 27  0  0  0  0  0  0  0  0], end state:[ 6 22 27  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1531, score:[2640.25], loss:[3.38669], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6  4 15  0  0  0  0  0  0  0  0], end state:[ 1  4 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1532, score:[2760.25], loss:[2.94002], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 4 12 36  1  1  0  0  0  0  0  0], end state:[ 6 12 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1533, score:[2709.50], loss:[2.73755], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5  4 23  0  0  0  0  0  0  0  0], end state:[ 0  4 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1534, score:[2688.75], loss:[2.91073], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3  3 11  0  0  0  0  0  0  0  0], end state:[ 5  3 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1535, score:[2780.75], loss:[2.83163], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 3 10 27  0  0  0  0  0  0  0  0], end state:[ 5 10 27  0  1  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1536, score:[2789.50], loss:[2.64083], sequence:[2], random actions:[24], eInit:[0.0100], init state:[2 1 4 0 0 1 0 0 0 0 0], end state:[4 1 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1537, score:[2789.00], loss:[2.77714], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 0  7 20  0  0  0  0  0  0  0  0], end state:[ 2  7 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1538, score:[2756.75], loss:[2.70869], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 6  2 50  0  0  0  0  0  0  0  0], end state:[ 1  2 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1539, score:[2744.75], loss:[2.70168], sequence:[5], random actions:[42], eInit:[0.0100], init state:[ 1  3 43  0  0  0  0  0  0  0  0], end state:[ 3  3 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1540, score:[2746.75], loss:[2.86027], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 3 18  5  0  0  0  0  0  0  0  0], end state:[ 5 18  5  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1541, score:[2796.00], loss:[2.69926], sequence:[7], random actions:[30], eInit:[0.0100], init state:[ 0 19 34  0  0  0  0  0  0  0  0], end state:[ 2 19 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1542, score:[2763.00], loss:[2.73960], sequence:[8], random actions:[31], eInit:[0.0100], init state:[1 7 1 0 0 0 0 0 0 0 0], end state:[3 7 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1543, score:[2697.25], loss:[2.94928], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 18 13  0  0  0  0  0  0  0  0], end state:[ 5 18 13  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1544, score:[2797.75], loss:[2.48999], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 12 44  0  0  0  0  0  0  0  0], end state:[ 3 12 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1545, score:[2827.25], loss:[2.34258], sequence:[2], random actions:[15], eInit:[0.0100], init state:[ 1  3 29  0  0  0  0  0  0  0  0], end state:[ 3  3 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1546, score:[2810.50], loss:[2.26707], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 0 13 45  0  0  0  0  0  0  0  0], end state:[ 2 13 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1547, score:[2767.50], loss:[2.32047], sequence:[4], random actions:[45], eInit:[0.0100], init state:[ 0  5 40  0  0  0  0  0  0  0  0], end state:[ 2  5 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1548, score:[2760.75], loss:[2.41564], sequence:[5], random actions:[37], eInit:[0.0100], init state:[ 6 14 13  0  0  0  0  0  0  0  0], end state:[ 1 14 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1549, score:[2773.50], loss:[2.26903], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 0  2 43  0  0  0  0  0  0  0  0], end state:[ 2  2 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1550, score:[2596.00], loss:[2.51864], sequence:[0], random actions:[31], eInit:[0.0100], init state:[5 9 4 0 0 0 0 0 0 0 0], end state:[0 9 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1551, score:[2772.50], loss:[2.51387], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 3 12  7  0  0  0  0  0  0  0  0], end state:[ 5 12  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1552, score:[2776.75], loss:[2.26480], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 1  6 16  0  0  0  0  0  0  0  0], end state:[ 3  6 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1553, score:[2775.25], loss:[2.20836], sequence:[3], random actions:[37], eInit:[0.0100], init state:[2 0 7 1 0 0 0 0 1 1 1], end state:[4 0 7 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 1554, score:[2764.25], loss:[2.22946], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 6 17 30  0  0  0  0  0  0  0  0], end state:[ 1 17 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1555, score:[2583.50], loss:[2.51695], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4 23 20  0  0  0  0  0  0  0  0], end state:[ 6 23 20  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1556, score:[2740.50], loss:[2.59771], sequence:[1], random actions:[32], eInit:[0.0100], init state:[6 9 6 0 0 0 0 0 0 0 0], end state:[1 9 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1557, score:[2763.25], loss:[2.41913], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0 23 28  1  0  0  1  0  0  1  1], end state:[ 2 23 28  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1558, score:[2753.50], loss:[2.33324], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 6 17 28  0  0  0  0  0  0  0  0], end state:[ 1 17 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1559, score:[2808.75], loss:[2.05211], sequence:[4], random actions:[19], eInit:[0.0100], init state:[ 2  5 30  0  0  0  0  0  0  0  0], end state:[ 4  5 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1560, score:[2698.00], loss:[2.21184], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  0 32  0  0  0  0  0  0  0  0], end state:[ 0  0 32  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1561, score:[2662.00], loss:[2.55360], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  5 56  0  0  0  0  0  0  0  0], end state:[ 6  5 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1562, score:[2731.25], loss:[2.46325], sequence:[0], random actions:[30], eInit:[0.0100], init state:[0 4 3 0 0 0 0 0 0 0 0], end state:[2 4 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1563, score:[2769.75], loss:[2.45388], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1 16 56  0  0  0  0  0  0  0  0], end state:[ 3 16 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1564, score:[2815.25], loss:[2.35838], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 1 20 25  0  0  0  0  0  0  0  0], end state:[ 3 20 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1565, score:[2798.00], loss:[2.13847], sequence:[3], random actions:[23], eInit:[0.0100], init state:[0 6 1 0 0 0 0 0 0 0 0], end state:[2 6 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1566, score:[2787.00], loss:[2.26166], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 1  8 50  1  1  0  0  0  0  0  0], end state:[ 3  8 50  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1567, score:[2787.00], loss:[2.12999], sequence:[5], random actions:[22], eInit:[0.0100], init state:[ 2 13 20  0  0  0  0  0  0  0  0], end state:[ 4 13 20  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1568, score:[2695.50], loss:[2.22991], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5  4 46  0  0  0  0  0  0  0  0], end state:[ 0  4 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1569, score:[2767.00], loss:[2.33128], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 1 14 42  0  0  0  0  0  0  0  0], end state:[ 3 14 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1570, score:[2763.25], loss:[2.25600], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0  5 59  0  0  0  0  0  0  0  0], end state:[ 2  5 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1571, score:[2682.50], loss:[2.55227], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 17 40  0  0  0  0  0  0  0  0], end state:[ 0 17 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1572, score:[2791.50], loss:[2.32530], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0  8 57  1  1  0  0  0  0  0  0], end state:[ 2  8 57  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1573, score:[2764.75], loss:[2.22277], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0  8 49  1  1  0  0  0  0  0  0], end state:[ 2  8 49  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1574, score:[2802.00], loss:[1.98778], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 1 21 13  1  1  0  1  0  0  1  1], end state:[ 3 21 13  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1575, score:[2761.25], loss:[2.15253], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 6  1 40  0  0  0  0  0  0  0  0], end state:[ 1  1 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1576, score:[2771.25], loss:[2.13578], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 2  4 24  0  0  0  0  0  0  0  0], end state:[ 4  4 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1577, score:[2764.75], loss:[2.20847], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 2 20 16  0  0  0  0  0  0  0  0], end state:[ 4 20 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1578, score:[2812.25], loss:[1.86971], sequence:[7], random actions:[21], eInit:[0.0100], init state:[ 1  7 13  0  0  0  0  0  0  0  0], end state:[ 3  7 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1579, score:[2670.00], loss:[2.14884], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  5 20  0  0  0  0  0  0  0  0], end state:[ 6  5 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1580, score:[2682.50], loss:[2.05941], sequence:[0], random actions:[31], eInit:[0.0100], init state:[3 7 6 0 0 0 0 0 0 0 0], end state:[5 7 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1581, score:[2677.75], loss:[2.00985], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 13 19  1  1  0  0  0  0  0  0], end state:[ 6 13 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1582, score:[2707.25], loss:[2.27364], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 15 36  0  0  0  0  0  0  0  0], end state:[ 0 15 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1583, score:[2681.75], loss:[2.27763], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 3 20 24  0  0  0  0  0  0  0  0], end state:[ 5 20 24  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1584, score:[2778.50], loss:[2.06781], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 2 20 33  1  1  0  0  0  0  0  0], end state:[ 4 20 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1585, score:[2798.00], loss:[2.02534], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2 12 13  0  0  0  0  0  0  0  0], end state:[ 4 12 13  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1586, score:[2781.25], loss:[1.95209], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 0 15 30  0  0  0  0  0  0  0  0], end state:[ 2 15 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1587, score:[2697.00], loss:[2.22328], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 23 41  1  0  0  0  0  0  1  1], end state:[ 0 23 41  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1588, score:[2754.25], loss:[2.24851], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 2  6 18  0  0  0  0  0  0  0  0], end state:[ 4  6 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1589, score:[2813.75], loss:[2.03776], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 0 23 27  1  0  0  1  0  0  1  1], end state:[ 2 23 27  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1590, score:[2729.50], loss:[2.31440], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 14  7  0  0  0  0  0  0  0  0], end state:[ 0 14  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1591, score:[2738.00], loss:[2.33510], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0  8 29  1  0  0  0  0  0  0  0], end state:[ 2  8 29  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1592, score:[2792.25], loss:[2.19369], sequence:[2], random actions:[19], eInit:[0.0100], init state:[2 8 3 1 0 0 0 0 0 0 0], end state:[4 8 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1593, score:[2756.25], loss:[2.23034], sequence:[3], random actions:[40], eInit:[0.0100], init state:[ 1 22 12  1  0  0  0  0  0  1  1], end state:[ 3 22 12  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1594, score:[2672.75], loss:[2.01476], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 16  6  0  0  0  0  0  0  0  0], end state:[ 4 16  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1595, score:[2779.25], loss:[2.03977], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 22 18  1  0  0  0  0  0  1  1], end state:[ 3 22 18  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1596, score:[2747.75], loss:[1.85127], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 22 40  1  0  0  0  0  0  1  1], end state:[ 4 22 40  1  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1597, score:[2752.25], loss:[2.14636], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 6 18 42  0  0  0  0  0  0  0  0], end state:[ 1 18 42  1  0  1  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1598, score:[2758.25], loss:[2.29146], sequence:[4], random actions:[31], eInit:[0.0100], init state:[0 8 1 1 0 0 0 0 0 0 0], end state:[2 8 1 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1599, score:[2735.50], loss:[2.15033], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 2 11  3  0  0  0  0  0  0  0  0], end state:[ 4 11  3  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1600, score:[2703.25], loss:[2.25240], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5 22 45  1  0  0  1  0  0  1  1], end state:[ 0 22 45  1  1  0  0  0  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1601, score:[2756.00], loss:[2.31560], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 1  9 42  0  0  0  0  0  0  0  0], end state:[ 3  9 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1602, score:[2697.75], loss:[2.43613], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 21 18  0  0  0  0  0  0  0  0], end state:[ 6 21 18  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1603, score:[2793.00], loss:[2.59809], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 13 37  0  0  0  0  0  0  0  0], end state:[ 3 13 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1604, score:[2787.25], loss:[2.30638], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 0 13 27  0  0  0  0  0  0  0  0], end state:[ 2 13 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1605, score:[2805.00], loss:[2.10462], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 1  0 58  0  0  1  0  0  0  0  0], end state:[ 3  0 58  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1606, score:[2819.75], loss:[2.00392], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 0 11 29  0  0  0  0  0  0  0  0], end state:[ 2 11 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1607, score:[2755.00], loss:[2.03983], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 6 12 47  0  0  0  0  0  0  0  0], end state:[ 1 12 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1608, score:[2727.50], loss:[2.07808], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 22  6  1  0  0  1  0  0  1  1], end state:[ 0 22  6  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1609, score:[2729.00], loss:[2.24938], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 0  4 31  0  0  0  0  0  0  0  0], end state:[ 2  4 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1610, score:[2670.50], loss:[2.68072], sequence:[0], random actions:[24], eInit:[0.0100], init state:[4 1 0 0 0 1 0 0 0 0 0], end state:[6 1 0 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1611, score:[2699.25], loss:[2.89957], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 13 56  0  0  0  0  0  0  0  0], end state:[ 0 13 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1612, score:[2774.25], loss:[2.74882], sequence:[1], random actions:[30], eInit:[0.0100], init state:[0 0 0 1 0 0 0 0 0 1 1], end state:[2 0 0 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 1613, score:[2723.00], loss:[2.91691], sequence:[0], random actions:[45], eInit:[0.0100], init state:[ 3 10 50  0  0  0  0  0  0  0  0], end state:[ 5 10 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1614, score:[2678.50], loss:[2.98815], sequence:[0], random actions:[23], eInit:[0.0100], init state:[5 2 8 0 0 0 0 0 0 0 0], end state:[0 2 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1615, score:[2773.75], loss:[2.91386], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 0 18 29  0  0  0  0  0  0  0  0], end state:[ 2 18 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1616, score:[2677.25], loss:[2.83452], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 1  5 37  0  0  0  0  0  0  0  0], end state:[ 3  5 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1617, score:[2708.50], loss:[2.96318], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 0  3 12  0  0  0  0  0  0  0  0], end state:[ 2  3 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1618, score:[2786.75], loss:[2.95718], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1  9 22  0  0  0  0  0  0  0  0], end state:[ 3  9 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1619, score:[2698.25], loss:[3.09928], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  4 57  0  0  0  0  0  0  0  0], end state:[ 0  4 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1620, score:[2803.25], loss:[3.01761], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  6 19  0  0  0  0  0  0  0  0], end state:[ 3  6 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1621, score:[2666.75], loss:[3.09105], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 22 41  1  0  0  0  0  0  1  1], end state:[ 4 22 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1622, score:[2735.75], loss:[3.30314], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 18 59  1  1  0  1  0  0  0  0], end state:[ 0 18 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1623, score:[2700.00], loss:[3.35556], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 14 21  0  0  0  0  0  0  0  0], end state:[ 0 14 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1624, score:[2761.50], loss:[3.38449], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 6  0 40  0  0  1  0  0  0  0  0], end state:[ 1  0 40  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1625, score:[2757.00], loss:[3.21406], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 6 23 49  1  0  0  0  0  0  1  1], end state:[ 1 23 49  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1626, score:[2790.00], loss:[3.18851], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 6  9 13  0  0  0  0  0  0  0  0], end state:[ 1  9 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1627, score:[2741.25], loss:[3.06836], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 5 21 48  1  0  0  1  0  0  1  1], end state:[ 0 21 48  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1628, score:[2728.75], loss:[3.12712], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4 13 26  1  1  0  0  0  0  0  0], end state:[ 6 13 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1629, score:[2733.50], loss:[3.08320], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 0  7 28  0  0  0  0  0  0  0  0], end state:[ 2  7 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1630, score:[2753.75], loss:[2.95083], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 14 25  0  0  0  0  0  0  0  0], end state:[ 2 14 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1631, score:[2771.75], loss:[2.99471], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 4 14 12  0  0  0  0  0  0  0  0], end state:[ 6 14 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1632, score:[2785.00], loss:[2.88043], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 0  6 59  0  0  0  0  0  0  0  0], end state:[ 2  6 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1633, score:[2628.00], loss:[3.17148], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  3 27  0  0  0  0  0  0  0  0], end state:[ 6  3 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1634, score:[2715.50], loss:[2.99035], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 12 35  0  0  0  0  0  0  0  0], end state:[ 0 12 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1635, score:[2711.75], loss:[2.78476], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 3  2 57  0  0  0  0  0  0  0  0], end state:[ 5  2 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1636, score:[2771.75], loss:[2.62854], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 5  3 55  0  0  0  0  0  0  0  0], end state:[ 0  3 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1637, score:[2790.00], loss:[2.47050], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 1  8 54  1  1  0  0  0  0  0  0], end state:[ 3  8 54  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1638, score:[2752.25], loss:[2.63512], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 5 20 49  1  0  0  0  0  0  0  0], end state:[ 0 20 49  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1639, score:[2800.75], loss:[2.60285], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 0  9 25  0  0  0  0  0  0  0  0], end state:[ 2  9 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1640, score:[2782.50], loss:[2.76000], sequence:[5], random actions:[35], eInit:[0.0100], init state:[ 1  8 37  1  1  0  1  0  1  0  0], end state:[ 3  8 37  1  1  0  1  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1641, score:[2813.25], loss:[2.44941], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 1  6 52  0  0  0  0  0  0  0  0], end state:[ 3  6 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1642, score:[2791.25], loss:[2.19207], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 0  0 19  1  0  0  0  0  1  0  0], end state:[ 2  0 19  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1643, score:[2706.25], loss:[2.15153], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 3  2 29  0  0  0  0  0  0  0  0], end state:[ 5  2 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1644, score:[2768.75], loss:[2.33974], sequence:[1], random actions:[37], eInit:[0.0100], init state:[ 3  6 57  0  0  0  0  0  0  0  0], end state:[ 5  6 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1645, score:[2742.75], loss:[2.37428], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 5 22 20  1  0  0  1  0  0  1  1], end state:[ 0 22 20  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1646, score:[2687.50], loss:[2.54619], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4  0 44  1  0  1  0  0  0  0  0], end state:[ 6  0 44  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1647, score:[2750.00], loss:[2.36435], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 4  3 32  0  0  0  0  0  0  0  0], end state:[ 6  3 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1648, score:[2778.25], loss:[2.45031], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1 19 33  0  0  0  0  0  0  0  0], end state:[ 3 19 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1649, score:[2793.25], loss:[2.48483], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 2  0 41  0  0  1  0  0  0  0  0], end state:[ 4  0 41  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1650, score:[2710.00], loss:[2.62123], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6  4 19  0  0  0  0  0  0  0  0], end state:[ 1  4 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1651, score:[2813.75], loss:[2.32961], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  5 34  0  0  0  0  0  0  0  0], end state:[ 3  5 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1652, score:[2826.50], loss:[2.20615], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 0 21 35  1  0  0  0  0  0  1  1], end state:[ 2 21 35  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1653, score:[2774.00], loss:[2.26930], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0 18 35  0  0  0  0  0  0  0  0], end state:[ 2 18 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1654, score:[2809.00], loss:[2.15722], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 1 12 26  0  0  0  0  0  0  0  0], end state:[ 3 12 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1655, score:[2722.75], loss:[2.20644], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 13 36  0  0  0  0  0  0  0  0], end state:[ 4 13 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1656, score:[2648.50], loss:[2.62290], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4  9 22  0  0  0  0  0  0  0  0], end state:[ 6  9 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1657, score:[2670.25], loss:[2.47193], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 3  6 42  0  0  0  0  0  0  0  0], end state:[ 5  6 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1658, score:[2759.75], loss:[2.53909], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 6 12 49  0  0  0  0  0  0  0  0], end state:[ 1 12 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1659, score:[2776.00], loss:[2.46361], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 22 45  1  0  0  0  0  0  1  1], end state:[ 4 22 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1660, score:[2749.00], loss:[2.67699], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 2  6 48  0  0  0  0  0  0  0  0], end state:[ 4  6 48  0  0  0  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1661, score:[2736.25], loss:[3.09089], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 4  8 10  0  0  0  0  0  0  0  0], end state:[ 6  8 10  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1662, score:[2733.75], loss:[3.26122], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 0 15 30  0  0  0  0  0  0  0  0], end state:[ 2 15 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1663, score:[2586.00], loss:[3.59454], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5 10 31  0  0  0  0  0  0  0  0], end state:[ 0 10 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1664, score:[2702.25], loss:[3.53147], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 13 50  0  0  0  0  0  0  0  0], end state:[ 4 13 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1665, score:[2695.75], loss:[3.44129], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 12 20  0  0  0  0  0  0  0  0], end state:[ 5 12 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1666, score:[2688.75], loss:[3.36070], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 2 20 44  1  1  0  0  0  0  1  1], end state:[ 4 20 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1667, score:[2754.50], loss:[3.44424], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 1 14 51  0  0  0  0  0  0  0  0], end state:[ 3 14 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1668, score:[2673.00], loss:[3.31359], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 12 38  0  0  0  0  0  0  0  0], end state:[ 0 12 38  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1669, score:[2787.50], loss:[3.24281], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 1  9 58  0  0  0  0  0  0  0  0], end state:[ 3  9 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1670, score:[2687.75], loss:[3.24254], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6  2 39  0  0  0  0  0  0  0  0], end state:[ 1  2 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1671, score:[2666.00], loss:[3.33499], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 5 14 57  0  0  0  0  0  0  0  0], end state:[ 0 14 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1672, score:[2695.75], loss:[3.70308], sequence:[0], random actions:[36], eInit:[0.0100], init state:[5 8 5 0 0 0 0 0 0 0 0], end state:[0 8 5 0 0 0 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1673, score:[2764.00], loss:[3.69064], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 5 19 35  1  0  0  1  0  0  0  0], end state:[ 0 19 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1674, score:[2781.25], loss:[3.24679], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 5 12 44  0  0  0  0  0  0  0  0], end state:[ 0 12 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1675, score:[2673.50], loss:[3.41125], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6 19 27  0  0  0  0  0  0  0  0], end state:[ 1 19 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1676, score:[2754.00], loss:[3.38802], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 15 54  0  0  0  0  0  0  0  0], end state:[ 3 15 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1677, score:[2782.25], loss:[3.19727], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 1 15 20  0  0  0  0  0  0  0  0], end state:[ 3 15 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1678, score:[2768.75], loss:[2.71892], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 0  7 40  0  0  0  0  0  0  0  0], end state:[ 2  7 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1679, score:[2688.00], loss:[2.78383], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3  7 56  0  0  0  0  0  0  0  0], end state:[ 5  7 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1680, score:[2730.00], loss:[2.84151], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 2 19  7  0  0  0  0  0  0  0  0], end state:[ 4 19  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1681, score:[2807.75], loss:[2.51562], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 6 21 14  1  1  0  1  0  0  1  1], end state:[ 1 21 14  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1682, score:[2767.75], loss:[2.26579], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 0  5 38  0  0  0  0  0  0  0  0], end state:[ 2  5 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1683, score:[2632.25], loss:[2.78277], sequence:[0], random actions:[37], eInit:[0.0100], init state:[5 5 1 0 0 0 0 0 0 0 0], end state:[0 5 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1684, score:[2633.50], loss:[2.95662], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4  4 31  0  0  0  0  0  0  0  0], end state:[ 6  4 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1685, score:[2680.75], loss:[2.81174], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 5 12  9  0  0  0  0  0  0  0  0], end state:[ 0 12  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1686, score:[2723.25], loss:[2.84505], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 20 27  0  0  0  0  0  0  0  0], end state:[ 5 20 27  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1687, score:[2718.50], loss:[2.72659], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 3  0 35  0  0  1  0  0  0  0  0], end state:[ 5  0 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1688, score:[2764.25], loss:[2.82505], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4 15 26  0  0  0  0  0  0  0  0], end state:[ 6 15 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1689, score:[2741.50], loss:[2.67040], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2 16  9  0  0  0  0  0  0  0  0], end state:[ 4 16  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1690, score:[2768.50], loss:[2.69935], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 0 11 10  0  0  0  0  0  0  0  0], end state:[ 2 11 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1691, score:[2779.75], loss:[2.57441], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 1 17 39  0  0  0  0  0  0  0  0], end state:[ 3 17 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1692, score:[2781.25], loss:[2.29913], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 0 23 35  1  0  0  1  0  0  1  1], end state:[ 2 23 35  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1693, score:[2747.75], loss:[2.33341], sequence:[6], random actions:[38], eInit:[0.0100], init state:[ 3 11 52  0  0  0  0  0  0  0  0], end state:[ 5 11 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1694, score:[2806.25], loss:[2.27174], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 0 12 46  0  0  0  0  0  0  0  0], end state:[ 2 12 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1695, score:[2746.00], loss:[2.20209], sequence:[8], random actions:[20], eInit:[0.0100], init state:[ 5  5 33  0  0  0  0  0  0  0  0], end state:[ 0  5 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1696, score:[2755.50], loss:[2.29808], sequence:[9], random actions:[21], eInit:[0.0100], init state:[ 6  0 59  0  0  1  0  0  0  0  0], end state:[ 1  0 59  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1697, score:[2735.75], loss:[2.42288], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6 14 43  0  0  0  0  0  0  0  0], end state:[ 1 14 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1698, score:[2756.00], loss:[2.10668], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3 14 34  0  0  0  0  0  0  0  0], end state:[ 5 14 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1699, score:[2741.75], loss:[2.21794], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2  2 15  0  0  0  0  0  0  0  0], end state:[ 4  2 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1700, score:[2704.50], loss:[2.30908], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 3 10  5  0  0  0  0  0  0  0  0], end state:[ 5 10  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1701, score:[2753.50], loss:[2.41281], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 6 13 58  0  0  0  0  0  0  0  0], end state:[ 1 13 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1702, score:[2675.50], loss:[2.31529], sequence:[0], random actions:[28], eInit:[0.0100], init state:[4 2 7 0 0 0 0 0 0 0 0], end state:[6 2 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1703, score:[2641.75], loss:[2.38101], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4  4 53  0  0  0  0  0  0  0  0], end state:[ 6  4 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1704, score:[2688.50], loss:[2.38771], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 15 49  0  0  0  0  0  0  0  0], end state:[ 6 15 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1705, score:[2741.25], loss:[2.50674], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 13  2  0  0  0  0  0  0  0  0], end state:[ 4 13  2  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1706, score:[2755.50], loss:[2.50688], sequence:[2], random actions:[27], eInit:[0.0100], init state:[1 0 3 1 0 0 0 0 0 1 1], end state:[3 0 3 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 1707, score:[2680.75], loss:[2.47538], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 17 33  0  0  0  0  0  0  0  0], end state:[ 0 17 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1708, score:[2719.00], loss:[2.53941], sequence:[0], random actions:[33], eInit:[0.0100], init state:[4 6 6 0 0 0 0 0 0 0 0], end state:[6 6 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1709, score:[2784.25], loss:[2.97296], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 2  8 14  1  0  0  0  0  0  0  0], end state:[ 4  8 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1710, score:[2735.25], loss:[2.89431], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 6 17 49  0  0  0  0  0  0  0  0], end state:[ 1 17 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1711, score:[2802.50], loss:[2.75132], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1  2 28  0  0  0  0  0  0  0  0], end state:[ 3  2 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1712, score:[2665.25], loss:[3.27926], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4 20 38  0  0  0  0  0  0  0  0], end state:[ 6 20 38  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1713, score:[2738.50], loss:[3.15879], sequence:[1], random actions:[16], eInit:[0.0100], init state:[ 6 12  0  0  0  0  0  0  0  0  0], end state:[ 1 12  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1714, score:[2717.50], loss:[3.41259], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 18 55  1  1  0  1  0  0  0  0], end state:[ 0 18 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1715, score:[2729.75], loss:[3.43915], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 0 13 31  0  0  0  0  0  0  0  0], end state:[ 2 13 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1716, score:[2751.50], loss:[3.36169], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 5 22 54  1  0  0  1  0  0  1  1], end state:[ 0 22 54  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1717, score:[2765.00], loss:[3.10622], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 4 16  8  0  0  0  0  0  0  0  0], end state:[ 6 16  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1718, score:[2780.75], loss:[2.92091], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 1 10 55  0  0  0  0  0  0  0  0], end state:[ 3 10 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1719, score:[2787.25], loss:[2.83086], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 6 13 57  0  0  0  0  0  0  0  0], end state:[ 1 13 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1720, score:[2699.00], loss:[2.73311], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  7 14  0  0  0  0  0  0  0  0], end state:[ 6  7 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1721, score:[2763.00], loss:[2.85809], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1 22 23  1  0  0  0  0  0  1  1], end state:[ 3 22 23  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1722, score:[2609.75], loss:[3.10855], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  6 43  0  0  0  0  0  0  0  0], end state:[ 6  6 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1723, score:[2748.00], loss:[2.99592], sequence:[1], random actions:[34], eInit:[0.0100], init state:[5 7 9 0 0 0 0 0 0 0 0], end state:[0 7 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1724, score:[2690.25], loss:[2.86759], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 2 10 11  0  0  0  0  0  0  0  0], end state:[ 4 10 11  1  1  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1725, score:[2675.50], loss:[2.69249], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  7 57  0  0  0  0  0  0  0  0], end state:[ 6  7 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1726, score:[2747.75], loss:[2.60496], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 2  9 27  0  0  0  0  0  0  0  0], end state:[ 4  9 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1727, score:[2707.25], loss:[2.97716], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 3 14 34  0  0  0  0  0  0  0  0], end state:[ 5 14 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1728, score:[2543.50], loss:[3.39641], sequence:[0], random actions:[35], eInit:[0.0100], init state:[2 9 4 0 0 0 0 0 0 0 0], end state:[4 9 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1729, score:[2735.75], loss:[3.72427], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 1 13 35  0  0  0  0  0  0  0  0], end state:[ 3 13 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1730, score:[2762.75], loss:[3.53397], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 3 17 21  0  0  0  0  0  0  0  0], end state:[ 5 17 21  0  1  0  1  0  0  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1731, score:[2787.00], loss:[3.53300], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 0  4 17  0  0  0  0  0  0  0  0], end state:[ 2  4 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1732, score:[2763.00], loss:[3.34949], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 3 13 20  0  0  0  0  0  0  0  0], end state:[ 5 13 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1733, score:[2680.50], loss:[3.45618], sequence:[0], random actions:[24], eInit:[0.0100], init state:[6 9 4 0 0 0 0 0 0 0 0], end state:[1 9 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1734, score:[2771.75], loss:[3.64169], sequence:[1], random actions:[37], eInit:[0.0100], init state:[ 0  7 25  0  0  0  0  0  0  0  0], end state:[ 2  7 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1735, score:[2720.00], loss:[3.60148], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 1 12 11  0  0  0  0  0  0  0  0], end state:[ 3 12 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1736, score:[2608.00], loss:[3.79169], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 16 51  0  0  0  0  0  0  0  0], end state:[ 6 16 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1737, score:[2828.00], loss:[3.73004], sequence:[1], random actions:[24], eInit:[0.0100], init state:[0 8 1 1 0 0 0 0 0 0 0], end state:[2 8 1 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1738, score:[2766.00], loss:[3.40297], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 23 17  1  0  0  1  0  0  1  1], end state:[ 2 23 17  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1739, score:[2780.25], loss:[3.57940], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 3 11 29  0  0  0  0  0  0  0  0], end state:[ 5 11 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1740, score:[2741.75], loss:[3.75460], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 5 20 15  1  0  0  0  0  0  0  0], end state:[ 0 20 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1741, score:[2694.75], loss:[3.65514], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 20 23  1  0  0  0  0  0  0  0], end state:[ 0 20 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1742, score:[2765.50], loss:[3.54716], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1 14 29  0  0  0  0  0  0  0  0], end state:[ 3 14 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1743, score:[2796.75], loss:[3.41827], sequence:[2], random actions:[24], eInit:[0.0100], init state:[0 5 9 0 0 0 0 0 0 0 0], end state:[2 5 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1744, score:[2735.00], loss:[3.56940], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 0 20 53  1  1  0  1  0  0  1  1], end state:[ 2 20 53  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1745, score:[2668.50], loss:[3.73675], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 3 16  3  0  0  0  0  0  0  0  0], end state:[ 5 16  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1746, score:[2723.00], loss:[3.64469], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 2 15 55  0  0  0  0  0  0  0  0], end state:[ 4 15 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1747, score:[2688.25], loss:[3.58151], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5  3 44  0  0  0  0  0  0  0  0], end state:[ 0  3 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1748, score:[2743.75], loss:[3.90755], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3 19 22  0  0  0  0  0  0  0  0], end state:[ 5 19 22  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1749, score:[2746.75], loss:[3.56434], sequence:[2], random actions:[30], eInit:[0.0100], init state:[1 2 0 0 0 0 0 0 0 0 0], end state:[3 2 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1750, score:[2745.50], loss:[3.61844], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 4 14 55  0  0  0  0  0  0  0  0], end state:[ 6 14 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1751, score:[2688.00], loss:[3.58692], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 18 11  1  1  0  1  0  0  0  0], end state:[ 0 18 11  0  0  1  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1752, score:[2739.75], loss:[3.49060], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 5 21 52  1  0  0  1  0  0  1  1], end state:[ 0 21 52  1  1  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1753, score:[2671.75], loss:[3.98693], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 13 57  0  0  0  0  0  0  0  0], end state:[ 0 13 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1754, score:[2718.00], loss:[3.87070], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 11 21  0  0  0  0  0  0  0  0], end state:[ 5 11 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1755, score:[2689.00], loss:[3.72685], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  7 13  0  0  0  0  0  0  0  0], end state:[ 0  7 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1756, score:[2651.25], loss:[3.83212], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4 21  1  0  0  0  0  0  0  0  0], end state:[ 6 21  1  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1757, score:[2666.25], loss:[3.99775], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3  6 46  0  0  0  0  0  0  0  0], end state:[ 5  6 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1758, score:[2806.50], loss:[3.40185], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 4 14 45  0  0  0  0  0  0  0  0], end state:[ 6 14 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1759, score:[2690.25], loss:[3.51934], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5  7 32  0  0  0  0  0  0  0  0], end state:[ 0  7 32  0  0  0  0  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1760, score:[2752.25], loss:[3.67594], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 6 16  0  0  0  0  0  0  0  0  0], end state:[ 1 16  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1761, score:[2700.00], loss:[3.72516], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5 14 12  0  0  0  0  0  0  0  0], end state:[ 0 14 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1762, score:[2685.25], loss:[4.16548], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 20 32  0  0  0  0  0  0  0  0], end state:[ 6 20 32  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1763, score:[2721.50], loss:[4.29319], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3  5 55  0  0  0  0  0  0  0  0], end state:[ 5  5 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1764, score:[2670.50], loss:[4.09114], sequence:[0], random actions:[22], eInit:[0.0100], init state:[4 5 9 0 0 0 0 0 0 0 0], end state:[6 5 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1765, score:[2677.25], loss:[4.44933], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 6  4 26  0  0  0  0  0  0  0  0], end state:[ 1  4 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1766, score:[2760.75], loss:[4.10199], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 0 19  6  0  0  0  0  0  0  0  0], end state:[ 2 19  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1767, score:[2650.25], loss:[3.96677], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 4 10 45  1  1  0  1  0  0  0  0], end state:[ 6 10 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1768, score:[2721.75], loss:[4.12111], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 1  8 21  1  0  0  0  0  0  0  0], end state:[ 3  8 21  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1769, score:[2789.25], loss:[3.72768], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 4 15  2  0  0  0  0  0  0  0  0], end state:[ 6 15  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1770, score:[2816.00], loss:[3.33994], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 0 19 52  0  0  0  0  0  0  0  0], end state:[ 2 19 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1771, score:[2804.50], loss:[3.07359], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1  0 31  0  0  1  0  0  0  0  0], end state:[ 3  0 31  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1772, score:[2730.00], loss:[3.06601], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  8 26  1  0  0  0  0  0  0  0], end state:[ 1  8 26  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1773, score:[2764.50], loss:[3.01507], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2  4 45  0  0  0  0  0  0  0  0], end state:[ 4  4 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1774, score:[2767.00], loss:[3.04670], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 4  2 23  0  0  0  0  0  0  0  0], end state:[ 6  2 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1775, score:[2716.50], loss:[3.05553], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 15 46  0  0  0  0  0  0  0  0], end state:[ 0 15 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1776, score:[2667.00], loss:[3.28960], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5 20 45  1  0  0  0  0  0  0  0], end state:[ 0 20 45  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1777, score:[2802.00], loss:[3.20446], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 4  5 13  0  0  0  0  0  0  0  0], end state:[ 6  5 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1778, score:[2702.25], loss:[3.11218], sequence:[0], random actions:[30], eInit:[0.0100], init state:[6 1 0 0 0 1 0 0 0 0 0], end state:[1 1 0 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1779, score:[2746.75], loss:[3.33137], sequence:[1], random actions:[29], eInit:[0.0100], init state:[1 9 3 0 0 0 0 0 0 0 0], end state:[3 9 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1780, score:[2796.50], loss:[3.34373], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 0 19 30  0  0  0  0  0  0  0  0], end state:[ 2 19 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1781, score:[2793.25], loss:[3.11891], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 0 22 29  1  0  0  0  0  0  1  1], end state:[ 2 22 29  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1782, score:[2679.25], loss:[2.99671], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 13 54  0  0  0  0  0  0  0  0], end state:[ 0 13 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1783, score:[2720.75], loss:[3.16930], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 18  7  1  1  0  1  0  0  0  0], end state:[ 0 18  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1784, score:[2805.00], loss:[2.87104], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 6 23 23  1  0  0  1  0  0  1  1], end state:[ 1 23 23  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1785, score:[2781.25], loss:[2.70365], sequence:[2], random actions:[18], eInit:[0.0100], init state:[ 6  3 17  0  0  0  0  0  0  0  0], end state:[ 1  3 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1786, score:[2781.50], loss:[2.56092], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1  0 27  1  0  0  0  0  0  0  0], end state:[ 3  0 27  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1787, score:[2739.50], loss:[3.08184], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 2 12 51  0  0  0  0  0  0  0  0], end state:[ 4 12 51  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1788, score:[2767.75], loss:[3.25039], sequence:[5], random actions:[37], eInit:[0.0100], init state:[ 1 21 43  1  0  0  0  0  0  1  1], end state:[ 3 21 43  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1789, score:[2693.50], loss:[3.55326], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6  8 21  1  0  0  0  0  0  0  0], end state:[ 1  8 21  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1790, score:[2736.50], loss:[3.40729], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 2  7 12  0  0  0  0  0  0  0  0], end state:[ 4  7 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1791, score:[2631.00], loss:[3.44736], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 21 23  1  1  0  1  0  0  1  1], end state:[ 5 21 23  1  0  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 1792, score:[2626.00], loss:[3.61618], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 3 22  8  1  0  0  0  0  0  1  1], end state:[ 5 22  8  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1793, score:[2758.50], loss:[3.78872], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1  8 21  1  0  0  0  0  0  0  0], end state:[ 3  8 21  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1794, score:[2732.25], loss:[3.84082], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 2 12 23  0  0  0  0  0  0  0  0], end state:[ 4 12 23  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1795, score:[2805.50], loss:[3.84350], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 6 21 38  1  0  0  0  0  0  1  1], end state:[ 1 21 38  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1796, score:[2730.00], loss:[3.89535], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 1 11 40  0  0  0  0  0  0  0  0], end state:[ 3 11 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1797, score:[2722.25], loss:[3.87063], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5  6 26  0  0  0  0  0  0  0  0], end state:[ 0  6 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1798, score:[2778.75], loss:[3.79136], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 4 23 26  0  0  0  0  0  0  0  0], end state:[ 6 23 26  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1799, score:[2769.75], loss:[3.39485], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6 11 25  0  0  0  0  0  0  0  0], end state:[ 1 11 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1800, score:[2751.75], loss:[2.98255], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 2 18 41  0  0  0  0  0  0  0  0], end state:[ 4 18 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1801, score:[2653.50], loss:[3.23738], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 22 23  1  0  0  1  0  0  1  1], end state:[ 0 22 23  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1802, score:[2794.75], loss:[3.15150], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 15 33  0  0  0  0  0  0  0  0], end state:[ 3 15 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1803, score:[2730.50], loss:[3.26978], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 19 36  1  0  0  1  0  0  0  0], end state:[ 0 19 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1804, score:[2742.75], loss:[3.40486], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 5  7 33  0  0  0  0  0  0  0  0], end state:[ 0  7 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1805, score:[2694.75], loss:[3.84356], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 2 19  1  0  0  0  0  0  0  0  0], end state:[ 4 19  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1806, score:[2749.50], loss:[4.04236], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3 10  1  0  0  0  0  0  0  0  0], end state:[ 5 10  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1807, score:[2765.75], loss:[4.13886], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 21 27  1  1  0  1  0  0  1  1], end state:[ 4 21 27  0  0  1  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1808, score:[2779.00], loss:[3.90133], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 2 22 10  1  0  0  0  0  0  1  1], end state:[ 4 22 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1809, score:[2771.50], loss:[3.93140], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 0 20 19  0  0  0  0  0  0  0  0], end state:[ 2 20 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1810, score:[2765.25], loss:[3.77237], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 4  4 44  0  0  0  0  0  0  0  0], end state:[ 6  4 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1811, score:[2721.25], loss:[3.91428], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 4 22 37  0  0  0  0  0  0  0  0], end state:[ 6 22 37  0  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1812, score:[2597.25], loss:[3.73913], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 23 18  0  0  0  0  0  0  0  0], end state:[ 6 23 18  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1813, score:[2656.00], loss:[3.73472], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6 20 36  1  1  0  0  0  0  0  0], end state:[ 1 20 36  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1814, score:[2719.00], loss:[3.55316], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4 21 58  0  0  0  0  0  0  0  0], end state:[ 6 21 58  0  1  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1815, score:[2799.25], loss:[3.31073], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0  2 51  0  0  0  0  0  0  0  0], end state:[ 2  2 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1816, score:[2738.00], loss:[3.12835], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 5 21 34  1  0  0  1  0  1  1  1], end state:[ 0 21 34  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1817, score:[2729.25], loss:[3.07437], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 12 50  1  1  0  1  0  0  0  0], end state:[ 6 12 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1818, score:[2656.00], loss:[3.21369], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 10 19  0  0  0  0  0  0  0  0], end state:[ 0 10 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1819, score:[2771.50], loss:[2.96547], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 18 20  0  0  0  0  0  0  0  0], end state:[ 3 18 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1820, score:[2804.50], loss:[2.61208], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1  1 20  0  0  0  0  0  0  0  0], end state:[ 3  1 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1821, score:[2737.25], loss:[2.82514], sequence:[3], random actions:[30], eInit:[0.0100], init state:[5 7 0 0 0 0 0 0 0 0 0], end state:[0 7 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1822, score:[2760.50], loss:[2.79570], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 2  4 40  0  0  0  0  0  0  0  0], end state:[ 4  4 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1823, score:[2774.50], loss:[2.80638], sequence:[5], random actions:[35], eInit:[0.0100], init state:[ 0 16  4  0  0  0  0  0  0  0  0], end state:[ 2 16  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1824, score:[2754.75], loss:[2.74612], sequence:[6], random actions:[16], eInit:[0.0100], init state:[ 2 22 47  1  0  0  0  0  0  1  1], end state:[ 4 22 47  1  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1825, score:[2754.25], loss:[3.03315], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 3 19 44  0  0  0  0  0  0  0  0], end state:[ 5 19 44  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1826, score:[2749.00], loss:[2.86227], sequence:[8], random actions:[32], eInit:[0.0100], init state:[ 1 11  6  0  0  0  0  0  0  0  0], end state:[ 3 11  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1827, score:[2760.25], loss:[2.99297], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 6 19  7  0  0  0  0  0  0  0  0], end state:[ 1 19  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1828, score:[2753.75], loss:[2.80194], sequence:[10], random actions:[20], eInit:[0.0100], init state:[ 4 14 12  0  0  0  0  0  0  0  0], end state:[ 6 14 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1829, score:[2706.25], loss:[3.13846], sequence:[0], random actions:[30], eInit:[0.0100], init state:[6 4 9 0 0 0 0 0 0 0 0], end state:[1 4 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1830, score:[2670.00], loss:[3.03792], sequence:[0], random actions:[18], eInit:[0.0100], init state:[ 4  6 41  0  0  0  0  0  0  0  0], end state:[ 6  6 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1831, score:[2790.25], loss:[2.60900], sequence:[1], random actions:[20], eInit:[0.0100], init state:[0 7 8 0 0 0 0 0 0 0 0], end state:[2 7 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1832, score:[2802.50], loss:[2.51512], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 22 36  1  0  0  0  0  0  1  1], end state:[ 2 22 36  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1833, score:[2624.25], loss:[2.78747], sequence:[0], random actions:[41], eInit:[0.0100], init state:[ 4 10 56  1  1  0  1  0  0  0  0], end state:[ 6 10 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1834, score:[2798.25], loss:[2.61871], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  9 55  0  0  0  0  0  0  0  0], end state:[ 3  9 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1835, score:[2717.25], loss:[2.55337], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 14 51  0  0  0  0  0  0  0  0], end state:[ 6 14 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1836, score:[2721.75], loss:[2.59352], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 10 30  0  0  0  0  0  0  0  0], end state:[ 0 10 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1837, score:[2775.50], loss:[2.60946], sequence:[1], random actions:[39], eInit:[0.0100], init state:[1 0 8 1 0 0 0 0 1 1 1], end state:[3 0 8 1 0 0 0 0 1 1 1]
INFO:Reinforcement.Functions:episode: 1838, score:[2732.75], loss:[2.71922], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 22 54  0  0  0  0  0  0  0  0], end state:[ 6 22 54  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1839, score:[2744.50], loss:[2.90345], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 1  0 31  0  0  1  0  0  0  0  0], end state:[ 3  0 31  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1840, score:[2747.00], loss:[2.75880], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1  2 44  0  0  0  0  0  0  0  0], end state:[ 3  2 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1841, score:[2694.75], loss:[2.98350], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 15 44  0  0  0  0  0  0  0  0], end state:[ 5 15 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1842, score:[2763.25], loss:[2.82886], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 5 18 37  1  1  0  1  0  0  0  0], end state:[ 0 18 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1843, score:[2671.25], loss:[2.72408], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5  5 13  0  0  0  0  0  0  0  0], end state:[ 0  5 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1844, score:[2718.75], loss:[2.91654], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 18 55  0  0  0  0  0  0  0  0], end state:[ 6 18 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1845, score:[2779.25], loss:[2.90231], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 20 38  1  1  0  0  0  0  0  0], end state:[ 2 20 38  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1846, score:[2741.25], loss:[3.17667], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 17 35  0  0  0  0  0  0  0  0], end state:[ 4 17 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1847, score:[2696.00], loss:[3.14592], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6 13 23  0  0  0  0  0  0  0  0], end state:[ 1 13 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1848, score:[2738.00], loss:[3.23243], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 3 12 48  0  0  0  0  0  0  0  0], end state:[ 5 12 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1849, score:[2732.75], loss:[3.09441], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6 15 35  0  0  0  0  0  0  0  0], end state:[ 1 15 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1850, score:[2718.75], loss:[2.94192], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3  0 42  0  0  1  0  0  0  0  0], end state:[ 5  0 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1851, score:[2738.25], loss:[3.12018], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 4 12 38  1  1  0  0  0  0  0  0], end state:[ 6 12 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1852, score:[2777.25], loss:[3.19480], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 23 27  1  0  0  1  0  0  1  1], end state:[ 3 23 27  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1853, score:[2760.75], loss:[3.08997], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 1 23 21  1  0  0  1  0  0  1  1], end state:[ 3 23 21  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1854, score:[2814.00], loss:[3.05795], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 0  3 50  0  0  0  0  0  0  0  0], end state:[ 2  3 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1855, score:[2787.25], loss:[2.81379], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 2 11 55  0  0  0  0  0  0  0  0], end state:[ 4 11 55  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1856, score:[2672.00], loss:[3.07939], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 3 21 46  1  0  0  0  0  0  1  1], end state:[ 5 21 46  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1857, score:[2786.50], loss:[2.88794], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4 17 18  0  0  0  0  0  0  0  0], end state:[ 6 17 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1858, score:[2789.75], loss:[2.66226], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 3 13 24  0  0  0  0  0  0  0  0], end state:[ 5 13 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1859, score:[2724.00], loss:[3.19366], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 0 17 41  0  0  0  0  0  0  0  0], end state:[ 2 17 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1860, score:[2799.00], loss:[3.11876], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 21 21  1  1  0  1  0  0  1  1], end state:[ 2 21 21  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1861, score:[2806.75], loss:[3.01199], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1  0 38  0  0  1  0  0  0  0  0], end state:[ 3  0 38  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1862, score:[2703.50], loss:[3.14067], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6 18  4  0  0  0  0  0  0  0  0], end state:[ 1 18  4  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1863, score:[2730.00], loss:[2.96097], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 3 16 39  0  0  0  0  0  0  0  0], end state:[ 5 16 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1864, score:[2760.75], loss:[3.01602], sequence:[1], random actions:[16], eInit:[0.0100], init state:[ 0 15 36  0  0  0  0  0  0  0  0], end state:[ 2 15 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1865, score:[2727.25], loss:[2.95148], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  8 51  0  0  0  0  0  0  0  0], end state:[ 0  8 51  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1866, score:[2815.00], loss:[2.81526], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2 22 28  1  0  0  0  0  0  1  1], end state:[ 4 22 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1867, score:[2768.50], loss:[2.79298], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 6  3 15  0  0  0  0  0  0  0  0], end state:[ 1  3 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1868, score:[2791.75], loss:[2.72619], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 6 19 59  0  0  0  0  0  0  0  0], end state:[ 1 19 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1869, score:[2824.00], loss:[2.59560], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 0 16 20  0  0  0  0  0  0  0  0], end state:[ 2 16 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1870, score:[2805.75], loss:[2.71347], sequence:[5], random actions:[33], eInit:[0.0100], init state:[1 9 7 0 0 0 0 0 0 0 0], end state:[3 9 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1871, score:[2770.75], loss:[2.67366], sequence:[6], random actions:[36], eInit:[0.0100], init state:[ 2 22 18  1  0  0  0  0  0  1  1], end state:[ 4 22 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1872, score:[2737.25], loss:[2.92700], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 3  7 52  0  0  0  0  0  0  0  0], end state:[ 5  7 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1873, score:[2633.00], loss:[3.03971], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  2 59  0  0  0  0  0  0  0  0], end state:[ 0  2 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1874, score:[2791.75], loss:[3.08281], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 22  6  1  0  0  0  0  0  1  1], end state:[ 3 22  6  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1875, score:[2724.25], loss:[3.02165], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 4 10 15  1  1  0  1  1  0  0  0], end state:[ 6 10 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1876, score:[2750.50], loss:[2.99090], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 4  9 59  1  0  0  0  0  0  0  0], end state:[ 6  9 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1877, score:[2714.25], loss:[3.02843], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 1 12 31  0  0  0  0  0  0  0  0], end state:[ 3 12 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1878, score:[2753.25], loss:[3.38352], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6 19  1  0  0  0  0  0  0  0  0], end state:[ 1 19  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1879, score:[2825.25], loss:[3.13515], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1  5 12  0  0  0  0  0  0  0  0], end state:[ 3  5 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1880, score:[2808.25], loss:[2.91017], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 0  1 55  0  0  0  0  0  0  0  0], end state:[ 2  1 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1881, score:[2750.00], loss:[3.11232], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 4 11  0  1  1  0  0  0  0  0  0], end state:[ 6 11  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1882, score:[2780.50], loss:[2.90429], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 2  9 56  0  0  0  0  0  0  0  0], end state:[ 4  9 56  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1883, score:[2812.00], loss:[2.76556], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 1 17  6  0  0  0  0  0  0  0  0], end state:[ 3 17  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1884, score:[2708.25], loss:[2.87616], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  3 52  0  0  0  0  0  0  0  0], end state:[ 1  3 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1885, score:[2732.50], loss:[3.15829], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5  9 16  0  0  0  0  0  0  0  0], end state:[ 0  9 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1886, score:[2821.25], loss:[2.95779], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 2 10 22  0  0  0  0  0  0  0  0], end state:[ 4 10 22  1  1  0  1  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1887, score:[2799.50], loss:[2.96118], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 2  5 34  0  0  0  0  0  0  0  0], end state:[ 4  5 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1888, score:[2789.00], loss:[3.00473], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 3  9 31  0  0  0  0  0  0  0  0], end state:[ 5  9 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1889, score:[2767.00], loss:[2.76205], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 2 21 46  1  0  0  0  0  0  1  1], end state:[ 4 21 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1890, score:[2684.50], loss:[3.14775], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3  9 13  0  0  0  0  0  0  0  0], end state:[ 5  9 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1891, score:[2812.25], loss:[3.21696], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0 19 33  0  0  0  0  0  0  0  0], end state:[ 2 19 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1892, score:[2735.00], loss:[3.24478], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 13 29  0  0  0  0  0  0  0  0], end state:[ 0 13 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1893, score:[2829.50], loss:[2.94451], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 13 32  0  0  0  0  0  0  0  0], end state:[ 3 13 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1894, score:[2784.75], loss:[2.81968], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2  1 57  0  0  0  0  0  0  0  0], end state:[ 4  1 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1895, score:[2783.50], loss:[2.47439], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 0  5 32  0  0  0  0  0  0  0  0], end state:[ 2  5 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1896, score:[2738.50], loss:[2.50632], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 5 10 59  0  0  0  0  0  0  0  0], end state:[ 0 10 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1897, score:[2666.75], loss:[2.75257], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4  8 20  0  0  0  0  0  0  0  0], end state:[ 6  8 20  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1898, score:[2782.00], loss:[2.74757], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2  4 10  0  0  0  0  0  0  0  0], end state:[ 4  4 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1899, score:[2804.25], loss:[2.62107], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 17 31  0  0  0  0  0  0  0  0], end state:[ 3 17 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1900, score:[2749.25], loss:[2.54871], sequence:[3], random actions:[28], eInit:[0.0100], init state:[3 7 8 0 0 0 0 0 0 0 0], end state:[5 7 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1901, score:[2750.50], loss:[2.95418], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 5 14 15  0  0  0  0  0  0  0  0], end state:[ 0 14 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1902, score:[2811.00], loss:[2.84865], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 6  1 46  0  0  0  0  0  0  0  0], end state:[ 1  1 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1903, score:[2659.50], loss:[3.03297], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 15 47  0  0  0  0  0  0  0  0], end state:[ 5 15 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1904, score:[2772.75], loss:[2.87347], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2 19 44  0  0  0  0  0  0  0  0], end state:[ 4 19 44  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1905, score:[2794.00], loss:[2.96618], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 0 11  2  0  0  0  0  0  0  0  0], end state:[ 2 11  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1906, score:[2734.50], loss:[2.96479], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 4 23 55  0  0  0  0  0  0  0  0], end state:[ 6 23 55  1  0  1  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1907, score:[2776.50], loss:[3.12394], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 22  7  1  0  0  0  0  0  1  1], end state:[ 3 22  7  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1908, score:[2790.00], loss:[2.75253], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 6  1 14  0  0  0  0  0  0  0  0], end state:[ 1  1 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1909, score:[2773.75], loss:[2.92956], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 0 20 45  1  1  0  1  0  0  1  1], end state:[ 2 20 45  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1910, score:[2778.50], loss:[3.00293], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 3  7 32  0  0  0  0  0  0  0  0], end state:[ 5  7 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1911, score:[2720.50], loss:[3.25200], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5 13 51  0  0  0  0  0  0  0  0], end state:[ 0 13 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1912, score:[2778.50], loss:[3.36556], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 0 17  2  0  0  0  0  0  0  0  0], end state:[ 2 17  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1913, score:[2744.50], loss:[3.35059], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 5 21 55  1  0  0  1  0  0  1  1], end state:[ 0 21 55  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1914, score:[2779.00], loss:[3.44061], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 2 14 38  0  0  0  0  0  0  0  0], end state:[ 4 14 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1915, score:[2773.25], loss:[3.17768], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 4 18 50  0  0  0  0  0  0  0  0], end state:[ 6 18 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1916, score:[2682.50], loss:[3.32040], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 2  6 36  0  0  0  0  0  0  0  0], end state:[ 4  6 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1917, score:[2707.00], loss:[3.60288], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 1 14 49  0  0  0  0  0  0  0  0], end state:[ 3 14 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1918, score:[2814.50], loss:[3.12065], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 2  6 43  0  0  0  0  0  0  0  0], end state:[ 4  6 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1919, score:[2772.25], loss:[3.08455], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 3 18 24  0  0  0  0  0  0  0  0], end state:[ 5 18 24  0  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1920, score:[2761.75], loss:[2.93176], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 1  6 12  0  0  0  0  0  0  0  0], end state:[ 3  6 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1921, score:[2712.00], loss:[3.12729], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5  0 18  0  0  0  0  0  0  0  0], end state:[ 0  0 18  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1922, score:[2752.50], loss:[3.28123], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 6  9 14  0  0  0  0  0  0  0  0], end state:[ 1  9 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1923, score:[2796.50], loss:[3.27306], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2  6 36  0  0  0  0  0  0  0  0], end state:[ 4  6 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1924, score:[2761.75], loss:[3.10611], sequence:[3], random actions:[23], eInit:[0.0100], init state:[4 7 0 0 0 0 0 0 0 0 0], end state:[6 7 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1925, score:[2673.75], loss:[3.20652], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5 17 27  0  0  0  0  0  0  0  0], end state:[ 0 17 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1926, score:[2708.75], loss:[3.35889], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 12 39  0  0  0  0  0  0  0  0], end state:[ 0 12 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1927, score:[2759.00], loss:[3.43294], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 6  9 29  0  0  0  0  0  0  0  0], end state:[ 1  9 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1928, score:[2738.50], loss:[3.27223], sequence:[2], random actions:[16], eInit:[0.0100], init state:[ 1 22 58  1  0  0  0  0  0  1  1], end state:[ 3 22 58  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1929, score:[2789.50], loss:[3.18435], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1 23 32  1  0  0  1  0  0  1  1], end state:[ 3 23 32  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1930, score:[2664.50], loss:[3.05041], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 4 13 40  0  0  0  0  0  0  0  0], end state:[ 6 13 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1931, score:[2741.25], loss:[3.20365], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6  3 32  0  0  0  0  0  0  0  0], end state:[ 1  3 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1932, score:[2704.50], loss:[3.73010], sequence:[0], random actions:[19], eInit:[0.0100], init state:[ 4  7 51  0  0  0  0  0  0  0  0], end state:[ 6  7 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1933, score:[2697.75], loss:[3.84314], sequence:[0], random actions:[17], eInit:[0.0100], init state:[ 3  3 35  0  0  0  0  0  0  0  0], end state:[ 5  3 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1934, score:[2753.50], loss:[3.55881], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 6  9 40  0  0  0  0  0  0  0  0], end state:[ 1  9 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1935, score:[2680.50], loss:[3.46429], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 4  6 37  0  0  0  0  0  0  0  0], end state:[ 6  6 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1936, score:[2661.50], loss:[3.64052], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 2 22 45  1  0  0  0  0  0  1  1], end state:[ 4 22 45  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1937, score:[2719.50], loss:[4.84408], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 2 15 33  0  0  0  0  0  0  0  0], end state:[ 4 15 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1938, score:[2703.25], loss:[5.47542], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6 13 25  0  0  0  0  0  0  0  0], end state:[ 1 13 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1939, score:[2709.75], loss:[5.31988], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 2 14 12  0  0  0  0  0  0  0  0], end state:[ 4 14 12  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1940, score:[2634.75], loss:[5.67718], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 2 15 19  0  0  0  0  0  0  0  0], end state:[ 4 15 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1941, score:[2727.75], loss:[5.74414], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 2  3 22  0  0  0  0  0  0  0  0], end state:[ 4  3 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1942, score:[2688.75], loss:[5.64341], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 3  5 15  0  0  0  0  0  0  0  0], end state:[ 5  5 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1943, score:[2695.50], loss:[5.64489], sequence:[0], random actions:[28], eInit:[0.0100], init state:[0 1 5 0 0 1 0 0 0 0 0], end state:[2 1 5 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1944, score:[2760.00], loss:[5.43947], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 2 18 28  0  0  0  0  0  0  0  0], end state:[ 4 18 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1945, score:[2792.25], loss:[5.49165], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 6  9 40  0  0  0  0  0  0  0  0], end state:[ 1  9 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1946, score:[2809.50], loss:[5.42091], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 6  8 41  1  1  0  1  0  1  0  0], end state:[ 1  8 41  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1947, score:[2784.75], loss:[5.50877], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 2 22 51  1  0  0  0  0  0  1  1], end state:[ 4 22 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1948, score:[2679.75], loss:[5.50197], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 4 21 39  0  0  0  0  0  0  0  0], end state:[ 6 21 39  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1949, score:[2733.25], loss:[5.39615], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5 13  0  0  0  0  0  0  0  0  0], end state:[ 0 13  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1950, score:[2784.75], loss:[5.00161], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6  8 51  1  1  0  0  0  0  0  0], end state:[ 1  8 51  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1951, score:[2699.25], loss:[4.85236], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 17 56  0  0  0  0  0  0  0  0], end state:[ 5 17 56  0  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1952, score:[2764.25], loss:[3.68263], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 5  1 53  0  0  0  0  0  0  0  0], end state:[ 0  1 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1953, score:[2754.00], loss:[3.51514], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 4 20 31  0  0  0  0  0  0  0  0], end state:[ 6 20 31  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1954, score:[2689.75], loss:[3.72997], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 6 13 31  0  0  0  0  0  0  0  0], end state:[ 1 13 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1955, score:[2768.75], loss:[3.47872], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 1 22 56  1  0  0  0  0  0  1  1], end state:[ 3 22 56  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1956, score:[2745.75], loss:[3.42632], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 2  4 59  0  0  0  0  0  0  0  0], end state:[ 4  4 59  0  1  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1957, score:[2745.50], loss:[3.36938], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 1 12 13  0  0  0  0  0  0  0  0], end state:[ 3 12 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1958, score:[2758.25], loss:[3.17697], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 6 22  1  1  0  0  0  0  0  1  1], end state:[ 1 22  1  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1959, score:[2699.50], loss:[3.17357], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6 15 28  0  0  0  0  0  0  0  0], end state:[ 1 15 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1960, score:[2790.00], loss:[3.01464], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 5 19  6  1  0  0  1  1  0  0  0], end state:[ 0 19  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1961, score:[2682.25], loss:[3.17669], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 10  6  1  1  0  1  0  0  0  0], end state:[ 6 10  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1962, score:[2793.00], loss:[3.03423], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 1 16 54  0  0  0  0  0  0  0  0], end state:[ 3 16 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1963, score:[2760.75], loss:[3.10415], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 0  0 46  0  0  1  0  0  0  0  0], end state:[ 2  0 46  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1964, score:[2774.00], loss:[3.50578], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 6  3 26  0  0  0  0  0  0  0  0], end state:[ 1  3 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1965, score:[2802.50], loss:[3.10382], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 2  6 13  0  0  0  0  0  0  0  0], end state:[ 4  6 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1966, score:[2800.00], loss:[2.86812], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 1 15 28  0  0  0  0  0  0  0  0], end state:[ 3 15 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1967, score:[2739.50], loss:[2.89120], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 5 17 28  0  0  0  0  0  0  0  0], end state:[ 0 17 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1968, score:[2706.75], loss:[3.11352], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 4  1 39  0  0  0  0  0  0  0  0], end state:[ 6  1 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1969, score:[2806.00], loss:[2.93015], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 4 23 34  0  0  0  0  0  0  0  0], end state:[ 6 23 34  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1970, score:[2761.75], loss:[2.83535], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6 23 20  1  0  0  1  0  0  1  1], end state:[ 1 23 20  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1971, score:[2711.25], loss:[2.61395], sequence:[0], random actions:[31], eInit:[0.0100], init state:[3 4 4 0 0 0 0 0 0 0 0], end state:[5 4 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1972, score:[2738.50], loss:[2.49515], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 4 16 33  0  0  0  0  0  0  0  0], end state:[ 6 16 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1973, score:[2795.75], loss:[2.39966], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 6 23 57  1  0  0  0  0  0  1  1], end state:[ 1 23 57  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1974, score:[2788.50], loss:[2.26141], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 1  5 37  0  0  0  0  0  0  0  0], end state:[ 3  5 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1975, score:[2798.00], loss:[2.37077], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 2 13  1  0  0  0  0  0  0  0  0], end state:[ 4 13  1  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1976, score:[2801.00], loss:[2.35376], sequence:[5], random actions:[21], eInit:[0.0100], init state:[ 0  1 27  0  0  0  0  0  0  0  0], end state:[ 2  1 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1977, score:[2798.25], loss:[2.34634], sequence:[6], random actions:[23], eInit:[0.0100], init state:[ 1  0 55  0  0  1  0  0  0  0  0], end state:[ 3  0 55  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1978, score:[2754.00], loss:[2.71220], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 3 10  2  0  0  0  0  0  0  0  0], end state:[ 5 10  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1979, score:[2711.75], loss:[3.04057], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  6 37  0  0  0  0  0  0  0  0], end state:[ 0  6 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1980, score:[2743.00], loss:[3.18640], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4 23 26  0  0  0  0  0  0  0  0], end state:[ 6 23 26  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1981, score:[2778.25], loss:[3.18712], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 4 14 30  0  0  0  0  0  0  0  0], end state:[ 6 14 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1982, score:[2753.50], loss:[3.32901], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 3 10 30  0  0  0  0  0  0  0  0], end state:[ 5 10 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1983, score:[2761.00], loss:[3.13614], sequence:[4], random actions:[37], eInit:[0.0100], init state:[2 1 5 0 0 1 0 0 0 0 0], end state:[4 1 5 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1984, score:[2810.00], loss:[2.96218], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 2  9 51  0  0  0  0  0  0  0  0], end state:[ 4  9 51  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1985, score:[2791.25], loss:[2.87901], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 0 14  3  0  0  0  0  0  0  0  0], end state:[ 2 14  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1986, score:[2795.75], loss:[2.85816], sequence:[7], random actions:[36], eInit:[0.0100], init state:[ 0  3 42  0  0  0  0  0  0  0  0], end state:[ 2  3 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1987, score:[2784.00], loss:[2.73044], sequence:[8], random actions:[29], eInit:[0.0100], init state:[ 2  0 19  1  0  0  0  0  1  0  0], end state:[ 4  0 19  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1988, score:[2667.25], loss:[2.96223], sequence:[0], random actions:[30], eInit:[0.0100], init state:[4 9 3 0 0 0 0 0 0 0 0], end state:[6 9 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1989, score:[2699.50], loss:[3.08870], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 12 11  0  0  0  0  0  0  0  0], end state:[ 0 12 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1990, score:[2743.75], loss:[3.27550], sequence:[1], random actions:[17], eInit:[0.0100], init state:[ 4 23 44  0  0  0  0  0  0  0  0], end state:[ 6 23 44  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 1991, score:[2782.50], loss:[3.21911], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 6  2 19  0  0  0  0  0  0  0  0], end state:[ 1  2 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1992, score:[2758.25], loss:[3.07338], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 2 16 43  0  0  0  0  0  0  0  0], end state:[ 4 16 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1993, score:[2778.75], loss:[3.02062], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 5 17 10  0  0  0  0  0  0  0  0], end state:[ 0 17 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1994, score:[2793.75], loss:[3.03208], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 0 21 25  1  1  0  1  0  0  1  1], end state:[ 2 21 25  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1995, score:[2752.50], loss:[3.00728], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 4 18 22  0  0  0  0  0  0  0  0], end state:[ 6 18 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1996, score:[2758.00], loss:[2.82442], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 2 23 12  1  0  0  0  0  0  1  1], end state:[ 4 23 12  1  1  1  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1997, score:[2798.50], loss:[2.67290], sequence:[8], random actions:[23], eInit:[0.0100], init state:[ 1  8 25  1  0  0  0  0  0  0  0], end state:[ 3  8 25  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1998, score:[2797.50], loss:[2.48672], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 2 17 25  0  0  0  0  0  0  0  0], end state:[ 4 17 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1999, score:[2752.75], loss:[2.47976], sequence:[10], random actions:[33], eInit:[0.0100], init state:[ 2 19 18  0  0  0  0  0  0  0  0], end state:[ 4 19 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2000, score:[2741.25], loss:[2.79208], sequence:[11], random actions:[36], eInit:[0.0100], init state:[ 2 12 26  0  0  0  0  0  0  0  0], end state:[ 4 12 26  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2001, score:[2778.75], loss:[2.97240], sequence:[12], random actions:[30], eInit:[0.0100], init state:[ 6 21 41  1  0  0  0  0  0  1  1], end state:[ 1 21 41  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2002, score:[2775.00], loss:[2.85384], sequence:[13], random actions:[26], eInit:[0.0100], init state:[ 2  4 54  0  0  0  0  0  0  0  0], end state:[ 4  4 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2003, score:[2791.00], loss:[2.50759], sequence:[14], random actions:[22], eInit:[0.0100], init state:[ 4 10 46  1  1  0  1  0  0  0  0], end state:[ 6 10 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2004, score:[2791.00], loss:[2.51045], sequence:[15], random actions:[22], eInit:[0.0100], init state:[ 2 18 17  0  0  0  0  0  0  0  0], end state:[ 4 18 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2005, score:[2718.50], loss:[2.93651], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 6  8 27  1  0  0  0  0  0  0  0], end state:[ 1  8 27  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2006, score:[2712.75], loss:[2.82682], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6 11 48  0  0  0  0  0  0  0  0], end state:[ 1 11 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2007, score:[2749.50], loss:[2.52261], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 2 13 27  0  0  0  0  0  0  0  0], end state:[ 4 13 27  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2008, score:[2692.00], loss:[2.58063], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  8 45  1  1  0  0  0  0  0  0], end state:[ 1  8 45  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2009, score:[2756.50], loss:[2.68512], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 3 10 28  0  0  0  0  0  0  0  0], end state:[ 5 10 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2010, score:[2757.00], loss:[2.63765], sequence:[2], random actions:[29], eInit:[0.0100], init state:[6 7 9 0 0 0 0 0 0 0 0], end state:[1 7 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2011, score:[2779.50], loss:[2.62464], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 0  9 56  0  0  0  0  0  0  0  0], end state:[ 2  9 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2012, score:[2733.50], loss:[2.47374], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 1 10 48  0  0  0  0  0  0  0  0], end state:[ 3 10 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2013, score:[2805.25], loss:[2.54313], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 3 16 35  0  0  0  0  0  0  0  0], end state:[ 5 16 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2014, score:[2755.25], loss:[2.46309], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 6  6 19  0  0  0  0  0  0  0  0], end state:[ 1  6 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2015, score:[2738.00], loss:[2.82412], sequence:[3], random actions:[34], eInit:[0.0100], init state:[0 6 5 0 0 0 0 0 0 0 0], end state:[2 6 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2016, score:[2778.50], loss:[2.96437], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 2  6 59  0  0  0  0  0  0  0  0], end state:[ 4  6 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2017, score:[2702.75], loss:[3.06326], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4  8 12  0  0  0  0  0  0  0  0], end state:[ 6  8 12  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2018, score:[2732.25], loss:[3.27718], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 10 30  1  1  0  1  0  0  0  0], end state:[ 6 10 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2019, score:[2729.50], loss:[3.34284], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6  2 28  0  0  0  0  0  0  0  0], end state:[ 1  2 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2020, score:[2620.50], loss:[3.47105], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 5 22 34  1  0  0  1  0  0  1  1], end state:[ 0 22 34  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2021, score:[2806.00], loss:[3.47927], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 17  3  0  0  0  0  0  0  0  0], end state:[ 3 17  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2022, score:[2734.00], loss:[3.32011], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 10  3  0  0  0  0  0  0  0  0], end state:[ 5 10  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2023, score:[2746.75], loss:[3.36867], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6  0 40  0  0  1  0  0  0  0  0], end state:[ 1  0 40  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2024, score:[2757.25], loss:[3.45314], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0  9 54  0  0  0  0  0  0  0  0], end state:[ 2  9 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2025, score:[2712.75], loss:[3.50854], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 2 12 58  0  0  0  0  0  0  0  0], end state:[ 4 12 58  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2026, score:[2757.25], loss:[3.52371], sequence:[1], random actions:[26], eInit:[0.0100], init state:[6 9 3 0 0 0 0 0 0 0 0], end state:[1 9 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2027, score:[2798.75], loss:[3.24990], sequence:[2], random actions:[30], eInit:[0.0100], init state:[0 7 8 0 0 0 0 0 0 0 0], end state:[2 7 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2028, score:[2753.00], loss:[3.45411], sequence:[3], random actions:[33], eInit:[0.0100], init state:[3 2 6 0 0 0 0 0 0 0 0], end state:[5 2 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2029, score:[2811.75], loss:[3.46478], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 0 11 55  0  0  0  0  0  0  0  0], end state:[ 2 11 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2030, score:[2799.00], loss:[3.20814], sequence:[5], random actions:[23], eInit:[0.0100], init state:[ 2 22 10  1  0  0  0  0  0  1  1], end state:[ 4 22 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2031, score:[2742.25], loss:[3.13965], sequence:[6], random actions:[23], eInit:[0.0100], init state:[ 5 17 24  0  0  0  0  0  0  0  0], end state:[ 0 17 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2032, score:[2780.50], loss:[2.91719], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 6  2 19  0  0  0  0  0  0  0  0], end state:[ 1  2 19  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2033, score:[2829.50], loss:[2.63885], sequence:[8], random actions:[24], eInit:[0.0100], init state:[0 3 7 0 0 0 0 0 0 0 0], end state:[2 3 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2034, score:[2815.25], loss:[2.58535], sequence:[9], random actions:[31], eInit:[0.0100], init state:[ 0 16  6  0  0  0  0  0  0  0  0], end state:[ 2 16  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2035, score:[2615.50], loss:[2.83160], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 4  6 11  0  0  0  0  0  0  0  0], end state:[ 6  6 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2036, score:[2715.75], loss:[2.67238], sequence:[0], random actions:[20], eInit:[0.0100], init state:[ 4  1 43  0  0  0  0  0  0  0  0], end state:[ 6  1 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2037, score:[2761.50], loss:[2.85248], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3  4 37  0  0  0  0  0  0  0  0], end state:[ 5  4 37  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2038, score:[2770.75], loss:[2.90038], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0 20  0  0  0  0  0  0  0  0  0], end state:[ 2 20  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2039, score:[2751.50], loss:[2.70698], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 3  0 49  0  0  1  0  0  0  0  0], end state:[ 5  0 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2040, score:[2734.00], loss:[2.77317], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 5 11 11  0  0  0  0  0  0  0  0], end state:[ 0 11 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2041, score:[2695.75], loss:[2.62001], sequence:[0], random actions:[18], eInit:[0.0100], init state:[5 7 0 0 0 0 0 0 0 0 0], end state:[0 7 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2042, score:[2771.00], loss:[2.53135], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4 20 30  0  0  0  0  0  0  0  0], end state:[ 6 20 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2043, score:[2788.00], loss:[2.43398], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1 21 40  1  0  0  0  0  0  1  1], end state:[ 3 21 40  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2044, score:[2773.25], loss:[2.27339], sequence:[3], random actions:[36], eInit:[0.0100], init state:[1 5 1 0 0 0 0 0 0 0 0], end state:[3 5 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2045, score:[2733.50], loss:[2.68349], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 11  5  0  0  0  0  0  0  0  0], end state:[ 0 11  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2046, score:[2741.00], loss:[2.45522], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 6  1 56  0  0  0  0  0  0  0  0], end state:[ 1  1 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2047, score:[2718.75], loss:[2.80681], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  6 46  0  0  0  0  0  0  0  0], end state:[ 0  6 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2048, score:[2774.00], loss:[2.73721], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  1 15  0  0  0  0  0  0  0  0], end state:[ 3  1 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2049, score:[2766.50], loss:[2.67585], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 4 13  5  1  1  0  1  0  0  0  0], end state:[ 6 13  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2050, score:[2772.00], loss:[2.73043], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 2 17 37  0  0  0  0  0  0  0  0], end state:[ 4 17 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2051, score:[2803.50], loss:[2.59565], sequence:[4], random actions:[20], eInit:[0.0100], init state:[ 2 12 27  0  0  0  0  0  0  0  0], end state:[ 4 12 27  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2052, score:[2789.50], loss:[2.67843], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 2  7 52  0  0  0  0  0  0  0  0], end state:[ 4  7 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2053, score:[2774.25], loss:[2.55795], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 0 20 16  0  0  0  0  0  0  0  0], end state:[ 2 20 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2054, score:[2757.00], loss:[2.83011], sequence:[7], random actions:[33], eInit:[0.0100], init state:[ 6  9 11  0  0  0  0  0  0  0  0], end state:[ 1  9 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2055, score:[2772.50], loss:[2.89940], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 3  7 29  0  0  0  0  0  0  0  0], end state:[ 5  7 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2056, score:[2738.75], loss:[3.01312], sequence:[9], random actions:[27], eInit:[0.0100], init state:[ 2 17 56  0  0  0  0  0  0  0  0], end state:[ 4 17 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2057, score:[2757.00], loss:[2.92162], sequence:[10], random actions:[26], eInit:[0.0100], init state:[4 2 6 0 0 0 0 0 0 0 0], end state:[6 2 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2058, score:[2783.50], loss:[3.00318], sequence:[11], random actions:[31], eInit:[0.0100], init state:[ 6 18 40  0  0  0  0  0  0  0  0], end state:[ 1 18 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2059, score:[2718.75], loss:[2.94218], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 3 17 31  0  0  0  0  0  0  0  0], end state:[ 5 17 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2060, score:[2806.00], loss:[2.94690], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 14 48  0  0  0  0  0  0  0  0], end state:[ 3 14 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2061, score:[2700.00], loss:[3.07359], sequence:[0], random actions:[27], eInit:[0.0100], init state:[5 9 4 0 0 0 0 0 0 0 0], end state:[0 9 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2062, score:[2759.00], loss:[3.26752], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 3 16 31  0  0  0  0  0  0  0  0], end state:[ 5 16 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2063, score:[2804.25], loss:[2.84447], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2  6 20  0  0  0  0  0  0  0  0], end state:[ 4  6 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2064, score:[2710.50], loss:[3.17538], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5  7 49  0  0  0  0  0  0  0  0], end state:[ 0  7 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2065, score:[2719.50], loss:[3.22528], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 12  9  1  1  0  0  0  0  0  0], end state:[ 6 12  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2066, score:[2744.50], loss:[3.56773], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 3 20 33  1  1  0  0  0  0  0  0], end state:[ 5 20 33  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2067, score:[2816.50], loss:[3.20477], sequence:[2], random actions:[19], eInit:[0.0100], init state:[ 3 17 48  0  0  0  0  0  0  0  0], end state:[ 5 17 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2068, score:[2735.50], loss:[3.26918], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 2 12  9  0  0  0  0  0  0  0  0], end state:[ 4 12  9  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2069, score:[2744.75], loss:[3.32034], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 5 22 46  1  0  0  1  0  0  1  1], end state:[ 0 22 46  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2070, score:[2717.25], loss:[3.89217], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 5 12 22  0  0  0  0  0  0  0  0], end state:[ 0 12 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2071, score:[2741.75], loss:[3.70810], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 4 11 55  1  1  0  0  0  0  0  0], end state:[ 6 11 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2072, score:[2781.50], loss:[3.65120], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 3 13  2  0  0  0  0  0  0  0  0], end state:[ 5 13  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2073, score:[2692.50], loss:[3.81973], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 23 17  0  0  0  0  0  0  0  0], end state:[ 6 23 17  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2074, score:[2675.75], loss:[4.04186], sequence:[0], random actions:[35], eInit:[0.0100], init state:[4 3 4 0 0 0 0 0 0 0 0], end state:[6 3 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2075, score:[2772.75], loss:[3.76437], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1 19 47  0  0  0  0  0  0  0  0], end state:[ 3 19 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2076, score:[2691.25], loss:[3.81511], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3 23 55  1  0  0  0  0  0  1  1], end state:[ 5 23 55  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2077, score:[2718.75], loss:[3.88313], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  0 17  0  0  0  0  0  0  0  0], end state:[ 0  0 17  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2078, score:[2764.75], loss:[3.86446], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 2 23 30  1  0  0  1  0  0  1  1], end state:[ 4 23 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2079, score:[2802.00], loss:[3.68165], sequence:[2], random actions:[22], eInit:[0.0100], init state:[0 8 8 1 0 0 0 0 0 0 0], end state:[2 8 8 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2080, score:[2722.00], loss:[3.86011], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 1  8 49  1  1  0  0  0  0  0  0], end state:[ 3  8 49  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2081, score:[2750.25], loss:[4.07508], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 6 16 36  0  0  0  0  0  0  0  0], end state:[ 1 16 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2082, score:[2767.50], loss:[3.66237], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 1 13 37  0  0  0  0  0  0  0  0], end state:[ 3 13 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2083, score:[2801.25], loss:[3.44484], sequence:[3], random actions:[22], eInit:[0.0100], init state:[2 9 2 0 0 0 0 0 0 0 0], end state:[4 9 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2084, score:[2590.75], loss:[3.69999], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 6 10 46  0  0  0  0  0  0  0  0], end state:[ 1 10 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2085, score:[2765.00], loss:[3.73777], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 0 13 23  0  0  0  0  0  0  0  0], end state:[ 2 13 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2086, score:[2680.50], loss:[4.10678], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 6 20 38  1  1  0  0  0  0  0  0], end state:[ 1 20 38  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2087, score:[2674.00], loss:[3.88923], sequence:[0], random actions:[27], eInit:[0.0100], init state:[5 9 7 0 0 0 0 0 0 0 0], end state:[0 9 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2088, score:[2821.50], loss:[3.58108], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1 14 41  0  0  0  0  0  0  0  0], end state:[ 3 14 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2089, score:[2797.50], loss:[3.56292], sequence:[2], random actions:[30], eInit:[0.0100], init state:[2 4 4 0 0 0 0 0 0 0 0], end state:[4 4 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2090, score:[2780.25], loss:[3.71301], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 3  2 39  0  0  0  0  0  0  0  0], end state:[ 5  2 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2091, score:[2742.25], loss:[3.53122], sequence:[4], random actions:[40], eInit:[0.0100], init state:[ 2 12 28  0  0  0  0  0  0  0  0], end state:[ 4 12 28  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2092, score:[2763.50], loss:[3.66348], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 4  6 30  0  0  0  0  0  0  0  0], end state:[ 6  6 30  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2093, score:[2784.75], loss:[3.71667], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 0  8 47  1  1  0  0  0  0  0  0], end state:[ 2  8 47  0  0  0  1  0  1  0  1]
INFO:Reinforcement.Functions:episode: 2094, score:[2784.25], loss:[3.52450], sequence:[7], random actions:[22], eInit:[0.0100], init state:[ 6  1 10  0  0  0  0  0  0  0  0], end state:[ 1  1 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2095, score:[2766.00], loss:[3.39078], sequence:[8], random actions:[40], eInit:[0.0100], init state:[2 3 9 0 0 0 0 0 0 0 0], end state:[4 3 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2096, score:[2815.25], loss:[3.36251], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 0 23  8  1  0  0  0  0  0  1  1], end state:[ 2 23  8  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2097, score:[2778.00], loss:[3.10636], sequence:[10], random actions:[23], eInit:[0.0100], init state:[ 2 13 39  0  0  0  0  0  0  0  0], end state:[ 4 13 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2098, score:[2725.50], loss:[3.28487], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4  8 35  0  0  0  0  0  0  0  0], end state:[ 6  8 35  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2099, score:[2771.75], loss:[3.55402], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 1 23 15  1  0  0  1  0  0  1  1], end state:[ 3 23 15  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2100, score:[2780.25], loss:[3.67404], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 6 10 54  0  0  0  0  0  0  0  0], end state:[ 1 10 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2101, score:[2732.00], loss:[3.64065], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 3 11 16  0  0  0  0  0  0  0  0], end state:[ 5 11 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2102, score:[2738.75], loss:[3.51304], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 3  5 15  0  0  0  0  0  0  0  0], end state:[ 5  5 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2103, score:[2715.75], loss:[3.53937], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 4  6 11  0  0  0  0  0  0  0  0], end state:[ 6  6 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2104, score:[2794.25], loss:[3.30093], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0  0 41  0  0  1  0  0  0  0  0], end state:[ 2  0 41  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2105, score:[2827.75], loss:[3.01048], sequence:[2], random actions:[17], eInit:[0.0100], init state:[ 1 15 24  0  0  0  0  0  0  0  0], end state:[ 3 15 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2106, score:[2779.50], loss:[3.18943], sequence:[3], random actions:[20], eInit:[0.0100], init state:[ 5 17 54  0  0  0  0  0  0  0  0], end state:[ 0 17 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2107, score:[2802.00], loss:[2.98469], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 1 22 51  1  0  0  0  0  0  1  1], end state:[ 3 22 51  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2108, score:[2755.00], loss:[3.02120], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 6 11  5  0  0  0  0  0  0  0  0], end state:[ 1 11  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2109, score:[2744.00], loss:[2.87470], sequence:[6], random actions:[33], eInit:[0.0100], init state:[ 3  4 16  0  0  0  0  0  0  0  0], end state:[ 5  4 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2110, score:[2752.50], loss:[2.96124], sequence:[7], random actions:[35], eInit:[0.0100], init state:[ 1 11 38  0  0  0  0  0  0  0  0], end state:[ 3 11 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2111, score:[2797.25], loss:[2.74852], sequence:[8], random actions:[27], eInit:[0.0100], init state:[2 0 0 1 0 0 0 0 0 1 1], end state:[4 0 0 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 2112, score:[2684.50], loss:[2.93213], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 19  6  1  0  0  1  1  0  0  0], end state:[ 0 19  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2113, score:[2742.25], loss:[3.13591], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 5 15 35  0  0  0  0  0  0  0  0], end state:[ 0 15 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2114, score:[2756.00], loss:[3.20286], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 1 17 57  0  0  0  0  0  0  0  0], end state:[ 3 17 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2115, score:[2750.75], loss:[3.15061], sequence:[3], random actions:[40], eInit:[0.0100], init state:[ 1  1 21  0  0  0  0  0  0  0  0], end state:[ 3  1 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2116, score:[2686.75], loss:[3.26220], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 20 35  1  0  0  0  0  0  0  0], end state:[ 0 20 35  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2117, score:[2829.50], loss:[3.09188], sequence:[1], random actions:[18], eInit:[0.0100], init state:[ 1 13 56  0  0  0  0  0  0  0  0], end state:[ 3 13 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2118, score:[2790.75], loss:[3.06332], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 1 22 47  1  0  0  0  0  0  1  1], end state:[ 3 22 47  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2119, score:[2715.75], loss:[2.93458], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 23 44  1  0  0  1  0  0  1  1], end state:[ 5 23 44  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2120, score:[2815.75], loss:[2.88250], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 19 27  0  0  0  0  0  0  0  0], end state:[ 3 19 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2121, score:[2766.50], loss:[2.90723], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0 15 46  0  0  0  0  0  0  0  0], end state:[ 2 15 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2122, score:[2752.00], loss:[2.92433], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 3  4 11  0  0  0  0  0  0  0  0], end state:[ 5  4 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2123, score:[2717.75], loss:[3.32873], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 13 49  0  0  0  0  0  0  0  0], end state:[ 6 13 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2124, score:[2661.00], loss:[3.41849], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 3 17 43  0  0  0  0  0  0  0  0], end state:[ 5 17 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2125, score:[2735.25], loss:[3.35695], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4  5 36  0  0  0  0  0  0  0  0], end state:[ 6  5 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2126, score:[2739.25], loss:[3.27479], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6 14 52  0  0  0  0  0  0  0  0], end state:[ 1 14 52  0  0  0  1  0  0  0  1]
INFO:Reinforcement.Functions:episode: 2127, score:[2771.75], loss:[3.23181], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 22 11  1  0  0  0  0  0  1  1], end state:[ 4 22 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2128, score:[2746.25], loss:[3.51014], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 1 20 38  1  1  0  0  0  0  0  0], end state:[ 3 20 38  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2129, score:[2795.75], loss:[3.28034], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 6 20  6  0  0  0  0  0  0  0  0], end state:[ 1 20  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2130, score:[2650.50], loss:[3.36822], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 12 57  0  0  0  0  0  0  0  0], end state:[ 0 12 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2131, score:[2747.75], loss:[3.33842], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 6 19 58  0  0  0  0  0  0  0  0], end state:[ 1 19 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2132, score:[2666.50], loss:[3.42187], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4  4 11  0  0  0  0  0  0  0  0], end state:[ 6  4 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2133, score:[2765.25], loss:[3.39782], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 0  6 41  0  0  0  0  0  0  0  0], end state:[ 2  6 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2134, score:[2618.50], loss:[3.32795], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4  8 29  0  0  0  0  0  0  0  0], end state:[ 6  8 29  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2135, score:[2733.25], loss:[3.54130], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 21 31  1  0  0  0  0  0  1  1], end state:[ 5 21 31  1  0  0  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 2136, score:[2801.75], loss:[3.58778], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1 17 54  0  0  0  0  0  0  0  0], end state:[ 3 17 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2137, score:[2705.75], loss:[3.40777], sequence:[0], random actions:[33], eInit:[0.0100], init state:[1 0 0 1 0 0 0 0 0 1 1], end state:[3 0 0 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 2138, score:[2818.00], loss:[3.39763], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1 20 22  0  0  0  0  0  0  0  0], end state:[ 3 20 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2139, score:[2771.25], loss:[3.24076], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 1  0 27  1  0  0  0  0  0  0  0], end state:[ 3  0 27  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2140, score:[2794.00], loss:[3.34852], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 2  5 35  0  0  0  0  0  0  0  0], end state:[ 4  5 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2141, score:[2759.75], loss:[3.20198], sequence:[4], random actions:[38], eInit:[0.0100], init state:[ 0 13  5  0  0  0  0  0  0  0  0], end state:[ 2 13  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2142, score:[2721.75], loss:[3.19349], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 23 26  0  0  0  0  0  0  0  0], end state:[ 6 23 26  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2143, score:[2792.25], loss:[3.09736], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 3  4 39  0  0  0  0  0  0  0  0], end state:[ 5  4 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2144, score:[2763.00], loss:[3.12577], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 18 23  0  0  0  0  0  0  0  0], end state:[ 4 18 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2145, score:[2790.75], loss:[3.09741], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 3 18 33  0  0  0  0  0  0  0  0], end state:[ 5 18 33  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2146, score:[2782.75], loss:[3.10249], sequence:[4], random actions:[29], eInit:[0.0100], init state:[3 6 0 0 0 0 0 0 0 0 0], end state:[5 6 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2147, score:[2783.00], loss:[2.99805], sequence:[5], random actions:[23], eInit:[0.0100], init state:[4 6 6 0 0 0 0 0 0 0 0], end state:[6 6 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2148, score:[2723.00], loss:[2.79853], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 2 14 29  0  0  0  0  0  0  0  0], end state:[ 4 14 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2149, score:[2802.25], loss:[2.89626], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0  9 53  0  0  0  0  0  0  0  0], end state:[ 2  9 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2150, score:[2813.00], loss:[2.64358], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 3  8 28  1  0  0  0  0  0  0  0], end state:[ 5  8 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2151, score:[2822.75], loss:[2.55047], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 2 10  6  0  0  0  0  0  0  0  0], end state:[ 4 10  6  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2152, score:[2792.00], loss:[2.32601], sequence:[4], random actions:[8], eInit:[0.0100], init state:[ 1 10 48  0  0  0  0  0  0  0  0], end state:[ 3 10 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2153, score:[2724.00], loss:[2.43517], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6 21  1  1  1  0  1  0  0  1  1], end state:[ 1 21  1  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2154, score:[2617.00], loss:[3.07251], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 17  8  0  0  0  0  0  0  0  0], end state:[ 0 17  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2155, score:[2721.75], loss:[2.93618], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 14 21  0  0  0  0  0  0  0  0], end state:[ 6 14 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2156, score:[2719.50], loss:[2.94685], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 4 10 27  1  1  0  1  0  1  0  0], end state:[ 6 10 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2157, score:[2704.50], loss:[3.16156], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 6 17 41  0  0  0  0  0  0  0  0], end state:[ 1 17 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2158, score:[2786.75], loss:[2.90868], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 3 15 32  0  0  0  0  0  0  0  0], end state:[ 5 15 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2159, score:[2788.00], loss:[2.84129], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 3  6 40  0  0  0  0  0  0  0  0], end state:[ 5  6 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2160, score:[2743.50], loss:[2.85974], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 0  2 15  0  0  0  0  0  0  0  0], end state:[ 2  2 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2161, score:[2727.50], loss:[2.92741], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6  8 38  1  1  0  1  0  1  0  0], end state:[ 1  8 38  1  0  1  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 2162, score:[2746.00], loss:[2.90953], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2 23 13  1  0  0  0  0  0  1  1], end state:[ 4 23 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2163, score:[2776.00], loss:[3.05490], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 0 12 46  0  0  0  0  0  0  0  0], end state:[ 2 12 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2164, score:[2785.75], loss:[3.00984], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 3 17 28  0  0  0  0  0  0  0  0], end state:[ 5 17 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2165, score:[2795.25], loss:[2.73906], sequence:[4], random actions:[19], eInit:[0.0100], init state:[ 0  1 49  0  0  0  0  0  0  0  0], end state:[ 2  1 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2166, score:[2693.00], loss:[2.80650], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4 14 30  0  0  0  0  0  0  0  0], end state:[ 6 14 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2167, score:[2669.75], loss:[2.85636], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 4 11 15  1  1  0  0  0  0  0  0], end state:[ 6 11 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2168, score:[2781.75], loss:[3.14744], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 2  9 32  0  0  0  0  0  0  0  0], end state:[ 4  9 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2169, score:[2748.25], loss:[3.48351], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 3 17 44  0  0  0  0  0  0  0  0], end state:[ 5 17 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2170, score:[2762.00], loss:[3.23741], sequence:[3], random actions:[39], eInit:[0.0100], init state:[ 2  2 25  0  0  0  0  0  0  0  0], end state:[ 4  2 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2171, score:[2752.50], loss:[3.40018], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 2 20 43  1  1  0  0  0  0  1  1], end state:[ 4 20 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2172, score:[2758.50], loss:[3.24319], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 2  6 11  0  0  0  0  0  0  0  0], end state:[ 4  6 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2173, score:[2747.75], loss:[3.18539], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 5  0 58  0  0  0  0  0  0  0  0], end state:[ 0  0 58  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2174, score:[2738.00], loss:[3.32098], sequence:[7], random actions:[34], eInit:[0.0100], init state:[5 0 3 0 0 0 0 0 0 0 0], end state:[0 0 3 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:episode: 2175, score:[2717.75], loss:[3.19017], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 2 15 45  0  0  0  0  0  0  0  0], end state:[ 4 15 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2176, score:[2753.25], loss:[3.24568], sequence:[1], random actions:[29], eInit:[0.0100], init state:[1 1 4 0 0 1 0 0 0 0 0], end state:[3 1 4 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2177, score:[2708.50], loss:[3.27119], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 19  8  0  0  0  0  0  0  0  0], end state:[ 6 19  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2178, score:[2725.25], loss:[3.41713], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 0  6 24  0  0  0  0  0  0  0  0], end state:[ 2  6 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2179, score:[2761.50], loss:[3.25826], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 0 17 10  0  0  0  0  0  0  0  0], end state:[ 2 17 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2180, score:[2712.50], loss:[3.36053], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 2 15 59  0  0  0  0  0  0  0  0], end state:[ 4 15 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2181, score:[2778.25], loss:[3.34777], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 1 21 18  1  1  0  1  0  0  1  1], end state:[ 3 21 18  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2182, score:[2817.50], loss:[3.35146], sequence:[2], random actions:[21], eInit:[0.0100], init state:[ 1  0 11  1  0  0  0  0  1  1  1], end state:[ 3  0 11  1  0  0  0  0  1  1  1]
INFO:Reinforcement.Functions:episode: 2183, score:[2777.25], loss:[3.41783], sequence:[3], random actions:[38], eInit:[0.0100], init state:[ 1 22 54  1  0  0  0  0  0  1  1], end state:[ 3 22 54  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2184, score:[2717.75], loss:[3.55594], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 17 57  0  0  0  0  0  0  0  0], end state:[ 0 17 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2185, score:[2785.25], loss:[3.37489], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 0  6 16  0  0  0  0  0  0  0  0], end state:[ 2  6 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2186, score:[2805.00], loss:[3.18660], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 2  7 15  0  0  0  0  0  0  0  0], end state:[ 4  7 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2187, score:[2687.75], loss:[3.18144], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 10 30  0  0  0  0  0  0  0  0], end state:[ 5 10 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2188, score:[2671.50], loss:[3.62891], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 22 35  1  0  0  1  0  0  1  1], end state:[ 0 22 35  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2189, score:[2682.00], loss:[3.47014], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4  2 37  0  0  0  0  0  0  0  0], end state:[ 6  2 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2190, score:[2755.25], loss:[3.48319], sequence:[1], random actions:[28], eInit:[0.0100], init state:[2 0 1 1 0 0 0 0 0 1 1], end state:[4 0 1 1 0 0 0 0 0 1 1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2191, score:[2739.25], loss:[3.34318], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 6 11 32  0  0  0  0  0  0  0  0], end state:[ 1 11 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2192, score:[2779.50], loss:[3.15795], sequence:[3], random actions:[32], eInit:[0.0100], init state:[3 2 5 0 0 0 0 0 0 0 0], end state:[5 2 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2193, score:[2697.50], loss:[2.99708], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4  6 40  0  0  0  0  0  0  0  0], end state:[ 6  6 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2194, score:[2711.25], loss:[2.98151], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4 23 55  0  0  0  0  0  0  0  0], end state:[ 6 23 55  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2195, score:[2765.75], loss:[3.20751], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1  0 41  0  0  1  0  0  0  0  0], end state:[ 3  0 41  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2196, score:[2721.75], loss:[3.06725], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 4  1 22  0  0  0  0  0  0  0  0], end state:[ 6  1 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2197, score:[2669.25], loss:[3.55490], sequence:[0], random actions:[41], eInit:[0.0100], init state:[6 2 8 0 0 0 0 0 0 0 0], end state:[1 2 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2198, score:[2733.50], loss:[3.24903], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 20 54  1  1  0  1  0  0  1  1], end state:[ 5 20 54  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2199, score:[2798.25], loss:[3.10911], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 6 16 45  0  0  0  0  0  0  0  0], end state:[ 1 16 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2200, score:[2791.25], loss:[2.89061], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2 13 30  0  0  0  0  0  0  0  0], end state:[ 4 13 30  0  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2201, score:[2765.00], loss:[2.85551], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 4  2 36  0  0  0  0  0  0  0  0], end state:[ 6  2 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2202, score:[2752.25], loss:[3.11216], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 3 17  6  0  0  0  0  0  0  0  0], end state:[ 5 17  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2203, score:[2660.75], loss:[3.37915], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 5 23 57  1  0  0  0  0  0  1  1], end state:[ 0 23 57  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2204, score:[2745.75], loss:[3.40070], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1 14 46  0  0  0  0  0  0  0  0], end state:[ 3 14 46  0  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2205, score:[2757.75], loss:[3.21767], sequence:[2], random actions:[18], eInit:[0.0100], init state:[ 5 18 13  1  1  0  1  0  0  0  0], end state:[ 0 18 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2206, score:[2772.25], loss:[3.01998], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 1  7 27  0  0  0  0  0  0  0  0], end state:[ 3  7 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2207, score:[2769.75], loss:[3.01142], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 0 23 40  1  0  0  1  0  0  1  1], end state:[ 2 23 40  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2208, score:[2725.00], loss:[3.06676], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 4  6 41  0  0  0  0  0  0  0  0], end state:[ 6  6 41  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2209, score:[2798.25], loss:[3.19186], sequence:[1], random actions:[25], eInit:[0.0100], init state:[3 6 9 0 0 0 0 0 0 0 0], end state:[5 6 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2210, score:[2754.75], loss:[2.98243], sequence:[2], random actions:[37], eInit:[0.0100], init state:[ 4 18  8  0  0  0  0  0  0  0  0], end state:[ 6 18  8  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2211, score:[2784.75], loss:[2.90596], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 4 16 44  0  0  0  0  0  0  0  0], end state:[ 6 16 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2212, score:[2775.75], loss:[2.75333], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 2  2 27  0  0  0  0  0  0  0  0], end state:[ 4  2 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2213, score:[2726.25], loss:[2.93132], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 15 59  0  0  0  0  0  0  0  0], end state:[ 6 15 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2214, score:[2757.75], loss:[2.81906], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4 20 53  0  0  0  0  0  0  0  0], end state:[ 6 20 53  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2215, score:[2766.50], loss:[2.74748], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 2 15 45  0  0  0  0  0  0  0  0], end state:[ 4 15 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2216, score:[2770.75], loss:[2.67586], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 0 12  3  0  0  0  0  0  0  0  0], end state:[ 2 12  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2217, score:[2769.75], loss:[2.85091], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 0 20 54  1  1  0  1  0  0  1  1], end state:[ 2 20 54  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2218, score:[2724.75], loss:[3.06985], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  4 59  0  0  0  0  0  0  0  0], end state:[ 0  4 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2219, score:[2687.00], loss:[3.06582], sequence:[0], random actions:[28], eInit:[0.0100], init state:[5 3 2 0 0 0 0 0 0 0 0], end state:[0 3 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2220, score:[2776.75], loss:[3.24994], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 3 19 39  0  0  0  0  0  0  0  0], end state:[ 5 19 39  0  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2221, score:[2804.00], loss:[3.00059], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 1 21  0  1  1  0  1  0  0  1  1], end state:[ 3 21  0  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2222, score:[2732.25], loss:[3.10105], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 2 14 47  0  0  0  0  0  0  0  0], end state:[ 4 14 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2223, score:[2777.50], loss:[3.15618], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 3  5 37  0  0  0  0  0  0  0  0], end state:[ 5  5 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2224, score:[2678.25], loss:[3.13249], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 5 10 18  0  0  0  0  0  0  0  0], end state:[ 0 10 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2225, score:[2753.00], loss:[3.13998], sequence:[1], random actions:[49], eInit:[0.0100], init state:[0 9 7 0 0 0 0 0 0 0 0], end state:[2 9 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2226, score:[2723.75], loss:[3.25931], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 3 22 13  1  0  0  0  0  0  1  1], end state:[ 5 22 13  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2227, score:[2747.00], loss:[3.23052], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 5 22 44  1  0  0  1  0  0  1  1], end state:[ 0 22 44  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2228, score:[2771.25], loss:[3.09278], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0  8 15  1  0  0  0  0  0  0  0], end state:[ 2  8 15  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2229, score:[2797.50], loss:[2.88028], sequence:[3], random actions:[37], eInit:[0.0100], init state:[2 6 3 0 0 0 0 0 0 0 0], end state:[4 6 3 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2230, score:[2673.25], loss:[2.78547], sequence:[0], random actions:[40], eInit:[0.0100], init state:[3 0 6 1 0 0 0 0 1 1 1], end state:[5 0 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2231, score:[2772.25], loss:[2.80903], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 4  5 46  0  0  0  0  0  0  0  0], end state:[ 6  5 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2232, score:[2675.25], loss:[3.01411], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 17 25  0  0  0  0  0  0  0  0], end state:[ 6 17 25  0  1  0  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2233, score:[2745.75], loss:[3.40433], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 4  5 43  0  0  0  0  0  0  0  0], end state:[ 6  5 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2234, score:[2801.75], loss:[3.18084], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 13 13  0  0  0  0  0  0  0  0], end state:[ 3 13 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2235, score:[2759.50], loss:[2.90265], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 4  3 32  0  0  0  0  0  0  0  0], end state:[ 6  3 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2236, score:[2772.50], loss:[2.73215], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 4  1 40  0  0  0  0  0  0  0  0], end state:[ 6  1 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2237, score:[2740.00], loss:[2.59284], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 5 22 54  1  0  0  1  0  0  1  1], end state:[ 0 22 54  1  0  0  1  0  0  0  1]
INFO:Reinforcement.Functions:episode: 2238, score:[2698.50], loss:[2.87199], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 6  7 27  0  0  0  0  0  0  0  0], end state:[ 1  7 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2239, score:[2770.25], loss:[2.88960], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 4 18 31  0  0  0  0  0  0  0  0], end state:[ 6 18 31  0  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 2240, score:[2717.00], loss:[2.73871], sequence:[0], random actions:[23], eInit:[0.0100], init state:[5 6 9 0 0 0 0 0 0 0 0], end state:[0 6 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2241, score:[2750.00], loss:[2.83034], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3  1 11  0  0  0  0  0  0  0  0], end state:[ 5  1 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2242, score:[2754.25], loss:[2.85912], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 2 13 16  0  0  0  0  0  0  0  0], end state:[ 4 13 16  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2243, score:[2745.25], loss:[2.77397], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 4 23 28  0  0  0  0  0  0  0  0], end state:[ 6 23 28  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2244, score:[2727.50], loss:[2.98900], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3  3 33  0  0  0  0  0  0  0  0], end state:[ 5  3 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2245, score:[2791.00], loss:[2.72905], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 3 12 24  0  0  0  0  0  0  0  0], end state:[ 5 12 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2246, score:[2749.00], loss:[2.92050], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 6 20 57  1  1  0  1  0  0  1  1], end state:[ 1 20 57  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2247, score:[2739.00], loss:[3.04756], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1 10 50  0  0  0  0  0  0  0  0], end state:[ 3 10 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2248, score:[2694.25], loss:[3.34633], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 3 19 30  0  0  0  0  0  0  0  0], end state:[ 5 19 30  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2249, score:[2742.50], loss:[3.17567], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 3  7 20  0  0  0  0  0  0  0  0], end state:[ 5  7 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2250, score:[2790.25], loss:[2.85787], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 4  3 31  0  0  0  0  0  0  0  0], end state:[ 6  3 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2251, score:[2698.50], loss:[3.04573], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 18 30  1  1  0  1  0  0  0  0], end state:[ 0 18 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2252, score:[2700.00], loss:[3.55862], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 6 16 56  0  0  0  0  0  0  0  0], end state:[ 1 16 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2253, score:[2797.00], loss:[3.68961], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0 14  6  0  0  0  0  0  0  0  0], end state:[ 2 14  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2254, score:[2770.75], loss:[3.86195], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 1  5 44  0  0  0  0  0  0  0  0], end state:[ 3  5 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2255, score:[2691.00], loss:[3.83663], sequence:[0], random actions:[42], eInit:[0.0100], init state:[ 4  9 14  0  0  0  0  0  0  0  0], end state:[ 6  9 14  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2256, score:[2719.50], loss:[3.93830], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 3 22 29  1  0  0  0  0  0  1  1], end state:[ 5 22 29  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2257, score:[2776.50], loss:[4.11477], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 1 23 58  1  0  0  0  0  0  1  1], end state:[ 3 23 58  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2258, score:[2767.25], loss:[3.94174], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 6 23 18  1  0  0  1  0  0  1  1], end state:[ 1 23 18  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2259, score:[2737.25], loss:[3.63599], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 4  5 17  0  0  0  0  0  0  0  0], end state:[ 6  5 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2260, score:[2780.00], loss:[3.60537], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 1  8 49  1  1  0  0  0  0  0  0], end state:[ 3  8 49  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2261, score:[2725.25], loss:[3.72106], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  9 52  0  0  0  0  0  0  0  0], end state:[ 0  9 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2262, score:[2768.50], loss:[3.75102], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 3  2 58  0  0  0  0  0  0  0  0], end state:[ 5  2 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2263, score:[2746.25], loss:[3.93621], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 6  2 27  0  0  0  0  0  0  0  0], end state:[ 1  2 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2264, score:[2802.00], loss:[3.80828], sequence:[3], random actions:[26], eInit:[0.0100], init state:[3 1 5 0 0 1 0 0 0 0 0], end state:[5 1 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2265, score:[2745.00], loss:[3.58784], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 6  7 31  0  0  0  0  0  0  0  0], end state:[ 1  7 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2266, score:[2768.25], loss:[3.60538], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 5  4 25  0  0  0  0  0  0  0  0], end state:[ 0  4 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2267, score:[2796.25], loss:[3.55261], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 6  0 18  1  0  0  0  0  1  0  0], end state:[ 1  0 18  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2268, score:[2764.75], loss:[3.35999], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 0  4 44  0  0  0  0  0  0  0  0], end state:[ 2  4 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2269, score:[2751.00], loss:[3.10914], sequence:[8], random actions:[39], eInit:[0.0100], init state:[ 6 22 10  1  0  0  0  0  0  1  1], end state:[ 1 22 10  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2270, score:[2724.00], loss:[3.28360], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  3 29  0  0  0  0  0  0  0  0], end state:[ 0  3 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2271, score:[2732.50], loss:[3.54724], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 23 55  1  0  0  0  0  0  1  1], end state:[ 5 23 55  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2272, score:[2803.75], loss:[4.02604], sequence:[1], random actions:[25], eInit:[0.0100], init state:[3 4 8 0 0 0 0 0 0 0 0], end state:[5 4 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2273, score:[2770.00], loss:[3.74279], sequence:[2], random actions:[20], eInit:[0.0100], init state:[ 1 10  9  0  0  0  0  0  0  0  0], end state:[ 3 10  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2274, score:[2791.00], loss:[3.63869], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 1 19 38  0  0  0  0  0  0  0  0], end state:[ 3 19 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2275, score:[2732.75], loss:[3.59340], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 3 20 15  0  0  0  0  0  0  0  0], end state:[ 5 20 15  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2276, score:[2685.00], loss:[4.09824], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 15  2  0  0  0  0  0  0  0  0], end state:[ 0 15  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2277, score:[2780.00], loss:[4.13989], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 2  9 16  0  0  0  0  0  0  0  0], end state:[ 4  9 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2278, score:[2763.00], loss:[3.96299], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 4  3 34  0  0  0  0  0  0  0  0], end state:[ 6  3 34  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2279, score:[2813.00], loss:[3.78749], sequence:[3], random actions:[30], eInit:[0.0100], init state:[0 3 5 0 0 0 0 0 0 0 0], end state:[2 3 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2280, score:[2758.00], loss:[3.73607], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 1 23  9  1  0  0  0  0  0  1  1], end state:[ 3 23  9  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2281, score:[2799.00], loss:[3.64312], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 4 16 49  0  0  0  0  0  0  0  0], end state:[ 6 16 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2282, score:[2782.75], loss:[3.60942], sequence:[6], random actions:[35], eInit:[0.0100], init state:[ 2 22 40  1  0  0  0  0  0  1  1], end state:[ 4 22 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2283, score:[2801.75], loss:[3.57745], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 5  2 58  0  0  0  0  0  0  0  0], end state:[ 0  2 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2284, score:[2699.75], loss:[3.53313], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3  9 34  0  0  0  0  0  0  0  0], end state:[ 5  9 34  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2285, score:[2809.00], loss:[3.46159], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 2 21 29  1  1  0  1  0  0  1  1], end state:[ 4 21 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2286, score:[2779.00], loss:[3.39243], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 4  7 51  0  0  0  0  0  0  0  0], end state:[ 6  7 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2287, score:[2795.25], loss:[3.38424], sequence:[3], random actions:[20], eInit:[0.0100], init state:[5 9 5 0 0 0 0 0 0 0 0], end state:[0 9 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2288, score:[2744.25], loss:[3.24793], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2  4 45  0  0  0  0  0  0  0  0], end state:[ 4  4 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2289, score:[2802.25], loss:[2.84608], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 0  5 39  0  0  0  0  0  0  0  0], end state:[ 2  5 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2290, score:[2798.00], loss:[2.60060], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 1 14 58  0  0  0  0  0  0  0  0], end state:[ 3 14 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2291, score:[2801.25], loss:[2.51015], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 1  6 38  0  0  0  0  0  0  0  0], end state:[ 3  6 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2292, score:[2739.25], loss:[2.48393], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 6 13 37  0  0  0  0  0  0  0  0], end state:[ 1 13 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2293, score:[2717.75], loss:[2.55348], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 18 59  1  1  0  1  0  0  0  0], end state:[ 0 18 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2294, score:[2755.00], loss:[2.52151], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 4 23  4  0  0  0  0  0  0  0  0], end state:[ 6 23  4  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2295, score:[2817.50], loss:[2.35468], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 2 10  6  0  0  0  0  0  0  0  0], end state:[ 4 10  6  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2296, score:[2760.75], loss:[2.27869], sequence:[3], random actions:[32], eInit:[0.0100], init state:[3 1 6 0 0 1 0 0 0 0 0], end state:[5 1 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2297, score:[2811.75], loss:[2.35222], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 3 16  1  0  0  0  0  0  0  0  0], end state:[ 5 16  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2298, score:[2785.00], loss:[2.36705], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 0 18 28  0  0  0  0  0  0  0  0], end state:[ 2 18 28  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2299, score:[2750.00], loss:[2.59993], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 4  5 58  0  0  0  0  0  0  0  0], end state:[ 6  5 58  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2300, score:[2730.50], loss:[2.89486], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 14  3  0  0  0  0  0  0  0  0], end state:[ 0 14  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2301, score:[2794.75], loss:[2.75003], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 0  3 46  0  0  0  0  0  0  0  0], end state:[ 2  3 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2302, score:[2796.00], loss:[2.57959], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 5  8 39  0  0  0  0  0  0  0  0], end state:[ 0  8 39  1  1  0  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2303, score:[2747.50], loss:[2.71331], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 4 10 48  1  1  0  1  0  0  0  0], end state:[ 6 10 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2304, score:[2786.50], loss:[2.69037], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 0  3 52  0  0  0  0  0  0  0  0], end state:[ 2  3 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2305, score:[2740.25], loss:[2.75720], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 2 10  8  0  0  0  0  0  0  0  0], end state:[ 4 10  8  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2306, score:[2821.75], loss:[2.98416], sequence:[6], random actions:[23], eInit:[0.0100], init state:[ 1 18  6  0  0  0  0  0  0  0  0], end state:[ 3 18  6  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2307, score:[2751.75], loss:[2.88570], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 6 15 49  0  0  0  0  0  0  0  0], end state:[ 1 15 49  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2308, score:[2707.00], loss:[3.01858], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 11 18  1  1  0  0  0  0  0  0], end state:[ 6 11 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2309, score:[2786.00], loss:[3.07338], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 0 12  1  0  0  0  0  0  0  0  0], end state:[ 2 12  1  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2310, score:[2731.50], loss:[3.04076], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5 14 10  0  0  0  0  0  0  0  0], end state:[ 0 14 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2311, score:[2730.75], loss:[3.03815], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3 22 28  1  0  0  0  0  0  1  1], end state:[ 5 22 28  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2312, score:[2779.50], loss:[2.98295], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 6 18 52  0  0  0  0  0  0  0  0], end state:[ 1 18 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2313, score:[2757.25], loss:[2.94896], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 6 15 18  0  0  0  0  0  0  0  0], end state:[ 1 15 18  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2314, score:[2711.25], loss:[3.25610], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 16 51  0  0  0  0  0  0  0  0], end state:[ 5 16 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2315, score:[2690.00], loss:[2.98131], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 1  2 25  0  0  0  0  0  0  0  0], end state:[ 3  2 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2316, score:[2740.50], loss:[3.00945], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 2 15 13  0  0  0  0  0  0  0  0], end state:[ 4 15 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2317, score:[2807.75], loss:[2.86087], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2 18 14  0  0  0  0  0  0  0  0], end state:[ 4 18 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2318, score:[2816.50], loss:[2.70640], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 1  8 37  1  1  0  1  0  1  0  0], end state:[ 3  8 37  1  1  0  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2319, score:[2824.75], loss:[2.50405], sequence:[4], random actions:[20], eInit:[0.0100], init state:[ 0 16 27  0  0  0  0  0  0  0  0], end state:[ 2 16 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2320, score:[2766.00], loss:[2.81327], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 5 19 44  1  0  0  1  0  0  0  0], end state:[ 0 19 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2321, score:[2562.00], loss:[2.98331], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3  6 53  0  0  0  0  0  0  0  0], end state:[ 5  6 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2322, score:[2816.75], loss:[2.75214], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2  5 29  0  0  0  0  0  0  0  0], end state:[ 4  5 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2323, score:[2766.50], loss:[2.54207], sequence:[2], random actions:[36], eInit:[0.0100], init state:[ 3  0 27  1  0  0  0  0  0  0  0], end state:[ 5  0 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2324, score:[2768.50], loss:[2.67476], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 1  7 13  0  0  0  0  0  0  0  0], end state:[ 3  7 13  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2325, score:[2755.25], loss:[2.68123], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 4  5 29  0  0  0  0  0  0  0  0], end state:[ 6  5 29  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2326, score:[2772.75], loss:[2.68852], sequence:[5], random actions:[23], eInit:[0.0100], init state:[ 5 16 11  0  0  0  0  0  0  0  0], end state:[ 0 16 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2327, score:[2782.00], loss:[2.49227], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 0 10 24  0  0  0  0  0  0  0  0], end state:[ 2 10 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2328, score:[2727.50], loss:[2.51850], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 3 12 30  0  0  0  0  0  0  0  0], end state:[ 5 12 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2329, score:[2678.25], loss:[2.78017], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 23 25  0  0  0  0  0  0  0  0], end state:[ 6 23 25  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2330, score:[2807.25], loss:[2.94201], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 13  7  0  0  0  0  0  0  0  0], end state:[ 3 13  7  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2331, score:[2742.25], loss:[2.78381], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 4 11 39  1  1  0  0  0  0  0  0], end state:[ 6 11 39  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2332, score:[2744.25], loss:[2.82401], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 3  5 24  0  0  0  0  0  0  0  0], end state:[ 5  5 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2333, score:[2783.50], loss:[2.76579], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 4 11 45  1  1  0  0  0  0  0  0], end state:[ 6 11 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2334, score:[2805.50], loss:[2.50798], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 4 15 53  0  0  0  0  0  0  0  0], end state:[ 6 15 53  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2335, score:[2796.25], loss:[2.47964], sequence:[6], random actions:[20], eInit:[0.0100], init state:[ 4  4 16  0  0  0  0  0  0  0  0], end state:[ 6  4 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2336, score:[2814.25], loss:[2.51847], sequence:[7], random actions:[28], eInit:[0.0100], init state:[ 4  8 22  0  0  0  0  0  0  0  0], end state:[ 6  8 22  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2337, score:[2784.75], loss:[2.61656], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 3 14 15  0  0  0  0  0  0  0  0], end state:[ 5 14 15  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2338, score:[2699.50], loss:[2.93261], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 0 10 47  0  0  0  0  0  0  0  0], end state:[ 2 10 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2339, score:[2777.50], loss:[2.98476], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 1  8 47  1  1  0  0  0  0  0  0], end state:[ 3  8 47  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2340, score:[2744.25], loss:[3.02966], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 0 19 38  0  0  0  0  0  0  0  0], end state:[ 2 19 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2341, score:[2660.75], loss:[3.10693], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 3 12  5  0  0  0  0  0  0  0  0], end state:[ 5 12  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2342, score:[2755.25], loss:[3.24885], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 2 17 43  0  0  0  0  0  0  0  0], end state:[ 4 17 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2343, score:[2755.00], loss:[3.14904], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 6 13 51  0  0  0  0  0  0  0  0], end state:[ 1 13 51  0  0  0  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2344, score:[2740.00], loss:[2.98657], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 3 22 42  1  0  0  0  0  0  1  1], end state:[ 5 22 42  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2345, score:[2790.00], loss:[3.34392], sequence:[4], random actions:[27], eInit:[0.0100], init state:[0 9 1 0 0 0 0 0 0 0 0], end state:[2 9 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2346, score:[2801.00], loss:[3.19566], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 2 19 43  0  0  0  0  0  0  0  0], end state:[ 4 19 43  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2347, score:[2801.25], loss:[2.98213], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 0 21 58  1  0  0  0  0  0  1  1], end state:[ 2 21 58  0  0  1  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2348, score:[2712.25], loss:[2.99501], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 17 54  0  0  0  0  0  0  0  0], end state:[ 6 17 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2349, score:[2745.25], loss:[3.14824], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 3  6 45  0  0  0  0  0  0  0  0], end state:[ 5  6 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2350, score:[2766.75], loss:[3.06488], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 19 59  0  0  0  0  0  0  0  0], end state:[ 3 19 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2351, score:[2769.25], loss:[3.08998], sequence:[3], random actions:[39], eInit:[0.0100], init state:[ 0  3 38  0  0  0  0  0  0  0  0], end state:[ 2  3 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2352, score:[2763.25], loss:[3.25327], sequence:[4], random actions:[20], eInit:[0.0100], init state:[4 8 9 0 0 0 0 0 0 0 0], end state:[6 8 9 1 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2353, score:[2740.25], loss:[3.28776], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 4 20 26  0  0  0  0  0  0  0  0], end state:[ 6 20 26  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2354, score:[2800.25], loss:[2.96892], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 3 10  5  0  0  0  0  0  0  0  0], end state:[ 5 10  5  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2355, score:[2791.00], loss:[2.76200], sequence:[7], random actions:[34], eInit:[0.0100], init state:[ 2  5 14  0  0  0  0  0  0  0  0], end state:[ 4  5 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2356, score:[2684.50], loss:[2.94093], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 6  6 27  0  0  0  0  0  0  0  0], end state:[ 1  6 27  0  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2357, score:[2763.25], loss:[2.93981], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 2 23 52  1  0  0  0  0  0  1  1], end state:[ 4 23 52  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2358, score:[2714.50], loss:[2.87647], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5  1 42  0  0  0  0  0  0  0  0], end state:[ 0  1 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2359, score:[2706.25], loss:[2.87216], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5  2 38  0  0  0  0  0  0  0  0], end state:[ 0  2 38  0  1  1  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2360, score:[2613.50], loss:[3.25519], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 17 45  0  0  0  0  0  0  0  0], end state:[ 0 17 45  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2361, score:[2692.00], loss:[3.52426], sequence:[0], random actions:[26], eInit:[0.0100], init state:[6 5 9 0 0 0 0 0 0 0 0], end state:[1 5 9 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2362, score:[2724.50], loss:[3.80513], sequence:[0], random actions:[29], eInit:[0.0100], init state:[5 7 1 0 0 0 0 0 0 0 0], end state:[0 7 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2363, score:[2792.50], loss:[3.81759], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 20 10  0  0  0  0  0  0  0  0], end state:[ 3 20 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2364, score:[2780.25], loss:[3.74372], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 2  5 20  0  0  0  0  0  0  0  0], end state:[ 4  5 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2365, score:[2709.25], loss:[4.02979], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 6  8 52  1  1  0  0  0  0  0  0], end state:[ 1  8 52  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2366, score:[2839.00], loss:[3.77499], sequence:[1], random actions:[16], eInit:[0.0100], init state:[2 1 9 0 0 1 0 0 0 0 0], end state:[4 1 9 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2367, score:[2801.00], loss:[3.67520], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 0 13 36  0  0  0  0  0  0  0  0], end state:[ 2 13 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2368, score:[2723.25], loss:[3.61334], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 3  3 47  0  0  0  0  0  0  0  0], end state:[ 5  3 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2369, score:[2699.25], loss:[3.72273], sequence:[0], random actions:[30], eInit:[0.0100], init state:[4 6 1 0 0 0 0 0 0 0 0], end state:[6 6 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2370, score:[2793.00], loss:[3.49374], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 4  3 27  0  0  0  0  0  0  0  0], end state:[ 6  3 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2371, score:[2742.00], loss:[4.07625], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6 17 35  0  0  0  0  0  0  0  0], end state:[ 1 17 35  0  0  1  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2372, score:[2771.25], loss:[3.71172], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0 22 26  1  0  0  0  0  0  1  1], end state:[ 2 22 26  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2373, score:[2800.00], loss:[3.63560], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 0  1 17  0  0  0  0  0  0  0  0], end state:[ 2  1 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2374, score:[2709.50], loss:[3.98992], sequence:[0], random actions:[35], eInit:[0.0100], init state:[6 0 9 1 0 0 0 0 1 1 1], end state:[1 0 9 1 0 0 0 0 1 1 1]
INFO:Reinforcement.Functions:episode: 2375, score:[2791.00], loss:[4.14904], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 19 59  0  0  0  0  0  0  0  0], end state:[ 3 19 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2376, score:[2788.50], loss:[4.02253], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 1 23 48  1  0  0  0  0  0  1  1], end state:[ 3 23 48  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2377, score:[2675.50], loss:[3.71724], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 6  5 57  0  0  0  0  0  0  0  0], end state:[ 1  5 57  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2378, score:[2762.25], loss:[3.82073], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 0  9 55  0  0  0  0  0  0  0  0], end state:[ 2  9 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2379, score:[2569.00], loss:[3.35039], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 4 10 44  1  1  0  1  0  0  0  0], end state:[ 6 10 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2380, score:[2786.25], loss:[3.57509], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 0 10 56  0  0  0  0  0  0  0  0], end state:[ 2 10 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2381, score:[2705.00], loss:[3.99258], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4  9 40  1  0  0  0  0  0  0  0], end state:[ 6  9 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2382, score:[2757.50], loss:[3.93058], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 0 18 59  0  0  0  0  0  0  0  0], end state:[ 2 18 59  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2383, score:[2739.50], loss:[3.66413], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 1  1 11  0  0  0  0  0  0  0  0], end state:[ 3  1 11  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2384, score:[2703.00], loss:[4.00177], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 16 16  0  0  0  0  0  0  0  0], end state:[ 0 16 16  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2385, score:[2812.25], loss:[3.83068], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  7 14  0  0  0  0  0  0  0  0], end state:[ 3  7 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2386, score:[2817.25], loss:[3.36108], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 2  4 32  0  0  0  0  0  0  0  0], end state:[ 4  4 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2387, score:[2663.50], loss:[3.98635], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  2 37  0  0  0  0  0  0  0  0], end state:[ 1  2 37  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2388, score:[2484.00], loss:[4.35358], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 22 10  1  0  0  0  0  0  1  1], end state:[ 5 22 10  1  0  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2389, score:[2794.00], loss:[4.32350], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1  3 38  0  0  0  0  0  0  0  0], end state:[ 3  3 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2390, score:[2727.25], loss:[4.39078], sequence:[0], random actions:[23], eInit:[0.0100], init state:[ 6 14 38  0  0  0  0  0  0  0  0], end state:[ 1 14 38  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2391, score:[2773.50], loss:[4.23744], sequence:[1], random actions:[41], eInit:[0.0100], init state:[ 1  4 33  0  0  0  0  0  0  0  0], end state:[ 3  4 33  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2392, score:[2778.50], loss:[4.00580], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 0  7 10  0  0  0  0  0  0  0  0], end state:[ 2  7 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2393, score:[2745.75], loss:[4.07752], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1 16 55  0  0  0  0  0  0  0  0], end state:[ 3 16 55  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2394, score:[2760.00], loss:[4.22789], sequence:[4], random actions:[23], eInit:[0.0100], init state:[6 3 8 0 0 0 0 0 0 0 0], end state:[1 3 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2395, score:[2652.00], loss:[4.28813], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 3  0 51  0  0  1  0  0  0  0  0], end state:[ 5  0 51  1  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2396, score:[2779.50], loss:[4.49675], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 0 19 44  0  0  0  0  0  0  0  0], end state:[ 2 19 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2397, score:[2789.00], loss:[3.95850], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 0  4 54  0  0  0  0  0  0  0  0], end state:[ 2  4 54  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2398, score:[2675.75], loss:[4.14689], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 17 27  0  0  0  0  0  0  0  0], end state:[ 5 17 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2399, score:[2771.25], loss:[4.08895], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0 15 47  0  0  0  0  0  0  0  0], end state:[ 2 15 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2400, score:[2791.75], loss:[3.65549], sequence:[2], random actions:[26], eInit:[0.0100], init state:[2 4 2 0 0 0 0 0 0 0 0], end state:[4 4 2 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2401, score:[2704.75], loss:[3.91886], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 4 14 40  0  0  0  0  0  0  0  0], end state:[ 6 14 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2402, score:[2749.00], loss:[4.04301], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6 18 21  0  0  0  0  0  0  0  0], end state:[ 1 18 21  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2403, score:[2775.00], loss:[3.88036], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1  2 48  0  0  0  0  0  0  0  0], end state:[ 3  2 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2404, score:[2758.75], loss:[3.57286], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 2 18 50  0  0  0  0  0  0  0  0], end state:[ 4 18 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2405, score:[2801.25], loss:[3.00037], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 1 11  0  0  0  0  0  0  0  0  0], end state:[ 3 11  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2406, score:[2736.25], loss:[3.05502], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 3 14 30  0  0  0  0  0  0  0  0], end state:[ 5 14 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2407, score:[2799.00], loss:[3.26462], sequence:[6], random actions:[34], eInit:[0.0100], init state:[ 0  7 50  0  0  0  0  0  0  0  0], end state:[ 2  7 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2408, score:[2806.00], loss:[3.32197], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 0  1 30  0  0  0  0  0  0  0  0], end state:[ 2  1 30  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2409, score:[2701.25], loss:[3.87942], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 5 15  9  0  0  0  0  0  0  0  0], end state:[ 0 15  9  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2410, score:[2814.25], loss:[3.70580], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 2  7 48  0  0  0  0  0  0  0  0], end state:[ 4  7 48  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2411, score:[2806.75], loss:[3.47818], sequence:[2], random actions:[17], eInit:[0.0100], init state:[ 2 22 51  1  0  0  0  0  0  1  1], end state:[ 4 22 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2412, score:[2825.75], loss:[3.21501], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 1  0 32  0  0  1  0  0  0  0  0], end state:[ 3  0 32  0  0  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2413, score:[2758.25], loss:[3.08681], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 4  8 25  0  0  0  0  0  0  0  0], end state:[ 6  8 25  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2414, score:[2768.00], loss:[3.04490], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 3 18 31  0  0  0  0  0  0  0  0], end state:[ 5 18 31  1  1  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2415, score:[2779.00], loss:[2.94448], sequence:[6], random actions:[25], eInit:[0.0100], init state:[ 6 20 34  1  1  0  0  0  0  0  0], end state:[ 1 20 34  0  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2416, score:[2820.25], loss:[2.67089], sequence:[7], random actions:[19], eInit:[0.0100], init state:[ 3 12 56  0  0  0  0  0  0  0  0], end state:[ 5 12 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2417, score:[2676.00], loss:[2.63660], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 3  8 22  1  0  0  0  0  0  0  0], end state:[ 5  8 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2418, score:[2791.75], loss:[2.90289], sequence:[1], random actions:[19], eInit:[0.0100], init state:[ 6  0 23  1  0  0  0  0  1  0  0], end state:[ 1  0 23  1  0  0  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2419, score:[2794.00], loss:[2.59092], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1 14 51  0  0  0  0  0  0  0  0], end state:[ 3 14 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2420, score:[2788.25], loss:[2.78510], sequence:[3], random actions:[28], eInit:[0.0100], init state:[0 2 1 0 0 0 0 0 0 0 0], end state:[2 2 1 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2421, score:[2782.50], loss:[2.75645], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 6 23  4  1  0  0  0  0  0  1  1], end state:[ 1 23  4  1  0  0  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2422, score:[2751.75], loss:[3.07842], sequence:[5], random actions:[38], eInit:[0.0100], init state:[ 6 13 24  0  0  0  0  0  0  0  0], end state:[ 1 13 24  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2423, score:[2679.50], loss:[3.12432], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 0 16 51  0  0  0  0  0  0  0  0], end state:[ 2 16 51  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2424, score:[2810.00], loss:[2.84703], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0  0 10  1  0  0  0  0  1  1  1], end state:[ 2  0 10  1  0  0  0  0  1  1  1]
INFO:Reinforcement.Functions:episode: 2425, score:[2783.25], loss:[2.53325], sequence:[2], random actions:[28], eInit:[0.0100], init state:[6 1 2 0 0 1 0 0 0 0 0], end state:[1 1 2 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2426, score:[2733.75], loss:[2.53838], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 3  0 50  0  0  1  0  0  0  0  0], end state:[ 5  0 50  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2427, score:[2752.50], loss:[2.80278], sequence:[1], random actions:[23], eInit:[0.0100], init state:[ 3 19  6  0  0  0  0  0  0  0  0], end state:[ 5 19  6  1  0  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2428, score:[2780.50], loss:[2.92140], sequence:[2], random actions:[31], eInit:[0.0100], init state:[1 6 4 0 0 0 0 0 0 0 0], end state:[3 6 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2429, score:[2801.25], loss:[2.69164], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 2  8 36  1  1  0  1  0  1  0  0], end state:[ 4  8 36  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2430, score:[2834.25], loss:[2.67355], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 1 14 27  0  0  0  0  0  0  0  0], end state:[ 3 14 27  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2431, score:[2810.75], loss:[2.63754], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 0 20 25  0  0  0  0  0  0  0  0], end state:[ 2 20 25  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2432, score:[2803.50], loss:[2.67964], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 2 22  9  1  0  0  0  0  0  1  1], end state:[ 4 22  9  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2433, score:[2783.25], loss:[2.95682], sequence:[7], random actions:[39], eInit:[0.0100], init state:[ 2 22 56  1  0  0  0  0  0  1  1], end state:[ 4 22 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2434, score:[2757.50], loss:[2.90072], sequence:[8], random actions:[30], eInit:[0.0100], init state:[3 8 0 1 0 0 0 0 0 0 0], end state:[5 8 0 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2435, score:[2772.25], loss:[2.98857], sequence:[9], random actions:[27], eInit:[0.0100], init state:[ 3 11  3  0  0  0  0  0  0  0  0], end state:[ 5 11  3  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2436, score:[2813.75], loss:[2.77589], sequence:[10], random actions:[22], eInit:[0.0100], init state:[ 1 19 42  0  0  0  0  0  0  0  0], end state:[ 3 19 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2437, score:[2755.50], loss:[2.72632], sequence:[11], random actions:[33], eInit:[0.0100], init state:[ 1  0 20  1  0  0  0  0  1  0  0], end state:[ 3  0 20  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2438, score:[2807.25], loss:[2.58560], sequence:[12], random actions:[32], eInit:[0.0100], init state:[ 2  5 35  0  0  0  0  0  0  0  0], end state:[ 4  5 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2439, score:[2750.00], loss:[2.59013], sequence:[13], random actions:[35], eInit:[0.0100], init state:[ 1 16  0  0  0  0  0  0  0  0  0], end state:[ 3 16  0  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2440, score:[2725.25], loss:[3.08543], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 0 20 36  1  1  0  0  0  0  0  0], end state:[ 2 20 36  1  0  0  0  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2441, score:[2776.50], loss:[3.03165], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 6 18 31  0  0  0  0  0  0  0  0], end state:[ 1 18 31  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2442, score:[2806.00], loss:[2.95406], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 1 19 23  0  0  0  0  0  0  0  0], end state:[ 3 19 23  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2443, score:[2808.25], loss:[2.90576], sequence:[3], random actions:[36], eInit:[0.0100], init state:[ 0 15 20  0  0  0  0  0  0  0  0], end state:[ 2 15 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2444, score:[2730.00], loss:[2.87945], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 18 22  0  0  0  0  0  0  0  0], end state:[ 4 18 22  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2445, score:[2807.25], loss:[2.71487], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0  8 56  1  1  0  0  0  0  0  0], end state:[ 2  8 56  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2446, score:[2635.25], loss:[2.84025], sequence:[0], random actions:[17], eInit:[0.0100], init state:[ 4  0 19  1  0  0  0  0  1  0  0], end state:[ 6  0 19  1  0  1  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 2447, score:[2759.75], loss:[3.29282], sequence:[1], random actions:[14], eInit:[0.0100], init state:[4 1 2 0 0 1 0 0 0 0 0], end state:[6 1 2 0 0 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2448, score:[2673.00], loss:[3.34172], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4  8 21  0  0  0  0  0  0  0  0], end state:[ 6  8 21  1  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2449, score:[2677.00], loss:[3.64854], sequence:[0], random actions:[26], eInit:[0.0100], init state:[5 6 7 0 0 0 0 0 0 0 0], end state:[0 6 7 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2450, score:[2643.50], loss:[3.93343], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 5  5 56  0  0  0  0  0  0  0  0], end state:[ 0  5 56  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2451, score:[2648.75], loss:[4.15322], sequence:[0], random actions:[34], eInit:[0.0100], init state:[5 9 0 0 0 0 0 0 0 0 0], end state:[0 9 0 0 1 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2452, score:[2755.50], loss:[4.16814], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 4 11 47  1  1  0  0  0  0  0  0], end state:[ 6 11 47  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2453, score:[2760.75], loss:[4.19481], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 4 10 46  1  1  0  1  0  0  0  0], end state:[ 6 10 46  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2454, score:[2793.25], loss:[4.34389], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 2 10 37  0  0  0  0  0  0  0  0], end state:[ 4 10 37  1  1  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2455, score:[2780.25], loss:[4.20055], sequence:[4], random actions:[32], eInit:[0.0100], init state:[0 9 6 0 0 0 0 0 0 0 0], end state:[2 9 6 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2456, score:[2707.25], loss:[4.35240], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5 20 48  1  0  0  0  0  0  0  0], end state:[ 0 20 48  1  1  0  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2457, score:[2825.00], loss:[3.84738], sequence:[1], random actions:[17], eInit:[0.0100], init state:[ 2  3 32  0  0  0  0  0  0  0  0], end state:[ 4  3 32  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2458, score:[2680.25], loss:[3.63261], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 14 43  0  0  0  0  0  0  0  0], end state:[ 6 14 43  1  1  0  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2459, score:[2779.50], loss:[3.87829], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 6 11 17  0  0  0  0  0  0  0  0], end state:[ 1 11 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2460, score:[2764.00], loss:[3.70914], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 0  6 14  0  0  0  0  0  0  0  0], end state:[ 2  6 14  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2461, score:[2750.75], loss:[3.83968], sequence:[3], random actions:[35], eInit:[0.0100], init state:[0 6 8 0 0 0 0 0 0 0 0], end state:[2 6 8 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2462, score:[2764.75], loss:[3.96389], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 3  9 35  0  0  0  0  0  0  0  0], end state:[ 5  9 35  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2463, score:[2758.75], loss:[4.08098], sequence:[5], random actions:[33], eInit:[0.0100], init state:[ 0 10  2  0  0  0  0  0  0  0  0], end state:[ 2 10  2  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2464, score:[2786.25], loss:[3.87910], sequence:[6], random actions:[32], eInit:[0.0100], init state:[1 2 4 0 0 0 0 0 0 0 0], end state:[3 2 4 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2465, score:[2747.25], loss:[4.20922], sequence:[7], random actions:[33], eInit:[0.0100], init state:[ 1 14 26  0  0  0  0  0  0  0  0], end state:[ 3 14 26  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2466, score:[2780.75], loss:[3.91914], sequence:[8], random actions:[24], eInit:[0.0100], init state:[ 6  1 40  0  0  0  0  0  0  0  0], end state:[ 1  1 40  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2467, score:[2612.50], loss:[3.83649], sequence:[0], random actions:[25], eInit:[0.0100], init state:[ 4  9 10  0  0  0  0  0  0  0  0], end state:[ 6  9 10  1  0  0  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 2468, score:[2684.00], loss:[4.49962], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 6 16 20  0  0  0  0  0  0  0  0], end state:[ 1 16 20  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2469, score:[2655.75], loss:[4.37364], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4  4 17  0  0  0  0  0  0  0  0], end state:[ 6  4 17  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2470, score:[2661.75], loss:[4.33046], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 5 11 44  0  0  0  0  0  0  0  0], end state:[ 0 11 44  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-42/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-42/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-42/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-42/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2840.0, [892]) , maxSequence:(21, [930])
INFO:Reinforcement.Functions:episode: 2471, score:[2557.50], loss:[4.60452], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 16 10  0  0  0  0  0  0  0  0], end state:[ 6 16 10  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2472, score:[2613.50], loss:[4.96169], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 2  5 42  0  0  0  0  0  0  0  0], end state:[ 4  5 42  0  0  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2473, score:[2768.00], loss:[4.93709], sequence:[1], random actions:[28], eInit:[0.0100], init state:[2 9 5 0 0 0 0 0 0 0 0], end state:[4 9 5 0 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2474, score:[2742.00], loss:[4.72693], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 3  5 14  0  0  0  0  0  0  0  0], end state:[ 5  5 14  0  0  0  0  0  0  0  0]

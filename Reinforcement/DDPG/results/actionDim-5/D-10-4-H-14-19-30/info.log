INFO:Reinforcement.Functions:policy:[{'seqLen': 1, 'numOfDevices': 5, 'stateDim': (1, 8), 'rewardScaleFactor': 1.0, 'fname': '/home/yochaiz/SmartHome/Reinforcement/Policies/Week/policy2.json'}]
INFO:Reinforcement.Functions:Actor:[{'epsilon_min': 0.01, 'TAU': 0.001, 'epsilon_decay': 0.99, 'epsilon': 1.0, 'k': 32, 'actionDim': 5, 'curBackupIdx': 0, 'nBackups': 3, 'nActions': 32}]
INFO:Reinforcement.Functions:Critic:[{'nBackups': 3, 'curBackupIdx': 0, 'TAU': 0.001, 'actionDim': 5}]
INFO:Reinforcement.Functions:results:[{'baseFolder': '/home/yochaiz/SmartHome/Reinforcement/DDPG', 'loss': [], 'folderName': 'D-10-4-H-14-19-30', 'fullPath': '/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30', 'score': [], 'actionDim': 'actionDim-5'}]
INFO:Reinforcement.Functions:args:[{'desc': '"deep model **sequential**"', 'k': 32, 'rewardScale': 1.0, 'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json', 'gpuNum': 0, 'sequential': True, 'random': False, 'gpuFrac': 0.3}]
INFO:Reinforcement.Functions:settings:[{'minGameScore': 2448, 'nEpochs': 1, 'nGamesPerSave': 10, 'minGameScoreRatio': 0.85, 'dequeSize': 50000, 'minGameSequence': 500, 'gameMinutesLength': 2880, 'TAU': 0.001, 'batchSize': 64, 'trainSetSize': 64, 'nModelBackups': 3, 'learningRate': 0.001, 'gamma': 0.95}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:===== DESCRIPTIONS =====
INFO:Reinforcement.Functions:[General]: "deep model **sequential**"
INFO:Reinforcement.Functions:[Actor]: Try deeper architecture
INFO:Reinforcement.Functions:[Actor]: Fixed bug where future reward (step 13) used continuous action instead of discrete action
INFO:Reinforcement.Functions:[Actor]: No more threading during replays
INFO:Reinforcement.Functions:[Critic]: Try deeper architecture
INFO:Reinforcement.Functions:===== ============ =====
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 8)              0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 256)            2304      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)              (None, 1, 5)              1285      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 5)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 266,757
INFO:Reinforcement.Functions:Trainable params: 266,757
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 8)         0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 256)       2304        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 5)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_8 (Dense)                 (None, 1, 256)       65792       dense_7[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_9 (Dense)                 (None, 256)          1536        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_8[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_9[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_10 (Dense)                (None, 1, 256)       65792       activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_11 (Dense)                (None, 1, 256)       65792       dense_10[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_12 (Dense)                (None, 1, 256)       65792       dense_11[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_13 (Dense)                (None, 1, 1)         257         dense_12[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_13[0][0]                   
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 267,265
INFO:Reinforcement.Functions:Trainable params: 267,265
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[2004.40], loss:[29.16814], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.46], optActionInPoolButNotSelected:[0.52], random actions:[126], eInit:[1.0000], init state:[ 3 23 49  1  0  0  0  0], end state:[ 5 23 49  1  0  0  0  0], runtime(seconds):[422.99]
INFO:Reinforcement.Functions:episode: 2, score:[2186.00], loss:[29.99278], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.55], optActionInPoolButNotSelected:[0.43], random actions:[113], eInit:[0.9900], init state:[ 4 11 56  1  1  0  0  0], end state:[ 6 11 56  0  0  0  0  0], runtime(seconds):[423.00]
INFO:Reinforcement.Functions:episode: 3, score:[2343.20], loss:[30.64341], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.70], optActionInPoolButNotSelected:[0.27], random actions:[112], eInit:[0.9801], init state:[5 0 3 0 0 0 0 0], end state:[0 0 3 0 0 0 0 0], runtime(seconds):[424.38]
INFO:Reinforcement.Functions:episode: 4, score:[2318.80], loss:[27.48395], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.67], optActionInPoolButNotSelected:[0.31], random actions:[116], eInit:[0.9703], init state:[ 5 12 10  0  0  0  0  0], end state:[ 0 12 10  1  0  0  0  0], runtime(seconds):[424.36]
INFO:Reinforcement.Functions:episode: 5, score:[2333.20], loss:[38.05487], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.70], optActionInPoolButNotSelected:[0.27], random actions:[118], eInit:[0.9606], init state:[ 6  0 17  1  0  0  0  0], end state:[ 1  0 17  0  0  0  0  0], runtime(seconds):[423.42]
INFO:Reinforcement.Functions:episode: 6, score:[2248.80], loss:[35.36409], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.65], optActionInPoolButNotSelected:[0.33], random actions:[118], eInit:[0.9510], init state:[ 6 12 24  0  0  0  0  0], end state:[ 1 12 24  0  0  0  0  0], runtime(seconds):[424.29]
INFO:Reinforcement.Functions:episode: 7, score:[2331.20], loss:[33.68610], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.70], optActionInPoolButNotSelected:[0.27], random actions:[116], eInit:[0.9415], init state:[ 0  0 31  0  0  1  0  0], end state:[ 2  0 31  0  0  0  0  0], runtime(seconds):[424.37]
INFO:Reinforcement.Functions:episode: 8, score:[2445.20], loss:[30.82051], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.75], optActionInPoolButNotSelected:[0.22], random actions:[123], eInit:[0.9321], init state:[ 0 12 38  0  0  0  0  0], end state:[ 2 12 38  0  0  0  0  0], runtime(seconds):[423.77]
INFO:Reinforcement.Functions:episode: 9, score:[2501.60], loss:[28.26392], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.81], optActionInPoolButNotSelected:[0.16], random actions:[108], eInit:[0.9227], init state:[ 1  0 45  0  0  1  0  0], end state:[ 3  0 45  0  0  0  0  0], runtime(seconds):[423.51]
INFO:Reinforcement.Functions:episode: 10, score:[2495.20], loss:[27.09773], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.78], optActionInPoolButNotSelected:[0.19], random actions:[100], eInit:[0.9135], init state:[ 1 12 52  0  0  0  0  0], end state:[ 3 12 52  0  0  0  0  0], runtime(seconds):[424.10]
INFO:Reinforcement.Functions:Optimal models save history:[(1, [('Actor', 1), ('Critic', 1)]), (2, [('Actor', 2), ('Critic', 2)]), (3, [('Actor', 0), ('Critic', 0)]), (8, [('Actor', 1), ('Critic', 1)]), (9, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2501.599999999974, [9]) , maxSequence:(2, [10])
INFO:Reinforcement.Functions:episode: 11, score:[2446.80], loss:[25.07041], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.75], optActionInPoolButNotSelected:[0.22], random actions:[115], eInit:[0.9044], init state:[ 2  0 59  0  0  1  0  0], end state:[ 4  0 59  0  0  0  0  0], runtime(seconds):[424.61]
INFO:Reinforcement.Functions:episode: 12, score:[2419.20], loss:[23.64659], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.21], random actions:[101], eInit:[0.8953], init state:[ 2 13  6  0  0  0  0  0], end state:[ 4 13  6  0  0  0  0  0], runtime(seconds):[424.32]
INFO:Reinforcement.Functions:episode: 13, score:[2366.00], loss:[21.09590], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.72], optActionInPoolButNotSelected:[0.25], random actions:[98], eInit:[0.8864], init state:[ 3  1 13  0  0  0  0  0], end state:[ 5  1 13  0  0  0  0  0], runtime(seconds):[424.37]
INFO:Reinforcement.Functions:episode: 14, score:[2440.00], loss:[24.97476], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.21], random actions:[115], eInit:[0.8775], init state:[ 3 13 20  0  0  0  0  0], end state:[ 5 13 20  0  0  0  0  0], runtime(seconds):[426.68]
INFO:Reinforcement.Functions:episode: 15, score:[2445.60], loss:[22.40025], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.22], random actions:[99], eInit:[0.8687], init state:[ 4  1 27  0  0  0  0  0], end state:[ 6  1 27  0  0  0  0  0], runtime(seconds):[429.26]
INFO:Reinforcement.Functions:episode: 16, score:[2541.20], loss:[17.23240], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.82], optActionInPoolButNotSelected:[0.15], random actions:[111], eInit:[0.8601], init state:[ 4 13 34  0  0  0  0  0], end state:[ 6 13 34  0  0  0  0  0], runtime(seconds):[428.13]
INFO:Reinforcement.Functions:episode: 17, score:[2617.20], loss:[19.36784], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.86], optActionInPoolButNotSelected:[0.10], random actions:[104], eInit:[0.8515], init state:[ 5  1 41  0  0  0  0  0], end state:[ 0  1 41  0  0  0  0  0], runtime(seconds):[428.36]
INFO:Reinforcement.Functions:episode: 18, score:[2465.60], loss:[19.95165], sequence:[3], isInPoolRatio:[1.00], optActionSelectedRatio:[0.81], optActionInPoolButNotSelected:[0.16], random actions:[124], eInit:[0.8429], init state:[ 5 13 48  0  0  0  0  0], end state:[ 0 13 48  0  0  0  0  0], runtime(seconds):[427.21]
INFO:Reinforcement.Functions:episode: 19, score:[2589.60], loss:[17.58029], sequence:[4], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.11], random actions:[118], eInit:[0.8345], init state:[ 6  1 55  0  0  0  0  0], end state:[ 1  1 55  0  0  0  0  0], runtime(seconds):[424.38]
INFO:Reinforcement.Functions:episode: 20, score:[2630.00], loss:[15.67348], sequence:[5], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[111], eInit:[0.8262], init state:[ 6 14  2  0  0  0  0  0], end state:[ 1 14  2  0  0  0  0  0], runtime(seconds):[425.88]
INFO:Reinforcement.Functions:Optimal models save history:[(16, [('Actor', 0), ('Critic', 0)]), (17, [('Actor', 1), ('Critic', 1)]), (20, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2629.999999999993, [20]) , maxSequence:(5, [20])
INFO:Reinforcement.Functions:episode: 21, score:[2639.60], loss:[15.38959], sequence:[6], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.08], random actions:[115], eInit:[0.8179], init state:[0 2 9 0 0 0 0 0], end state:[2 2 9 0 0 0 0 0], runtime(seconds):[425.95]
INFO:Reinforcement.Functions:episode: 22, score:[2666.40], loss:[17.14694], sequence:[7], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[93], eInit:[0.8097], init state:[ 0 14 16  0  0  0  0  0], end state:[ 2 14 16  0  0  0  0  0], runtime(seconds):[426.11]
INFO:Reinforcement.Functions:episode: 23, score:[2683.20], loss:[13.77039], sequence:[8], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[98], eInit:[0.8016], init state:[ 1  2 23  0  0  0  0  0], end state:[ 3  2 23  0  0  0  0  0], runtime(seconds):[426.19]
INFO:Reinforcement.Functions:episode: 24, score:[2677.60], loss:[12.83413], sequence:[9], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[97], eInit:[0.7936], init state:[ 1 14 30  0  0  0  0  0], end state:[ 3 14 30  0  0  0  0  0], runtime(seconds):[426.40]
INFO:Reinforcement.Functions:episode: 25, score:[2670.00], loss:[14.21962], sequence:[10], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[105], eInit:[0.7857], init state:[ 2  2 37  0  0  0  0  0], end state:[ 4  2 37  0  0  0  0  0], runtime(seconds):[425.56]
INFO:Reinforcement.Functions:episode: 26, score:[2552.80], loss:[13.79823], sequence:[11], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.12], random actions:[107], eInit:[0.7778], init state:[ 2 14 44  0  0  0  0  0], end state:[ 4 14 44  0  0  0  0  0], runtime(seconds):[425.12]
INFO:Reinforcement.Functions:episode: 27, score:[2575.20], loss:[12.14356], sequence:[12], isInPoolRatio:[1.00], optActionSelectedRatio:[0.83], optActionInPoolButNotSelected:[0.14], random actions:[101], eInit:[0.7700], init state:[ 3  2 51  0  0  0  0  0], end state:[ 5  2 51  0  0  0  0  0], runtime(seconds):[425.11]
INFO:Reinforcement.Functions:episode: 28, score:[2621.20], loss:[11.33950], sequence:[13], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.12], random actions:[98], eInit:[0.7623], init state:[ 3 14 58  0  0  0  0  0], end state:[ 5 14 58  0  0  0  0  0], runtime(seconds):[424.95]
INFO:Reinforcement.Functions:episode: 29, score:[2576.80], loss:[13.72072], sequence:[14], isInPoolRatio:[1.00], optActionSelectedRatio:[0.84], optActionInPoolButNotSelected:[0.13], random actions:[97], eInit:[0.7547], init state:[4 3 5 0 0 0 0 0], end state:[6 3 5 0 0 0 0 0], runtime(seconds):[423.62]
INFO:Reinforcement.Functions:episode: 30, score:[2646.00], loss:[11.90238], sequence:[15], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.09], random actions:[86], eInit:[0.7472], init state:[ 4 15 12  0  0  0  0  0], end state:[ 6 15 12  0  0  0  0  0], runtime(seconds):[424.65]
INFO:Reinforcement.Functions:Optimal models save history:[(21, [('Actor', 0), ('Critic', 0)]), (22, [('Actor', 1), ('Critic', 1)]), (23, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2683.1999999999925, [23]) , maxSequence:(15, [30])
INFO:Reinforcement.Functions:episode: 31, score:[2633.60], loss:[11.16076], sequence:[16], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.10], random actions:[94], eInit:[0.7397], init state:[ 5  3 19  0  0  0  0  0], end state:[ 0  3 19  0  0  0  0  0], runtime(seconds):[425.19]
INFO:Reinforcement.Functions:episode: 32, score:[2664.80], loss:[11.97918], sequence:[17], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[88], eInit:[0.7323], init state:[ 5 15 26  0  0  0  0  0], end state:[ 0 15 26  0  0  0  0  0], runtime(seconds):[425.92]
INFO:Reinforcement.Functions:episode: 33, score:[2704.00], loss:[11.20367], sequence:[18], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[85], eInit:[0.7250], init state:[ 6  3 33  0  0  0  0  0], end state:[ 1  3 33  0  0  0  0  0], runtime(seconds):[426.06]
INFO:Reinforcement.Functions:episode: 34, score:[2677.20], loss:[10.22009], sequence:[19], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[101], eInit:[0.7177], init state:[ 6 15 40  0  0  0  0  0], end state:[ 1 15 40  0  0  0  0  0], runtime(seconds):[425.88]
INFO:Reinforcement.Functions:episode: 35, score:[2692.80], loss:[10.24285], sequence:[20], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[91], eInit:[0.7106], init state:[ 0  3 47  0  0  0  0  0], end state:[ 2  3 47  0  0  0  0  0], runtime(seconds):[426.47]
INFO:Reinforcement.Functions:episode: 36, score:[2684.80], loss:[10.67899], sequence:[21], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[96], eInit:[0.7034], init state:[ 0 15 54  0  0  0  0  0], end state:[ 2 15 54  0  0  0  0  0], runtime(seconds):[425.36]
INFO:Reinforcement.Functions:episode: 37, score:[2712.40], loss:[8.70577], sequence:[22], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[82], eInit:[0.6964], init state:[1 4 1 0 0 0 0 0], end state:[3 4 1 0 0 0 0 0], runtime(seconds):[425.84]
INFO:Reinforcement.Functions:episode: 38, score:[2708.40], loss:[8.88211], sequence:[23], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[103], eInit:[0.6894], init state:[ 1 16  8  0  0  0  0  0], end state:[ 3 16  8  0  0  0  0  0], runtime(seconds):[425.96]
INFO:Reinforcement.Functions:episode: 39, score:[2619.60], loss:[9.47078], sequence:[24], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[93], eInit:[0.6826], init state:[ 2  4 15  0  0  0  0  0], end state:[ 4  4 15  0  0  0  0  0], runtime(seconds):[425.46]
INFO:Reinforcement.Functions:episode: 40, score:[2590.40], loss:[10.53074], sequence:[25], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.10], random actions:[95], eInit:[0.6757], init state:[ 2 16 22  0  0  0  0  0], end state:[ 4 16 22  0  0  0  0  0], runtime(seconds):[425.11]
INFO:Reinforcement.Functions:Optimal models save history:[(33, [('Actor', 0), ('Critic', 0)]), (37, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2712.399999999999, [37]) , maxSequence:(25, [40])
INFO:Reinforcement.Functions:episode: 41, score:[2662.00], loss:[10.45868], sequence:[26], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[98], eInit:[0.6690], init state:[ 3  4 29  0  0  0  0  0], end state:[ 5  4 29  0  0  0  0  0], runtime(seconds):[425.71]
INFO:Reinforcement.Functions:episode: 42, score:[2694.40], loss:[9.56218], sequence:[27], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[88], eInit:[0.6623], init state:[ 3 16 36  0  0  0  0  0], end state:[ 5 16 36  0  0  0  0  0], runtime(seconds):[425.95]
INFO:Reinforcement.Functions:episode: 43, score:[2640.00], loss:[9.26131], sequence:[28], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.10], random actions:[94], eInit:[0.6557], init state:[ 4  4 43  0  0  0  0  0], end state:[ 6  4 43  0  0  0  0  0], runtime(seconds):[424.60]
INFO:Reinforcement.Functions:episode: 44, score:[2727.60], loss:[9.74961], sequence:[29], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[78], eInit:[0.6491], init state:[ 4 16 50  0  0  0  0  0], end state:[ 6 16 50  0  0  0  0  0], runtime(seconds):[425.49]
INFO:Reinforcement.Functions:episode: 45, score:[2664.80], loss:[9.53975], sequence:[30], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[82], eInit:[0.6426], init state:[ 5  4 57  0  0  0  0  0], end state:[ 0  4 57  0  0  0  0  0], runtime(seconds):[425.12]
INFO:Reinforcement.Functions:episode: 46, score:[2718.00], loss:[9.60950], sequence:[31], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[75], eInit:[0.6362], init state:[ 5 17  4  0  0  0  0  0], end state:[ 0 17  4  0  0  0  0  0], runtime(seconds):[425.14]
INFO:Reinforcement.Functions:episode: 47, score:[2708.80], loss:[9.61383], sequence:[32], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[79], eInit:[0.6298], init state:[ 6  5 11  0  0  0  0  0], end state:[ 1  5 11  0  0  0  0  0], runtime(seconds):[425.39]
INFO:Reinforcement.Functions:episode: 48, score:[2731.60], loss:[9.54067], sequence:[33], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[74], eInit:[0.6235], init state:[ 6 17 18  0  0  0  0  0], end state:[ 1 17 18  0  0  0  0  0], runtime(seconds):[426.17]
INFO:Reinforcement.Functions:episode: 49, score:[2718.80], loss:[8.74416], sequence:[34], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.03], random actions:[108], eInit:[0.6173], init state:[ 0  5 25  0  0  0  0  0], end state:[ 2  5 25  0  0  0  0  0], runtime(seconds):[426.17]
INFO:Reinforcement.Functions:episode: 50, score:[2743.60], loss:[8.46389], sequence:[35], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[82], eInit:[0.6111], init state:[ 0 17 32  0  0  0  0  0], end state:[ 2 17 32  0  0  0  0  0], runtime(seconds):[423.50]
INFO:Reinforcement.Functions:Optimal models save history:[(44, [('Actor', 2), ('Critic', 2)]), (48, [('Actor', 0), ('Critic', 0)]), (50, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2743.599999999999, [50]) , maxSequence:(35, [50])
INFO:Reinforcement.Functions:episode: 51, score:[2693.60], loss:[9.44776], sequence:[36], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[86], eInit:[0.6050], init state:[ 1  5 39  0  0  0  0  0], end state:[ 3  5 39  0  0  0  0  0], runtime(seconds):[424.58]
INFO:Reinforcement.Functions:episode: 52, score:[2749.20], loss:[9.46253], sequence:[37], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[72], eInit:[0.5990], init state:[ 1 17 46  0  0  0  0  0], end state:[ 3 17 46  0  0  0  0  0], runtime(seconds):[424.57]
INFO:Reinforcement.Functions:episode: 53, score:[2740.00], loss:[7.82895], sequence:[38], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[70], eInit:[0.5930], init state:[ 2  5 53  0  0  0  0  0], end state:[ 4  5 53  0  0  0  0  0], runtime(seconds):[423.85]
INFO:Reinforcement.Functions:episode: 54, score:[2664.40], loss:[9.21216], sequence:[39], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[80], eInit:[0.5870], init state:[ 2 18  0  0  0  0  0  0], end state:[ 4 18  0  0  0  0  0  0], runtime(seconds):[423.88]
INFO:Reinforcement.Functions:episode: 55, score:[2678.00], loss:[8.95485], sequence:[40], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[104], eInit:[0.5812], init state:[3 6 7 0 0 0 0 0], end state:[5 6 7 0 0 0 0 0], runtime(seconds):[423.84]
INFO:Reinforcement.Functions:episode: 56, score:[2716.40], loss:[8.94212], sequence:[41], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[77], eInit:[0.5754], init state:[ 3 18 14  0  0  0  0  0], end state:[ 5 18 14  1  1  0  1  0], runtime(seconds):[424.06]
INFO:Reinforcement.Functions:episode: 57, score:[2624.40], loss:[9.38337], sequence:[42], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[82], eInit:[0.5696], init state:[ 4  6 21  0  0  0  0  0], end state:[ 6  6 21  0  0  0  0  0], runtime(seconds):[422.99]
INFO:Reinforcement.Functions:episode: 58, score:[2666.80], loss:[9.03051], sequence:[43], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[88], eInit:[0.5639], init state:[ 4 18 28  0  0  0  0  0], end state:[ 6 18 28  0  0  0  0  0], runtime(seconds):[422.89]
INFO:Reinforcement.Functions:episode: 59, score:[2640.80], loss:[9.59304], sequence:[44], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.09], random actions:[80], eInit:[0.5583], init state:[ 5  6 35  0  0  0  0  0], end state:[ 0  6 35  0  0  0  0  0], runtime(seconds):[423.84]
INFO:Reinforcement.Functions:episode: 60, score:[2697.20], loss:[8.73592], sequence:[45], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[77], eInit:[0.5527], init state:[ 5 18 42  1  1  0  1  0], end state:[ 0 18 42  0  0  0  0  0], runtime(seconds):[423.72]
INFO:Reinforcement.Functions:Optimal models save history:[(52, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2749.199999999996, [52]) , maxSequence:(45, [60])
INFO:Reinforcement.Functions:episode: 61, score:[2757.20], loss:[8.05718], sequence:[46], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[63], eInit:[0.5472], init state:[ 6  6 49  0  0  0  0  0], end state:[ 1  6 49  0  0  0  0  0], runtime(seconds):[425.04]
INFO:Reinforcement.Functions:episode: 62, score:[2729.60], loss:[8.20081], sequence:[47], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[84], eInit:[0.5417], init state:[ 6 18 56  0  0  0  0  0], end state:[ 1 18 56  0  0  0  0  0], runtime(seconds):[423.99]
INFO:Reinforcement.Functions:episode: 63, score:[2680.80], loss:[9.03627], sequence:[48], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[101], eInit:[0.5363], init state:[0 7 3 0 0 0 0 0], end state:[2 7 3 0 0 0 0 0], runtime(seconds):[423.06]
INFO:Reinforcement.Functions:episode: 64, score:[2748.00], loss:[7.76257], sequence:[49], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[87], eInit:[0.5309], init state:[ 0 19 10  0  0  0  0  0], end state:[ 2 19 10  0  0  0  0  0], runtime(seconds):[423.36]
INFO:Reinforcement.Functions:episode: 65, score:[2756.80], loss:[7.01983], sequence:[50], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[78], eInit:[0.5256], init state:[ 1  7 17  0  0  0  0  0], end state:[ 3  7 17  0  0  0  0  0], runtime(seconds):[425.08]
INFO:Reinforcement.Functions:episode: 66, score:[2718.40], loss:[8.17987], sequence:[51], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[77], eInit:[0.5203], init state:[ 1 19 24  0  0  0  0  0], end state:[ 3 19 24  0  0  0  0  0], runtime(seconds):[423.81]
INFO:Reinforcement.Functions:episode: 67, score:[2744.40], loss:[9.44053], sequence:[52], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[76], eInit:[0.5151], init state:[ 2  7 31  0  0  0  0  0], end state:[ 4  7 31  0  0  0  0  0], runtime(seconds):[423.95]
INFO:Reinforcement.Functions:episode: 68, score:[2639.60], loss:[8.38272], sequence:[53], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[88], eInit:[0.5100], init state:[ 2 19 38  0  0  0  0  0], end state:[ 4 19 38  0  0  0  0  0], runtime(seconds):[425.17]
INFO:Reinforcement.Functions:episode: 69, score:[2708.40], loss:[9.27171], sequence:[54], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[69], eInit:[0.5049], init state:[ 3  7 45  0  0  0  0  0], end state:[ 5  7 45  0  0  0  0  0], runtime(seconds):[425.83]
INFO:Reinforcement.Functions:episode: 70, score:[2729.20], loss:[8.24004], sequence:[55], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[90], eInit:[0.4998], init state:[ 3 19 52  0  0  0  0  0], end state:[ 5 19 52  1  0  0  1  0], runtime(seconds):[423.39]
INFO:Reinforcement.Functions:Optimal models save history:[(61, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(2757.1999999999975, [61]) , maxSequence:(55, [70])
INFO:Reinforcement.Functions:episode: 71, score:[2665.20], loss:[8.16817], sequence:[56], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[86], eInit:[0.4948], init state:[ 4  7 59  0  0  0  0  0], end state:[ 6  7 59  0  0  0  0  0], runtime(seconds):[425.12]
INFO:Reinforcement.Functions:episode: 72, score:[2744.80], loss:[7.15716], sequence:[57], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[53], eInit:[0.4899], init state:[ 4 20  6  0  0  0  0  0], end state:[ 6 20  6  0  0  0  0  0], runtime(seconds):[422.79]
INFO:Reinforcement.Functions:episode: 73, score:[2664.40], loss:[8.52738], sequence:[58], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[84], eInit:[0.4850], init state:[ 5  8 13  0  0  0  0  0], end state:[ 0  8 13  0  0  0  0  0], runtime(seconds):[422.68]
INFO:Reinforcement.Functions:episode: 74, score:[2704.00], loss:[8.53446], sequence:[59], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[68], eInit:[0.4801], init state:[ 5 20 20  1  0  0  0  0], end state:[ 0 20 20  0  0  0  0  0], runtime(seconds):[423.26]
INFO:Reinforcement.Functions:episode: 75, score:[2733.60], loss:[7.30890], sequence:[60], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[88], eInit:[0.4753], init state:[ 6  8 27  1  0  0  0  0], end state:[ 1  8 27  1  0  0  0  0], runtime(seconds):[423.67]
INFO:Reinforcement.Functions:episode: 76, score:[2743.60], loss:[8.43035], sequence:[61], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[70], eInit:[0.4706], init state:[ 6 20 34  1  1  0  0  0], end state:[ 1 20 34  1  1  0  0  0], runtime(seconds):[423.50]
INFO:Reinforcement.Functions:episode: 77, score:[2746.00], loss:[6.52891], sequence:[62], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[77], eInit:[0.4659], init state:[ 0  8 41  1  1  0  1  0], end state:[ 2  8 41  1  1  0  1  0], runtime(seconds):[423.17]
INFO:Reinforcement.Functions:episode: 78, score:[2753.20], loss:[6.84966], sequence:[63], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[75], eInit:[0.4612], init state:[ 0 20 48  1  1  0  1  0], end state:[ 2 20 48  1  1  0  1  0], runtime(seconds):[424.28]
INFO:Reinforcement.Functions:episode: 79, score:[2756.00], loss:[6.35208], sequence:[64], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[80], eInit:[0.4566], init state:[ 1  8 55  1  1  0  0  0], end state:[ 3  8 55  1  1  0  0  0], runtime(seconds):[424.54]
INFO:Reinforcement.Functions:episode: 80, score:[2747.20], loss:[7.36131], sequence:[65], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[67], eInit:[0.4520], init state:[ 1 21  2  1  1  0  1  0], end state:[ 3 21  2  1  1  0  1  0], runtime(seconds):[424.78]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2757.1999999999975, [61]) , maxSequence:(65, [80])
INFO:Reinforcement.Functions:episode: 81, score:[2770.80], loss:[6.32734], sequence:[66], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[67], eInit:[0.4475], init state:[2 9 9 0 0 0 0 0], end state:[4 9 9 0 0 0 0 0], runtime(seconds):[424.61]
INFO:Reinforcement.Functions:episode: 82, score:[2726.40], loss:[6.28646], sequence:[67], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[60], eInit:[0.4430], init state:[ 2 21 16  1  1  0  1  0], end state:[ 4 21 16  0  0  0  0  0], runtime(seconds):[425.10]
INFO:Reinforcement.Functions:episode: 83, score:[2756.40], loss:[6.35139], sequence:[68], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[64], eInit:[0.4386], init state:[ 3  9 23  0  0  0  0  0], end state:[ 5  9 23  0  0  0  0  0], runtime(seconds):[424.27]
INFO:Reinforcement.Functions:episode: 84, score:[2740.40], loss:[6.37143], sequence:[69], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[70], eInit:[0.4342], init state:[ 3 21 30  1  0  0  0  0], end state:[ 5 21 30  1  0  0  0  0], runtime(seconds):[422.28]
INFO:Reinforcement.Functions:episode: 85, score:[2658.00], loss:[7.06264], sequence:[70], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[75], eInit:[0.4299], init state:[ 4  9 37  1  0  0  0  0], end state:[ 6  9 37  0  0  0  0  0], runtime(seconds):[423.40]
INFO:Reinforcement.Functions:episode: 86, score:[2746.00], loss:[6.77541], sequence:[71], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[71], eInit:[0.4256], init state:[ 4 21 44  0  0  0  0  0], end state:[ 6 21 44  1  0  0  0  0], runtime(seconds):[424.02]
INFO:Reinforcement.Functions:episode: 87, score:[2728.40], loss:[7.28190], sequence:[72], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[68], eInit:[0.4213], init state:[ 5  9 51  0  0  0  0  0], end state:[ 0  9 51  0  0  0  0  0], runtime(seconds):[423.16]
INFO:Reinforcement.Functions:episode: 88, score:[2717.60], loss:[6.55782], sequence:[73], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[76], eInit:[0.4171], init state:[ 5 21 58  1  0  0  1  0], end state:[ 0 21 58  1  0  0  0  0], runtime(seconds):[424.02]
INFO:Reinforcement.Functions:episode: 89, score:[2766.40], loss:[6.84990], sequence:[74], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[77], eInit:[0.4129], init state:[ 6 10  5  0  0  0  0  0], end state:[ 1 10  5  0  0  0  0  0], runtime(seconds):[424.34]
INFO:Reinforcement.Functions:episode: 90, score:[2788.80], loss:[5.37595], sequence:[75], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[58], eInit:[0.4088], init state:[ 6 22 12  1  0  0  0  0], end state:[ 1 22 12  1  0  0  0  0], runtime(seconds):[424.36]
INFO:Reinforcement.Functions:Optimal models save history:[(81, [('Actor', 2), ('Critic', 2)]), (90, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(2788.799999999998, [90]) , maxSequence:(75, [90])
INFO:Reinforcement.Functions:episode: 91, score:[2789.20], loss:[5.71727], sequence:[76], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[62], eInit:[0.4047], init state:[ 0 10 19  0  0  0  0  0], end state:[ 2 10 19  0  0  0  0  0], runtime(seconds):[424.43]
INFO:Reinforcement.Functions:episode: 92, score:[2761.20], loss:[5.61017], sequence:[77], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[73], eInit:[0.4007], init state:[ 0 22 26  1  0  0  0  0], end state:[ 2 22 26  1  0  0  0  0], runtime(seconds):[424.83]
INFO:Reinforcement.Functions:episode: 93, score:[2752.00], loss:[5.04342], sequence:[78], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[82], eInit:[0.3967], init state:[ 1 10 33  0  0  0  0  0], end state:[ 3 10 33  0  0  0  0  0], runtime(seconds):[424.73]
INFO:Reinforcement.Functions:episode: 94, score:[2776.00], loss:[5.29527], sequence:[79], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[68], eInit:[0.3927], init state:[ 1 22 40  1  0  0  0  0], end state:[ 3 22 40  1  0  0  0  0], runtime(seconds):[423.46]
INFO:Reinforcement.Functions:episode: 95, score:[2775.60], loss:[5.06818], sequence:[80], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[58], eInit:[0.3888], init state:[ 2 10 47  0  0  0  0  0], end state:[ 4 10 47  1  1  0  1  0], runtime(seconds):[424.10]
INFO:Reinforcement.Functions:episode: 96, score:[2753.60], loss:[4.84482], sequence:[81], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[66], eInit:[0.3849], init state:[ 2 22 54  1  0  0  0  0], end state:[ 4 22 54  0  0  0  0  0], runtime(seconds):[424.28]
INFO:Reinforcement.Functions:episode: 97, score:[2723.60], loss:[5.29245], sequence:[82], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[61], eInit:[0.3810], init state:[ 3 11  1  0  0  0  0  0], end state:[ 5 11  1  0  0  0  0  0], runtime(seconds):[423.90]
INFO:Reinforcement.Functions:episode: 98, score:[2692.40], loss:[5.38906], sequence:[83], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[70], eInit:[0.3772], init state:[ 3 23  8  1  0  0  0  0], end state:[ 5 23  8  1  0  0  1  0], runtime(seconds):[423.15]
INFO:Reinforcement.Functions:episode: 99, score:[2726.00], loss:[5.99272], sequence:[84], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[59], eInit:[0.3735], init state:[ 4 11 15  1  1  0  0  0], end state:[ 6 11 15  0  0  0  0  0], runtime(seconds):[424.58]
INFO:Reinforcement.Functions:episode: 100, score:[2715.20], loss:[6.09103], sequence:[85], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[67], eInit:[0.3697], init state:[ 4 23 22  0  0  0  0  0], end state:[ 6 23 22  1  1  0  1  0], runtime(seconds):[424.36]
INFO:Reinforcement.Functions:Optimal models save history:[(91, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2789.1999999999966, [91]) , maxSequence:(85, [100])
INFO:Reinforcement.Functions:episode: 101, score:[2666.80], loss:[6.95305], sequence:[86], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[63], eInit:[0.3660], init state:[ 5 11 29  0  0  0  0  0], end state:[ 0 11 29  0  0  0  0  0], runtime(seconds):[423.17]
INFO:Reinforcement.Functions:episode: 102, score:[2774.80], loss:[6.29257], sequence:[87], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[60], eInit:[0.3624], init state:[ 5 23 36  1  0  0  0  0], end state:[ 0 23 36  1  0  0  1  0], runtime(seconds):[424.48]
INFO:Reinforcement.Functions:episode: 103, score:[2726.80], loss:[6.35964], sequence:[88], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[67], eInit:[0.3587], init state:[ 6 11 43  0  0  0  0  0], end state:[ 1 11 43  0  0  0  0  0], runtime(seconds):[424.25]
INFO:Reinforcement.Functions:episode: 104, score:[2769.20], loss:[5.55160], sequence:[89], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[53], eInit:[0.3552], init state:[ 6 23 50  1  0  0  0  0], end state:[ 1 23 50  1  0  0  0  0], runtime(seconds):[423.66]
INFO:Reinforcement.Functions:episode: 105, score:[2787.20], loss:[5.18988], sequence:[90], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[70], eInit:[0.3516], init state:[ 0 11 57  0  0  0  0  0], end state:[ 2 11 57  0  0  0  0  0], runtime(seconds):[423.27]
INFO:Reinforcement.Functions:episode: 106, score:[2791.20], loss:[5.18515], sequence:[91], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[55], eInit:[0.3481], init state:[1 0 4 1 0 0 0 0], end state:[3 0 4 1 0 0 0 0], runtime(seconds):[424.28]
INFO:Reinforcement.Functions:episode: 107, score:[2790.80], loss:[4.75100], sequence:[92], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[57], eInit:[0.3446], init state:[ 1 12 11  0  0  0  0  0], end state:[ 3 12 11  0  0  0  0  0], runtime(seconds):[424.71]
INFO:Reinforcement.Functions:episode: 108, score:[2764.00], loss:[5.49937], sequence:[93], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[70], eInit:[0.3412], init state:[ 2  0 18  1  0  0  0  0], end state:[ 4  0 18  1  0  0  0  0], runtime(seconds):[424.19]
INFO:Reinforcement.Functions:episode: 109, score:[2737.60], loss:[5.78263], sequence:[94], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[50], eInit:[0.3378], init state:[ 2 12 25  0  0  0  0  0], end state:[ 4 12 25  1  1  0  0  0], runtime(seconds):[424.99]
INFO:Reinforcement.Functions:episode: 110, score:[2730.40], loss:[6.18381], sequence:[95], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[62], eInit:[0.3344], init state:[ 3  0 32  0  0  1  0  0], end state:[ 5  0 32  0  0  0  0  0], runtime(seconds):[424.71]
INFO:Reinforcement.Functions:Optimal models save history:[(106, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2791.199999999997, [106]) , maxSequence:(95, [110])
INFO:Reinforcement.Functions:episode: 111, score:[2733.20], loss:[6.44514], sequence:[96], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[67], eInit:[0.3310], init state:[ 3 12 39  0  0  0  0  0], end state:[ 5 12 39  0  0  0  0  0], runtime(seconds):[423.09]
INFO:Reinforcement.Functions:episode: 112, score:[2748.00], loss:[5.36043], sequence:[97], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[48], eInit:[0.3277], init state:[ 4  0 46  1  0  1  0  0], end state:[ 6  0 46  0  0  1  0  0], runtime(seconds):[423.10]
INFO:Reinforcement.Functions:episode: 113, score:[2790.80], loss:[5.62174], sequence:[98], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[41], eInit:[0.3244], init state:[ 4 12 53  1  1  0  1  0], end state:[ 6 12 53  0  0  0  0  0], runtime(seconds):[423.44]
INFO:Reinforcement.Functions:episode: 114, score:[2744.40], loss:[5.96282], sequence:[99], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[64], eInit:[0.3212], init state:[5 1 0 0 0 0 0 0], end state:[0 1 0 0 0 1 0 0], runtime(seconds):[423.27]
INFO:Reinforcement.Functions:episode: 115, score:[2778.40], loss:[5.21553], sequence:[100], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.3180], init state:[ 5 13  7  0  0  0  0  0], end state:[ 0 13  7  0  0  0  0  0], runtime(seconds):[423.12]
INFO:Reinforcement.Functions:episode: 116, score:[2754.80], loss:[5.84694], sequence:[101], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[56], eInit:[0.3148], init state:[ 6  1 14  0  0  0  0  0], end state:[ 1  1 14  0  0  0  0  0], runtime(seconds):[424.22]
INFO:Reinforcement.Functions:episode: 117, score:[2774.80], loss:[6.00815], sequence:[102], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[55], eInit:[0.3117], init state:[ 6 13 21  0  0  0  0  0], end state:[ 1 13 21  0  0  0  0  0], runtime(seconds):[424.81]
INFO:Reinforcement.Functions:episode: 118, score:[2777.60], loss:[5.36640], sequence:[103], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[61], eInit:[0.3085], init state:[ 0  1 28  0  0  0  0  0], end state:[ 2  1 28  0  0  0  0  0], runtime(seconds):[423.36]
INFO:Reinforcement.Functions:episode: 119, score:[2792.00], loss:[5.27533], sequence:[104], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[60], eInit:[0.3055], init state:[ 0 13 35  0  0  0  0  0], end state:[ 2 13 35  0  0  0  0  0], runtime(seconds):[424.52]
INFO:Reinforcement.Functions:episode: 120, score:[2810.00], loss:[4.84460], sequence:[105], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[54], eInit:[0.3024], init state:[ 1  1 42  0  0  0  0  0], end state:[ 3  1 42  0  0  0  0  0], runtime(seconds):[424.12]
INFO:Reinforcement.Functions:Optimal models save history:[(119, [('Actor', 0), ('Critic', 0)]), (120, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2809.999999999998, [120]) , maxSequence:(105, [120])
INFO:Reinforcement.Functions:episode: 121, score:[2788.00], loss:[5.25824], sequence:[106], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.2994], init state:[ 1 13 49  0  0  0  0  0], end state:[ 3 13 49  0  0  0  0  0], runtime(seconds):[423.66]
INFO:Reinforcement.Functions:episode: 122, score:[2796.80], loss:[4.72838], sequence:[107], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[48], eInit:[0.2964], init state:[ 2  1 56  0  0  0  0  0], end state:[ 4  1 56  0  0  0  0  0], runtime(seconds):[423.80]
INFO:Reinforcement.Functions:episode: 123, score:[2731.60], loss:[5.45024], sequence:[108], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[46], eInit:[0.2934], init state:[ 2 14  3  0  0  0  0  0], end state:[ 4 14  3  0  0  0  0  0], runtime(seconds):[424.16]
INFO:Reinforcement.Functions:episode: 124, score:[2767.60], loss:[5.58653], sequence:[109], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[56], eInit:[0.2905], init state:[ 3  2 10  0  0  0  0  0], end state:[ 5  2 10  0  0  0  0  0], runtime(seconds):[423.46]
INFO:Reinforcement.Functions:episode: 125, score:[2763.20], loss:[4.81741], sequence:[110], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[54], eInit:[0.2876], init state:[ 3 14 17  0  0  0  0  0], end state:[ 5 14 17  0  0  0  0  0], runtime(seconds):[422.53]
INFO:Reinforcement.Functions:episode: 126, score:[2762.40], loss:[4.78897], sequence:[111], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[43], eInit:[0.2847], init state:[ 4  2 24  0  0  0  0  0], end state:[ 6  2 24  0  0  0  0  0], runtime(seconds):[423.33]
INFO:Reinforcement.Functions:episode: 127, score:[2706.80], loss:[5.87007], sequence:[112], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[59], eInit:[0.2819], init state:[ 4 14 31  0  0  0  0  0], end state:[ 6 14 31  0  0  0  0  0], runtime(seconds):[423.59]
INFO:Reinforcement.Functions:episode: 128, score:[2791.20], loss:[4.99201], sequence:[113], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[48], eInit:[0.2790], init state:[ 5  2 38  0  0  0  0  0], end state:[ 0  2 38  0  0  0  0  0], runtime(seconds):[422.96]
INFO:Reinforcement.Functions:episode: 129, score:[2740.00], loss:[5.18613], sequence:[114], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[52], eInit:[0.2763], init state:[ 5 14 45  0  0  0  0  0], end state:[ 0 14 45  0  0  0  0  0], runtime(seconds):[424.44]
INFO:Reinforcement.Functions:episode: 130, score:[2762.40], loss:[6.40876], sequence:[115], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[52], eInit:[0.2735], init state:[ 6  2 52  0  0  0  0  0], end state:[ 1  2 52  0  0  0  0  0], runtime(seconds):[424.58]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2809.999999999998, [120]) , maxSequence:(115, [130])
INFO:Reinforcement.Functions:episode: 131, score:[2726.80], loss:[5.75653], sequence:[116], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[61], eInit:[0.2708], init state:[ 6 14 59  0  0  0  0  0], end state:[ 1 14 59  0  0  0  0  0], runtime(seconds):[424.42]
INFO:Reinforcement.Functions:episode: 132, score:[2800.80], loss:[5.05092], sequence:[117], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[50], eInit:[0.2680], init state:[0 3 6 0 0 0 0 0], end state:[2 3 6 0 0 0 0 0], runtime(seconds):[423.34]
INFO:Reinforcement.Functions:episode: 133, score:[2766.00], loss:[4.51966], sequence:[118], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[55], eInit:[0.2654], init state:[ 0 15 13  0  0  0  0  0], end state:[ 2 15 13  0  0  0  0  0], runtime(seconds):[423.99]
INFO:Reinforcement.Functions:episode: 134, score:[2821.60], loss:[4.54621], sequence:[119], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[43], eInit:[0.2627], init state:[ 1  3 20  0  0  0  0  0], end state:[ 3  3 20  0  0  0  0  0], runtime(seconds):[423.98]
INFO:Reinforcement.Functions:episode: 135, score:[2810.00], loss:[4.54353], sequence:[120], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[49], eInit:[0.2601], init state:[ 1 15 27  0  0  0  0  0], end state:[ 3 15 27  0  0  0  0  0], runtime(seconds):[422.62]
INFO:Reinforcement.Functions:episode: 136, score:[2800.40], loss:[3.47764], sequence:[121], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[51], eInit:[0.2575], init state:[ 2  3 34  0  0  0  0  0], end state:[ 4  3 34  0  0  0  0  0], runtime(seconds):[424.30]
INFO:Reinforcement.Functions:episode: 137, score:[2756.80], loss:[3.92583], sequence:[122], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[48], eInit:[0.2549], init state:[ 2 15 41  0  0  0  0  0], end state:[ 4 15 41  0  0  0  0  0], runtime(seconds):[424.46]
INFO:Reinforcement.Functions:episode: 138, score:[2737.20], loss:[4.80399], sequence:[123], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[47], eInit:[0.2524], init state:[ 3  3 48  0  0  0  0  0], end state:[ 5  3 48  0  0  0  0  0], runtime(seconds):[423.48]
INFO:Reinforcement.Functions:episode: 139, score:[2770.80], loss:[5.46110], sequence:[124], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[52], eInit:[0.2498], init state:[ 3 15 55  0  0  0  0  0], end state:[ 5 15 55  0  0  0  0  0], runtime(seconds):[423.88]
INFO:Reinforcement.Functions:episode: 140, score:[2692.40], loss:[4.14923], sequence:[125], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[56], eInit:[0.2473], init state:[4 4 2 0 0 0 0 0], end state:[6 4 2 0 0 0 0 0], runtime(seconds):[423.65]
INFO:Reinforcement.Functions:Optimal models save history:[(134, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999985, [134]) , maxSequence:(125, [140])
INFO:Reinforcement.Functions:episode: 141, score:[2748.00], loss:[4.64099], sequence:[126], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[55], eInit:[0.2449], init state:[ 4 16  9  0  0  0  0  0], end state:[ 6 16  9  0  0  0  1  0], runtime(seconds):[423.60]
INFO:Reinforcement.Functions:episode: 142, score:[2773.20], loss:[4.74306], sequence:[127], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[53], eInit:[0.2424], init state:[ 5  4 16  0  0  0  0  0], end state:[ 0  4 16  0  0  0  0  0], runtime(seconds):[422.44]
INFO:Reinforcement.Functions:episode: 143, score:[2766.40], loss:[4.98496], sequence:[128], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[47], eInit:[0.2400], init state:[ 5 16 23  0  0  0  0  0], end state:[ 0 16 23  0  0  0  0  0], runtime(seconds):[423.55]
INFO:Reinforcement.Functions:episode: 144, score:[2788.80], loss:[4.24292], sequence:[129], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.2376], init state:[ 6  4 30  0  0  0  0  0], end state:[ 1  4 30  0  0  0  0  0], runtime(seconds):[423.74]
INFO:Reinforcement.Functions:episode: 145, score:[2812.40], loss:[4.43884], sequence:[130], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[43], eInit:[0.2352], init state:[ 6 16 37  0  0  0  0  0], end state:[ 1 16 37  0  0  0  0  0], runtime(seconds):[422.56]
INFO:Reinforcement.Functions:episode: 146, score:[2800.00], loss:[4.30784], sequence:[131], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[49], eInit:[0.2329], init state:[ 0  4 44  0  0  0  0  0], end state:[ 2  4 44  0  0  0  0  0], runtime(seconds):[423.67]
INFO:Reinforcement.Functions:episode: 147, score:[2781.20], loss:[4.21002], sequence:[132], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[45], eInit:[0.2305], init state:[ 0 16 51  0  0  0  0  0], end state:[ 2 16 51  0  0  0  0  0], runtime(seconds):[424.86]
INFO:Reinforcement.Functions:episode: 148, score:[2810.00], loss:[4.10581], sequence:[133], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[43], eInit:[0.2282], init state:[ 1  4 58  0  0  0  0  0], end state:[ 3  4 58  0  0  0  0  0], runtime(seconds):[424.52]
INFO:Reinforcement.Functions:episode: 149, score:[2811.60], loss:[4.24039], sequence:[134], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[44], eInit:[0.2259], init state:[ 1 17  5  0  0  0  0  0], end state:[ 3 17  5  0  0  0  0  0], runtime(seconds):[423.24]
INFO:Reinforcement.Functions:episode: 150, score:[2770.40], loss:[4.30020], sequence:[135], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[47], eInit:[0.2237], init state:[ 2  5 12  0  0  0  0  0], end state:[ 4  5 12  0  0  0  0  0], runtime(seconds):[424.60]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999985, [134]) , maxSequence:(135, [150])
INFO:Reinforcement.Functions:episode: 151, score:[2715.20], loss:[5.72562], sequence:[136], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[44], eInit:[0.2215], init state:[ 2 17 19  0  0  0  0  0], end state:[ 4 17 19  0  0  0  0  0], runtime(seconds):[424.11]
INFO:Reinforcement.Functions:episode: 152, score:[2758.40], loss:[5.45774], sequence:[137], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[50], eInit:[0.2192], init state:[ 3  5 26  0  0  0  0  0], end state:[ 5  5 26  0  0  0  0  0], runtime(seconds):[422.74]
INFO:Reinforcement.Functions:episode: 153, score:[2813.20], loss:[4.31222], sequence:[138], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[37], eInit:[0.2170], init state:[ 3 17 33  0  0  0  0  0], end state:[ 5 17 33  0  0  0  0  0], runtime(seconds):[423.23]
INFO:Reinforcement.Functions:episode: 154, score:[2758.00], loss:[4.48725], sequence:[139], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[52], eInit:[0.2149], init state:[ 4  5 40  0  0  0  0  0], end state:[ 6  5 40  0  0  0  0  0], runtime(seconds):[423.26]
INFO:Reinforcement.Functions:episode: 155, score:[2756.00], loss:[4.66655], sequence:[140], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[53], eInit:[0.2127], init state:[ 4 17 47  0  0  0  0  0], end state:[ 6 17 47  0  0  0  0  0], runtime(seconds):[422.30]
INFO:Reinforcement.Functions:episode: 156, score:[2675.20], loss:[4.90642], sequence:[141], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[54], eInit:[0.2106], init state:[ 5  5 54  0  0  0  0  0], end state:[ 0  5 54  0  0  0  0  0], runtime(seconds):[423.27]
INFO:Reinforcement.Functions:episode: 157, score:[2774.40], loss:[5.37797], sequence:[142], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[43], eInit:[0.2085], init state:[ 5 18  1  1  1  0  1  0], end state:[ 0 18  1  0  0  0  0  0], runtime(seconds):[424.69]
INFO:Reinforcement.Functions:episode: 158, score:[2775.60], loss:[5.00342], sequence:[143], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[35], eInit:[0.2064], init state:[6 6 8 0 0 0 0 0], end state:[1 6 8 0 0 0 0 0], runtime(seconds):[424.05]
INFO:Reinforcement.Functions:episode: 159, score:[2752.40], loss:[5.01665], sequence:[144], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[48], eInit:[0.2043], init state:[ 6 18 15  0  0  0  0  0], end state:[ 1 18 15  0  0  0  0  0], runtime(seconds):[423.04]
INFO:Reinforcement.Functions:episode: 160, score:[2810.80], loss:[4.86687], sequence:[145], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[44], eInit:[0.2023], init state:[ 0  6 22  0  0  0  0  0], end state:[ 2  6 22  0  0  0  0  0], runtime(seconds):[423.92]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999985, [134]) , maxSequence:(145, [160])
INFO:Reinforcement.Functions:episode: 161, score:[2802.80], loss:[4.33829], sequence:[146], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[40], eInit:[0.2003], init state:[ 0 18 29  0  0  0  0  0], end state:[ 2 18 29  0  1  1  1  1], runtime(seconds):[425.76]
INFO:Reinforcement.Functions:episode: 162, score:[2798.80], loss:[4.12115], sequence:[147], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[47], eInit:[0.1983], init state:[ 1  6 36  0  0  0  0  0], end state:[ 3  6 36  0  0  0  0  0], runtime(seconds):[423.09]
INFO:Reinforcement.Functions:episode: 163, score:[2786.80], loss:[4.85286], sequence:[148], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[49], eInit:[0.1963], init state:[ 1 18 43  0  0  0  0  0], end state:[ 3 18 43  0  0  0  0  0], runtime(seconds):[424.12]
INFO:Reinforcement.Functions:episode: 164, score:[2803.20], loss:[4.63620], sequence:[149], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[47], eInit:[0.1943], init state:[ 2  6 50  0  0  0  0  0], end state:[ 4  6 50  0  0  0  0  0], runtime(seconds):[425.79]
INFO:Reinforcement.Functions:episode: 165, score:[2769.60], loss:[4.74189], sequence:[150], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[42], eInit:[0.1924], init state:[ 2 18 57  0  0  0  0  0], end state:[ 4 18 57  0  0  0  0  0], runtime(seconds):[427.05]
INFO:Reinforcement.Functions:episode: 166, score:[2746.80], loss:[4.81140], sequence:[151], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[40], eInit:[0.1905], init state:[3 7 4 0 0 0 0 0], end state:[5 7 4 0 0 0 0 0], runtime(seconds):[422.32]
INFO:Reinforcement.Functions:episode: 167, score:[2722.80], loss:[5.67537], sequence:[152], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[35], eInit:[0.1886], init state:[ 3 19 11  0  0  0  0  0], end state:[ 5 19 11  1  0  0  1  0], runtime(seconds):[440.35]
INFO:Reinforcement.Functions:episode: 168, score:[2739.20], loss:[4.86328], sequence:[153], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[52], eInit:[0.1867], init state:[ 4  7 18  0  0  0  0  0], end state:[ 6  7 18  0  0  0  0  0], runtime(seconds):[442.01]
INFO:Reinforcement.Functions:episode: 169, score:[2768.40], loss:[5.43133], sequence:[154], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[47], eInit:[0.1848], init state:[ 4 19 25  0  0  0  0  0], end state:[ 6 19 25  0  0  0  0  0], runtime(seconds):[424.28]
INFO:Reinforcement.Functions:episode: 170, score:[2745.20], loss:[5.74566], sequence:[155], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[53], eInit:[0.1830], init state:[ 5  7 32  0  0  0  0  0], end state:[ 0  7 32  0  0  0  0  0], runtime(seconds):[427.96]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-30/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999985, [134]) , maxSequence:(155, [170])
INFO:Reinforcement.Functions:episode: 171, score:[2774.80], loss:[5.16373], sequence:[156], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[40], eInit:[0.1811], init state:[ 5 19 39  1  0  0  1  0], end state:[ 0 19 39  0  0  0  0  0], runtime(seconds):[427.24]
INFO:Reinforcement.Functions:episode: 172, score:[2793.20], loss:[5.46491], sequence:[157], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[42], eInit:[0.1793], init state:[ 6  7 46  0  0  0  0  0], end state:[ 1  7 46  0  0  0  0  0], runtime(seconds):[426.83]
INFO:Reinforcement.Functions:episode: 173, score:[2783.60], loss:[5.35225], sequence:[158], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[32], eInit:[0.1775], init state:[ 6 19 53  0  0  0  0  0], end state:[ 1 19 53  0  0  0  0  0], runtime(seconds):[425.19]
INFO:Reinforcement.Functions:episode: 174, score:[2799.20], loss:[5.02343], sequence:[159], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[48], eInit:[0.1757], init state:[0 8 0 1 0 0 0 0], end state:[2 8 0 0 0 0 0 0], runtime(seconds):[423.81]
INFO:Reinforcement.Functions:episode: 175, score:[2814.00], loss:[4.94697], sequence:[160], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[34], eInit:[0.1740], init state:[ 0 20  7  0  0  0  0  0], end state:[ 2 20  7  0  0  0  0  0], runtime(seconds):[424.60]

INFO:Reinforcement.Functions:args:[{'desc': '"deep model **sequential** 0.9 minGameRatio"', 'gpuFrac': 0.3, 'k': 32, 'random': False, 'settings': '/home/yochaiz/SmartHome/Reinforcement/settings2.json', 'gpuNum': 0, 'sequential': True, 'rewardScale': 1.0}]
INFO:Reinforcement.Functions:results:[{'folderName': 'D-10-4-H-14-19-50', 'fullPath': '/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50', 'loss': [], 'score': [], 'baseFolder': '/home/yochaiz/SmartHome/Reinforcement/DDPG', 'actionDim': 'actionDim-5'}]
INFO:Reinforcement.Functions:Critic:[{'nBackups': 3, 'curBackupIdx': 0, 'actionDim': 5, 'TAU': 0.001}]
INFO:Reinforcement.Functions:settings:[{'nGamesPerSave': 10, 'gameMinutesLength': 2880, 'nEpochs': 1, 'minGameSequence': 500, 'dequeSize': 50000, 'minGameScore': 2592, 'learningRate': 0.001, 'trainSetSize': 64, 'batchSize': 64, 'gamma': 0.99, 'nModelBackups': 3, 'minGameScoreRatio': 0.9, 'TAU': 0.001}]
INFO:Reinforcement.Functions:policy:[{'rewardScaleFactor': 1.0, 'numOfDevices': 5, 'seqLen': 1, 'fname': '/home/yochaiz/SmartHome/Reinforcement/Policies/Week/policy2.json', 'stateDim': (1, 8)}]
INFO:Reinforcement.Functions:Actor:[{'nBackups': 3, 'curBackupIdx': 0, 'actionDim': 5, 'epsilon_min': 0.01, 'TAU': 0.001, 'k': 32, 'epsilon_decay': 0.99, 'nActions': 32, 'epsilon': 1.0}]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:===== DESCRIPTIONS =====
INFO:Reinforcement.Functions:[General]: "deep model **sequential** 0.9 minGameRatio"
INFO:Reinforcement.Functions:[Actor]: Try deeper architecture
INFO:Reinforcement.Functions:[Actor]: Fixed bug where future reward (step 13) used continuous action instead of discrete action
INFO:Reinforcement.Functions:[Actor]: No more threading during replays
INFO:Reinforcement.Functions:[Critic]: Try deeper architecture
INFO:Reinforcement.Functions:===== ============ =====
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 8)              0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 256)            2304      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)              (None, 1, 5)              1285      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 5)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 266,757
INFO:Reinforcement.Functions:Trainable params: 266,757
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 8)         0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 256)       2304        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 5)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_8 (Dense)                 (None, 1, 256)       65792       dense_7[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_9 (Dense)                 (None, 256)          1536        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_8[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_9[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_10 (Dense)                (None, 1, 256)       65792       activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_11 (Dense)                (None, 1, 256)       65792       dense_10[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_12 (Dense)                (None, 1, 256)       65792       dense_11[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_13 (Dense)                (None, 1, 1)         257         dense_12[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_13[0][0]                   
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 267,265
INFO:Reinforcement.Functions:Trainable params: 267,265
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[1838.00], loss:[67.11057], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.36], optActionInPoolButNotSelected:[0.63], random actions:[115], eInit:[1.0000], init state:[ 2 23 17  1  0  0  1  0], end state:[ 4 23 17  0  0  0  0  0], runtime(seconds):[424.16]
INFO:Reinforcement.Functions:episode: 2, score:[2323.20], loss:[43.28847], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.68], optActionInPoolButNotSelected:[0.30], random actions:[103], eInit:[0.9900], init state:[ 3 11 24  0  0  0  0  0], end state:[ 5 11 24  0  0  0  0  0], runtime(seconds):[424.44]
INFO:Reinforcement.Functions:episode: 3, score:[2188.40], loss:[35.54099], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.65], optActionInPoolButNotSelected:[0.32], random actions:[119], eInit:[0.9801], init state:[ 3 23 31  1  0  0  1  0], end state:[ 5 23 31  1  0  0  0  0], runtime(seconds):[424.64]
INFO:Reinforcement.Functions:episode: 4, score:[2308.40], loss:[35.16817], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.67], optActionInPoolButNotSelected:[0.31], random actions:[115], eInit:[0.9703], init state:[ 4 11 38  1  1  0  0  0], end state:[ 6 11 38  1  0  0  0  0], runtime(seconds):[425.58]
INFO:Reinforcement.Functions:episode: 5, score:[2377.60], loss:[32.93078], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.72], optActionInPoolButNotSelected:[0.25], random actions:[114], eInit:[0.9606], init state:[ 4 23 45  0  0  0  0  0], end state:[ 6 23 45  1  0  0  0  0], runtime(seconds):[424.92]
INFO:Reinforcement.Functions:episode: 6, score:[2203.20], loss:[34.84371], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.62], optActionInPoolButNotSelected:[0.35], random actions:[139], eInit:[0.9510], init state:[ 5 11 52  0  0  0  0  0], end state:[ 0 11 52  1  0  0  0  0], runtime(seconds):[425.43]
INFO:Reinforcement.Functions:episode: 7, score:[2204.00], loss:[30.02704], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.59], optActionInPoolButNotSelected:[0.39], random actions:[106], eInit:[0.9415], init state:[ 5 23 59  1  0  0  0  0], end state:[ 0 23 59  1  0  0  1  0], runtime(seconds):[426.05]
INFO:Reinforcement.Functions:episode: 8, score:[2340.40], loss:[33.32010], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.68], optActionInPoolButNotSelected:[0.29], random actions:[113], eInit:[0.9321], init state:[ 6 12  6  0  0  0  0  0], end state:[ 1 12  6  0  0  0  0  0], runtime(seconds):[425.72]
INFO:Reinforcement.Functions:episode: 9, score:[2358.40], loss:[34.47508], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.71], optActionInPoolButNotSelected:[0.26], random actions:[123], eInit:[0.9227], init state:[ 0  0 13  1  0  0  0  0], end state:[ 2  0 13  1  0  0  0  0], runtime(seconds):[424.93]
INFO:Reinforcement.Functions:episode: 10, score:[2480.80], loss:[35.73587], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.80], optActionInPoolButNotSelected:[0.17], random actions:[111], eInit:[0.9135], init state:[ 0 12 20  0  0  0  0  0], end state:[ 2 12 20  0  0  0  0  0], runtime(seconds):[425.24]
INFO:Reinforcement.Functions:Optimal models save history:[(1, [('Actor', 1), ('Critic', 1)]), (2, [('Actor', 2), ('Critic', 2)]), (5, [('Actor', 0), ('Critic', 0)]), (10, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2480.7999999999874, [10]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
INFO:Reinforcement.Functions:episode: 11, score:[2502.40], loss:[31.75522], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.82], optActionInPoolButNotSelected:[0.15], random actions:[119], eInit:[0.9044], init state:[ 1  0 27  1  0  0  0  0], end state:[ 3  0 27  1  0  0  0  0], runtime(seconds):[425.45]
INFO:Reinforcement.Functions:episode: 12, score:[2529.60], loss:[28.54819], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.83], optActionInPoolButNotSelected:[0.15], random actions:[99], eInit:[0.8953], init state:[ 1 12 34  0  0  0  0  0], end state:[ 3 12 34  0  0  0  0  0], runtime(seconds):[424.79]
INFO:Reinforcement.Functions:episode: 13, score:[2562.80], loss:[23.87924], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.84], optActionInPoolButNotSelected:[0.13], random actions:[108], eInit:[0.8864], init state:[ 2  0 41  0  0  1  0  0], end state:[ 4  0 41  1  0  1  0  0], runtime(seconds):[426.06]
INFO:Reinforcement.Functions:episode: 14, score:[2547.20], loss:[25.96350], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.83], optActionInPoolButNotSelected:[0.14], random actions:[128], eInit:[0.8775], init state:[ 2 12 48  0  0  0  0  0], end state:[ 4 12 48  0  0  0  0  0], runtime(seconds):[429.46]
INFO:Reinforcement.Functions:episode: 15, score:[2600.40], loss:[21.40376], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.12], random actions:[100], eInit:[0.8687], init state:[ 3  0 55  0  0  1  0  0], end state:[ 5  0 55  0  0  0  0  0], runtime(seconds):[431.80]
INFO:Reinforcement.Functions:episode: 16, score:[2616.40], loss:[22.56840], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.86], optActionInPoolButNotSelected:[0.10], random actions:[120], eInit:[0.8601], init state:[ 3 13  2  0  0  0  0  0], end state:[ 5 13  2  0  0  0  0  0], runtime(seconds):[429.58]
INFO:Reinforcement.Functions:episode: 17, score:[2580.00], loss:[20.00402], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.84], optActionInPoolButNotSelected:[0.13], random actions:[101], eInit:[0.8515], init state:[4 1 9 0 0 1 0 0], end state:[6 1 9 0 1 0 0 0], runtime(seconds):[429.78]
INFO:Reinforcement.Functions:episode: 18, score:[2650.80], loss:[19.68937], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.09], random actions:[106], eInit:[0.8429], init state:[ 4 13 16  1  1  0  0  0], end state:[ 6 13 16  0  0  0  0  0], runtime(seconds):[428.17]
INFO:Reinforcement.Functions:episode: 19, score:[2628.40], loss:[16.50164], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.10], random actions:[106], eInit:[0.8345], init state:[ 5  1 23  0  0  0  0  0], end state:[ 0  1 23  0  0  0  0  0], runtime(seconds):[425.21]
INFO:Reinforcement.Functions:episode: 20, score:[2592.40], loss:[16.92851], sequence:[3], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.12], random actions:[113], eInit:[0.8262], init state:[ 5 13 30  0  0  0  0  0], end state:[ 0 13 30  0  0  0  0  0], runtime(seconds):[426.71]
INFO:Reinforcement.Functions:Optimal models save history:[(11, [('Actor', 2), ('Critic', 2)]), (12, [('Actor', 0), ('Critic', 0)]), (13, [('Actor', 1), ('Critic', 1)]), (15, [('Actor', 2), ('Critic', 2)]), (16, [('Actor', 0), ('Critic', 0)]), (18, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2650.7999999999824, [18]) , maxSequence:(3, [20])
INFO:Reinforcement.Functions:episode: 21, score:[2622.40], loss:[19.11032], sequence:[4], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[116], eInit:[0.8179], init state:[ 6  1 37  0  0  0  0  0], end state:[ 1  1 37  0  0  0  0  0], runtime(seconds):[426.66]
INFO:Reinforcement.Functions:episode: 22, score:[2641.60], loss:[15.82386], sequence:[5], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[111], eInit:[0.8097], init state:[ 6 13 44  0  0  0  0  0], end state:[ 1 13 44  0  0  0  0  0], runtime(seconds):[427.99]
INFO:Reinforcement.Functions:episode: 23, score:[2642.00], loss:[14.38175], sequence:[6], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[122], eInit:[0.8016], init state:[ 0  1 51  0  0  0  0  0], end state:[ 2  1 51  0  0  0  0  0], runtime(seconds):[427.30]
INFO:Reinforcement.Functions:episode: 24, score:[2631.60], loss:[13.46704], sequence:[7], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[101], eInit:[0.7936], init state:[ 0 13 58  0  0  0  0  0], end state:[ 2 13 58  0  0  0  0  0], runtime(seconds):[427.42]
INFO:Reinforcement.Functions:episode: 25, score:[2655.20], loss:[13.43207], sequence:[8], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[100], eInit:[0.7857], init state:[1 2 5 0 0 0 0 0], end state:[3 2 5 0 0 0 0 0], runtime(seconds):[428.00]
INFO:Reinforcement.Functions:episode: 26, score:[2674.80], loss:[12.90573], sequence:[9], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.06], random actions:[95], eInit:[0.7778], init state:[ 1 14 12  0  0  0  0  0], end state:[ 3 14 12  0  0  0  0  0], runtime(seconds):[427.05]
INFO:Reinforcement.Functions:episode: 27, score:[2685.60], loss:[11.12322], sequence:[10], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.05], random actions:[110], eInit:[0.7700], init state:[ 2  2 19  0  0  0  0  0], end state:[ 4  2 19  0  0  0  0  0], runtime(seconds):[426.89]
INFO:Reinforcement.Functions:episode: 28, score:[2603.20], loss:[10.98540], sequence:[11], isInPoolRatio:[1.00], optActionSelectedRatio:[0.86], optActionInPoolButNotSelected:[0.11], random actions:[98], eInit:[0.7623], init state:[ 2 14 26  0  0  0  0  0], end state:[ 4 14 26  0  0  0  0  0], runtime(seconds):[426.72]
INFO:Reinforcement.Functions:episode: 29, score:[2663.20], loss:[11.60650], sequence:[12], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[104], eInit:[0.7547], init state:[ 3  2 33  0  0  0  0  0], end state:[ 5  2 33  0  0  0  0  0], runtime(seconds):[426.32]
INFO:Reinforcement.Functions:episode: 30, score:[2700.00], loss:[11.27174], sequence:[13], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[91], eInit:[0.7472], init state:[ 3 14 40  0  0  0  0  0], end state:[ 5 14 40  0  0  0  0  0], runtime(seconds):[425.47]
INFO:Reinforcement.Functions:Optimal models save history:[(25, [('Actor', 2), ('Critic', 2)]), (26, [('Actor', 0), ('Critic', 0)]), (27, [('Actor', 1), ('Critic', 1)]), (30, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2699.999999999996, [30]) , maxSequence:(13, [30])
INFO:Reinforcement.Functions:episode: 31, score:[2591.20], loss:[15.07124], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.86], optActionInPoolButNotSelected:[0.11], random actions:[100], eInit:[0.7397], init state:[ 4  2 47  0  0  0  0  0], end state:[ 6  2 47  0  0  0  0  0], runtime(seconds):[425.71]
INFO:Reinforcement.Functions:episode: 32, score:[2684.40], loss:[12.63127], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[87], eInit:[0.7323], init state:[ 4 14 54  0  0  0  0  0], end state:[ 6 14 54  0  0  0  0  0], runtime(seconds):[427.20]
INFO:Reinforcement.Functions:episode: 33, score:[2616.00], loss:[11.05816], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[102], eInit:[0.7250], init state:[5 3 1 0 0 0 0 0], end state:[0 3 1 0 0 0 0 0], runtime(seconds):[426.35]
INFO:Reinforcement.Functions:episode: 34, score:[2643.20], loss:[11.21430], sequence:[3], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[97], eInit:[0.7177], init state:[ 5 15  8  0  0  0  0  0], end state:[ 0 15  8  0  0  0  0  0], runtime(seconds):[427.39]
INFO:Reinforcement.Functions:episode: 35, score:[2658.40], loss:[11.00858], sequence:[4], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[102], eInit:[0.7106], init state:[ 6  3 15  0  0  0  0  0], end state:[ 1  3 15  0  0  0  0  0], runtime(seconds):[427.69]
INFO:Reinforcement.Functions:episode: 36, score:[2659.20], loss:[10.69960], sequence:[5], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[84], eInit:[0.7034], init state:[ 6 15 22  0  0  0  0  0], end state:[ 1 15 22  0  0  0  0  0], runtime(seconds):[427.83]
INFO:Reinforcement.Functions:episode: 37, score:[2720.80], loss:[11.00897], sequence:[6], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[92], eInit:[0.6964], init state:[ 0  3 29  0  0  0  0  0], end state:[ 2  3 29  0  0  0  0  0], runtime(seconds):[427.28]
INFO:Reinforcement.Functions:episode: 38, score:[2674.40], loss:[11.06129], sequence:[7], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[82], eInit:[0.6894], init state:[ 0 15 36  0  0  0  0  0], end state:[ 2 15 36  0  0  0  0  0], runtime(seconds):[427.24]
INFO:Reinforcement.Functions:episode: 39, score:[2702.00], loss:[10.42935], sequence:[8], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[83], eInit:[0.6826], init state:[ 1  3 43  0  0  0  0  0], end state:[ 3  3 43  0  0  0  0  0], runtime(seconds):[427.24]
INFO:Reinforcement.Functions:episode: 40, score:[2761.20], loss:[10.91095], sequence:[9], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[76], eInit:[0.6757], init state:[ 1 15 50  0  0  0  0  0], end state:[ 3 15 50  0  0  0  0  0], runtime(seconds):[426.59]
INFO:Reinforcement.Functions:Optimal models save history:[(37, [('Actor', 0), ('Critic', 0)]), (40, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2761.1999999999975, [40]) , maxSequence:(13, [30])
INFO:Reinforcement.Functions:episode: 41, score:[2726.00], loss:[9.14044], sequence:[10], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.03], random actions:[101], eInit:[0.6690], init state:[ 2  3 57  0  0  0  0  0], end state:[ 4  3 57  0  0  0  0  0], runtime(seconds):[427.10]
INFO:Reinforcement.Functions:episode: 42, score:[2598.00], loss:[10.05401], sequence:[11], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.10], random actions:[90], eInit:[0.6623], init state:[ 2 16  4  0  0  0  0  0], end state:[ 4 16  4  0  0  0  0  0], runtime(seconds):[427.88]
INFO:Reinforcement.Functions:episode: 43, score:[2685.60], loss:[9.94369], sequence:[12], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[81], eInit:[0.6557], init state:[ 3  4 11  0  0  0  0  0], end state:[ 5  4 11  0  0  0  0  0], runtime(seconds):[427.02]
INFO:Reinforcement.Functions:episode: 44, score:[2691.20], loss:[10.49577], sequence:[13], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[87], eInit:[0.6491], init state:[ 3 16 18  0  0  0  0  0], end state:[ 5 16 18  0  0  0  0  0], runtime(seconds):[427.07]
INFO:Reinforcement.Functions:episode: 45, score:[2673.60], loss:[9.64169], sequence:[14], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[91], eInit:[0.6426], init state:[ 4  4 25  0  0  0  0  0], end state:[ 6  4 25  0  0  0  0  0], runtime(seconds):[427.05]
INFO:Reinforcement.Functions:episode: 46, score:[2714.00], loss:[9.95754], sequence:[15], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[88], eInit:[0.6362], init state:[ 4 16 32  0  0  0  0  0], end state:[ 6 16 32  0  1  0  0  0], runtime(seconds):[427.35]
INFO:Reinforcement.Functions:episode: 47, score:[2682.80], loss:[8.66790], sequence:[16], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[83], eInit:[0.6298], init state:[ 5  4 39  0  0  0  0  0], end state:[ 0  4 39  0  0  0  0  0], runtime(seconds):[426.56]
INFO:Reinforcement.Functions:episode: 48, score:[2648.40], loss:[10.37985], sequence:[17], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[83], eInit:[0.6235], init state:[ 5 16 46  0  0  0  0  0], end state:[ 0 16 46  0  0  0  0  0], runtime(seconds):[429.87]
INFO:Reinforcement.Functions:episode: 49, score:[2677.20], loss:[8.98935], sequence:[18], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[99], eInit:[0.6173], init state:[ 6  4 53  0  0  0  0  0], end state:[ 1  4 53  0  0  0  0  0], runtime(seconds):[425.88]
INFO:Reinforcement.Functions:episode: 50, score:[2712.80], loss:[10.38493], sequence:[19], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[83], eInit:[0.6111], init state:[ 6 17  0  0  0  0  0  0], end state:[ 1 17  0  0  0  0  0  0], runtime(seconds):[424.24]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2761.1999999999975, [40]) , maxSequence:(19, [50])
INFO:Reinforcement.Functions:episode: 51, score:[2716.00], loss:[10.81865], sequence:[20], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[83], eInit:[0.6050], init state:[0 5 7 0 0 0 0 0], end state:[2 5 7 0 0 0 0 0], runtime(seconds):[424.95]
INFO:Reinforcement.Functions:episode: 52, score:[2760.80], loss:[8.72378], sequence:[21], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[74], eInit:[0.5990], init state:[ 0 17 14  0  0  0  0  0], end state:[ 2 17 14  0  0  0  0  0], runtime(seconds):[425.58]
INFO:Reinforcement.Functions:episode: 53, score:[2756.80], loss:[8.89385], sequence:[22], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[75], eInit:[0.5930], init state:[ 1  5 21  0  0  0  0  0], end state:[ 3  5 21  0  0  0  0  0], runtime(seconds):[424.82]
INFO:Reinforcement.Functions:episode: 54, score:[2733.60], loss:[9.07180], sequence:[23], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[77], eInit:[0.5870], init state:[ 1 17 28  0  0  0  0  0], end state:[ 3 17 28  0  0  0  0  0], runtime(seconds):[425.19]
INFO:Reinforcement.Functions:episode: 55, score:[2746.80], loss:[8.89616], sequence:[24], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[72], eInit:[0.5812], init state:[ 2  5 35  0  0  0  0  0], end state:[ 4  5 35  0  0  0  0  0], runtime(seconds):[426.39]
INFO:Reinforcement.Functions:episode: 56, score:[2637.20], loss:[9.51424], sequence:[25], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[87], eInit:[0.5754], init state:[ 2 17 42  0  0  0  0  0], end state:[ 4 17 42  0  0  0  0  0], runtime(seconds):[425.29]
INFO:Reinforcement.Functions:episode: 57, score:[2759.20], loss:[9.67548], sequence:[26], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[58], eInit:[0.5696], init state:[ 3  5 49  0  0  0  0  0], end state:[ 5  5 49  0  0  0  0  0], runtime(seconds):[424.67]
INFO:Reinforcement.Functions:episode: 58, score:[2762.00], loss:[8.60470], sequence:[27], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[75], eInit:[0.5639], init state:[ 3 17 56  0  0  0  0  0], end state:[ 5 17 56  0  0  0  0  0], runtime(seconds):[424.17]
INFO:Reinforcement.Functions:episode: 59, score:[2620.00], loss:[8.48324], sequence:[28], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[79], eInit:[0.5583], init state:[4 6 3 0 0 0 0 0], end state:[6 6 3 0 0 0 0 0], runtime(seconds):[424.25]
INFO:Reinforcement.Functions:episode: 60, score:[2686.00], loss:[8.80937], sequence:[29], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[73], eInit:[0.5527], init state:[ 4 18 10  0  0  0  0  0], end state:[ 6 18 10  0  0  0  0  0], runtime(seconds):[423.75]
INFO:Reinforcement.Functions:Optimal models save history:[(58, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(2761.9999999999995, [58]) , maxSequence:(29, [60])
INFO:Reinforcement.Functions:episode: 61, score:[2734.80], loss:[8.13621], sequence:[30], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[75], eInit:[0.5472], init state:[ 5  6 17  0  0  0  0  0], end state:[ 0  6 17  0  0  0  0  0], runtime(seconds):[423.67]
INFO:Reinforcement.Functions:episode: 62, score:[2680.40], loss:[9.29510], sequence:[31], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[74], eInit:[0.5417], init state:[ 5 18 24  1  1  0  1  0], end state:[ 0 18 24  0  0  0  0  0], runtime(seconds):[425.18]
INFO:Reinforcement.Functions:episode: 63, score:[2724.80], loss:[8.95420], sequence:[32], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[88], eInit:[0.5363], init state:[ 6  6 31  0  0  0  0  0], end state:[ 1  6 31  0  0  0  0  0], runtime(seconds):[425.25]
INFO:Reinforcement.Functions:episode: 64, score:[2736.40], loss:[8.97056], sequence:[33], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[69], eInit:[0.5309], init state:[ 6 18 38  0  0  0  0  0], end state:[ 1 18 38  0  0  0  0  0], runtime(seconds):[425.04]
INFO:Reinforcement.Functions:episode: 65, score:[2759.60], loss:[9.52971], sequence:[34], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[70], eInit:[0.5256], init state:[ 0  6 45  0  0  0  0  0], end state:[ 2  6 45  0  0  0  0  0], runtime(seconds):[426.44]
INFO:Reinforcement.Functions:episode: 66, score:[2710.80], loss:[8.69575], sequence:[35], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[73], eInit:[0.5203], init state:[ 0 18 52  0  0  0  0  0], end state:[ 2 18 52  0  0  0  0  0], runtime(seconds):[426.70]
INFO:Reinforcement.Functions:episode: 67, score:[2739.60], loss:[9.21831], sequence:[36], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[70], eInit:[0.5151], init state:[ 1  6 59  0  0  0  0  0], end state:[ 3  6 59  0  0  0  0  0], runtime(seconds):[425.17]
INFO:Reinforcement.Functions:episode: 68, score:[2739.20], loss:[7.72157], sequence:[37], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[80], eInit:[0.5100], init state:[ 1 19  6  0  0  0  0  0], end state:[ 3 19  6  0  0  0  0  0], runtime(seconds):[425.38]
INFO:Reinforcement.Functions:episode: 69, score:[2745.60], loss:[8.82879], sequence:[38], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[84], eInit:[0.5049], init state:[ 2  7 13  0  0  0  0  0], end state:[ 4  7 13  0  0  0  0  0], runtime(seconds):[425.64]
INFO:Reinforcement.Functions:episode: 70, score:[2724.00], loss:[8.10930], sequence:[39], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[66], eInit:[0.4998], init state:[ 2 19 20  0  0  0  0  0], end state:[ 4 19 20  0  0  0  0  0], runtime(seconds):[425.28]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2761.9999999999995, [58]) , maxSequence:(39, [70])
INFO:Reinforcement.Functions:episode: 71, score:[2706.80], loss:[9.59516], sequence:[40], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[75], eInit:[0.4948], init state:[ 3  7 27  0  0  0  0  0], end state:[ 5  7 27  0  0  0  0  0], runtime(seconds):[423.90]
INFO:Reinforcement.Functions:episode: 72, score:[2737.20], loss:[8.78082], sequence:[41], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[83], eInit:[0.4899], init state:[ 3 19 34  0  0  0  0  0], end state:[ 5 19 34  1  0  0  1  0], runtime(seconds):[423.52]
INFO:Reinforcement.Functions:episode: 73, score:[2721.20], loss:[8.09580], sequence:[42], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[82], eInit:[0.4850], init state:[ 4  7 41  0  0  0  0  0], end state:[ 6  7 41  0  0  0  0  0], runtime(seconds):[423.73]
INFO:Reinforcement.Functions:episode: 74, score:[2702.00], loss:[8.72763], sequence:[43], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[70], eInit:[0.4801], init state:[ 4 19 48  0  0  0  0  0], end state:[ 6 19 48  0  0  0  0  0], runtime(seconds):[423.07]
INFO:Reinforcement.Functions:episode: 75, score:[2688.40], loss:[7.94049], sequence:[44], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[75], eInit:[0.4753], init state:[ 5  7 55  0  0  0  0  0], end state:[ 0  7 55  0  0  0  0  0], runtime(seconds):[423.80]
INFO:Reinforcement.Functions:episode: 76, score:[2663.60], loss:[8.77583], sequence:[45], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[77], eInit:[0.4706], init state:[ 5 20  2  1  0  0  0  0], end state:[ 0 20  2  0  0  0  0  0], runtime(seconds):[424.12]
INFO:Reinforcement.Functions:episode: 77, score:[2742.80], loss:[7.77176], sequence:[46], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[70], eInit:[0.4659], init state:[6 8 9 1 0 0 0 0], end state:[1 8 9 1 0 0 0 0], runtime(seconds):[424.02]
INFO:Reinforcement.Functions:episode: 78, score:[2730.00], loss:[8.02388], sequence:[47], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[74], eInit:[0.4612], init state:[ 6 20 16  0  0  0  0  0], end state:[ 1 20 16  0  0  0  0  0], runtime(seconds):[423.34]
INFO:Reinforcement.Functions:episode: 79, score:[2769.20], loss:[7.24430], sequence:[48], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[66], eInit:[0.4566], init state:[ 0  8 23  1  0  0  0  0], end state:[ 2  8 23  1  0  0  0  0], runtime(seconds):[424.46]
INFO:Reinforcement.Functions:episode: 80, score:[2756.00], loss:[7.96980], sequence:[49], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[65], eInit:[0.4520], init state:[ 0 20 30  1  1  0  0  0], end state:[ 2 20 30  0  0  0  0  0], runtime(seconds):[425.15]
INFO:Reinforcement.Functions:Optimal models save history:[(79, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2769.199999999997, [79]) , maxSequence:(49, [80])
INFO:Reinforcement.Functions:episode: 81, score:[2757.20], loss:[6.98014], sequence:[50], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[65], eInit:[0.4475], init state:[ 1  8 37  1  1  0  1  0], end state:[ 3  8 37  1  1  0  1  0], runtime(seconds):[423.46]
INFO:Reinforcement.Functions:episode: 82, score:[2794.40], loss:[7.27102], sequence:[51], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[52], eInit:[0.4430], init state:[ 1 20 44  1  1  0  0  0], end state:[ 3 20 44  0  0  0  0  0], runtime(seconds):[425.46]
INFO:Reinforcement.Functions:episode: 83, score:[2772.80], loss:[6.22154], sequence:[52], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[64], eInit:[0.4386], init state:[ 2  8 51  1  1  0  0  0], end state:[ 4  8 51  0  0  0  0  0], runtime(seconds):[425.07]
INFO:Reinforcement.Functions:episode: 84, score:[2740.80], loss:[6.80830], sequence:[53], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[66], eInit:[0.4342], init state:[ 2 20 58  1  1  0  1  0], end state:[ 4 20 58  0  0  0  0  0], runtime(seconds):[424.87]
INFO:Reinforcement.Functions:episode: 85, score:[2750.00], loss:[6.77305], sequence:[54], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[64], eInit:[0.4299], init state:[3 9 5 0 0 0 0 0], end state:[5 9 5 0 0 0 0 0], runtime(seconds):[424.19]
INFO:Reinforcement.Functions:episode: 86, score:[2707.60], loss:[6.39174], sequence:[55], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[66], eInit:[0.4256], init state:[ 3 21 12  1  1  0  1  0], end state:[ 5 21 12  1  0  0  1  0], runtime(seconds):[424.65]
INFO:Reinforcement.Functions:episode: 87, score:[2664.80], loss:[7.24358], sequence:[56], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[70], eInit:[0.4213], init state:[ 4  9 19  0  0  0  0  0], end state:[ 6  9 19  0  0  0  0  0], runtime(seconds):[424.78]
INFO:Reinforcement.Functions:episode: 88, score:[2706.80], loss:[6.64331], sequence:[57], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[72], eInit:[0.4171], init state:[ 4 21 26  0  0  0  0  0], end state:[ 6 21 26  1  1  0  1  0], runtime(seconds):[423.81]
INFO:Reinforcement.Functions:episode: 89, score:[2724.00], loss:[6.03918], sequence:[58], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[85], eInit:[0.4129], init state:[ 5  9 33  0  0  0  0  0], end state:[ 0  9 33  0  0  0  0  0], runtime(seconds):[424.72]
INFO:Reinforcement.Functions:episode: 90, score:[2676.40], loss:[7.82561], sequence:[59], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[67], eInit:[0.4088], init state:[ 5 21 40  1  0  0  1  0], end state:[ 0 21 40  1  0  0  0  0], runtime(seconds):[424.44]
INFO:Reinforcement.Functions:Optimal models save history:[(82, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(2794.3999999999987, [82]) , maxSequence:(59, [90])
INFO:Reinforcement.Functions:episode: 91, score:[2751.20], loss:[7.31679], sequence:[60], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[64], eInit:[0.4047], init state:[ 6  9 47  0  0  0  0  0], end state:[ 1  9 47  0  0  0  0  0], runtime(seconds):[423.73]
INFO:Reinforcement.Functions:episode: 92, score:[2752.40], loss:[6.38982], sequence:[61], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[85], eInit:[0.4007], init state:[ 6 21 54  1  0  0  0  0], end state:[ 1 21 54  1  0  0  0  0], runtime(seconds):[425.37]
INFO:Reinforcement.Functions:episode: 93, score:[2789.60], loss:[6.42456], sequence:[62], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[61], eInit:[0.3967], init state:[ 0 10  1  0  0  0  0  0], end state:[ 2 10  1  0  0  0  0  0], runtime(seconds):[426.01]
INFO:Reinforcement.Functions:episode: 94, score:[2788.40], loss:[6.33846], sequence:[63], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[55], eInit:[0.3927], init state:[ 0 22  8  1  0  0  0  0], end state:[ 2 22  8  1  0  0  0  0], runtime(seconds):[425.68]
INFO:Reinforcement.Functions:episode: 95, score:[2794.40], loss:[5.56525], sequence:[64], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[61], eInit:[0.3888], init state:[ 1 10 15  0  0  0  0  0], end state:[ 3 10 15  0  0  0  0  0], runtime(seconds):[425.05]
INFO:Reinforcement.Functions:episode: 96, score:[2758.40], loss:[5.88613], sequence:[65], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[64], eInit:[0.3849], init state:[ 1 22 22  1  0  0  0  0], end state:[ 3 22 22  1  0  0  0  0], runtime(seconds):[426.51]
INFO:Reinforcement.Functions:episode: 97, score:[2757.20], loss:[4.84919], sequence:[66], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[73], eInit:[0.3810], init state:[ 2 10 29  0  0  0  0  0], end state:[ 4 10 29  0  0  0  0  0], runtime(seconds):[425.52]
INFO:Reinforcement.Functions:episode: 98, score:[2753.60], loss:[5.48573], sequence:[67], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[57], eInit:[0.3772], init state:[ 2 22 36  1  0  0  0  0], end state:[ 4 22 36  0  0  0  0  0], runtime(seconds):[424.80]
INFO:Reinforcement.Functions:episode: 99, score:[2785.20], loss:[5.27359], sequence:[68], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[63], eInit:[0.3735], init state:[ 3 10 43  0  0  0  0  0], end state:[ 5 10 43  0  0  0  0  0], runtime(seconds):[425.18]
INFO:Reinforcement.Functions:episode: 100, score:[2670.40], loss:[6.35955], sequence:[69], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[56], eInit:[0.3697], init state:[ 3 22 50  1  0  0  0  0], end state:[ 5 22 50  0  0  0  0  0], runtime(seconds):[425.08]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2794.3999999999987, [82, 95]) , maxSequence:(69, [100])
INFO:Reinforcement.Functions:episode: 101, score:[2739.60], loss:[8.02080], sequence:[70], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[45], eInit:[0.3660], init state:[ 4 10 57  1  1  0  1  0], end state:[ 6 10 57  0  0  0  0  0], runtime(seconds):[423.90]
INFO:Reinforcement.Functions:episode: 102, score:[2731.60], loss:[5.56883], sequence:[71], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[66], eInit:[0.3624], init state:[ 4 23  4  0  0  0  0  0], end state:[ 6 23  4  1  0  0  0  0], runtime(seconds):[423.95]
INFO:Reinforcement.Functions:episode: 103, score:[2765.20], loss:[5.81042], sequence:[72], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[53], eInit:[0.3587], init state:[ 5 11 11  0  0  0  0  0], end state:[ 0 11 11  0  0  0  0  0], runtime(seconds):[425.37]
INFO:Reinforcement.Functions:episode: 104, score:[2756.80], loss:[5.54917], sequence:[73], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[55], eInit:[0.3552], init state:[ 5 23 18  1  0  0  0  0], end state:[ 0 23 18  1  0  0  1  0], runtime(seconds):[425.89]
INFO:Reinforcement.Functions:episode: 105, score:[2772.80], loss:[6.05759], sequence:[74], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[70], eInit:[0.3516], init state:[ 6 11 25  0  0  0  0  0], end state:[ 1 11 25  0  0  0  0  0], runtime(seconds):[424.05]
INFO:Reinforcement.Functions:episode: 106, score:[2793.60], loss:[6.24270], sequence:[75], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[58], eInit:[0.3481], init state:[ 6 23 32  1  0  0  1  0], end state:[ 1 23 32  1  0  0  1  0], runtime(seconds):[426.18]
INFO:Reinforcement.Functions:episode: 107, score:[2755.60], loss:[6.21691], sequence:[76], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[57], eInit:[0.3446], init state:[ 0 11 39  0  0  0  0  0], end state:[ 2 11 39  0  0  0  0  0], runtime(seconds):[425.60]
INFO:Reinforcement.Functions:episode: 108, score:[2767.60], loss:[5.45328], sequence:[77], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[57], eInit:[0.3412], init state:[ 0 23 46  1  0  0  0  0], end state:[ 2 23 46  1  0  0  0  0], runtime(seconds):[425.55]
INFO:Reinforcement.Functions:episode: 109, score:[2784.40], loss:[5.73635], sequence:[78], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[65], eInit:[0.3378], init state:[ 1 11 53  0  0  0  0  0], end state:[ 3 11 53  0  0  0  0  0], runtime(seconds):[424.29]
INFO:Reinforcement.Functions:episode: 110, score:[2766.00], loss:[5.06697], sequence:[79], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[51], eInit:[0.3344], init state:[2 0 0 1 0 0 0 0], end state:[4 0 0 1 0 0 0 0], runtime(seconds):[425.33]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2794.3999999999987, [82, 95]) , maxSequence:(79, [110])
INFO:Reinforcement.Functions:episode: 111, score:[2764.00], loss:[5.50643], sequence:[80], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[58], eInit:[0.3310], init state:[ 2 12  7  0  0  0  0  0], end state:[ 4 12  7  1  1  0  0  0], runtime(seconds):[424.35]
INFO:Reinforcement.Functions:episode: 112, score:[2712.00], loss:[6.79055], sequence:[81], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[59], eInit:[0.3277], init state:[ 3  0 14  1  0  0  0  0], end state:[ 5  0 14  0  0  0  0  0], runtime(seconds):[422.95]
INFO:Reinforcement.Functions:episode: 113, score:[2755.60], loss:[5.59094], sequence:[82], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[61], eInit:[0.3244], init state:[ 3 12 21  0  0  0  0  0], end state:[ 5 12 21  0  0  0  0  0], runtime(seconds):[424.06]
INFO:Reinforcement.Functions:episode: 114, score:[2685.60], loss:[6.51089], sequence:[83], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[58], eInit:[0.3212], init state:[ 4  0 28  1  0  0  0  0], end state:[ 6  0 28  1  0  0  0  0], runtime(seconds):[424.11]
INFO:Reinforcement.Functions:episode: 115, score:[2656.00], loss:[7.19859], sequence:[84], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[60], eInit:[0.3180], init state:[ 4 12 35  1  1  0  0  0], end state:[ 6 12 35  0  0  0  0  0], runtime(seconds):[423.87]
INFO:Reinforcement.Functions:episode: 116, score:[2728.80], loss:[6.43138], sequence:[85], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[62], eInit:[0.3148], init state:[ 5  0 42  0  0  0  0  0], end state:[ 0  0 42  1  1  0  1  1], runtime(seconds):[424.96]
INFO:Reinforcement.Functions:episode: 117, score:[2766.40], loss:[5.60698], sequence:[86], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[55], eInit:[0.3117], init state:[ 5 12 49  0  0  0  0  0], end state:[ 0 12 49  0  0  0  0  0], runtime(seconds):[425.37]
INFO:Reinforcement.Functions:episode: 118, score:[2776.00], loss:[5.86340], sequence:[87], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[47], eInit:[0.3085], init state:[ 6  0 56  0  0  1  0  0], end state:[ 1  0 56  0  0  1  0  0], runtime(seconds):[425.59]
INFO:Reinforcement.Functions:episode: 119, score:[2807.20], loss:[5.18298], sequence:[88], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[46], eInit:[0.3055], init state:[ 6 13  3  0  0  0  0  0], end state:[ 1 13  3  0  0  0  0  0], runtime(seconds):[424.27]
INFO:Reinforcement.Functions:episode: 120, score:[2784.00], loss:[6.39092], sequence:[89], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[63], eInit:[0.3024], init state:[ 0  1 10  0  0  0  0  0], end state:[ 2  1 10  0  0  0  0  0], runtime(seconds):[425.82]
INFO:Reinforcement.Functions:Optimal models save history:[(119, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(2807.1999999999985, [119]) , maxSequence:(89, [120])
INFO:Reinforcement.Functions:episode: 121, score:[2801.20], loss:[5.51183], sequence:[90], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[52], eInit:[0.2994], init state:[ 0 13 17  0  0  0  0  0], end state:[ 2 13 17  0  0  0  0  0], runtime(seconds):[425.98]
INFO:Reinforcement.Functions:episode: 122, score:[2811.20], loss:[4.96869], sequence:[91], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[58], eInit:[0.2964], init state:[ 1  1 24  0  0  0  0  0], end state:[ 3  1 24  0  0  0  0  0], runtime(seconds):[424.23]
INFO:Reinforcement.Functions:episode: 123, score:[2787.60], loss:[4.61274], sequence:[92], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[54], eInit:[0.2934], init state:[ 1 13 31  0  0  0  0  0], end state:[ 3 13 31  0  0  0  0  0], runtime(seconds):[424.92]
INFO:Reinforcement.Functions:episode: 124, score:[2734.00], loss:[4.37200], sequence:[93], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[58], eInit:[0.2905], init state:[ 2  1 38  0  0  0  0  0], end state:[ 4  1 38  0  0  0  0  0], runtime(seconds):[425.29]
INFO:Reinforcement.Functions:episode: 125, score:[2752.80], loss:[5.31293], sequence:[94], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[56], eInit:[0.2876], init state:[ 2 13 45  0  0  0  0  0], end state:[ 4 13 45  0  0  0  0  0], runtime(seconds):[425.64]
INFO:Reinforcement.Functions:episode: 126, score:[2779.60], loss:[4.28861], sequence:[95], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[55], eInit:[0.2847], init state:[ 3  1 52  0  0  0  0  0], end state:[ 5  1 52  0  0  0  0  0], runtime(seconds):[425.38]
INFO:Reinforcement.Functions:episode: 127, score:[2752.40], loss:[4.84898], sequence:[96], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[49], eInit:[0.2819], init state:[ 3 13 59  0  0  0  0  0], end state:[ 5 13 59  0  0  0  0  0], runtime(seconds):[425.46]
INFO:Reinforcement.Functions:episode: 128, score:[2772.40], loss:[5.28190], sequence:[97], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[40], eInit:[0.2790], init state:[4 2 6 0 0 0 0 0], end state:[6 2 6 0 0 0 0 0], runtime(seconds):[424.52]
INFO:Reinforcement.Functions:episode: 129, score:[2708.80], loss:[5.18081], sequence:[98], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[50], eInit:[0.2763], init state:[ 4 14 13  0  0  0  0  0], end state:[ 6 14 13  0  0  0  0  0], runtime(seconds):[423.55]
INFO:Reinforcement.Functions:episode: 130, score:[2763.60], loss:[5.31640], sequence:[99], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[55], eInit:[0.2735], init state:[ 5  2 20  0  0  0  0  0], end state:[ 0  2 20  0  0  0  0  0], runtime(seconds):[424.10]
INFO:Reinforcement.Functions:Optimal models save history:[(122, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(2811.1999999999985, [122]) , maxSequence:(99, [130])
INFO:Reinforcement.Functions:episode: 131, score:[2735.20], loss:[5.19260], sequence:[100], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[54], eInit:[0.2708], init state:[ 5 14 27  0  0  0  0  0], end state:[ 0 14 27  0  0  0  0  0], runtime(seconds):[424.28]
INFO:Reinforcement.Functions:episode: 132, score:[2722.80], loss:[5.16396], sequence:[101], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[60], eInit:[0.2680], init state:[ 6  2 34  0  0  0  0  0], end state:[ 1  2 34  0  0  0  0  0], runtime(seconds):[424.35]
INFO:Reinforcement.Functions:episode: 133, score:[2779.20], loss:[4.77602], sequence:[102], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[53], eInit:[0.2654], init state:[ 6 14 41  0  0  0  0  0], end state:[ 1 14 41  0  0  0  0  0], runtime(seconds):[424.39]
INFO:Reinforcement.Functions:episode: 134, score:[2757.60], loss:[4.84896], sequence:[103], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[55], eInit:[0.2627], init state:[ 0  2 48  0  0  0  0  0], end state:[ 2  2 48  0  0  0  0  0], runtime(seconds):[424.70]
INFO:Reinforcement.Functions:episode: 135, score:[2810.00], loss:[4.89747], sequence:[104], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[46], eInit:[0.2601], init state:[ 0 14 55  0  0  0  0  0], end state:[ 2 14 55  0  0  0  0  0], runtime(seconds):[425.31]
INFO:Reinforcement.Functions:episode: 136, score:[2766.80], loss:[4.93751], sequence:[105], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[47], eInit:[0.2575], init state:[1 3 2 0 0 0 0 0], end state:[3 3 2 0 0 0 0 0], runtime(seconds):[424.76]
INFO:Reinforcement.Functions:episode: 137, score:[2780.40], loss:[5.15615], sequence:[106], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[50], eInit:[0.2549], init state:[ 1 15  9  0  0  0  0  0], end state:[ 3 15  9  0  0  0  0  0], runtime(seconds):[425.71]
INFO:Reinforcement.Functions:episode: 138, score:[2772.80], loss:[5.26754], sequence:[107], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[53], eInit:[0.2524], init state:[ 2  3 16  0  0  0  0  0], end state:[ 4  3 16  0  0  0  0  0], runtime(seconds):[425.53]
INFO:Reinforcement.Functions:episode: 139, score:[2737.60], loss:[5.07378], sequence:[108], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[58], eInit:[0.2498], init state:[ 2 15 23  0  0  0  0  0], end state:[ 4 15 23  0  0  0  0  0], runtime(seconds):[424.07]
INFO:Reinforcement.Functions:episode: 140, score:[2771.60], loss:[5.27146], sequence:[109], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.2473], init state:[ 3  3 30  0  0  0  0  0], end state:[ 5  3 30  0  0  0  0  0], runtime(seconds):[424.84]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2811.1999999999985, [122]) , maxSequence:(109, [140])
INFO:Reinforcement.Functions:episode: 141, score:[2785.20], loss:[5.23541], sequence:[110], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[45], eInit:[0.2449], init state:[ 3 15 37  0  0  0  0  0], end state:[ 5 15 37  0  0  0  0  0], runtime(seconds):[424.56]
INFO:Reinforcement.Functions:episode: 142, score:[2709.20], loss:[5.23134], sequence:[111], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[52], eInit:[0.2424], init state:[ 4  3 44  0  0  0  0  0], end state:[ 6  3 44  0  0  0  0  0], runtime(seconds):[423.16]
INFO:Reinforcement.Functions:episode: 143, score:[2792.80], loss:[5.71284], sequence:[112], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[54], eInit:[0.2400], init state:[ 4 15 51  0  0  0  0  0], end state:[ 6 15 51  0  0  0  0  0], runtime(seconds):[422.71]
INFO:Reinforcement.Functions:episode: 144, score:[2778.80], loss:[4.97253], sequence:[113], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.2376], init state:[ 5  3 58  0  0  0  0  0], end state:[ 0  3 58  0  0  0  0  0], runtime(seconds):[423.33]
INFO:Reinforcement.Functions:episode: 145, score:[2762.40], loss:[5.52395], sequence:[114], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[59], eInit:[0.2352], init state:[ 5 16  5  0  0  0  0  0], end state:[ 0 16  5  0  0  0  0  0], runtime(seconds):[424.74]
INFO:Reinforcement.Functions:episode: 146, score:[2745.20], loss:[5.21411], sequence:[115], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[55], eInit:[0.2329], init state:[ 6  4 12  0  0  0  0  0], end state:[ 1  4 12  0  0  0  0  0], runtime(seconds):[424.05]
INFO:Reinforcement.Functions:episode: 147, score:[2766.80], loss:[5.93850], sequence:[116], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[51], eInit:[0.2305], init state:[ 6 16 19  0  0  0  0  0], end state:[ 1 16 19  0  0  0  0  0], runtime(seconds):[425.89]
INFO:Reinforcement.Functions:episode: 148, score:[2810.00], loss:[5.26152], sequence:[117], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[53], eInit:[0.2282], init state:[ 0  4 26  0  0  0  0  0], end state:[ 2  4 26  0  0  0  0  0], runtime(seconds):[425.96]
INFO:Reinforcement.Functions:episode: 149, score:[2783.20], loss:[5.37834], sequence:[118], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[42], eInit:[0.2259], init state:[ 0 16 33  0  0  0  0  0], end state:[ 2 16 33  0  0  0  0  0], runtime(seconds):[425.31]
INFO:Reinforcement.Functions:episode: 150, score:[2811.60], loss:[4.34622], sequence:[119], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[38], eInit:[0.2237], init state:[ 1  4 40  0  0  0  0  0], end state:[ 3  4 40  0  0  0  0  0], runtime(seconds):[424.46]
INFO:Reinforcement.Functions:Optimal models save history:[(150, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(2811.599999999996, [150]) , maxSequence:(119, [150])
INFO:Reinforcement.Functions:episode: 151, score:[2789.20], loss:[5.27951], sequence:[120], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[53], eInit:[0.2215], init state:[ 1 16 47  0  0  0  0  0], end state:[ 3 16 47  0  0  0  0  0], runtime(seconds):[425.41]
INFO:Reinforcement.Functions:episode: 152, score:[2804.00], loss:[4.58577], sequence:[121], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[56], eInit:[0.2192], init state:[ 2  4 54  0  0  0  0  0], end state:[ 4  4 54  0  0  0  0  0], runtime(seconds):[425.10]
INFO:Reinforcement.Functions:episode: 153, score:[2768.80], loss:[4.68621], sequence:[122], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[54], eInit:[0.2170], init state:[ 2 17  1  0  0  0  0  0], end state:[ 4 17  1  0  0  0  0  0], runtime(seconds):[423.88]
INFO:Reinforcement.Functions:episode: 154, score:[2732.00], loss:[5.41352], sequence:[123], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[47], eInit:[0.2149], init state:[3 5 8 0 0 0 0 0], end state:[5 5 8 0 0 0 0 0], runtime(seconds):[424.56]
INFO:Reinforcement.Functions:episode: 155, score:[2753.60], loss:[4.76818], sequence:[124], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[39], eInit:[0.2127], init state:[ 3 17 15  0  0  0  0  0], end state:[ 5 17 15  0  0  0  0  0], runtime(seconds):[424.75]
INFO:Reinforcement.Functions:episode: 156, score:[2796.80], loss:[5.08819], sequence:[125], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[46], eInit:[0.2106], init state:[ 4  5 22  0  0  0  0  0], end state:[ 6  5 22  0  0  0  0  0], runtime(seconds):[424.83]
INFO:Reinforcement.Functions:episode: 157, score:[2734.40], loss:[4.87235], sequence:[126], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[47], eInit:[0.2085], init state:[ 4 17 29  0  0  0  0  0], end state:[ 6 17 29  0  0  0  0  0], runtime(seconds):[424.24]
INFO:Reinforcement.Functions:episode: 158, score:[2709.60], loss:[6.05373], sequence:[127], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[56], eInit:[0.2064], init state:[ 5  5 36  0  0  0  0  0], end state:[ 0  5 36  0  0  0  0  0], runtime(seconds):[424.98]
INFO:Reinforcement.Functions:episode: 159, score:[2738.80], loss:[5.39272], sequence:[128], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[45], eInit:[0.2043], init state:[ 5 17 43  0  0  0  0  0], end state:[ 0 17 43  0  0  0  0  0], runtime(seconds):[424.60]
INFO:Reinforcement.Functions:episode: 160, score:[2779.20], loss:[4.95428], sequence:[129], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[54], eInit:[0.2023], init state:[ 6  5 50  0  0  0  0  0], end state:[ 1  5 50  0  0  0  0  0], runtime(seconds):[425.56]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-50/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2811.599999999996, [150]) , maxSequence:(129, [160])
INFO:Reinforcement.Functions:episode: 161, score:[2760.40], loss:[6.29105], sequence:[130], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[36], eInit:[0.2003], init state:[ 6 17 57  0  0  0  0  0], end state:[ 1 17 57  0  0  0  0  0], runtime(seconds):[424.81]
INFO:Reinforcement.Functions:episode: 162, score:[2798.80], loss:[5.38933], sequence:[131], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[35], eInit:[0.1983], init state:[0 6 4 0 0 0 0 0], end state:[2 6 4 0 0 0 0 0], runtime(seconds):[424.56]
INFO:Reinforcement.Functions:episode: 163, score:[2815.20], loss:[4.99176], sequence:[132], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[40], eInit:[0.1963], init state:[ 0 18 11  0  0  0  0  0], end state:[ 2 18 11  0  0  0  0  0], runtime(seconds):[423.83]
INFO:Reinforcement.Functions:episode: 164, score:[2805.20], loss:[4.81455], sequence:[133], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[46], eInit:[0.1943], init state:[ 1  6 18  0  0  0  0  0], end state:[ 3  6 18  0  0  0  0  0], runtime(seconds):[428.26]
INFO:Reinforcement.Functions:episode: 165, score:[2793.60], loss:[4.49118], sequence:[134], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[49], eInit:[0.1924], init state:[ 1 18 25  0  0  0  0  0], end state:[ 3 18 25  0  0  0  0  0], runtime(seconds):[426.54]
INFO:Reinforcement.Functions:episode: 166, score:[2778.00], loss:[4.40844], sequence:[135], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[46], eInit:[0.1905], init state:[ 2  6 32  0  0  0  0  0], end state:[ 4  6 32  0  0  0  0  0], runtime(seconds):[425.38]
INFO:Reinforcement.Functions:episode: 167, score:[2783.60], loss:[5.33327], sequence:[136], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[42], eInit:[0.1886], init state:[ 2 18 39  0  0  0  0  0], end state:[ 4 18 39  0  0  0  0  0], runtime(seconds):[458.74]
INFO:Reinforcement.Functions:episode: 168, score:[2778.00], loss:[4.84274], sequence:[137], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[44], eInit:[0.1867], init state:[ 3  6 46  0  0  0  0  0], end state:[ 5  6 46  0  0  0  0  0], runtime(seconds):[429.28]
INFO:Reinforcement.Functions:episode: 169, score:[2746.00], loss:[5.03995], sequence:[138], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[40], eInit:[0.1848], init state:[ 3 18 53  0  0  0  0  0], end state:[ 5 18 53  0  0  0  0  0], runtime(seconds):[426.69]
INFO:Reinforcement.Functions:episode: 170, score:[2782.00], loss:[4.73326], sequence:[139], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[40], eInit:[0.1830], init state:[4 7 0 0 0 0 0 0], end state:[6 7 0 0 0 0 0 0], runtime(seconds):[429.85]
INFO:Reinforcement.Functions:Optimal models save history:[(163, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(2815.1999999999994, [163]) , maxSequence:(139, [170])
INFO:Reinforcement.Functions:episode: 171, score:[2818.80], loss:[4.97401], sequence:[140], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[29], eInit:[0.1811], init state:[ 4 19  7  0  0  0  0  0], end state:[ 6 19  7  0  0  0  0  0], runtime(seconds):[427.66]
INFO:Reinforcement.Functions:episode: 172, score:[2794.80], loss:[4.49614], sequence:[141], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[35], eInit:[0.1793], init state:[ 5  7 14  0  0  0  0  0], end state:[ 0  7 14  0  0  0  0  0], runtime(seconds):[430.32]
INFO:Reinforcement.Functions:episode: 173, score:[2784.00], loss:[4.96680], sequence:[142], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[41], eInit:[0.1775], init state:[ 5 19 21  1  0  0  1  0], end state:[ 0 19 21  0  0  0  0  0], runtime(seconds):[426.90]
INFO:Reinforcement.Functions:episode: 174, score:[2737.60], loss:[5.02659], sequence:[143], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[47], eInit:[0.1757], init state:[ 6  7 28  0  0  0  0  0], end state:[ 1  7 28  0  0  0  0  0], runtime(seconds):[424.81]

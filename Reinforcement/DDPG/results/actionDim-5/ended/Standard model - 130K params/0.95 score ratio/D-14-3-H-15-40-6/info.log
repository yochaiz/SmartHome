INFO:Reinforcement.Functions:settings:[{'minGameScore': 2736, u'TAU': 0.001, u'minGameScoreRatio': 0.95, u'batchSize': 256, u'nGamesPerSave': 10, u'nEpochs': 1, u'minGameSequence': 500, u'nModelBackups': 3, u'gameMinutesLength': 2880, u'dequeSize': 50000, u'learningRate': 0.001, u'gamma': 0.95, u'trainSetSize': 128}]
INFO:Reinforcement.Functions:args:[{'random': True, 'gpuFrac': 0.3, 'sequential': False, 'gpuNum': 0, 'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json'}]
INFO:Reinforcement.Functions:results:[{'loss': [], 'score': []}]
INFO:Reinforcement.Functions:Actor:[{'epsilon_decay': 0.99, 'epsilon': 1.0, 'curBackupIdx': 0, 'epsilon_min': 0.01, 'TAU': 0.001, 'nBackups': 3, 'k': 10, 'actionDim': 5}]
INFO:Reinforcement.Functions:Critic:[{'TAU': 0.001, 'nBackups': 3, 'curBackupIdx': 0, 'actionDim': 5}]
INFO:Reinforcement.Functions:policy:[{'numOfDevices': 5, 'stateDim': (1, 8), 'seqLen': 1, 'policyJSON': {u'10': [{u'days': u'weekdays', u'times': [[u'21:00', u'23:29']]}, {u'days': [5], u'times': [[u'21:00', u'23:29']]}], u'6': [{u'days': u'weekdays', u'times': [[u'20:40', u'23:59'], [u'00:00', u'00:14']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'weekdays': [0, 1, 2, 3, 6], u'Devices': [u'Room light1', u'Room light2', u'Room light3 (backdoor)', u'Kitchen light', u'Toilets light'], u'days': [u'Monday', u'Tuesday', u'Wednesday', u'Thursday', u'Friday', u'Saturday', u'Sunday'], u'1': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:59'], [u'20:30', u'21:29']]}, {u'days': [4], u'times': [[u'10:00', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'0': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:29'], [u'08:00', u'08:59'], [u'20:30', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:59'], [u'09:30', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'23:59']]}], u'3': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:44'], [u'20:45', u'21:29'], [u'23:15', u'23:44']]}, {u'days': [4], u'times': [[u'10:00', u'10:59'], [u'12:45', u'13:14']]}, {u'days': [5], u'times': [[u'18:00', u'19:59'], [u'21:00', u'23:14']]}], u'2': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:30', u'01:09']]}, {u'days': [4], u'times': [[u'00:30', u'01:09']]}], u'5': [{u'days': u'weekdays', u'times': [[u'08:35', u'08:42'], [u'21:09', u'21:11'], [u'00:05', u'00:24']]}, {u'days': [4], u'times': [[u'10:18', u'10:29'], [u'00:05', u'00:24']]}, {u'days': [5], u'times': [[u'19:09', u'19:09'], [u'21:34', u'21:34']]}], u'4': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:34'], [u'21:05', u'21:08']]}, {u'days': [4], u'times': [[u'10:10', u'10:17']]}, {u'days': [5], u'times': [[u'19:05', u'19:08'], [u'21:20', u'21:33']]}], u'7': [{u'days': u'weekdays', u'times': [[u'20:40', u'23:59'], [u'00:00', u'00:14']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'Time format': u'%H:%M', u'9': [{u'days': u'weekdays', u'times': [[u'09:00', u'09:00'], [u'20:30', u'20:30']]}, {u'days': [4], u'times': [[u'13:29', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:00']]}], u'8': [{u'days': u'weekdays', u'times': [[u'20:31', u'20:54']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'weekend': [4, 5]}}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 8)              0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 512)            4608      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            131328    
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 5)              1285      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 5)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 137,221
INFO:Reinforcement.Functions:Trainable params: 137,221
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 8)         0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)                 (None, 1, 512)       4608        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 5)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)                 (None, 1, 256)       131328      dense_4[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)                 (None, 256)          1536        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_5[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_6[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 1)         257         activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_7[0][0]                    
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 137,729
INFO:Reinforcement.Functions:Trainable params: 137,729
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[1669.20], loss:[41.14853], sequence:[0], random actions:[109], eInit:[1.0000], init state:[ 3 22 53  1  0  0  0  0], end state:[ 5 22 53  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2, score:[2001.60], loss:[44.93880], sequence:[0], random actions:[120], eInit:[0.9900], init state:[ 3 14  9  0  0  0  0  0], end state:[ 5 14  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 3, score:[1768.80], loss:[40.76890], sequence:[0], random actions:[117], eInit:[0.9801], init state:[ 6  6 25  0  0  0  0  0], end state:[ 1  6 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 4, score:[2285.60], loss:[41.95751], sequence:[0], random actions:[126], eInit:[0.9703], init state:[ 5  9 11  0  0  0  0  0], end state:[ 0  9 11  1  0  1  0  1]
INFO:Reinforcement.Functions:episode: 5, score:[2439.20], loss:[35.44633], sequence:[0], random actions:[111], eInit:[0.9606], init state:[ 3 17  6  0  0  0  0  0], end state:[ 5 17  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 6, score:[2263.20], loss:[25.87339], sequence:[0], random actions:[114], eInit:[0.9510], init state:[ 5 18 37  1  1  0  1  0], end state:[ 0 18 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 7, score:[2129.60], loss:[24.53074], sequence:[0], random actions:[126], eInit:[0.9415], init state:[ 1 19 42  0  0  0  0  0], end state:[ 3 19 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 8, score:[2251.20], loss:[22.27751], sequence:[0], random actions:[113], eInit:[0.9321], init state:[ 1 11 24  0  0  0  0  0], end state:[ 3 11 24  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 9, score:[2350.00], loss:[20.91554], sequence:[0], random actions:[121], eInit:[0.9227], init state:[ 5 17  5  0  0  0  0  0], end state:[ 0 17  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 10, score:[2516.80], loss:[17.05625], sequence:[0], random actions:[105], eInit:[0.9135], init state:[ 5  4 29  0  0  0  0  0], end state:[ 0  4 29  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2516.799999999987, [10]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
INFO:Reinforcement.Functions:episode: 11, score:[2257.20], loss:[17.11131], sequence:[0], random actions:[121], eInit:[0.9044], init state:[ 2 22 47  1  0  0  0  0], end state:[ 4 22 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 12, score:[2413.60], loss:[17.32279], sequence:[0], random actions:[111], eInit:[0.8953], init state:[ 1  4 35  0  0  0  0  0], end state:[ 3  4 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 13, score:[2539.60], loss:[15.44974], sequence:[0], random actions:[125], eInit:[0.8864], init state:[ 5  6 36  0  0  0  0  0], end state:[ 0  6 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 14, score:[2455.20], loss:[15.47153], sequence:[0], random actions:[112], eInit:[0.8775], init state:[ 0  0 15  1  0  0  0  0], end state:[ 2  0 15  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 15, score:[2527.20], loss:[15.47671], sequence:[0], random actions:[119], eInit:[0.8687], init state:[ 3 14 57  0  0  0  0  0], end state:[ 5 14 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 16, score:[2574.80], loss:[14.19881], sequence:[0], random actions:[113], eInit:[0.8601], init state:[ 3 10 18  0  0  0  0  0], end state:[ 5 10 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 17, score:[2532.00], loss:[13.89841], sequence:[0], random actions:[113], eInit:[0.8515], init state:[3 6 5 0 0 0 0 0], end state:[5 6 5 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 18, score:[2563.20], loss:[13.30941], sequence:[0], random actions:[109], eInit:[0.8429], init state:[6 9 8 0 0 0 0 0], end state:[1 9 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 19, score:[2538.00], loss:[12.83740], sequence:[0], random actions:[111], eInit:[0.8345], init state:[ 2 10 45  0  0  0  0  0], end state:[ 4 10 45  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 20, score:[2586.80], loss:[12.10349], sequence:[0], random actions:[106], eInit:[0.8262], init state:[ 4  3 35  0  0  0  0  0], end state:[ 6  3 35  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2586.7999999999856, [20]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])
INFO:Reinforcement.Functions:episode: 21, score:[2581.20], loss:[11.09544], sequence:[0], random actions:[104], eInit:[0.8179], init state:[ 3  3 48  0  0  0  0  0], end state:[ 5  3 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 22, score:[2598.00], loss:[11.03136], sequence:[0], random actions:[124], eInit:[0.8097], init state:[ 0 20 41  1  1  0  0  0], end state:[ 2 20 41  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 23, score:[2646.80], loss:[10.81025], sequence:[0], random actions:[101], eInit:[0.8016], init state:[ 3 20 26  0  0  0  0  0], end state:[ 5 20 26  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 24, score:[2653.20], loss:[9.95817], sequence:[0], random actions:[95], eInit:[0.7936], init state:[ 0  6 35  0  0  0  0  0], end state:[ 2  6 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 25, score:[2629.60], loss:[9.50783], sequence:[0], random actions:[98], eInit:[0.7857], init state:[5 2 3 0 0 0 0 0], end state:[0 2 3 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 26, score:[2632.00], loss:[9.16448], sequence:[0], random actions:[89], eInit:[0.7778], init state:[ 2 23 53  1  0  0  0  0], end state:[ 4 23 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 27, score:[2616.80], loss:[8.61620], sequence:[0], random actions:[99], eInit:[0.7700], init state:[ 6  9 21  0  0  0  0  0], end state:[ 1  9 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 28, score:[2621.60], loss:[8.72502], sequence:[0], random actions:[113], eInit:[0.7623], init state:[3 2 3 0 0 0 0 0], end state:[5 2 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 29, score:[2683.20], loss:[7.82235], sequence:[0], random actions:[92], eInit:[0.7547], init state:[ 5  1 47  0  0  0  0  0], end state:[ 0  1 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 30, score:[2688.80], loss:[7.48461], sequence:[0], random actions:[91], eInit:[0.7472], init state:[ 2 23 59  1  0  0  0  0], end state:[ 4 23 59  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2688.7999999999897, [30]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])
INFO:Reinforcement.Functions:episode: 31, score:[2672.80], loss:[7.15861], sequence:[0], random actions:[112], eInit:[0.7397], init state:[ 3 14 46  0  0  0  0  0], end state:[ 5 14 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 32, score:[2644.00], loss:[7.00568], sequence:[0], random actions:[91], eInit:[0.7323], init state:[ 0 13 58  0  0  0  0  0], end state:[ 2 13 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 33, score:[2632.00], loss:[7.34071], sequence:[0], random actions:[89], eInit:[0.7250], init state:[ 3  5 52  0  0  0  0  0], end state:[ 5  5 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 34, score:[2673.20], loss:[7.12928], sequence:[0], random actions:[101], eInit:[0.7177], init state:[ 6  6 51  0  0  0  0  0], end state:[ 1  6 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 35, score:[2691.20], loss:[6.92047], sequence:[0], random actions:[82], eInit:[0.7106], init state:[ 1 11  6  0  0  0  0  0], end state:[ 3 11  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 36, score:[2691.20], loss:[6.54564], sequence:[0], random actions:[105], eInit:[0.7034], init state:[ 0 23 51  1  0  0  0  0], end state:[ 2 23 51  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 37, score:[2500.80], loss:[6.93214], sequence:[0], random actions:[82], eInit:[0.6964], init state:[ 5 13 30  0  0  0  0  0], end state:[ 0 13 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 38, score:[2686.00], loss:[6.75876], sequence:[0], random actions:[94], eInit:[0.6894], init state:[ 4 15 13  0  0  0  0  0], end state:[ 6 15 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 39, score:[2599.60], loss:[7.21818], sequence:[0], random actions:[106], eInit:[0.6826], init state:[ 5 14 51  0  0  0  0  0], end state:[ 0 14 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 40, score:[2725.20], loss:[6.16471], sequence:[0], random actions:[86], eInit:[0.6757], init state:[ 1 12 57  0  0  0  0  0], end state:[ 3 12 57  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2725.1999999999935, [40]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40])
INFO:Reinforcement.Functions:episode: 41, score:[2672.40], loss:[6.68138], sequence:[0], random actions:[89], eInit:[0.6690], init state:[ 5 21 11  1  0  0  1  0], end state:[ 0 21 11  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 42, score:[2702.40], loss:[5.99707], sequence:[0], random actions:[92], eInit:[0.6623], init state:[ 2  5 50  0  0  0  0  0], end state:[ 4  5 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 43, score:[2702.80], loss:[5.44980], sequence:[0], random actions:[93], eInit:[0.6557], init state:[ 0 10 50  0  0  0  0  0], end state:[ 2 10 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 44, score:[2716.40], loss:[5.33631], sequence:[0], random actions:[85], eInit:[0.6491], init state:[ 6 11 52  0  0  0  0  0], end state:[ 1 11 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 45, score:[2695.20], loss:[5.04670], sequence:[0], random actions:[90], eInit:[0.6426], init state:[5 2 9 0 0 0 0 0], end state:[0 2 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 46, score:[2718.00], loss:[5.32586], sequence:[0], random actions:[75], eInit:[0.6362], init state:[ 1 19 48  0  0  0  0  0], end state:[ 3 19 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 47, score:[2669.20], loss:[5.41385], sequence:[0], random actions:[86], eInit:[0.6298], init state:[ 4 22 10  0  0  0  0  0], end state:[ 6 22 10  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 48, score:[2679.60], loss:[5.33294], sequence:[0], random actions:[85], eInit:[0.6235], init state:[ 2  5 53  0  0  0  0  0], end state:[ 4  5 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 49, score:[2606.00], loss:[5.94553], sequence:[0], random actions:[90], eInit:[0.6173], init state:[4 2 7 0 0 0 0 0], end state:[6 2 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 50, score:[2722.80], loss:[5.24403], sequence:[0], random actions:[84], eInit:[0.6111], init state:[ 1  0 44  0  0  1  0  0], end state:[ 3  0 44  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2725.1999999999935, [40]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])
INFO:Reinforcement.Functions:episode: 51, score:[2698.40], loss:[5.05476], sequence:[0], random actions:[74], eInit:[0.6050], init state:[ 4 23  4  0  0  0  0  0], end state:[ 6 23  4  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 52, score:[2663.60], loss:[5.43511], sequence:[0], random actions:[77], eInit:[0.5990], init state:[3 8 6 1 0 0 0 0], end state:[5 8 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 53, score:[2699.20], loss:[5.28193], sequence:[0], random actions:[83], eInit:[0.5930], init state:[ 5 20 14  1  0  0  0  0], end state:[ 0 20 14  0  1  1  0  1]
INFO:Reinforcement.Functions:episode: 54, score:[2711.20], loss:[5.05857], sequence:[0], random actions:[83], eInit:[0.5870], init state:[ 5 19 59  1  0  0  1  0], end state:[ 0 19 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 55, score:[2739.60], loss:[4.70786], sequence:[1], random actions:[80], eInit:[0.5812], init state:[ 1  5 45  0  0  0  0  0], end state:[ 3  5 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 56, score:[2686.80], loss:[4.69896], sequence:[0], random actions:[71], eInit:[0.5754], init state:[ 3  7 25  0  0  0  0  0], end state:[ 5  7 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 57, score:[2653.20], loss:[4.87557], sequence:[0], random actions:[82], eInit:[0.5696], init state:[ 3  5 37  0  0  0  0  0], end state:[ 5  5 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 58, score:[2738.40], loss:[4.62724], sequence:[1], random actions:[72], eInit:[0.5639], init state:[ 4 14 51  0  0  0  0  0], end state:[ 6 14 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 59, score:[2680.40], loss:[4.51842], sequence:[0], random actions:[81], eInit:[0.5583], init state:[ 2 13 52  0  0  0  0  0], end state:[ 4 13 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 60, score:[2655.20], loss:[4.79435], sequence:[0], random actions:[85], eInit:[0.5527], init state:[ 4  5 34  0  0  0  0  0], end state:[ 6  5 34  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2739.5999999999976, [55]) , maxSequence:(1, [55, 58])
INFO:Reinforcement.Functions:episode: 61, score:[2687.60], loss:[5.12767], sequence:[0], random actions:[79], eInit:[0.5472], init state:[ 4 10 35  1  1  0  1  0], end state:[ 6 10 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 62, score:[2688.00], loss:[5.01830], sequence:[0], random actions:[77], eInit:[0.5417], init state:[ 6 15 17  0  0  0  0  0], end state:[ 1 15 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 63, score:[2704.40], loss:[4.64195], sequence:[0], random actions:[75], eInit:[0.5363], init state:[ 2 21  8  1  1  0  1  1], end state:[ 4 21  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 64, score:[2702.40], loss:[4.58015], sequence:[0], random actions:[83], eInit:[0.5309], init state:[4 6 2 0 0 0 0 0], end state:[6 6 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 65, score:[2721.60], loss:[4.17213], sequence:[0], random actions:[81], eInit:[0.5256], init state:[ 4 16 24  0  0  0  0  0], end state:[ 6 16 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 66, score:[2713.60], loss:[4.08619], sequence:[0], random actions:[83], eInit:[0.5203], init state:[ 2 23  4  1  0  0  0  0], end state:[ 4 23  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 67, score:[2675.20], loss:[4.42337], sequence:[0], random actions:[71], eInit:[0.5151], init state:[ 6  6 13  0  0  0  0  0], end state:[ 1  6 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 68, score:[2728.40], loss:[4.05266], sequence:[0], random actions:[70], eInit:[0.5100], init state:[ 2  3 42  0  0  0  0  0], end state:[ 4  3 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 69, score:[2752.00], loss:[3.78356], sequence:[1], random actions:[61], eInit:[0.5049], init state:[ 0  2 35  0  0  0  0  0], end state:[ 2  2 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 70, score:[2748.80], loss:[3.75818], sequence:[2], random actions:[74], eInit:[0.4998], init state:[ 6 17 27  0  0  0  0  0], end state:[ 1 17 27  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2751.999999999995, [69]) , maxSequence:(2, [70])
INFO:Reinforcement.Functions:episode: 71, score:[2738.40], loss:[3.72367], sequence:[3], random actions:[85], eInit:[0.4948], init state:[ 0  2 45  0  0  0  0  0], end state:[ 2  2 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 72, score:[2697.60], loss:[3.90412], sequence:[0], random actions:[76], eInit:[0.4899], init state:[ 5 23 22  1  0  0  0  0], end state:[ 0 23 22  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 73, score:[2692.80], loss:[4.20667], sequence:[0], random actions:[85], eInit:[0.4850], init state:[ 6 20 44  1  1  0  0  0], end state:[ 1 20 44  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 74, score:[2666.00], loss:[3.96716], sequence:[0], random actions:[78], eInit:[0.4801], init state:[ 3 14 59  0  0  0  0  0], end state:[ 5 14 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 75, score:[2695.60], loss:[3.99607], sequence:[0], random actions:[68], eInit:[0.4753], init state:[ 5  8 39  0  0  0  0  0], end state:[ 0  8 39  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 76, score:[2708.00], loss:[4.05741], sequence:[0], random actions:[87], eInit:[0.4706], init state:[ 2 10 28  0  0  0  0  0], end state:[ 4 10 28  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 77, score:[2723.60], loss:[3.70917], sequence:[0], random actions:[71], eInit:[0.4659], init state:[ 5  1 57  0  0  0  0  0], end state:[ 0  1 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 78, score:[2690.80], loss:[3.94983], sequence:[0], random actions:[73], eInit:[0.4612], init state:[ 3  1 51  0  0  0  0  0], end state:[ 5  1 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 79, score:[2767.60], loss:[3.80041], sequence:[1], random actions:[61], eInit:[0.4566], init state:[ 1  5 13  0  0  0  0  0], end state:[ 3  5 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 80, score:[2669.20], loss:[4.31301], sequence:[0], random actions:[77], eInit:[0.4520], init state:[ 4 12 56  1  1  0  1  0], end state:[ 6 12 56  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2767.5999999999967, [79]) , maxSequence:(3, [71])
INFO:Reinforcement.Functions:episode: 81, score:[2712.40], loss:[4.17993], sequence:[0], random actions:[82], eInit:[0.4475], init state:[ 0 22  0  1  0  0  0  0], end state:[ 2 22  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 82, score:[2687.60], loss:[3.93821], sequence:[0], random actions:[71], eInit:[0.4430], init state:[ 3  5 54  0  0  0  0  0], end state:[ 5  5 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 83, score:[2757.60], loss:[3.67110], sequence:[1], random actions:[68], eInit:[0.4386], init state:[ 4 16 28  0  0  0  0  0], end state:[ 6 16 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 84, score:[2764.40], loss:[3.58687], sequence:[2], random actions:[57], eInit:[0.4342], init state:[ 6 12 34  0  0  0  0  0], end state:[ 1 12 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 85, score:[2748.80], loss:[3.66627], sequence:[3], random actions:[67], eInit:[0.4299], init state:[ 0 13 20  0  0  0  0  0], end state:[ 2 13 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 86, score:[2774.40], loss:[3.53474], sequence:[4], random actions:[58], eInit:[0.4256], init state:[ 0  8 25  1  0  0  0  0], end state:[ 2  8 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 87, score:[2751.60], loss:[3.91014], sequence:[5], random actions:[58], eInit:[0.4213], init state:[ 3 23 43  1  0  0  1  0], end state:[ 5 23 43  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 88, score:[2764.00], loss:[3.40710], sequence:[6], random actions:[64], eInit:[0.4171], init state:[ 4 18 56  0  0  0  0  0], end state:[ 6 18 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 89, score:[2718.00], loss:[3.50721], sequence:[0], random actions:[73], eInit:[0.4129], init state:[ 1 15 42  0  0  0  0  0], end state:[ 3 15 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 90, score:[2795.20], loss:[3.27785], sequence:[1], random actions:[44], eInit:[0.4088], init state:[ 0  5 21  0  0  0  0  0], end state:[ 2  5 21  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2795.199999999997, [90]) , maxSequence:(6, [88])
INFO:Reinforcement.Functions:episode: 91, score:[2756.00], loss:[3.27483], sequence:[2], random actions:[64], eInit:[0.4047], init state:[ 0  6 37  0  0  0  0  0], end state:[ 2  6 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 92, score:[2734.80], loss:[3.14084], sequence:[0], random actions:[69], eInit:[0.4007], init state:[ 4 18 58  0  0  0  0  0], end state:[ 6 18 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 93, score:[2776.80], loss:[3.08546], sequence:[1], random actions:[44], eInit:[0.3967], init state:[ 4 19 49  0  0  0  0  0], end state:[ 6 19 49  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 94, score:[2778.00], loss:[3.16376], sequence:[2], random actions:[58], eInit:[0.3927], init state:[ 0  6 10  0  0  0  0  0], end state:[ 2  6 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 95, score:[2705.20], loss:[3.09571], sequence:[0], random actions:[73], eInit:[0.3888], init state:[ 5  4 15  0  0  0  0  0], end state:[ 0  4 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 96, score:[2764.00], loss:[3.05547], sequence:[1], random actions:[64], eInit:[0.3849], init state:[ 1  8 22  1  0  0  0  0], end state:[ 3  8 22  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 97, score:[2734.40], loss:[2.82228], sequence:[0], random actions:[71], eInit:[0.3810], init state:[ 2 12 44  0  0  0  0  0], end state:[ 4 12 44  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 98, score:[2690.80], loss:[3.10871], sequence:[0], random actions:[59], eInit:[0.3772], init state:[ 4 22 25  0  0  0  0  0], end state:[ 6 22 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 99, score:[2656.80], loss:[4.03520], sequence:[0], random actions:[63], eInit:[0.3735], init state:[ 4  4 56  0  0  0  0  0], end state:[ 6  4 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 100, score:[2731.60], loss:[3.39753], sequence:[0], random actions:[57], eInit:[0.3697], init state:[ 5 19 17  1  0  0  1  0], end state:[ 0 19 17  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2795.199999999997, [90]) , maxSequence:(6, [88])
INFO:Reinforcement.Functions:episode: 101, score:[2760.80], loss:[3.33224], sequence:[1], random actions:[59], eInit:[0.3660], init state:[ 4 16 40  0  0  0  0  0], end state:[ 6 16 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 102, score:[2761.20], loss:[3.11705], sequence:[2], random actions:[52], eInit:[0.3624], init state:[ 5  0 37  0  0  0  0  0], end state:[ 0  0 37  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 103, score:[2731.20], loss:[3.21641], sequence:[0], random actions:[67], eInit:[0.3587], init state:[ 1 16  1  0  0  0  0  0], end state:[ 3 16  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 104, score:[2686.80], loss:[3.51263], sequence:[0], random actions:[64], eInit:[0.3552], init state:[ 3  7 11  0  0  0  0  0], end state:[ 5  7 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 105, score:[2731.20], loss:[3.71656], sequence:[0], random actions:[71], eInit:[0.3516], init state:[ 1 20 53  1  1  0  1  0], end state:[ 3 20 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 106, score:[2736.00], loss:[3.33170], sequence:[0], random actions:[73], eInit:[0.3481], init state:[ 5 19  9  1  0  0  1  0], end state:[ 0 19  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 107, score:[2731.60], loss:[3.17330], sequence:[0], random actions:[60], eInit:[0.3446], init state:[ 5  5 15  0  0  0  0  0], end state:[ 0  5 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 108, score:[2786.80], loss:[2.91427], sequence:[1], random actions:[59], eInit:[0.3412], init state:[ 0 13  5  0  0  0  0  0], end state:[ 2 13  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 109, score:[2664.40], loss:[3.35821], sequence:[0], random actions:[69], eInit:[0.3378], init state:[ 3 19 24  0  0  0  0  0], end state:[ 5 19 24  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 110, score:[2750.00], loss:[3.50241], sequence:[1], random actions:[54], eInit:[0.3344], init state:[ 5 20 43  1  0  0  0  0], end state:[ 0 20 43  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2795.199999999997, [90]) , maxSequence:(6, [88])
INFO:Reinforcement.Functions:episode: 111, score:[2684.40], loss:[3.24318], sequence:[0], random actions:[68], eInit:[0.3310], init state:[3 0 2 1 0 0 0 0], end state:[5 0 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 112, score:[2750.80], loss:[3.09741], sequence:[1], random actions:[62], eInit:[0.3277], init state:[ 0 10 23  0  0  0  0  0], end state:[ 2 10 23  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 113, score:[2762.80], loss:[2.94680], sequence:[2], random actions:[51], eInit:[0.3244], init state:[ 2  9 54  0  0  0  0  0], end state:[ 4  9 54  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 114, score:[2796.40], loss:[2.76890], sequence:[3], random actions:[46], eInit:[0.3212], init state:[ 1 21 28  1  1  0  1  0], end state:[ 3 21 28  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 115, score:[2778.80], loss:[2.60822], sequence:[4], random actions:[58], eInit:[0.3180], init state:[ 1 15  0  0  0  0  0  0], end state:[ 3 15  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 116, score:[2739.20], loss:[2.54509], sequence:[5], random actions:[63], eInit:[0.3148], init state:[5 6 4 0 0 0 0 0], end state:[0 6 4 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 117, score:[2758.00], loss:[2.33812], sequence:[6], random actions:[64], eInit:[0.3117], init state:[2 2 2 0 0 0 0 0], end state:[4 2 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 118, score:[2775.60], loss:[2.40766], sequence:[7], random actions:[62], eInit:[0.3085], init state:[ 1  6 43  0  0  0  0  0], end state:[ 3  6 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 119, score:[2757.60], loss:[2.22710], sequence:[8], random actions:[55], eInit:[0.3055], init state:[ 2 11 37  0  0  0  0  0], end state:[ 4 11 37  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 120, score:[2772.40], loss:[2.31972], sequence:[9], random actions:[53], eInit:[0.3024], init state:[ 3 14 34  0  0  0  0  0], end state:[ 5 14 34  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2796.399999999997, [114]) , maxSequence:(9, [120])
INFO:Reinforcement.Functions:episode: 121, score:[2772.80], loss:[2.24110], sequence:[10], random actions:[54], eInit:[0.2994], init state:[ 6 23  4  1  0  0  0  0], end state:[ 1 23  4  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 122, score:[2767.20], loss:[2.21128], sequence:[11], random actions:[52], eInit:[0.2964], init state:[ 3 18 52  0  0  0  0  0], end state:[ 5 18 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 123, score:[2718.00], loss:[2.60242], sequence:[0], random actions:[50], eInit:[0.2934], init state:[ 5 18 54  1  1  0  1  0], end state:[ 0 18 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 124, score:[2752.00], loss:[2.26822], sequence:[1], random actions:[61], eInit:[0.2905], init state:[ 3 17 45  0  0  0  0  0], end state:[ 5 17 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 125, score:[2741.20], loss:[2.24065], sequence:[2], random actions:[63], eInit:[0.2876], init state:[ 3 13  3  0  0  0  0  0], end state:[ 5 13  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 126, score:[2770.00], loss:[2.19992], sequence:[3], random actions:[57], eInit:[0.2847], init state:[ 1 22  5  1  0  0  0  0], end state:[ 3 22  5  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 127, score:[2784.00], loss:[2.25700], sequence:[4], random actions:[51], eInit:[0.2819], init state:[ 0  6 16  0  0  0  0  0], end state:[ 2  6 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 128, score:[2716.40], loss:[2.23703], sequence:[0], random actions:[55], eInit:[0.2790], init state:[ 3 19 19  0  0  0  0  0], end state:[ 5 19 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 129, score:[2783.60], loss:[2.10332], sequence:[1], random actions:[52], eInit:[0.2763], init state:[ 2  9 26  0  0  0  0  0], end state:[ 4  9 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 130, score:[2734.40], loss:[2.21262], sequence:[0], random actions:[45], eInit:[0.2735], init state:[5 0 5 0 0 0 0 0], end state:[0 0 5 1 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2796.399999999997, [114]) , maxSequence:(11, [122])
INFO:Reinforcement.Functions:episode: 131, score:[2737.60], loss:[2.16211], sequence:[1], random actions:[57], eInit:[0.2708], init state:[ 6  1 57  0  0  0  0  0], end state:[ 1  1 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 132, score:[2711.60], loss:[2.54380], sequence:[0], random actions:[58], eInit:[0.2680], init state:[ 5 21 26  1  0  0  1  1], end state:[ 0 21 26  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 133, score:[2756.00], loss:[2.08885], sequence:[1], random actions:[66], eInit:[0.2654], init state:[ 6 21 52  1  0  0  0  0], end state:[ 1 21 52  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 134, score:[2769.20], loss:[2.16037], sequence:[2], random actions:[43], eInit:[0.2627], init state:[ 0  9 34  0  0  0  0  0], end state:[ 2  9 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 135, score:[2762.80], loss:[2.07147], sequence:[3], random actions:[41], eInit:[0.2601], init state:[3 9 5 0 0 0 0 0], end state:[5 9 5 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 136, score:[2758.80], loss:[2.17505], sequence:[4], random actions:[44], eInit:[0.2575], init state:[ 5 22 18  1  0  0  1  0], end state:[ 0 22 18  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 137, score:[2777.20], loss:[2.09866], sequence:[5], random actions:[47], eInit:[0.2549], init state:[ 0 23 36  1  0  0  1  0], end state:[ 2 23 36  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 138, score:[2756.40], loss:[2.54614], sequence:[6], random actions:[48], eInit:[0.2524], init state:[ 3  8 16  1  0  0  0  0], end state:[ 5  8 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 139, score:[2775.60], loss:[2.25706], sequence:[7], random actions:[52], eInit:[0.2498], init state:[ 2 10 30  0  0  0  0  0], end state:[ 4 10 30  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 140, score:[2752.40], loss:[2.33403], sequence:[8], random actions:[57], eInit:[0.2473], init state:[ 6  5 32  0  0  0  0  0], end state:[ 1  5 32  1  1  1  0  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2796.399999999997, [114]) , maxSequence:(11, [122])
INFO:Reinforcement.Functions:episode: 141, score:[2768.80], loss:[2.10452], sequence:[9], random actions:[48], eInit:[0.2449], init state:[ 3  6 37  0  0  0  0  0], end state:[ 5  6 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 142, score:[2701.20], loss:[2.37841], sequence:[0], random actions:[46], eInit:[0.2424], init state:[ 4 10 58  1  1  0  1  0], end state:[ 6 10 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 143, score:[2809.60], loss:[2.18224], sequence:[1], random actions:[30], eInit:[0.2400], init state:[ 3  1 30  0  0  0  0  0], end state:[ 5  1 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 144, score:[2783.20], loss:[2.13465], sequence:[2], random actions:[48], eInit:[0.2376], init state:[ 2 17 44  0  0  0  0  0], end state:[ 4 17 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 145, score:[2768.80], loss:[2.15298], sequence:[3], random actions:[46], eInit:[0.2352], init state:[ 6 11 47  0  0  0  0  0], end state:[ 1 11 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 146, score:[2761.20], loss:[2.31912], sequence:[4], random actions:[52], eInit:[0.2329], init state:[ 6  3 19  0  0  0  0  0], end state:[ 1  3 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 147, score:[2770.00], loss:[2.40921], sequence:[5], random actions:[54], eInit:[0.2305], init state:[ 1  5 16  0  0  0  0  0], end state:[ 3  5 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 148, score:[2724.40], loss:[2.56179], sequence:[0], random actions:[50], eInit:[0.2282], init state:[ 4 11  7  1  1  0  0  0], end state:[ 6 11  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 149, score:[2767.60], loss:[2.20193], sequence:[1], random actions:[53], eInit:[0.2259], init state:[ 6 14 52  0  0  0  0  0], end state:[ 1 14 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 150, score:[2776.40], loss:[2.10152], sequence:[2], random actions:[54], eInit:[0.2237], init state:[5 4 2 0 0 0 0 0], end state:[0 4 2 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2809.5999999999954, [143]) , maxSequence:(11, [122])
INFO:Reinforcement.Functions:episode: 151, score:[2792.80], loss:[1.97566], sequence:[3], random actions:[42], eInit:[0.2215], init state:[ 1 12 55  0  0  0  0  0], end state:[ 3 12 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 152, score:[2779.20], loss:[1.91678], sequence:[4], random actions:[53], eInit:[0.2192], init state:[ 6 11 55  0  0  0  0  0], end state:[ 1 11 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 153, score:[2756.80], loss:[2.13613], sequence:[5], random actions:[39], eInit:[0.2170], init state:[ 3  6 21  0  0  0  0  0], end state:[ 5  6 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 154, score:[2776.80], loss:[1.95999], sequence:[6], random actions:[40], eInit:[0.2149], init state:[ 0  4 42  0  0  0  0  0], end state:[ 2  4 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 155, score:[2776.40], loss:[1.89038], sequence:[7], random actions:[45], eInit:[0.2127], init state:[ 5  4 59  0  0  0  0  0], end state:[ 0  4 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 156, score:[2755.20], loss:[2.35682], sequence:[8], random actions:[55], eInit:[0.2106], init state:[ 5 15 38  0  0  0  0  0], end state:[ 0 15 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 157, score:[2738.00], loss:[2.31097], sequence:[9], random actions:[47], eInit:[0.2085], init state:[ 4 10 11  1  1  0  1  1], end state:[ 6 10 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 158, score:[2788.00], loss:[1.97182], sequence:[10], random actions:[50], eInit:[0.2064], init state:[ 1 10  5  0  0  0  0  0], end state:[ 3 10  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 159, score:[2765.60], loss:[1.82019], sequence:[11], random actions:[59], eInit:[0.2043], init state:[ 0  2 45  0  0  0  0  0], end state:[ 2  2 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 160, score:[2778.00], loss:[1.72256], sequence:[12], random actions:[49], eInit:[0.2023], init state:[ 0 15 22  0  0  0  0  0], end state:[ 2 15 22  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2809.5999999999954, [143]) , maxSequence:(12, [160])
INFO:Reinforcement.Functions:episode: 161, score:[2759.20], loss:[1.88462], sequence:[13], random actions:[51], eInit:[0.2003], init state:[ 2  9 35  0  0  0  0  0], end state:[ 4  9 35  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 162, score:[2752.00], loss:[2.07263], sequence:[14], random actions:[49], eInit:[0.1983], init state:[ 4 11 52  1  1  0  0  0], end state:[ 6 11 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 163, score:[2766.00], loss:[1.97664], sequence:[15], random actions:[42], eInit:[0.1963], init state:[ 6 11 58  0  0  0  0  0], end state:[ 1 11 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 164, score:[2776.40], loss:[1.99694], sequence:[16], random actions:[44], eInit:[0.1943], init state:[ 5 10 36  0  0  0  0  0], end state:[ 0 10 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 165, score:[2749.20], loss:[1.92642], sequence:[17], random actions:[44], eInit:[0.1924], init state:[3 2 0 0 0 0 0 0], end state:[5 2 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 166, score:[2700.00], loss:[2.04343], sequence:[0], random actions:[66], eInit:[0.1905], init state:[ 3  0 44  0  0  1  0  0], end state:[ 5  0 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 167, score:[2786.80], loss:[2.00451], sequence:[1], random actions:[44], eInit:[0.1886], init state:[ 6  1 11  0  0  0  0  0], end state:[ 1  1 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 168, score:[2784.80], loss:[1.89272], sequence:[2], random actions:[49], eInit:[0.1867], init state:[ 6 10 47  0  0  0  0  0], end state:[ 1 10 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 169, score:[2794.40], loss:[1.77322], sequence:[3], random actions:[37], eInit:[0.1848], init state:[ 1  1 41  0  0  0  0  0], end state:[ 3  1 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 170, score:[2810.80], loss:[1.74703], sequence:[4], random actions:[41], eInit:[0.1830], init state:[ 0 13 27  0  0  0  0  0], end state:[ 2 13 27  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2810.799999999998, [170]) , maxSequence:(17, [165])
INFO:Reinforcement.Functions:episode: 171, score:[2790.40], loss:[1.69807], sequence:[5], random actions:[34], eInit:[0.1811], init state:[ 5  2 50  0  0  0  0  0], end state:[ 0  2 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 172, score:[2722.40], loss:[1.89172], sequence:[0], random actions:[46], eInit:[0.1793], init state:[ 5 21 29  1  0  0  1  1], end state:[ 0 21 29  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 173, score:[2794.80], loss:[1.87882], sequence:[1], random actions:[39], eInit:[0.1775], init state:[ 5 21 18  1  0  0  1  0], end state:[ 0 21 18  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 174, score:[2741.60], loss:[1.93504], sequence:[2], random actions:[42], eInit:[0.1757], init state:[ 3  9 32  0  0  0  0  0], end state:[ 5  9 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 175, score:[2721.60], loss:[2.40685], sequence:[0], random actions:[39], eInit:[0.1740], init state:[ 3  5 21  0  0  0  0  0], end state:[ 5  5 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 176, score:[2808.40], loss:[3.00150], sequence:[1], random actions:[36], eInit:[0.1722], init state:[ 1  6 48  0  0  0  0  0], end state:[ 3  6 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 177, score:[2748.80], loss:[2.93581], sequence:[2], random actions:[45], eInit:[0.1705], init state:[ 5 20 58  1  0  0  0  0], end state:[ 0 20 58  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 178, score:[2782.80], loss:[2.40834], sequence:[3], random actions:[46], eInit:[0.1688], init state:[ 4 16 57  0  0  0  0  0], end state:[ 6 16 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 179, score:[2752.80], loss:[2.29673], sequence:[4], random actions:[53], eInit:[0.1671], init state:[ 6  8 52  1  1  0  0  0], end state:[ 1  8 52  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 180, score:[2784.00], loss:[2.35803], sequence:[5], random actions:[37], eInit:[0.1655], init state:[ 3 13 30  0  0  0  0  0], end state:[ 5 13 30  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2810.799999999998, [170]) , maxSequence:(17, [165])
INFO:Reinforcement.Functions:episode: 181, score:[2774.00], loss:[1.97173], sequence:[6], random actions:[41], eInit:[0.1638], init state:[ 5  1 47  0  0  0  0  0], end state:[ 0  1 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 182, score:[2770.40], loss:[1.91872], sequence:[7], random actions:[28], eInit:[0.1622], init state:[ 5  2 57  0  0  0  0  0], end state:[ 0  2 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 183, score:[2766.80], loss:[2.04846], sequence:[8], random actions:[44], eInit:[0.1605], init state:[ 3 22 39  1  0  0  0  0], end state:[ 5 22 39  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 184, score:[2772.40], loss:[2.28250], sequence:[9], random actions:[39], eInit:[0.1589], init state:[ 5 15 29  0  0  0  0  0], end state:[ 0 15 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 185, score:[2790.80], loss:[1.89684], sequence:[10], random actions:[37], eInit:[0.1574], init state:[ 1  2 39  0  0  0  0  0], end state:[ 3  2 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 186, score:[2739.60], loss:[1.95803], sequence:[11], random actions:[57], eInit:[0.1558], init state:[ 2 13 50  0  0  0  0  0], end state:[ 4 13 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 187, score:[2804.80], loss:[2.05406], sequence:[12], random actions:[44], eInit:[0.1542], init state:[ 3 13 36  0  0  0  0  0], end state:[ 5 13 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 188, score:[2798.00], loss:[1.88685], sequence:[13], random actions:[36], eInit:[0.1527], init state:[ 4  4 49  0  0  0  0  0], end state:[ 6  4 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 189, score:[2801.20], loss:[1.72462], sequence:[14], random actions:[33], eInit:[0.1512], init state:[ 0 14 58  0  0  0  0  0], end state:[ 2 14 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 190, score:[2818.80], loss:[1.72623], sequence:[15], random actions:[35], eInit:[0.1496], init state:[ 3 10 47  0  0  0  0  0], end state:[ 5 10 47  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2818.799999999998, [190]) , maxSequence:(17, [165])
INFO:Reinforcement.Functions:episode: 191, score:[2794.40], loss:[1.56876], sequence:[16], random actions:[32], eInit:[0.1481], init state:[ 5 23  4  1  0  0  1  0], end state:[ 0 23  4  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 192, score:[2806.80], loss:[1.62472], sequence:[17], random actions:[46], eInit:[0.1467], init state:[1 1 1 0 0 1 0 0], end state:[3 1 1 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 193, score:[2816.80], loss:[1.42110], sequence:[18], random actions:[34], eInit:[0.1452], init state:[ 3 22 16  1  0  0  0  0], end state:[ 5 22 16  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 194, score:[2804.00], loss:[1.50267], sequence:[19], random actions:[46], eInit:[0.1437], init state:[ 0 16 25  0  0  0  0  0], end state:[ 2 16 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 195, score:[2812.00], loss:[1.36818], sequence:[20], random actions:[38], eInit:[0.1423], init state:[ 5 21 55  1  0  0  1  0], end state:[ 0 21 55  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 196, score:[2826.40], loss:[1.38093], sequence:[21], random actions:[25], eInit:[0.1409], init state:[ 3 23 46  1  0  0  0  0], end state:[ 5 23 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 197, score:[2784.40], loss:[1.45578], sequence:[22], random actions:[36], eInit:[0.1395], init state:[2 3 8 0 0 0 0 0], end state:[4 3 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 198, score:[2710.00], loss:[1.64498], sequence:[0], random actions:[47], eInit:[0.1381], init state:[ 2 23 44  1  0  0  1  0], end state:[ 4 23 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 199, score:[2744.00], loss:[2.10823], sequence:[1], random actions:[36], eInit:[0.1367], init state:[ 3  6 19  0  0  0  0  0], end state:[ 5  6 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 200, score:[2750.40], loss:[1.71629], sequence:[2], random actions:[35], eInit:[0.1353], init state:[ 5  0 24  0  0  0  0  0], end state:[ 0  0 24  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2826.399999999997, [196]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 201, score:[2755.20], loss:[1.73071], sequence:[3], random actions:[40], eInit:[0.1340], init state:[1 5 9 0 0 0 0 0], end state:[3 5 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 202, score:[2818.40], loss:[1.55600], sequence:[4], random actions:[44], eInit:[0.1326], init state:[ 1 10 36  0  0  0  0  0], end state:[ 3 10 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 203, score:[2798.40], loss:[1.45323], sequence:[5], random actions:[40], eInit:[0.1313], init state:[ 5  4 17  0  0  0  0  0], end state:[ 0  4 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 204, score:[2756.40], loss:[1.76316], sequence:[6], random actions:[49], eInit:[0.1300], init state:[ 4  4 42  0  0  0  0  0], end state:[ 6  4 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 205, score:[2768.80], loss:[1.73969], sequence:[7], random actions:[47], eInit:[0.1287], init state:[ 5  8 55  0  0  0  0  0], end state:[ 0  8 55  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 206, score:[2768.00], loss:[1.69893], sequence:[8], random actions:[42], eInit:[0.1274], init state:[ 4 18 28  0  0  0  0  0], end state:[ 6 18 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 207, score:[2786.40], loss:[1.52782], sequence:[9], random actions:[38], eInit:[0.1261], init state:[ 3 14 59  0  0  0  0  0], end state:[ 5 14 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 208, score:[2747.20], loss:[1.94701], sequence:[10], random actions:[35], eInit:[0.1249], init state:[4 3 1 0 0 0 0 0], end state:[6 3 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 209, score:[2825.60], loss:[1.66479], sequence:[11], random actions:[29], eInit:[0.1236], init state:[ 0 17 59  0  0  0  0  0], end state:[ 2 17 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 210, score:[2810.80], loss:[1.51071], sequence:[12], random actions:[30], eInit:[0.1224], init state:[ 4 19 12  0  0  0  0  0], end state:[ 6 19 12  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2826.399999999997, [196]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 211, score:[2722.00], loss:[1.79718], sequence:[0], random actions:[45], eInit:[0.1212], init state:[ 3 23 32  1  0  0  1  0], end state:[ 5 23 32  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 212, score:[2803.20], loss:[1.93961], sequence:[1], random actions:[37], eInit:[0.1200], init state:[ 0  5 46  0  0  0  0  0], end state:[ 2  5 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 213, score:[2809.20], loss:[1.73618], sequence:[2], random actions:[37], eInit:[0.1188], init state:[ 2  9 40  0  0  0  0  0], end state:[ 4  9 40  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 214, score:[2821.20], loss:[1.70141], sequence:[3], random actions:[33], eInit:[0.1176], init state:[ 3 14 30  0  0  0  0  0], end state:[ 5 14 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 215, score:[2800.40], loss:[1.59988], sequence:[4], random actions:[27], eInit:[0.1164], init state:[5 8 2 0 0 0 0 0], end state:[0 8 2 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 216, score:[2783.20], loss:[1.66176], sequence:[5], random actions:[44], eInit:[0.1152], init state:[ 2  0 25  1  0  0  0  0], end state:[ 4  0 25  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 217, score:[2828.40], loss:[1.42930], sequence:[6], random actions:[30], eInit:[0.1141], init state:[ 0 22 13  1  0  0  0  0], end state:[ 2 22 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 218, score:[2797.60], loss:[1.37086], sequence:[7], random actions:[38], eInit:[0.1129], init state:[ 0  3 57  0  0  0  0  0], end state:[ 2  3 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 219, score:[2789.20], loss:[1.51718], sequence:[8], random actions:[26], eInit:[0.1118], init state:[ 3 23  2  1  0  0  0  0], end state:[ 5 23  2  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 220, score:[2807.60], loss:[1.44853], sequence:[9], random actions:[37], eInit:[0.1107], init state:[ 6 11 29  0  0  0  0  0], end state:[ 1 11 29  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2828.399999999998, [217]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 221, score:[2829.60], loss:[1.32077], sequence:[10], random actions:[30], eInit:[0.1096], init state:[ 1 21 26  1  1  0  1  0], end state:[ 3 21 26  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 222, score:[2794.80], loss:[1.29492], sequence:[11], random actions:[39], eInit:[0.1085], init state:[ 6 19  0  0  0  0  0  0], end state:[ 1 19  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 223, score:[2772.80], loss:[1.38066], sequence:[12], random actions:[44], eInit:[0.1074], init state:[ 5 19 35  1  0  0  1  0], end state:[ 0 19 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 224, score:[2793.20], loss:[1.39942], sequence:[13], random actions:[45], eInit:[0.1063], init state:[ 6  0 53  0  0  1  0  0], end state:[ 1  0 53  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 225, score:[2829.20], loss:[1.29360], sequence:[14], random actions:[32], eInit:[0.1053], init state:[ 0  2 20  0  0  0  0  0], end state:[ 2  2 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 226, score:[2803.20], loss:[1.24953], sequence:[15], random actions:[29], eInit:[0.1042], init state:[ 4  0 15  1  0  0  0  0], end state:[ 6  0 15  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 227, score:[2761.60], loss:[1.49257], sequence:[16], random actions:[31], eInit:[0.1032], init state:[ 3 15 47  0  0  0  0  0], end state:[ 5 15 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 228, score:[2785.60], loss:[1.32915], sequence:[17], random actions:[51], eInit:[0.1021], init state:[ 1 21 58  1  0  0  0  0], end state:[ 3 21 58  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 229, score:[2789.20], loss:[1.30542], sequence:[18], random actions:[25], eInit:[0.1011], init state:[ 3 17 36  0  0  0  0  0], end state:[ 5 17 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 230, score:[2821.60], loss:[1.16470], sequence:[19], random actions:[26], eInit:[0.1001], init state:[ 6  5 52  0  0  0  0  0], end state:[ 1  5 52  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2829.599999999998, [221]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 231, score:[2693.60], loss:[1.41258], sequence:[0], random actions:[29], eInit:[0.0991], init state:[ 4  1 32  0  0  0  0  0], end state:[ 6  1 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 232, score:[2821.20], loss:[1.36048], sequence:[1], random actions:[35], eInit:[0.0981], init state:[ 6 22 40  1  0  0  0  0], end state:[ 1 22 40  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 233, score:[2794.00], loss:[1.35745], sequence:[2], random actions:[32], eInit:[0.0971], init state:[ 4 19 19  0  0  0  0  0], end state:[ 6 19 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 234, score:[2810.80], loss:[1.40144], sequence:[3], random actions:[29], eInit:[0.0962], init state:[ 5 19 51  1  0  0  1  0], end state:[ 0 19 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 235, score:[2765.20], loss:[1.43883], sequence:[4], random actions:[33], eInit:[0.0952], init state:[ 1 11 27  0  0  0  0  0], end state:[ 3 11 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 236, score:[2825.20], loss:[1.46049], sequence:[5], random actions:[36], eInit:[0.0942], init state:[ 1 13 48  0  0  0  0  0], end state:[ 3 13 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 237, score:[2789.20], loss:[1.55457], sequence:[6], random actions:[47], eInit:[0.0933], init state:[ 2  7 37  0  0  0  0  0], end state:[ 4  7 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 238, score:[2789.60], loss:[1.56271], sequence:[7], random actions:[26], eInit:[0.0924], init state:[ 5 16  9  0  0  0  0  0], end state:[ 0 16  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 239, score:[2797.60], loss:[1.48805], sequence:[8], random actions:[32], eInit:[0.0914], init state:[ 3 13 16  0  0  0  0  0], end state:[ 5 13 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 240, score:[2758.80], loss:[1.45401], sequence:[9], random actions:[39], eInit:[0.0905], init state:[ 4  4 11  0  0  0  0  0], end state:[ 6  4 11  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2829.599999999998, [221]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 241, score:[2797.60], loss:[1.33911], sequence:[10], random actions:[44], eInit:[0.0896], init state:[ 6 12  0  0  0  0  0  0], end state:[ 1 12  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 242, score:[2736.00], loss:[1.72517], sequence:[0], random actions:[29], eInit:[0.0887], init state:[ 3  2 37  0  0  0  0  0], end state:[ 5  2 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 243, score:[2761.60], loss:[1.92654], sequence:[1], random actions:[31], eInit:[0.0878], init state:[ 5  3 16  0  0  0  0  0], end state:[ 0  3 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 244, score:[2790.40], loss:[1.77160], sequence:[2], random actions:[40], eInit:[0.0870], init state:[ 2 11 57  0  0  0  0  0], end state:[ 4 11 57  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 245, score:[2809.60], loss:[1.47929], sequence:[3], random actions:[30], eInit:[0.0861], init state:[ 5  3 26  0  0  0  0  0], end state:[ 0  3 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 246, score:[2790.80], loss:[1.65945], sequence:[4], random actions:[34], eInit:[0.0852], init state:[ 3 17 41  0  0  0  0  0], end state:[ 5 17 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 247, score:[2807.60], loss:[1.32472], sequence:[5], random actions:[27], eInit:[0.0844], init state:[ 6  2 52  0  0  0  0  0], end state:[ 1  2 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 248, score:[2796.00], loss:[1.49939], sequence:[6], random actions:[29], eInit:[0.0835], init state:[ 4  9 10  0  0  0  0  0], end state:[ 6  9 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 249, score:[2836.80], loss:[1.36160], sequence:[7], random actions:[24], eInit:[0.0827], init state:[ 1  4 53  0  0  0  0  0], end state:[ 3  4 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 250, score:[2800.80], loss:[1.45723], sequence:[8], random actions:[35], eInit:[0.0819], init state:[ 5  6 51  0  0  0  0  0], end state:[ 0  6 51  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2836.799999999999, [249]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 251, score:[2720.40], loss:[2.27030], sequence:[0], random actions:[35], eInit:[0.0811], init state:[ 5 19 17  1  0  0  1  0], end state:[ 0 19 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 252, score:[2807.60], loss:[1.88258], sequence:[1], random actions:[38], eInit:[0.0802], init state:[ 6 15 55  0  0  0  0  0], end state:[ 1 15 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 253, score:[2783.60], loss:[1.73491], sequence:[2], random actions:[35], eInit:[0.0794], init state:[ 5  7 42  0  0  0  0  0], end state:[ 0  7 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 254, score:[2810.40], loss:[1.74892], sequence:[3], random actions:[31], eInit:[0.0787], init state:[ 1 19 23  0  0  0  0  0], end state:[ 3 19 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 255, score:[2822.00], loss:[1.59086], sequence:[4], random actions:[37], eInit:[0.0779], init state:[0 7 9 0 0 0 0 0], end state:[2 7 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 256, score:[2806.40], loss:[1.45618], sequence:[5], random actions:[28], eInit:[0.0771], init state:[ 0  1 59  0  0  0  0  0], end state:[ 2  1 59  0  1  1  0  1]
INFO:Reinforcement.Functions:episode: 257, score:[2806.40], loss:[1.58356], sequence:[6], random actions:[39], eInit:[0.0763], init state:[ 1 12 54  0  0  0  0  0], end state:[ 3 12 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 258, score:[2766.00], loss:[1.73085], sequence:[7], random actions:[36], eInit:[0.0756], init state:[3 6 9 0 0 0 0 0], end state:[5 6 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 259, score:[2754.80], loss:[1.73496], sequence:[8], random actions:[40], eInit:[0.0748], init state:[ 3 19 40  0  0  0  0  0], end state:[ 5 19 40  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 260, score:[2785.20], loss:[1.68995], sequence:[9], random actions:[37], eInit:[0.0740], init state:[ 3 20 57  1  1  0  1  0], end state:[ 5 20 57  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2836.799999999999, [249]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 261, score:[2779.60], loss:[2.06356], sequence:[10], random actions:[31], eInit:[0.0733], init state:[ 0 17 13  0  0  0  0  0], end state:[ 2 17 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 262, score:[2767.20], loss:[1.87788], sequence:[11], random actions:[29], eInit:[0.0726], init state:[ 5 15 47  0  0  0  0  0], end state:[ 0 15 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 263, score:[2820.40], loss:[1.63767], sequence:[12], random actions:[36], eInit:[0.0718], init state:[ 1 16 48  0  0  0  0  0], end state:[ 3 16 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 264, score:[2807.20], loss:[1.56916], sequence:[13], random actions:[37], eInit:[0.0711], init state:[ 6 16  0  0  0  0  0  0], end state:[ 1 16  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 265, score:[2819.20], loss:[1.57777], sequence:[14], random actions:[31], eInit:[0.0704], init state:[ 6 17 14  0  0  0  0  0], end state:[ 1 17 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 266, score:[2805.20], loss:[1.45857], sequence:[15], random actions:[30], eInit:[0.0697], init state:[ 0 20 30  1  1  0  0  0], end state:[ 2 20 30  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 267, score:[2814.00], loss:[1.34488], sequence:[16], random actions:[37], eInit:[0.0690], init state:[ 1  9 57  0  0  0  0  0], end state:[ 3  9 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 268, score:[2778.80], loss:[1.47310], sequence:[17], random actions:[35], eInit:[0.0683], init state:[6 1 9 0 0 1 0 0], end state:[1 1 9 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 269, score:[2805.60], loss:[1.43351], sequence:[18], random actions:[32], eInit:[0.0676], init state:[ 2  8 52  1  1  0  0  0], end state:[ 4  8 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 270, score:[2769.20], loss:[1.47335], sequence:[19], random actions:[33], eInit:[0.0670], init state:[ 5 22 46  1  0  0  1  0], end state:[ 0 22 46  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2836.799999999999, [249]) , maxSequence:(22, [197])
INFO:Reinforcement.Functions:episode: 271, score:[2807.20], loss:[1.31757], sequence:[20], random actions:[22], eInit:[0.0663], init state:[ 3  5 12  0  0  0  0  0], end state:[ 5  5 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 272, score:[2809.60], loss:[1.21300], sequence:[21], random actions:[35], eInit:[0.0656], init state:[ 1 15 24  0  0  0  0  0], end state:[ 3 15 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 273, score:[2797.20], loss:[1.31665], sequence:[22], random actions:[32], eInit:[0.0650], init state:[ 3  5 34  0  0  0  0  0], end state:[ 5  5 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 274, score:[2805.20], loss:[1.37997], sequence:[23], random actions:[35], eInit:[0.0643], init state:[ 6 14 56  0  0  0  0  0], end state:[ 1 14 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 275, score:[2717.60], loss:[1.43270], sequence:[0], random actions:[34], eInit:[0.0637], init state:[ 4 12 49  1  1  0  1  0], end state:[ 6 12 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 276, score:[2792.80], loss:[1.48521], sequence:[1], random actions:[46], eInit:[0.0630], init state:[ 2  2 43  0  0  0  0  0], end state:[ 4  2 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 277, score:[2827.20], loss:[1.54796], sequence:[2], random actions:[41], eInit:[0.0624], init state:[ 0 11 54  0  0  0  0  0], end state:[ 2 11 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 278, score:[2821.60], loss:[1.46270], sequence:[3], random actions:[30], eInit:[0.0618], init state:[6 9 3 0 0 0 0 0], end state:[1 9 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 279, score:[2809.20], loss:[1.35400], sequence:[4], random actions:[33], eInit:[0.0612], init state:[ 4 22 19  0  0  0  0  0], end state:[ 6 22 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 280, score:[2699.60], loss:[1.47649], sequence:[0], random actions:[37], eInit:[0.0606], init state:[ 2 15 32  0  0  0  0  0], end state:[ 4 15 32  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2836.799999999999, [249]) , maxSequence:(23, [274])
INFO:Reinforcement.Functions:episode: 281, score:[2809.20], loss:[1.61478], sequence:[1], random actions:[21], eInit:[0.0600], init state:[ 2  4 14  0  0  0  0  0], end state:[ 4  4 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 282, score:[2798.80], loss:[1.41642], sequence:[2], random actions:[32], eInit:[0.0594], init state:[ 6 16 15  0  0  0  0  0], end state:[ 1 16 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 283, score:[2797.20], loss:[1.26779], sequence:[3], random actions:[31], eInit:[0.0588], init state:[ 0 22 21  1  0  0  0  0], end state:[ 2 22 21  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 284, score:[2805.20], loss:[1.26575], sequence:[4], random actions:[25], eInit:[0.0582], init state:[ 4 14 55  0  0  0  0  0], end state:[ 6 14 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 285, score:[2772.40], loss:[1.81584], sequence:[5], random actions:[32], eInit:[0.0576], init state:[ 3  8 35  1  1  0  1  0], end state:[ 5  8 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 286, score:[2778.00], loss:[1.44289], sequence:[6], random actions:[37], eInit:[0.0570], init state:[ 2 15  7  0  0  0  0  0], end state:[ 4 15  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 287, score:[2774.40], loss:[1.42770], sequence:[7], random actions:[27], eInit:[0.0565], init state:[ 4  9 24  0  0  0  0  0], end state:[ 6  9 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 288, score:[2796.40], loss:[1.60792], sequence:[8], random actions:[36], eInit:[0.0559], init state:[ 1 14 21  0  0  0  0  0], end state:[ 3 14 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 289, score:[2755.60], loss:[1.51029], sequence:[9], random actions:[35], eInit:[0.0553], init state:[ 5 21 24  1  0  0  1  1], end state:[ 0 21 24  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 290, score:[2800.80], loss:[1.48694], sequence:[10], random actions:[27], eInit:[0.0548], init state:[ 6  8 29  1  0  0  0  0], end state:[ 1  8 29  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2836.799999999999, [249]) , maxSequence:(23, [274])
INFO:Reinforcement.Functions:episode: 291, score:[2797.20], loss:[1.38189], sequence:[11], random actions:[37], eInit:[0.0542], init state:[ 5 17 47  0  0  0  0  0], end state:[ 0 17 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 292, score:[2823.20], loss:[1.29354], sequence:[12], random actions:[32], eInit:[0.0537], init state:[ 6 12 50  0  0  0  0  0], end state:[ 1 12 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 293, score:[2791.20], loss:[1.23710], sequence:[13], random actions:[26], eInit:[0.0531], init state:[ 4 20  8  0  0  0  0  0], end state:[ 6 20  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 294, score:[2805.20], loss:[1.30016], sequence:[14], random actions:[43], eInit:[0.0526], init state:[1 7 0 0 0 0 0 0], end state:[3 7 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 295, score:[2798.00], loss:[1.10725], sequence:[15], random actions:[37], eInit:[0.0521], init state:[ 5 23  7  1  0  0  1  0], end state:[ 0 23  7  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 296, score:[2831.60], loss:[1.05048], sequence:[16], random actions:[37], eInit:[0.0516], init state:[ 0 12 15  0  0  0  0  0], end state:[ 2 12 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 297, score:[2772.80], loss:[0.98463], sequence:[17], random actions:[30], eInit:[0.0511], init state:[ 2 15 52  0  0  0  0  0], end state:[ 4 15 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 298, score:[2814.40], loss:[1.07292], sequence:[18], random actions:[36], eInit:[0.0505], init state:[ 0  5 50  0  0  0  0  0], end state:[ 2  5 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 299, score:[2802.00], loss:[1.07979], sequence:[19], random actions:[22], eInit:[0.0500], init state:[ 5  4 31  0  0  0  0  0], end state:[ 0  4 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 300, score:[2830.00], loss:[0.93980], sequence:[20], random actions:[27], eInit:[0.0495], init state:[ 0 18 29  0  0  0  0  0], end state:[ 2 18 29  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2836.799999999999, [249]) , maxSequence:(23, [274])
INFO:Reinforcement.Functions:episode: 301, score:[2804.00], loss:[1.12540], sequence:[21], random actions:[33], eInit:[0.0490], init state:[ 5 20  0  1  0  0  0  0], end state:[ 0 20  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 302, score:[2800.00], loss:[1.36661], sequence:[22], random actions:[37], eInit:[0.0486], init state:[ 6 11 48  0  0  0  0  0], end state:[ 1 11 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 303, score:[2776.80], loss:[1.55563], sequence:[23], random actions:[31], eInit:[0.0481], init state:[ 5  6 19  0  0  0  0  0], end state:[ 0  6 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 304, score:[2781.60], loss:[1.57696], sequence:[24], random actions:[37], eInit:[0.0476], init state:[ 4 20 58  0  0  0  0  0], end state:[ 6 20 58  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 305, score:[2769.20], loss:[1.52489], sequence:[25], random actions:[28], eInit:[0.0471], init state:[ 3 13 12  0  0  0  0  0], end state:[ 5 13 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 306, score:[2817.60], loss:[1.27739], sequence:[26], random actions:[27], eInit:[0.0466], init state:[ 2  0 29  1  0  0  0  0], end state:[ 4  0 29  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 307, score:[2793.20], loss:[1.53462], sequence:[27], random actions:[36], eInit:[0.0462], init state:[ 6 20 33  1  1  0  0  0], end state:[ 1 20 33  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 308, score:[2816.00], loss:[1.34586], sequence:[28], random actions:[33], eInit:[0.0457], init state:[ 2  1 51  0  0  0  0  0], end state:[ 4  1 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 309, score:[2772.40], loss:[1.44899], sequence:[29], random actions:[46], eInit:[0.0453], init state:[ 5 14 55  0  0  0  0  0], end state:[ 0 14 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 310, score:[2834.40], loss:[1.43640], sequence:[30], random actions:[28], eInit:[0.0448], init state:[ 1 13 48  0  0  0  0  0], end state:[ 3 13 48  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2836.799999999999, [249]) , maxSequence:(30, [310])
INFO:Reinforcement.Functions:episode: 311, score:[2818.00], loss:[1.34527], sequence:[31], random actions:[22], eInit:[0.0444], init state:[ 2 19 47  0  0  0  0  0], end state:[ 4 19 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 312, score:[2717.60], loss:[1.66853], sequence:[0], random actions:[29], eInit:[0.0439], init state:[ 3  1 55  0  0  0  0  0], end state:[ 5  1 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 313, score:[2826.40], loss:[1.37613], sequence:[1], random actions:[30], eInit:[0.0435], init state:[ 0  0 15  1  0  0  0  0], end state:[ 2  0 15  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 314, score:[2826.80], loss:[1.39002], sequence:[2], random actions:[30], eInit:[0.0430], init state:[0 2 1 0 0 0 0 0], end state:[2 2 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 315, score:[2795.20], loss:[1.39965], sequence:[3], random actions:[35], eInit:[0.0426], init state:[ 5  4 35  0  0  0  0  0], end state:[ 0  4 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 316, score:[2781.60], loss:[1.75399], sequence:[4], random actions:[34], eInit:[0.0422], init state:[ 5  3 24  0  0  0  0  0], end state:[ 0  3 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 317, score:[2826.00], loss:[1.56928], sequence:[5], random actions:[36], eInit:[0.0418], init state:[ 0 11 41  0  0  0  0  0], end state:[ 2 11 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 318, score:[2845.60], loss:[1.45215], sequence:[6], random actions:[17], eInit:[0.0413], init state:[ 0  7 15  0  0  0  0  0], end state:[ 2  7 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 319, score:[2814.80], loss:[1.59082], sequence:[7], random actions:[29], eInit:[0.0409], init state:[ 5 14 47  0  0  0  0  0], end state:[ 0 14 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 320, score:[2840.00], loss:[1.33164], sequence:[8], random actions:[25], eInit:[0.0405], init state:[ 6 13 59  0  0  0  0  0], end state:[ 1 13 59  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2845.5999999999976, [318]) , maxSequence:(31, [311])
INFO:Reinforcement.Functions:episode: 321, score:[2817.20], loss:[1.41425], sequence:[9], random actions:[35], eInit:[0.0401], init state:[ 1 15 34  0  0  0  0  0], end state:[ 3 15 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 322, score:[2827.60], loss:[1.51099], sequence:[10], random actions:[33], eInit:[0.0397], init state:[ 1 17 46  0  0  0  0  0], end state:[ 3 17 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 323, score:[2789.60], loss:[1.57770], sequence:[11], random actions:[25], eInit:[0.0393], init state:[ 3  3 28  0  0  0  0  0], end state:[ 5  3 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 324, score:[2774.40], loss:[1.58131], sequence:[12], random actions:[34], eInit:[0.0389], init state:[ 5 20  7  1  0  0  0  0], end state:[ 0 20  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 325, score:[2741.60], loss:[1.63281], sequence:[13], random actions:[39], eInit:[0.0385], init state:[ 3  4 54  0  0  0  0  0], end state:[ 5  4 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 326, score:[2827.60], loss:[1.41690], sequence:[14], random actions:[29], eInit:[0.0381], init state:[ 0 22 11  1  0  0  0  0], end state:[ 2 22 11  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 327, score:[2826.80], loss:[1.31211], sequence:[15], random actions:[21], eInit:[0.0378], init state:[5 4 6 0 0 0 0 0], end state:[0 4 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 328, score:[2802.00], loss:[1.19729], sequence:[16], random actions:[34], eInit:[0.0374], init state:[ 1 13 57  0  0  0  0  0], end state:[ 3 13 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 329, score:[2819.20], loss:[1.22119], sequence:[17], random actions:[36], eInit:[0.0370], init state:[ 0  0 13  1  0  0  0  0], end state:[ 2  0 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 330, score:[2821.60], loss:[1.04762], sequence:[18], random actions:[35], eInit:[0.0366], init state:[1 4 6 0 0 0 0 0], end state:[3 4 6 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2845.5999999999976, [318]) , maxSequence:(31, [311])
INFO:Reinforcement.Functions:episode: 331, score:[2837.20], loss:[1.07461], sequence:[19], random actions:[27], eInit:[0.0363], init state:[1 0 7 1 0 0 0 0], end state:[3 0 7 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 332, score:[2706.00], loss:[1.45219], sequence:[0], random actions:[38], eInit:[0.0359], init state:[ 4  8 46  0  0  0  0  0], end state:[ 6  8 46  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 333, score:[2813.20], loss:[1.36817], sequence:[1], random actions:[32], eInit:[0.0356], init state:[ 6 22  8  1  0  0  0  0], end state:[ 1 22  8  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 334, score:[2820.80], loss:[1.21037], sequence:[2], random actions:[29], eInit:[0.0352], init state:[ 2  6 38  0  0  0  0  0], end state:[ 4  6 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 335, score:[2772.40], loss:[1.28094], sequence:[3], random actions:[29], eInit:[0.0348], init state:[ 3  9 58  0  0  0  0  0], end state:[ 5  9 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 336, score:[2791.20], loss:[1.38802], sequence:[4], random actions:[36], eInit:[0.0345], init state:[ 6 10 18  0  0  0  0  0], end state:[ 1 10 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 337, score:[2772.40], loss:[1.48059], sequence:[5], random actions:[37], eInit:[0.0342], init state:[ 5 14 23  0  0  0  0  0], end state:[ 0 14 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 338, score:[2816.80], loss:[1.47668], sequence:[6], random actions:[35], eInit:[0.0338], init state:[6 4 4 0 0 0 0 0], end state:[1 4 4 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 339, score:[2828.00], loss:[1.22468], sequence:[7], random actions:[35], eInit:[0.0335], init state:[ 2 11 23  0  0  0  0  0], end state:[ 4 11 23  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 340, score:[2854.00], loss:[1.04328], sequence:[8], random actions:[19], eInit:[0.0331], init state:[ 1  4 44  0  0  0  0  0], end state:[ 3  4 44  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(31, [311])
INFO:Reinforcement.Functions:episode: 341, score:[2795.20], loss:[1.04926], sequence:[9], random actions:[34], eInit:[0.0328], init state:[ 2 22 53  1  0  0  0  0], end state:[ 4 22 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 342, score:[2805.20], loss:[1.18131], sequence:[10], random actions:[42], eInit:[0.0325], init state:[ 6 20 34  1  1  0  0  0], end state:[ 1 20 34  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 343, score:[2842.40], loss:[0.97317], sequence:[11], random actions:[30], eInit:[0.0322], init state:[ 0 14 32  0  0  0  0  0], end state:[ 2 14 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 344, score:[2823.20], loss:[1.07744], sequence:[12], random actions:[35], eInit:[0.0318], init state:[ 0 19 49  0  0  0  0  0], end state:[ 2 19 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 345, score:[2788.80], loss:[1.06272], sequence:[13], random actions:[41], eInit:[0.0315], init state:[ 1 19  8  0  0  0  0  0], end state:[ 3 19  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 346, score:[2775.60], loss:[1.28543], sequence:[14], random actions:[43], eInit:[0.0312], init state:[ 2  4 37  0  0  0  0  0], end state:[ 4  4 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 347, score:[2799.60], loss:[1.20799], sequence:[15], random actions:[44], eInit:[0.0309], init state:[ 0 22 43  1  0  0  0  0], end state:[ 2 22 43  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 348, score:[2804.40], loss:[1.14136], sequence:[16], random actions:[35], eInit:[0.0306], init state:[ 3 10 47  0  0  0  0  0], end state:[ 5 10 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 349, score:[2818.40], loss:[1.16454], sequence:[17], random actions:[31], eInit:[0.0303], init state:[ 0 22  7  1  0  0  0  0], end state:[ 2 22  7  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 350, score:[2774.80], loss:[1.09625], sequence:[18], random actions:[25], eInit:[0.0300], init state:[ 4 21 59  0  0  0  0  0], end state:[ 6 21 59  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(31, [311])
INFO:Reinforcement.Functions:episode: 351, score:[2738.40], loss:[1.42309], sequence:[19], random actions:[33], eInit:[0.0297], init state:[ 3  2 25  0  0  0  0  0], end state:[ 5  2 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 352, score:[2828.00], loss:[1.23546], sequence:[20], random actions:[25], eInit:[0.0294], init state:[ 1  3 22  0  0  0  0  0], end state:[ 3  3 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 353, score:[2825.20], loss:[1.11963], sequence:[21], random actions:[33], eInit:[0.0291], init state:[ 2  9 41  0  0  0  0  0], end state:[ 4  9 41  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 354, score:[2774.00], loss:[1.35214], sequence:[22], random actions:[33], eInit:[0.0288], init state:[ 3 16 53  0  0  0  0  0], end state:[ 5 16 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 355, score:[2705.60], loss:[1.66304], sequence:[0], random actions:[36], eInit:[0.0285], init state:[ 3 22 54  1  0  0  0  0], end state:[ 5 22 54  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 356, score:[2807.60], loss:[1.33785], sequence:[1], random actions:[32], eInit:[0.0282], init state:[ 1 12 13  0  0  0  0  0], end state:[ 3 12 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 357, score:[2744.80], loss:[1.50238], sequence:[2], random actions:[40], eInit:[0.0279], init state:[ 5  7 47  0  0  0  0  0], end state:[ 0  7 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 358, score:[2845.20], loss:[1.21344], sequence:[3], random actions:[30], eInit:[0.0277], init state:[ 1 17 42  0  0  0  0  0], end state:[ 3 17 42  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 359, score:[2831.20], loss:[1.11939], sequence:[4], random actions:[28], eInit:[0.0274], init state:[ 0  4 33  0  0  0  0  0], end state:[ 2  4 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 360, score:[2833.20], loss:[1.13896], sequence:[5], random actions:[31], eInit:[0.0271], init state:[ 0 14 17  0  0  0  0  0], end state:[ 2 14 17  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(31, [311])
INFO:Reinforcement.Functions:episode: 361, score:[2736.80], loss:[1.42472], sequence:[6], random actions:[35], eInit:[0.0268], init state:[ 3 15 49  0  0  0  0  0], end state:[ 5 15 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 362, score:[2796.80], loss:[1.32932], sequence:[7], random actions:[32], eInit:[0.0266], init state:[ 6 14 53  0  0  0  0  0], end state:[ 1 14 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 363, score:[2757.60], loss:[1.74810], sequence:[8], random actions:[32], eInit:[0.0263], init state:[ 4  9 34  1  0  0  0  0], end state:[ 6  9 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 364, score:[2797.60], loss:[1.92053], sequence:[9], random actions:[33], eInit:[0.0260], init state:[ 0  6 57  0  0  0  0  0], end state:[ 2  6 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 365, score:[2782.00], loss:[1.48252], sequence:[10], random actions:[36], eInit:[0.0258], init state:[ 3  0 40  0  0  1  0  0], end state:[ 5  0 40  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 366, score:[2812.00], loss:[1.39883], sequence:[11], random actions:[37], eInit:[0.0255], init state:[ 2 10 46  0  0  0  0  0], end state:[ 4 10 46  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 367, score:[2824.00], loss:[1.34380], sequence:[12], random actions:[16], eInit:[0.0253], init state:[ 4 11 19  1  1  0  0  0], end state:[ 6 11 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 368, score:[2823.20], loss:[1.16303], sequence:[13], random actions:[23], eInit:[0.0250], init state:[ 2 15 42  0  0  0  0  0], end state:[ 4 15 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 369, score:[2808.00], loss:[1.27016], sequence:[14], random actions:[36], eInit:[0.0248], init state:[ 1  0 37  0  0  1  0  0], end state:[ 3  0 37  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 370, score:[2779.60], loss:[1.25849], sequence:[15], random actions:[43], eInit:[0.0245], init state:[ 4 23 45  0  0  0  0  0], end state:[ 6 23 45  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(31, [311])
INFO:Reinforcement.Functions:episode: 371, score:[2797.60], loss:[1.15352], sequence:[16], random actions:[25], eInit:[0.0243], init state:[ 2  2 47  0  0  0  0  0], end state:[ 4  2 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 372, score:[2752.00], loss:[1.38340], sequence:[17], random actions:[33], eInit:[0.0240], init state:[ 5  6 39  0  0  0  0  0], end state:[ 0  6 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 373, score:[2816.40], loss:[1.25871], sequence:[18], random actions:[30], eInit:[0.0238], init state:[ 6 17 45  0  0  0  0  0], end state:[ 1 17 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 374, score:[2804.40], loss:[1.09917], sequence:[19], random actions:[28], eInit:[0.0235], init state:[ 4 17 12  0  0  0  0  0], end state:[ 6 17 12  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 375, score:[2802.80], loss:[1.22528], sequence:[20], random actions:[28], eInit:[0.0233], init state:[ 2  8 54  1  1  0  0  0], end state:[ 4  8 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 376, score:[2828.00], loss:[0.98712], sequence:[21], random actions:[29], eInit:[0.0231], init state:[ 0  2 41  0  0  0  0  0], end state:[ 2  2 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 377, score:[2798.80], loss:[1.15613], sequence:[22], random actions:[38], eInit:[0.0228], init state:[ 3 12 39  0  0  0  0  0], end state:[ 5 12 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 378, score:[2804.00], loss:[1.12356], sequence:[23], random actions:[37], eInit:[0.0226], init state:[ 2 13  6  0  0  0  0  0], end state:[ 4 13  6  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 379, score:[2803.60], loss:[1.17759], sequence:[24], random actions:[34], eInit:[0.0224], init state:[ 6  5 13  0  0  0  0  0], end state:[ 1  5 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 380, score:[2801.20], loss:[1.05037], sequence:[25], random actions:[36], eInit:[0.0222], init state:[ 3 11 10  0  0  0  0  0], end state:[ 5 11 10  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(31, [311])
INFO:Reinforcement.Functions:episode: 381, score:[2804.40], loss:[1.17184], sequence:[26], random actions:[24], eInit:[0.0219], init state:[ 3  3 36  0  0  0  0  0], end state:[ 5  3 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 382, score:[2824.40], loss:[1.11815], sequence:[27], random actions:[28], eInit:[0.0217], init state:[ 4 21 18  0  0  0  0  0], end state:[ 6 21 18  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 383, score:[2781.20], loss:[1.14910], sequence:[28], random actions:[35], eInit:[0.0215], init state:[ 4  4 30  0  0  0  0  0], end state:[ 6  4 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 384, score:[2779.60], loss:[1.27752], sequence:[29], random actions:[32], eInit:[0.0213], init state:[ 5  4 52  0  0  0  0  0], end state:[ 0  4 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 385, score:[2824.00], loss:[1.13354], sequence:[30], random actions:[25], eInit:[0.0211], init state:[ 5  6 35  0  0  0  0  0], end state:[ 0  6 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 386, score:[2780.80], loss:[1.10104], sequence:[31], random actions:[29], eInit:[0.0209], init state:[ 4 22 25  0  0  0  0  0], end state:[ 6 22 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 387, score:[2818.80], loss:[1.10291], sequence:[32], random actions:[24], eInit:[0.0207], init state:[ 0 22  8  1  0  0  0  0], end state:[ 2 22  8  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 388, score:[2774.80], loss:[1.12390], sequence:[33], random actions:[44], eInit:[0.0205], init state:[ 4 21  4  0  0  0  0  0], end state:[ 6 21  4  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 389, score:[2823.60], loss:[1.07094], sequence:[34], random actions:[26], eInit:[0.0203], init state:[ 2  5 33  0  0  0  0  0], end state:[ 4  5 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 390, score:[2782.80], loss:[1.05999], sequence:[35], random actions:[39], eInit:[0.0200], init state:[ 6 10 43  0  0  0  0  0], end state:[ 1 10 43  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(35, [390])
INFO:Reinforcement.Functions:episode: 391, score:[2774.80], loss:[1.32891], sequence:[36], random actions:[24], eInit:[0.0198], init state:[ 1 20 32  1  1  0  0  0], end state:[ 3 20 32  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 392, score:[2808.40], loss:[1.15274], sequence:[37], random actions:[35], eInit:[0.0196], init state:[ 5 23 20  1  0  0  0  0], end state:[ 0 23 20  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 393, score:[2773.60], loss:[1.31248], sequence:[38], random actions:[27], eInit:[0.0195], init state:[ 4  3 35  0  0  0  0  0], end state:[ 6  3 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 394, score:[2826.00], loss:[1.17698], sequence:[39], random actions:[25], eInit:[0.0193], init state:[ 5  3 11  0  0  0  0  0], end state:[ 0  3 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 395, score:[2810.00], loss:[1.21189], sequence:[40], random actions:[33], eInit:[0.0191], init state:[ 0  3 38  0  0  0  0  0], end state:[ 2  3 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 396, score:[2803.60], loss:[1.17864], sequence:[41], random actions:[34], eInit:[0.0189], init state:[ 1 16  9  0  0  0  0  0], end state:[ 3 16  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 397, score:[2789.20], loss:[1.15745], sequence:[42], random actions:[25], eInit:[0.0187], init state:[ 4  5 28  0  0  0  0  0], end state:[ 6  5 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 398, score:[2815.20], loss:[1.11399], sequence:[43], random actions:[34], eInit:[0.0185], init state:[ 1  4 31  0  0  0  0  0], end state:[ 3  4 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 399, score:[2835.60], loss:[0.93263], sequence:[44], random actions:[26], eInit:[0.0183], init state:[ 1 19 24  0  0  0  0  0], end state:[ 3 19 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 400, score:[2789.20], loss:[0.97022], sequence:[45], random actions:[31], eInit:[0.0181], init state:[ 0 19 35  0  0  0  0  0], end state:[ 2 19 35  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(45, [400])
INFO:Reinforcement.Functions:episode: 401, score:[2793.60], loss:[1.07095], sequence:[46], random actions:[30], eInit:[0.0180], init state:[ 5  3 18  0  0  0  0  0], end state:[ 0  3 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 402, score:[2818.40], loss:[0.93345], sequence:[47], random actions:[36], eInit:[0.0178], init state:[ 2 12 17  0  0  0  0  0], end state:[ 4 12 17  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 403, score:[2789.60], loss:[1.16534], sequence:[48], random actions:[28], eInit:[0.0176], init state:[ 3 13 57  0  0  0  0  0], end state:[ 5 13 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 404, score:[2811.60], loss:[1.06849], sequence:[49], random actions:[27], eInit:[0.0174], init state:[ 1 21 30  1  0  0  0  0], end state:[ 3 21 30  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 405, score:[2824.80], loss:[0.96901], sequence:[50], random actions:[28], eInit:[0.0172], init state:[ 0  0 34  0  0  1  0  0], end state:[ 2  0 34  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 406, score:[2837.60], loss:[0.94591], sequence:[51], random actions:[26], eInit:[0.0171], init state:[ 3 23 54  1  0  0  0  0], end state:[ 5 23 54  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 407, score:[2783.20], loss:[1.26153], sequence:[52], random actions:[31], eInit:[0.0169], init state:[3 9 7 0 0 0 0 0], end state:[5 9 7 0 1 0 0 0]
INFO:Reinforcement.Functions:episode: 408, score:[2800.00], loss:[1.29691], sequence:[53], random actions:[39], eInit:[0.0167], init state:[ 2 23 51  1  0  0  0  0], end state:[ 4 23 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 409, score:[2829.60], loss:[1.16518], sequence:[54], random actions:[33], eInit:[0.0166], init state:[ 2 15 22  0  0  0  0  0], end state:[ 4 15 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 410, score:[2801.20], loss:[1.03234], sequence:[55], random actions:[38], eInit:[0.0164], init state:[ 3 20 42  1  1  0  0  0], end state:[ 5 20 42  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(55, [410])
INFO:Reinforcement.Functions:episode: 411, score:[2814.80], loss:[1.15298], sequence:[56], random actions:[29], eInit:[0.0162], init state:[ 2 13 54  0  0  0  0  0], end state:[ 4 13 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 412, score:[2836.00], loss:[1.20677], sequence:[57], random actions:[26], eInit:[0.0161], init state:[ 2  9 37  0  0  0  0  0], end state:[ 4  9 37  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 413, score:[2802.80], loss:[1.06482], sequence:[58], random actions:[24], eInit:[0.0159], init state:[ 5 22 36  1  0  0  1  0], end state:[ 0 22 36  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 414, score:[2802.80], loss:[0.99922], sequence:[59], random actions:[31], eInit:[0.0158], init state:[ 2 18  9  0  0  0  0  0], end state:[ 4 18  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 415, score:[2775.20], loss:[1.14938], sequence:[60], random actions:[31], eInit:[0.0156], init state:[ 4 23 58  0  0  0  0  0], end state:[ 6 23 58  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 416, score:[2810.00], loss:[1.09612], sequence:[61], random actions:[30], eInit:[0.0154], init state:[ 0  9 32  0  0  0  0  0], end state:[ 2  9 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 417, score:[2803.60], loss:[1.05122], sequence:[62], random actions:[24], eInit:[0.0153], init state:[ 6  8 47  1  1  0  0  0], end state:[ 1  8 47  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 418, score:[2812.00], loss:[1.06103], sequence:[63], random actions:[36], eInit:[0.0151], init state:[ 3 14 57  0  0  0  0  0], end state:[ 5 14 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 419, score:[2819.60], loss:[1.00158], sequence:[64], random actions:[33], eInit:[0.0150], init state:[ 3  1 14  0  0  0  0  0], end state:[ 5  1 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 420, score:[2803.20], loss:[0.95699], sequence:[65], random actions:[32], eInit:[0.0148], init state:[ 3  8 58  1  1  0  0  0], end state:[ 5  8 58  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(65, [420])
INFO:Reinforcement.Functions:episode: 421, score:[2832.80], loss:[0.93030], sequence:[66], random actions:[25], eInit:[0.0147], init state:[3 3 4 0 0 0 0 0], end state:[5 3 4 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 422, score:[2744.40], loss:[1.12172], sequence:[67], random actions:[32], eInit:[0.0145], init state:[ 6  5 57  0  0  0  0  0], end state:[ 1  5 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 423, score:[2809.20], loss:[1.06678], sequence:[68], random actions:[34], eInit:[0.0144], init state:[ 0 15 45  0  0  0  0  0], end state:[ 2 15 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 424, score:[2767.20], loss:[1.10156], sequence:[69], random actions:[29], eInit:[0.0142], init state:[ 5  1 17  0  0  0  0  0], end state:[ 0  1 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 425, score:[2810.40], loss:[1.16251], sequence:[70], random actions:[36], eInit:[0.0141], init state:[ 3  5 52  0  0  0  0  0], end state:[ 5  5 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 426, score:[2795.20], loss:[1.13849], sequence:[71], random actions:[28], eInit:[0.0140], init state:[ 5 18 45  1  1  0  1  0], end state:[ 0 18 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 427, score:[2814.80], loss:[1.12209], sequence:[72], random actions:[26], eInit:[0.0138], init state:[ 4  6 17  0  0  0  0  0], end state:[ 6  6 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 428, score:[2817.60], loss:[1.01651], sequence:[73], random actions:[22], eInit:[0.0137], init state:[ 3  5 45  0  0  0  0  0], end state:[ 5  5 45  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 429, score:[2815.60], loss:[1.09147], sequence:[74], random actions:[20], eInit:[0.0135], init state:[ 2  7 53  0  0  0  0  0], end state:[ 4  7 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 430, score:[2798.80], loss:[1.04287], sequence:[75], random actions:[30], eInit:[0.0134], init state:[ 0  9 26  0  0  0  0  0], end state:[ 2  9 26  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(75, [430])
INFO:Reinforcement.Functions:episode: 431, score:[2793.60], loss:[1.03786], sequence:[76], random actions:[24], eInit:[0.0133], init state:[ 4 10 19  1  1  0  1  0], end state:[ 6 10 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 432, score:[2804.00], loss:[1.30333], sequence:[77], random actions:[37], eInit:[0.0131], init state:[ 3  8 21  1  0  0  0  0], end state:[ 5  8 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 433, score:[2833.60], loss:[1.05231], sequence:[78], random actions:[25], eInit:[0.0130], init state:[ 1 23 15  1  0  0  1  0], end state:[ 3 23 15  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 434, score:[2825.60], loss:[0.96333], sequence:[79], random actions:[30], eInit:[0.0129], init state:[ 2 20 56  1  1  0  1  0], end state:[ 4 20 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 435, score:[2835.60], loss:[1.02119], sequence:[80], random actions:[28], eInit:[0.0128], init state:[ 0 19 16  0  0  0  0  0], end state:[ 2 19 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 436, score:[2816.80], loss:[0.85545], sequence:[81], random actions:[24], eInit:[0.0126], init state:[ 2  4 18  0  0  0  0  0], end state:[ 4  4 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 437, score:[2816.80], loss:[1.08640], sequence:[82], random actions:[35], eInit:[0.0125], init state:[ 0 19 23  0  0  0  0  0], end state:[ 2 19 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 438, score:[2796.80], loss:[1.09199], sequence:[83], random actions:[27], eInit:[0.0124], init state:[ 5 14 41  0  0  0  0  0], end state:[ 0 14 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 439, score:[2800.40], loss:[1.16580], sequence:[84], random actions:[29], eInit:[0.0123], init state:[ 5 18 34  1  1  0  1  0], end state:[ 0 18 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 440, score:[2783.60], loss:[1.05161], sequence:[85], random actions:[33], eInit:[0.0121], init state:[ 3  6 14  0  0  0  0  0], end state:[ 5  6 14  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(85, [440])
INFO:Reinforcement.Functions:episode: 441, score:[2853.20], loss:[0.94911], sequence:[86], random actions:[18], eInit:[0.0120], init state:[ 0 16 43  0  0  0  0  0], end state:[ 2 16 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 442, score:[2822.00], loss:[0.84827], sequence:[87], random actions:[28], eInit:[0.0119], init state:[ 0  5 51  0  0  0  0  0], end state:[ 2  5 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 443, score:[2746.40], loss:[1.03856], sequence:[88], random actions:[33], eInit:[0.0118], init state:[ 5 21  5  1  0  0  1  0], end state:[ 0 21  5  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 444, score:[2790.40], loss:[1.26492], sequence:[89], random actions:[35], eInit:[0.0117], init state:[ 0 12 57  0  0  0  0  0], end state:[ 2 12 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 445, score:[2774.00], loss:[1.14272], sequence:[90], random actions:[41], eInit:[0.0115], init state:[ 3  0 32  0  0  1  0  0], end state:[ 5  0 32  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 446, score:[2824.80], loss:[1.07370], sequence:[91], random actions:[29], eInit:[0.0114], init state:[ 0 11  1  0  0  0  0  0], end state:[ 2 11  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 447, score:[2800.80], loss:[1.24344], sequence:[92], random actions:[31], eInit:[0.0113], init state:[ 6 19 18  0  0  0  0  0], end state:[ 1 19 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 448, score:[2754.80], loss:[1.18773], sequence:[93], random actions:[34], eInit:[0.0112], init state:[ 5 18 51  1  1  0  1  0], end state:[ 0 18 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 449, score:[2838.80], loss:[1.02100], sequence:[94], random actions:[25], eInit:[0.0111], init state:[ 1  4 12  0  0  0  0  0], end state:[ 3  4 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 450, score:[2772.00], loss:[1.28592], sequence:[95], random actions:[35], eInit:[0.0110], init state:[ 5 12 54  0  0  0  0  0], end state:[ 0 12 54  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(95, [450])
INFO:Reinforcement.Functions:episode: 451, score:[2814.40], loss:[1.14222], sequence:[96], random actions:[33], eInit:[0.0109], init state:[ 0 17 52  0  0  0  0  0], end state:[ 2 17 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 452, score:[2816.40], loss:[1.06252], sequence:[97], random actions:[26], eInit:[0.0108], init state:[ 2 11  7  0  0  0  0  0], end state:[ 4 11  7  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 453, score:[2836.80], loss:[1.16852], sequence:[98], random actions:[24], eInit:[0.0106], init state:[ 0  6 17  0  0  0  0  0], end state:[ 2  6 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 454, score:[2808.00], loss:[1.23770], sequence:[99], random actions:[37], eInit:[0.0105], init state:[ 4  5 37  0  0  0  0  0], end state:[ 6  5 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 455, score:[2811.60], loss:[1.16105], sequence:[100], random actions:[31], eInit:[0.0104], init state:[ 3 16 55  0  0  0  0  0], end state:[ 5 16 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 456, score:[2808.40], loss:[1.02760], sequence:[101], random actions:[26], eInit:[0.0103], init state:[ 1  9 40  0  0  0  0  0], end state:[ 3  9 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 457, score:[2776.80], loss:[1.38691], sequence:[102], random actions:[39], eInit:[0.0102], init state:[ 3  2 22  0  0  0  0  0], end state:[ 5  2 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 458, score:[2799.20], loss:[1.28511], sequence:[103], random actions:[42], eInit:[0.0101], init state:[ 1 21 27  1  1  0  1  0], end state:[ 3 21 27  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 459, score:[2794.00], loss:[1.34479], sequence:[104], random actions:[35], eInit:[0.0100], init state:[6 9 2 0 0 0 0 0], end state:[1 9 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 460, score:[2837.60], loss:[1.49355], sequence:[105], random actions:[24], eInit:[0.0100], init state:[ 0 16 58  0  0  0  0  0], end state:[ 2 16 58  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(105, [460])
INFO:Reinforcement.Functions:episode: 461, score:[2818.40], loss:[1.40322], sequence:[106], random actions:[32], eInit:[0.0100], init state:[ 0 15 21  0  0  0  0  0], end state:[ 2 15 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 462, score:[2823.20], loss:[1.23305], sequence:[107], random actions:[28], eInit:[0.0100], init state:[ 4 19  7  0  0  0  0  0], end state:[ 6 19  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 463, score:[2786.40], loss:[1.11528], sequence:[108], random actions:[36], eInit:[0.0100], init state:[ 2 13 52  0  0  0  0  0], end state:[ 4 13 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 464, score:[2814.80], loss:[1.24718], sequence:[109], random actions:[19], eInit:[0.0100], init state:[ 5  5 41  0  0  0  0  0], end state:[ 0  5 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 465, score:[2827.20], loss:[0.99151], sequence:[110], random actions:[32], eInit:[0.0100], init state:[1 0 0 1 0 0 0 0], end state:[3 0 0 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 466, score:[2812.40], loss:[1.00832], sequence:[111], random actions:[30], eInit:[0.0100], init state:[ 1 15  0  0  0  0  0  0], end state:[ 3 15  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 467, score:[2821.60], loss:[1.05812], sequence:[112], random actions:[20], eInit:[0.0100], init state:[ 5  7 56  0  0  0  0  0], end state:[ 0  7 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 468, score:[2799.60], loss:[0.97332], sequence:[113], random actions:[27], eInit:[0.0100], init state:[ 6  4 57  0  0  0  0  0], end state:[ 1  4 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 469, score:[2830.80], loss:[0.94206], sequence:[114], random actions:[29], eInit:[0.0100], init state:[ 0  0 20  1  0  0  0  0], end state:[ 2  0 20  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 470, score:[2816.00], loss:[0.98332], sequence:[115], random actions:[35], eInit:[0.0100], init state:[ 0 14 46  0  0  0  0  0], end state:[ 2 14 46  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(115, [470])
INFO:Reinforcement.Functions:episode: 471, score:[2814.40], loss:[0.92639], sequence:[116], random actions:[32], eInit:[0.0100], init state:[ 2 22  6  1  0  0  0  0], end state:[ 4 22  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 472, score:[2835.20], loss:[0.90351], sequence:[117], random actions:[27], eInit:[0.0100], init state:[ 3 10 21  0  0  0  0  0], end state:[ 5 10 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 473, score:[2782.80], loss:[1.08963], sequence:[118], random actions:[20], eInit:[0.0100], init state:[ 5 13 11  0  0  0  0  0], end state:[ 0 13 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 474, score:[2712.80], loss:[1.27978], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 5 12 41  0  0  0  0  0], end state:[ 0 12 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 475, score:[2808.00], loss:[0.93172], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 1 22 56  1  0  0  0  0], end state:[ 3 22 56  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 476, score:[2817.60], loss:[1.03747], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 3  3 14  0  0  0  0  0], end state:[ 5  3 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 477, score:[2827.20], loss:[1.01714], sequence:[3], random actions:[32], eInit:[0.0100], init state:[6 1 9 0 0 1 0 0], end state:[1 1 9 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 478, score:[2834.00], loss:[0.82475], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 0  3 48  0  0  0  0  0], end state:[ 2  3 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 479, score:[2833.60], loss:[0.85137], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 6 19 57  0  0  0  0  0], end state:[ 1 19 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 480, score:[2719.20], loss:[1.14029], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 5  7 32  0  0  0  0  0], end state:[ 0  7 32  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 481, score:[2821.20], loss:[1.27644], sequence:[1], random actions:[22], eInit:[0.0100], init state:[ 2  4 52  0  0  0  0  0], end state:[ 4  4 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 482, score:[2820.80], loss:[1.20661], sequence:[2], random actions:[30], eInit:[0.0100], init state:[0 1 8 0 0 1 0 0], end state:[2 1 8 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 483, score:[2779.60], loss:[1.47970], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 4  1 43  0  0  0  0  0], end state:[ 6  1 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 484, score:[2787.60], loss:[1.18221], sequence:[4], random actions:[42], eInit:[0.0100], init state:[ 0  2 48  0  0  0  0  0], end state:[ 2  2 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 485, score:[2827.20], loss:[1.10096], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 6 11 17  0  0  0  0  0], end state:[ 1 11 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 486, score:[2790.80], loss:[1.07180], sequence:[6], random actions:[36], eInit:[0.0100], init state:[ 5  7 14  0  0  0  0  0], end state:[ 0  7 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 487, score:[2784.80], loss:[1.17183], sequence:[7], random actions:[32], eInit:[0.0100], init state:[ 4 19  3  0  0  0  0  0], end state:[ 6 19  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 488, score:[2788.80], loss:[1.16023], sequence:[8], random actions:[31], eInit:[0.0100], init state:[3 1 6 0 0 1 0 0], end state:[5 1 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 489, score:[2817.60], loss:[1.04307], sequence:[9], random actions:[36], eInit:[0.0100], init state:[ 1 11  4  0  0  0  0  0], end state:[ 3 11  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 490, score:[2809.60], loss:[1.07811], sequence:[10], random actions:[23], eInit:[0.0100], init state:[ 5  3 47  0  0  0  0  0], end state:[ 0  3 47  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 491, score:[2816.80], loss:[1.14822], sequence:[11], random actions:[20], eInit:[0.0100], init state:[ 6  5 30  0  0  0  0  0], end state:[ 1  5 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 492, score:[2758.80], loss:[1.44549], sequence:[12], random actions:[32], eInit:[0.0100], init state:[ 2 19 46  0  0  0  0  0], end state:[ 4 19 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 493, score:[2820.80], loss:[1.42826], sequence:[13], random actions:[28], eInit:[0.0100], init state:[ 6 14  4  0  0  0  0  0], end state:[ 1 14  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 494, score:[2831.20], loss:[1.13692], sequence:[14], random actions:[32], eInit:[0.0100], init state:[ 2 23  8  1  0  0  0  0], end state:[ 4 23  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 495, score:[2828.00], loss:[1.13339], sequence:[15], random actions:[28], eInit:[0.0100], init state:[ 0  4 36  0  0  0  0  0], end state:[ 2  4 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 496, score:[2834.00], loss:[1.17270], sequence:[16], random actions:[26], eInit:[0.0100], init state:[ 0  3 48  0  0  0  0  0], end state:[ 2  3 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 497, score:[2832.40], loss:[1.10663], sequence:[17], random actions:[32], eInit:[0.0100], init state:[ 0 13 44  0  0  0  0  0], end state:[ 2 13 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 498, score:[2777.20], loss:[1.20039], sequence:[18], random actions:[30], eInit:[0.0100], init state:[ 4 21 25  0  0  0  0  0], end state:[ 6 21 25  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 499, score:[2825.20], loss:[1.10778], sequence:[19], random actions:[37], eInit:[0.0100], init state:[ 0 16 26  0  0  0  0  0], end state:[ 2 16 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 500, score:[2846.00], loss:[0.91365], sequence:[20], random actions:[21], eInit:[0.0100], init state:[ 0  9 54  0  0  0  0  0], end state:[ 2  9 54  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 501, score:[2805.20], loss:[1.01093], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 6  2 11  0  0  0  0  0], end state:[ 1  2 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 502, score:[2784.40], loss:[1.15615], sequence:[22], random actions:[28], eInit:[0.0100], init state:[ 5 14 12  0  0  0  0  0], end state:[ 0 14 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 503, score:[2768.40], loss:[1.15063], sequence:[23], random actions:[37], eInit:[0.0100], init state:[ 3 12  3  0  0  0  0  0], end state:[ 5 12  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 504, score:[2792.00], loss:[1.13996], sequence:[24], random actions:[33], eInit:[0.0100], init state:[ 3  7 24  0  0  0  0  0], end state:[ 5  7 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 505, score:[2811.60], loss:[1.23452], sequence:[25], random actions:[26], eInit:[0.0100], init state:[ 6 13 12  0  0  0  0  0], end state:[ 1 13 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 506, score:[2794.40], loss:[1.15342], sequence:[26], random actions:[30], eInit:[0.0100], init state:[ 5  8 56  0  0  0  0  0], end state:[ 0  8 56  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 507, score:[2805.20], loss:[1.17942], sequence:[27], random actions:[25], eInit:[0.0100], init state:[ 5  4 23  0  0  0  0  0], end state:[ 0  4 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 508, score:[2815.20], loss:[1.11928], sequence:[28], random actions:[34], eInit:[0.0100], init state:[ 5 22 29  1  0  0  1  0], end state:[ 0 22 29  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 509, score:[2823.20], loss:[1.12754], sequence:[29], random actions:[32], eInit:[0.0100], init state:[ 6  6 30  0  0  0  0  0], end state:[ 1  6 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 510, score:[2762.80], loss:[1.19808], sequence:[30], random actions:[37], eInit:[0.0100], init state:[ 3 21 44  1  0  0  0  0], end state:[ 5 21 44  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 511, score:[2797.60], loss:[1.26483], sequence:[31], random actions:[32], eInit:[0.0100], init state:[ 0 14 20  0  0  0  0  0], end state:[ 2 14 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 512, score:[2818.00], loss:[1.18455], sequence:[32], random actions:[27], eInit:[0.0100], init state:[ 3 21 58  1  0  0  0  0], end state:[ 5 21 58  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 513, score:[2809.60], loss:[1.07796], sequence:[33], random actions:[39], eInit:[0.0100], init state:[ 6 11 44  0  0  0  0  0], end state:[ 1 11 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 514, score:[2822.00], loss:[1.08071], sequence:[34], random actions:[27], eInit:[0.0100], init state:[ 6 22 35  1  0  0  0  0], end state:[ 1 22 35  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 515, score:[2818.80], loss:[1.13908], sequence:[35], random actions:[32], eInit:[0.0100], init state:[ 0 18 36  0  0  0  0  0], end state:[ 2 18 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 516, score:[2790.80], loss:[1.30733], sequence:[36], random actions:[32], eInit:[0.0100], init state:[ 6  5 43  0  0  0  0  0], end state:[ 1  5 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 517, score:[2781.20], loss:[1.35994], sequence:[37], random actions:[40], eInit:[0.0100], init state:[ 6 20 26  0  0  0  0  0], end state:[ 1 20 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 518, score:[2782.40], loss:[1.30721], sequence:[38], random actions:[23], eInit:[0.0100], init state:[ 3  0 53  0  0  1  0  0], end state:[ 5  0 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 519, score:[2805.60], loss:[1.62013], sequence:[39], random actions:[39], eInit:[0.0100], init state:[ 3 14 32  0  0  0  0  0], end state:[ 5 14 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 520, score:[2804.80], loss:[1.25801], sequence:[40], random actions:[25], eInit:[0.0100], init state:[ 6 10 14  0  0  0  0  0], end state:[ 1 10 14  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 521, score:[2821.60], loss:[1.19022], sequence:[41], random actions:[25], eInit:[0.0100], init state:[ 0  1 33  0  0  0  0  0], end state:[ 2  1 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 522, score:[2756.80], loss:[1.10169], sequence:[42], random actions:[27], eInit:[0.0100], init state:[ 2 21 26  1  1  0  1  0], end state:[ 4 21 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 523, score:[2762.40], loss:[1.38786], sequence:[43], random actions:[22], eInit:[0.0100], init state:[ 5  9 14  0  0  0  0  0], end state:[ 0  9 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 524, score:[2757.20], loss:[1.50662], sequence:[44], random actions:[27], eInit:[0.0100], init state:[ 4  6 10  0  0  0  0  0], end state:[ 6  6 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 525, score:[2831.20], loss:[1.07612], sequence:[45], random actions:[27], eInit:[0.0100], init state:[ 2  6 10  0  0  0  0  0], end state:[ 4  6 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 526, score:[2827.20], loss:[1.18509], sequence:[46], random actions:[24], eInit:[0.0100], init state:[ 1 14 11  0  0  0  0  0], end state:[ 3 14 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 527, score:[2834.40], loss:[0.99578], sequence:[47], random actions:[28], eInit:[0.0100], init state:[ 0  0 34  0  0  1  0  0], end state:[ 2  0 34  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 528, score:[2794.40], loss:[1.09476], sequence:[48], random actions:[30], eInit:[0.0100], init state:[ 6  3 23  0  0  0  0  0], end state:[ 1  3 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 529, score:[2795.20], loss:[1.05865], sequence:[49], random actions:[34], eInit:[0.0100], init state:[ 4 19 23  0  0  0  0  0], end state:[ 6 19 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 530, score:[2805.20], loss:[1.15061], sequence:[50], random actions:[27], eInit:[0.0100], init state:[ 3  9 46  0  0  0  0  0], end state:[ 5  9 46  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 531, score:[2809.20], loss:[1.01818], sequence:[51], random actions:[24], eInit:[0.0100], init state:[2 1 9 0 0 1 0 0], end state:[4 1 9 1 0 1 0 0]
INFO:Reinforcement.Functions:episode: 532, score:[2819.60], loss:[1.22249], sequence:[52], random actions:[32], eInit:[0.0100], init state:[3 6 7 0 0 0 0 0], end state:[5 6 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 533, score:[2809.20], loss:[1.15566], sequence:[53], random actions:[34], eInit:[0.0100], init state:[ 3 19 27  0  0  0  0  0], end state:[ 5 19 27  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 534, score:[2796.40], loss:[1.21011], sequence:[54], random actions:[29], eInit:[0.0100], init state:[ 5  0 45  0  0  0  0  0], end state:[ 0  0 45  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 535, score:[2826.40], loss:[1.05621], sequence:[55], random actions:[25], eInit:[0.0100], init state:[ 1 11 37  0  0  0  0  0], end state:[ 3 11 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 536, score:[2814.80], loss:[1.03043], sequence:[56], random actions:[31], eInit:[0.0100], init state:[ 1 17 23  0  0  0  0  0], end state:[ 3 17 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 537, score:[2795.20], loss:[1.02048], sequence:[57], random actions:[34], eInit:[0.0100], init state:[ 3 18 50  0  0  0  0  0], end state:[ 5 18 50  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 538, score:[2788.40], loss:[1.18082], sequence:[58], random actions:[35], eInit:[0.0100], init state:[ 6  4 20  0  0  0  0  0], end state:[ 1  4 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 539, score:[2828.00], loss:[1.11335], sequence:[59], random actions:[25], eInit:[0.0100], init state:[ 3 11 44  0  0  0  0  0], end state:[ 5 11 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 540, score:[2811.60], loss:[1.00147], sequence:[60], random actions:[31], eInit:[0.0100], init state:[ 6  4 20  0  0  0  0  0], end state:[ 1  4 20  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 541, score:[2801.20], loss:[1.17598], sequence:[61], random actions:[27], eInit:[0.0100], init state:[ 5 18  3  1  1  0  1  0], end state:[ 0 18  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 542, score:[2836.80], loss:[0.98671], sequence:[62], random actions:[27], eInit:[0.0100], init state:[ 1 18 39  0  0  0  0  0], end state:[ 3 18 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 543, score:[2816.40], loss:[1.06607], sequence:[63], random actions:[35], eInit:[0.0100], init state:[ 2  6 36  0  0  0  0  0], end state:[ 4  6 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 544, score:[2830.40], loss:[0.92145], sequence:[64], random actions:[33], eInit:[0.0100], init state:[ 1 19  8  0  0  0  0  0], end state:[ 3 19  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 545, score:[2818.80], loss:[0.78352], sequence:[65], random actions:[34], eInit:[0.0100], init state:[ 1 19 15  0  0  0  0  0], end state:[ 3 19 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 546, score:[2808.80], loss:[0.91338], sequence:[66], random actions:[30], eInit:[0.0100], init state:[ 2  9 30  0  0  0  0  0], end state:[ 4  9 30  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 547, score:[2819.60], loss:[0.82220], sequence:[67], random actions:[30], eInit:[0.0100], init state:[ 1  2 44  0  0  0  0  0], end state:[ 3  2 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 548, score:[2813.60], loss:[0.88063], sequence:[68], random actions:[26], eInit:[0.0100], init state:[ 6  1 39  0  0  0  0  0], end state:[ 1  1 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 549, score:[2844.40], loss:[0.80389], sequence:[69], random actions:[23], eInit:[0.0100], init state:[1 0 3 1 0 0 0 0], end state:[3 0 3 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 550, score:[2823.20], loss:[0.90676], sequence:[70], random actions:[27], eInit:[0.0100], init state:[ 3  7 10  0  0  0  0  0], end state:[ 5  7 10  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 551, score:[2832.80], loss:[0.84918], sequence:[71], random actions:[30], eInit:[0.0100], init state:[ 3 21 12  1  1  0  1  0], end state:[ 5 21 12  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 552, score:[2822.80], loss:[0.90335], sequence:[72], random actions:[28], eInit:[0.0100], init state:[ 3 11 40  0  0  0  0  0], end state:[ 5 11 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 553, score:[2721.20], loss:[1.24457], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5 13 34  0  0  0  0  0], end state:[ 0 13 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 554, score:[2822.80], loss:[1.03166], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 1  6 48  0  0  0  0  0], end state:[ 3  6 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 555, score:[2814.80], loss:[0.96885], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 3 23 23  1  0  0  1  0], end state:[ 5 23 23  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 556, score:[2839.60], loss:[0.87766], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 0 22 13  1  0  0  0  0], end state:[ 2 22 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 557, score:[2834.80], loss:[0.86935], sequence:[4], random actions:[26], eInit:[0.0100], init state:[ 6 14 32  0  0  0  0  0], end state:[ 1 14 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 558, score:[2770.80], loss:[1.28913], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 4  2 52  0  0  0  0  0], end state:[ 6  2 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 559, score:[2812.00], loss:[1.29411], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 5  9 28  0  0  0  0  0], end state:[ 0  9 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 560, score:[2817.20], loss:[1.13385], sequence:[7], random actions:[36], eInit:[0.0100], init state:[ 1  8 11  1  0  0  0  0], end state:[ 3  8 11  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 561, score:[2831.20], loss:[0.96966], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 1  8 17  1  0  0  0  0], end state:[ 3  8 17  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 562, score:[2804.00], loss:[0.99891], sequence:[9], random actions:[39], eInit:[0.0100], init state:[6 8 6 1 0 0 0 0], end state:[1 8 6 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 563, score:[2815.60], loss:[1.00307], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 3  5 53  0  0  0  0  0], end state:[ 5  5 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 564, score:[2796.40], loss:[1.00789], sequence:[11], random actions:[19], eInit:[0.0100], init state:[ 0 21 50  1  0  0  0  0], end state:[ 2 21 50  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 565, score:[2818.00], loss:[0.97887], sequence:[12], random actions:[24], eInit:[0.0100], init state:[ 1  9 13  0  0  0  0  0], end state:[ 3  9 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 566, score:[2794.40], loss:[1.08230], sequence:[13], random actions:[38], eInit:[0.0100], init state:[ 2 11 21  0  0  0  0  0], end state:[ 4 11 21  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 567, score:[2783.20], loss:[1.23542], sequence:[14], random actions:[36], eInit:[0.0100], init state:[ 6  8 47  1  1  0  0  0], end state:[ 1  8 47  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 568, score:[2804.00], loss:[1.19994], sequence:[15], random actions:[32], eInit:[0.0100], init state:[ 4  1 55  0  0  0  0  0], end state:[ 6  1 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 569, score:[2806.40], loss:[1.15087], sequence:[16], random actions:[25], eInit:[0.0100], init state:[ 4  6 45  0  0  0  0  0], end state:[ 6  6 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 570, score:[2814.80], loss:[1.32519], sequence:[17], random actions:[25], eInit:[0.0100], init state:[ 3 12 34  0  0  0  0  0], end state:[ 5 12 34  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 571, score:[2794.00], loss:[1.39227], sequence:[18], random actions:[27], eInit:[0.0100], init state:[ 5 12 51  0  0  0  0  0], end state:[ 0 12 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 572, score:[2825.20], loss:[1.24857], sequence:[19], random actions:[26], eInit:[0.0100], init state:[1 8 8 1 0 0 0 0], end state:[3 8 8 1 0 0 1 0]
INFO:Reinforcement.Functions:episode: 573, score:[2832.40], loss:[1.05670], sequence:[20], random actions:[20], eInit:[0.0100], init state:[3 8 8 1 0 0 0 0], end state:[5 8 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 574, score:[2755.60], loss:[1.09931], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 4 14 58  0  0  0  0  0], end state:[ 6 14 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 575, score:[2824.80], loss:[1.11806], sequence:[22], random actions:[33], eInit:[0.0100], init state:[ 6 15 38  0  0  0  0  0], end state:[ 1 15 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 576, score:[2812.40], loss:[1.03650], sequence:[23], random actions:[30], eInit:[0.0100], init state:[ 6 17  4  0  0  0  0  0], end state:[ 1 17  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 577, score:[2794.00], loss:[1.06714], sequence:[24], random actions:[26], eInit:[0.0100], init state:[ 4  5 10  0  0  0  0  0], end state:[ 6  5 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 578, score:[2800.00], loss:[1.07277], sequence:[25], random actions:[34], eInit:[0.0100], init state:[2 0 8 1 0 0 0 0], end state:[4 0 8 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 579, score:[2836.00], loss:[0.92946], sequence:[26], random actions:[29], eInit:[0.0100], init state:[ 1  5 48  0  0  0  0  0], end state:[ 3  5 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 580, score:[2766.00], loss:[1.15574], sequence:[27], random actions:[29], eInit:[0.0100], init state:[ 5 10 48  0  0  0  0  0], end state:[ 0 10 48  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 581, score:[2796.80], loss:[1.31505], sequence:[28], random actions:[27], eInit:[0.0100], init state:[ 4  3 40  0  0  0  0  0], end state:[ 6  3 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 582, score:[2807.20], loss:[1.28159], sequence:[29], random actions:[35], eInit:[0.0100], init state:[2 0 6 1 0 0 0 0], end state:[4 0 6 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 583, score:[2773.20], loss:[1.17754], sequence:[30], random actions:[36], eInit:[0.0100], init state:[ 5  0 20  0  0  0  0  0], end state:[ 0  0 20  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 584, score:[2810.80], loss:[1.28691], sequence:[31], random actions:[31], eInit:[0.0100], init state:[ 6 13 38  0  0  0  0  0], end state:[ 1 13 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 585, score:[2830.00], loss:[1.11368], sequence:[32], random actions:[27], eInit:[0.0100], init state:[ 0  8 29  1  0  0  0  0], end state:[ 2  8 29  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 586, score:[2828.40], loss:[0.95566], sequence:[33], random actions:[34], eInit:[0.0100], init state:[ 0  9 22  0  0  0  0  0], end state:[ 2  9 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 587, score:[2810.40], loss:[1.05736], sequence:[34], random actions:[28], eInit:[0.0100], init state:[ 5  3 43  0  0  0  0  0], end state:[ 0  3 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 588, score:[2828.80], loss:[0.95232], sequence:[35], random actions:[29], eInit:[0.0100], init state:[ 6 16 49  0  0  0  0  0], end state:[ 1 16 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 589, score:[2812.80], loss:[1.09500], sequence:[36], random actions:[32], eInit:[0.0100], init state:[ 5 15 49  0  0  0  0  0], end state:[ 0 15 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 590, score:[2776.00], loss:[1.13429], sequence:[37], random actions:[28], eInit:[0.0100], init state:[3 8 1 1 0 0 0 0], end state:[5 8 1 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 591, score:[2753.60], loss:[1.29447], sequence:[38], random actions:[41], eInit:[0.0100], init state:[ 2  7 27  0  0  0  0  0], end state:[ 4  7 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 592, score:[2832.80], loss:[1.08083], sequence:[39], random actions:[29], eInit:[0.0100], init state:[ 1 19  9  0  0  0  0  0], end state:[ 3 19  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 593, score:[2806.00], loss:[1.03403], sequence:[40], random actions:[35], eInit:[0.0100], init state:[ 6 21 52  1  0  0  0  0], end state:[ 1 21 52  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 594, score:[2812.80], loss:[0.97664], sequence:[41], random actions:[34], eInit:[0.0100], init state:[ 2  6 30  0  0  0  0  0], end state:[ 4  6 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 595, score:[2796.80], loss:[0.89419], sequence:[42], random actions:[23], eInit:[0.0100], init state:[ 5  8 46  0  0  0  0  0], end state:[ 0  8 46  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 596, score:[2820.00], loss:[1.03874], sequence:[43], random actions:[21], eInit:[0.0100], init state:[ 5  9 37  0  0  0  0  0], end state:[ 0  9 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 597, score:[2796.80], loss:[1.26873], sequence:[44], random actions:[29], eInit:[0.0100], init state:[ 4 10 16  1  1  0  1  1], end state:[ 6 10 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 598, score:[2786.00], loss:[1.38687], sequence:[45], random actions:[20], eInit:[0.0100], init state:[ 4  8 34  0  0  0  0  0], end state:[ 6  8 34  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 599, score:[2836.00], loss:[1.12285], sequence:[46], random actions:[19], eInit:[0.0100], init state:[ 0  5 23  0  0  0  0  0], end state:[ 2  5 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 600, score:[2822.80], loss:[1.18916], sequence:[47], random actions:[35], eInit:[0.0100], init state:[0 3 8 0 0 0 0 0], end state:[2 3 8 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 601, score:[2800.40], loss:[1.08454], sequence:[48], random actions:[28], eInit:[0.0100], init state:[ 0 15 27  0  0  0  0  0], end state:[ 2 15 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 602, score:[2756.00], loss:[1.35445], sequence:[49], random actions:[21], eInit:[0.0100], init state:[ 5 15 41  0  0  0  0  0], end state:[ 0 15 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 603, score:[2819.60], loss:[1.11323], sequence:[50], random actions:[25], eInit:[0.0100], init state:[ 0  9 22  0  0  0  0  0], end state:[ 2  9 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 604, score:[2797.60], loss:[1.33353], sequence:[51], random actions:[32], eInit:[0.0100], init state:[ 5 23 44  1  0  0  0  0], end state:[ 0 23 44  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 605, score:[2847.20], loss:[1.10441], sequence:[52], random actions:[18], eInit:[0.0100], init state:[ 0 12 59  0  0  0  0  0], end state:[ 2 12 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 606, score:[2803.60], loss:[1.39878], sequence:[53], random actions:[31], eInit:[0.0100], init state:[ 4 14 43  0  0  0  0  0], end state:[ 6 14 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 607, score:[2770.40], loss:[1.41672], sequence:[54], random actions:[36], eInit:[0.0100], init state:[ 5  6 41  0  0  0  0  0], end state:[ 0  6 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 608, score:[2748.00], loss:[1.47329], sequence:[55], random actions:[34], eInit:[0.0100], init state:[ 4 23 24  0  0  0  0  0], end state:[ 6 23 24  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 609, score:[2740.40], loss:[1.69467], sequence:[56], random actions:[25], eInit:[0.0100], init state:[ 3 19 29  0  0  0  0  0], end state:[ 5 19 29  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 610, score:[2816.80], loss:[1.36520], sequence:[57], random actions:[25], eInit:[0.0100], init state:[ 0 14  3  0  0  0  0  0], end state:[ 2 14  3  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 611, score:[2815.60], loss:[1.25020], sequence:[58], random actions:[32], eInit:[0.0100], init state:[ 1 11  1  0  0  0  0  0], end state:[ 3 11  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 612, score:[2781.60], loss:[1.22965], sequence:[59], random actions:[32], eInit:[0.0100], init state:[ 5 22  5  1  0  0  1  0], end state:[ 0 22  5  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 613, score:[2787.60], loss:[1.42878], sequence:[60], random actions:[23], eInit:[0.0100], init state:[ 3  0 53  0  0  1  0  0], end state:[ 5  0 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 614, score:[2818.00], loss:[1.45004], sequence:[61], random actions:[25], eInit:[0.0100], init state:[ 2  8 25  1  0  0  0  0], end state:[ 4  8 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 615, score:[2825.20], loss:[1.32363], sequence:[62], random actions:[32], eInit:[0.0100], init state:[ 1  2 25  0  0  0  0  0], end state:[ 3  2 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 616, score:[2806.80], loss:[1.26414], sequence:[63], random actions:[29], eInit:[0.0100], init state:[ 1  2 36  0  0  0  0  0], end state:[ 3  2 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 617, score:[2809.20], loss:[1.19365], sequence:[64], random actions:[27], eInit:[0.0100], init state:[ 0  5 30  0  0  0  0  0], end state:[ 2  5 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 618, score:[2808.40], loss:[1.24392], sequence:[65], random actions:[33], eInit:[0.0100], init state:[ 4 23 52  0  0  0  0  0], end state:[ 6 23 52  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 619, score:[2839.20], loss:[1.15026], sequence:[66], random actions:[19], eInit:[0.0100], init state:[ 3  9 18  0  0  0  0  0], end state:[ 5  9 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 620, score:[2818.80], loss:[1.30080], sequence:[67], random actions:[25], eInit:[0.0100], init state:[ 6  3 25  0  0  0  0  0], end state:[ 1  3 25  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 621, score:[2764.00], loss:[1.25459], sequence:[68], random actions:[30], eInit:[0.0100], init state:[ 2 19  4  0  0  0  0  0], end state:[ 4 19  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 622, score:[2839.20], loss:[1.34420], sequence:[69], random actions:[18], eInit:[0.0100], init state:[ 3 16 16  0  0  0  0  0], end state:[ 5 16 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 623, score:[2830.40], loss:[1.16551], sequence:[70], random actions:[20], eInit:[0.0100], init state:[ 5  4 10  0  0  0  0  0], end state:[ 0  4 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 624, score:[2805.60], loss:[1.07042], sequence:[71], random actions:[40], eInit:[0.0100], init state:[ 3 13 19  0  0  0  0  0], end state:[ 5 13 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 625, score:[2817.60], loss:[1.14183], sequence:[72], random actions:[28], eInit:[0.0100], init state:[ 2 14 51  0  0  0  0  0], end state:[ 4 14 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 626, score:[2807.20], loss:[1.06547], sequence:[73], random actions:[27], eInit:[0.0100], init state:[4 1 2 0 0 1 0 0], end state:[6 1 2 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 627, score:[2805.60], loss:[1.02930], sequence:[74], random actions:[29], eInit:[0.0100], init state:[ 0  4 51  0  0  0  0  0], end state:[ 2  4 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 628, score:[2760.80], loss:[1.13691], sequence:[75], random actions:[41], eInit:[0.0100], init state:[ 3  9 36  0  0  0  0  0], end state:[ 5  9 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 629, score:[2803.60], loss:[1.07726], sequence:[76], random actions:[39], eInit:[0.0100], init state:[ 6 21 57  1  0  0  0  0], end state:[ 1 21 57  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 630, score:[2772.00], loss:[1.19187], sequence:[77], random actions:[27], eInit:[0.0100], init state:[ 5 11 55  0  0  0  0  0], end state:[ 0 11 55  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 631, score:[2782.80], loss:[1.21821], sequence:[78], random actions:[24], eInit:[0.0100], init state:[ 3 11 23  0  0  0  0  0], end state:[ 5 11 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 632, score:[2836.40], loss:[1.01316], sequence:[79], random actions:[18], eInit:[0.0100], init state:[ 0  9 36  0  0  0  0  0], end state:[ 2  9 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 633, score:[2821.60], loss:[0.97744], sequence:[80], random actions:[35], eInit:[0.0100], init state:[ 2 13  2  0  0  0  0  0], end state:[ 4 13  2  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 634, score:[2792.40], loss:[0.96073], sequence:[81], random actions:[35], eInit:[0.0100], init state:[ 4 17 23  0  0  0  0  0], end state:[ 6 17 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 635, score:[2788.80], loss:[1.12881], sequence:[82], random actions:[33], eInit:[0.0100], init state:[ 6  4 14  0  0  0  0  0], end state:[ 1  4 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 636, score:[2801.20], loss:[1.13400], sequence:[83], random actions:[26], eInit:[0.0100], init state:[ 5 12 59  0  0  0  0  0], end state:[ 0 12 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 637, score:[2801.20], loss:[1.02302], sequence:[84], random actions:[27], eInit:[0.0100], init state:[ 4 16  3  0  0  0  0  0], end state:[ 6 16  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 638, score:[2823.20], loss:[0.97602], sequence:[85], random actions:[24], eInit:[0.0100], init state:[ 2 22 54  1  0  0  0  0], end state:[ 4 22 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 639, score:[2819.60], loss:[1.04421], sequence:[86], random actions:[26], eInit:[0.0100], init state:[ 5 17 26  0  0  0  0  0], end state:[ 0 17 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 640, score:[2836.00], loss:[0.98511], sequence:[87], random actions:[29], eInit:[0.0100], init state:[ 0 22 27  1  0  0  0  0], end state:[ 2 22 27  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 641, score:[2828.80], loss:[1.00029], sequence:[88], random actions:[24], eInit:[0.0100], init state:[ 0 21 26  1  1  0  1  0], end state:[ 2 21 26  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 642, score:[2797.60], loss:[1.00216], sequence:[89], random actions:[22], eInit:[0.0100], init state:[ 2 20 30  1  1  0  0  0], end state:[ 4 20 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 643, score:[2795.60], loss:[1.04179], sequence:[90], random actions:[30], eInit:[0.0100], init state:[ 3  4 35  0  0  0  0  0], end state:[ 5  4 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 644, score:[2823.20], loss:[1.07615], sequence:[91], random actions:[30], eInit:[0.0100], init state:[ 1 13 55  0  0  0  0  0], end state:[ 3 13 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 645, score:[2790.80], loss:[1.36466], sequence:[92], random actions:[23], eInit:[0.0100], init state:[ 5  8 30  0  0  0  0  0], end state:[ 0  8 30  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 646, score:[2748.80], loss:[1.35398], sequence:[93], random actions:[38], eInit:[0.0100], init state:[ 4  8 56  0  0  0  0  0], end state:[ 6  8 56  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 647, score:[2810.80], loss:[1.42592], sequence:[94], random actions:[31], eInit:[0.0100], init state:[ 6  0 31  0  0  1  0  0], end state:[ 1  0 31  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 648, score:[2815.60], loss:[1.21446], sequence:[95], random actions:[29], eInit:[0.0100], init state:[ 0 12 12  0  0  0  0  0], end state:[ 2 12 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 649, score:[2816.40], loss:[1.14221], sequence:[96], random actions:[35], eInit:[0.0100], init state:[ 6 10 57  0  0  0  0  0], end state:[ 1 10 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 650, score:[2827.20], loss:[1.08361], sequence:[97], random actions:[29], eInit:[0.0100], init state:[ 0 17 12  0  0  0  0  0], end state:[ 2 17 12  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 651, score:[2786.40], loss:[1.25244], sequence:[98], random actions:[24], eInit:[0.0100], init state:[ 6  3 54  0  0  0  0  0], end state:[ 1  3 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 652, score:[2784.40], loss:[1.34054], sequence:[99], random actions:[38], eInit:[0.0100], init state:[ 5  1 27  0  0  0  0  0], end state:[ 0  1 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 653, score:[2825.20], loss:[1.18790], sequence:[100], random actions:[30], eInit:[0.0100], init state:[ 4  6 16  0  0  0  0  0], end state:[ 6  6 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 654, score:[2808.40], loss:[1.28914], sequence:[101], random actions:[25], eInit:[0.0100], init state:[ 3 23 43  1  0  0  1  0], end state:[ 5 23 43  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 655, score:[2818.40], loss:[1.28495], sequence:[102], random actions:[29], eInit:[0.0100], init state:[ 6 17 10  0  0  0  0  0], end state:[ 1 17 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 656, score:[2798.40], loss:[1.24613], sequence:[103], random actions:[30], eInit:[0.0100], init state:[ 4 21  8  0  0  0  0  0], end state:[ 6 21  8  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 657, score:[2795.20], loss:[1.24568], sequence:[104], random actions:[34], eInit:[0.0100], init state:[ 5 10 32  0  0  0  0  0], end state:[ 0 10 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 658, score:[2799.60], loss:[1.17280], sequence:[105], random actions:[34], eInit:[0.0100], init state:[ 5  9 29  0  0  0  0  0], end state:[ 0  9 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 659, score:[2738.80], loss:[1.38412], sequence:[106], random actions:[35], eInit:[0.0100], init state:[ 6 15 40  0  0  0  0  0], end state:[ 1 15 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 660, score:[2830.80], loss:[1.20830], sequence:[107], random actions:[23], eInit:[0.0100], init state:[ 5 18 46  1  1  0  1  0], end state:[ 0 18 46  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 661, score:[2818.40], loss:[1.12889], sequence:[108], random actions:[27], eInit:[0.0100], init state:[ 1 15 18  0  0  0  0  0], end state:[ 3 15 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 662, score:[2756.80], loss:[1.34378], sequence:[109], random actions:[24], eInit:[0.0100], init state:[ 2 22 30  1  0  0  0  0], end state:[ 4 22 30  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 663, score:[2781.60], loss:[1.23538], sequence:[110], random actions:[33], eInit:[0.0100], init state:[ 5 10  2  0  0  0  0  0], end state:[ 0 10  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 664, score:[2828.40], loss:[1.20310], sequence:[111], random actions:[26], eInit:[0.0100], init state:[ 1 10 18  0  0  0  0  0], end state:[ 3 10 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 665, score:[2776.00], loss:[1.28117], sequence:[112], random actions:[32], eInit:[0.0100], init state:[ 5 14  0  0  0  0  0  0], end state:[ 0 14  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 666, score:[2744.00], loss:[1.65117], sequence:[113], random actions:[28], eInit:[0.0100], init state:[ 3 17 32  0  0  0  0  0], end state:[ 5 17 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 667, score:[2818.00], loss:[1.13728], sequence:[114], random actions:[25], eInit:[0.0100], init state:[ 0 22 27  1  0  0  0  0], end state:[ 2 22 27  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 668, score:[2778.00], loss:[1.11106], sequence:[115], random actions:[37], eInit:[0.0100], init state:[ 0  1 12  0  0  0  0  0], end state:[ 2  1 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 669, score:[2804.00], loss:[1.05599], sequence:[116], random actions:[30], eInit:[0.0100], init state:[ 1 18 42  0  0  0  0  0], end state:[ 3 18 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 670, score:[2811.20], loss:[1.16567], sequence:[117], random actions:[35], eInit:[0.0100], init state:[ 6  8 12  1  0  0  0  0], end state:[ 1  8 12  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(118, [473])
INFO:Reinforcement.Functions:episode: 671, score:[2773.20], loss:[1.22556], sequence:[118], random actions:[34], eInit:[0.0100], init state:[ 3 19 23  0  0  0  0  0], end state:[ 5 19 23  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 672, score:[2822.00], loss:[1.14827], sequence:[119], random actions:[22], eInit:[0.0100], init state:[ 3 14 18  0  0  0  0  0], end state:[ 5 14 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 673, score:[2768.40], loss:[1.35122], sequence:[120], random actions:[39], eInit:[0.0100], init state:[ 2 21 12  1  1  0  1  0], end state:[ 4 21 12  0  0  0  1  0]
INFO:Reinforcement.Functions:episode: 674, score:[2798.80], loss:[1.89963], sequence:[121], random actions:[29], eInit:[0.0100], init state:[ 5 15  9  0  0  0  0  0], end state:[ 0 15  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 675, score:[2798.40], loss:[1.48033], sequence:[122], random actions:[35], eInit:[0.0100], init state:[ 0  8 20  1  0  0  0  0], end state:[ 2  8 20  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 676, score:[2842.80], loss:[1.21380], sequence:[123], random actions:[20], eInit:[0.0100], init state:[ 6  4 35  0  0  0  0  0], end state:[ 1  4 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 677, score:[2825.60], loss:[1.04969], sequence:[124], random actions:[13], eInit:[0.0100], init state:[ 2  3 56  0  0  0  0  0], end state:[ 4  3 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 678, score:[2788.80], loss:[1.13164], sequence:[125], random actions:[26], eInit:[0.0100], init state:[ 3 22 43  1  0  0  0  0], end state:[ 5 22 43  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 679, score:[2823.20], loss:[1.04110], sequence:[126], random actions:[25], eInit:[0.0100], init state:[ 4 18 55  0  0  0  0  0], end state:[ 6 18 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 680, score:[2803.60], loss:[1.31216], sequence:[127], random actions:[21], eInit:[0.0100], init state:[ 5 11 19  0  0  0  0  0], end state:[ 0 11 19  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(127, [680])
INFO:Reinforcement.Functions:episode: 681, score:[2806.40], loss:[1.74086], sequence:[128], random actions:[25], eInit:[0.0100], init state:[ 3 15 11  0  0  0  0  0], end state:[ 5 15 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 682, score:[2820.00], loss:[1.62278], sequence:[129], random actions:[22], eInit:[0.0100], init state:[ 5 20 26  1  0  0  0  0], end state:[ 0 20 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 683, score:[2812.40], loss:[1.27170], sequence:[130], random actions:[25], eInit:[0.0100], init state:[ 4 14 26  0  0  0  0  0], end state:[ 6 14 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 684, score:[2790.40], loss:[1.37089], sequence:[131], random actions:[34], eInit:[0.0100], init state:[ 5  4 36  0  0  0  0  0], end state:[ 0  4 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 685, score:[2817.60], loss:[1.32290], sequence:[132], random actions:[20], eInit:[0.0100], init state:[ 2 23 25  1  0  0  1  0], end state:[ 4 23 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 686, score:[2831.20], loss:[1.26725], sequence:[133], random actions:[24], eInit:[0.0100], init state:[ 4 15 34  0  0  0  0  0], end state:[ 6 15 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 687, score:[2784.40], loss:[1.12755], sequence:[134], random actions:[37], eInit:[0.0100], init state:[ 4  0 45  1  0  1  0  0], end state:[ 6  0 45  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 688, score:[2766.80], loss:[1.44215], sequence:[135], random actions:[33], eInit:[0.0100], init state:[ 4  3 10  0  0  0  0  0], end state:[ 6  3 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 689, score:[2785.60], loss:[1.53087], sequence:[136], random actions:[28], eInit:[0.0100], init state:[ 6  4 41  0  0  0  0  0], end state:[ 1  4 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 690, score:[2774.00], loss:[1.44818], sequence:[137], random actions:[21], eInit:[0.0100], init state:[ 2  4 18  0  0  0  0  0], end state:[ 4  4 18  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(137, [690])
INFO:Reinforcement.Functions:episode: 691, score:[2826.40], loss:[1.44614], sequence:[138], random actions:[27], eInit:[0.0100], init state:[ 1 13 52  0  0  0  0  0], end state:[ 3 13 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 692, score:[2795.60], loss:[1.21255], sequence:[139], random actions:[32], eInit:[0.0100], init state:[ 4 18 43  0  0  0  0  0], end state:[ 6 18 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 693, score:[2794.40], loss:[1.18446], sequence:[140], random actions:[36], eInit:[0.0100], init state:[ 5 16 46  0  0  0  0  0], end state:[ 0 16 46  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 694, score:[2816.80], loss:[1.36009], sequence:[141], random actions:[26], eInit:[0.0100], init state:[ 6  4 53  0  0  0  0  0], end state:[ 1  4 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 695, score:[2792.00], loss:[1.35339], sequence:[142], random actions:[30], eInit:[0.0100], init state:[ 5 14 19  0  0  0  0  0], end state:[ 0 14 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 696, score:[2829.60], loss:[1.01991], sequence:[143], random actions:[30], eInit:[0.0100], init state:[ 1 11 51  0  0  0  0  0], end state:[ 3 11 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 697, score:[2820.40], loss:[1.04513], sequence:[144], random actions:[34], eInit:[0.0100], init state:[ 4 23 56  0  0  0  0  0], end state:[ 6 23 56  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 698, score:[2805.20], loss:[1.02147], sequence:[145], random actions:[24], eInit:[0.0100], init state:[ 2 11 48  0  0  0  0  0], end state:[ 4 11 48  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 699, score:[2827.60], loss:[1.17909], sequence:[146], random actions:[32], eInit:[0.0100], init state:[6 0 7 1 0 0 0 0], end state:[1 0 7 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 700, score:[2828.40], loss:[1.06442], sequence:[147], random actions:[25], eInit:[0.0100], init state:[6 2 4 0 0 0 0 0], end state:[1 2 4 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(147, [700])
INFO:Reinforcement.Functions:episode: 701, score:[2806.00], loss:[0.99587], sequence:[148], random actions:[26], eInit:[0.0100], init state:[ 2  9 46  0  0  0  0  0], end state:[ 4  9 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 702, score:[2817.20], loss:[0.97552], sequence:[149], random actions:[31], eInit:[0.0100], init state:[ 2 14 22  0  0  0  0  0], end state:[ 4 14 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 703, score:[2838.80], loss:[1.04122], sequence:[150], random actions:[25], eInit:[0.0100], init state:[ 0 14 36  0  0  0  0  0], end state:[ 2 14 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 704, score:[2795.20], loss:[0.95390], sequence:[151], random actions:[37], eInit:[0.0100], init state:[ 6  2 33  0  0  0  0  0], end state:[ 1  2 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 705, score:[2783.20], loss:[1.05774], sequence:[152], random actions:[34], eInit:[0.0100], init state:[ 5 21  8  1  0  0  1  0], end state:[ 0 21  8  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 706, score:[2786.40], loss:[1.15052], sequence:[153], random actions:[31], eInit:[0.0100], init state:[ 2 15 42  0  0  0  0  0], end state:[ 4 15 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 707, score:[2804.00], loss:[1.00279], sequence:[154], random actions:[25], eInit:[0.0100], init state:[ 0  2 21  0  0  0  0  0], end state:[ 2  2 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 708, score:[2793.20], loss:[1.06564], sequence:[155], random actions:[28], eInit:[0.0100], init state:[ 0 13 15  0  0  0  0  0], end state:[ 2 13 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 709, score:[2797.60], loss:[1.07500], sequence:[156], random actions:[21], eInit:[0.0100], init state:[ 4  5 51  0  0  0  0  0], end state:[ 6  5 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 710, score:[2741.60], loss:[1.50615], sequence:[157], random actions:[38], eInit:[0.0100], init state:[ 2 22 22  1  0  0  0  0], end state:[ 4 22 22  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(157, [710])
INFO:Reinforcement.Functions:episode: 711, score:[2819.20], loss:[1.50008], sequence:[158], random actions:[33], eInit:[0.0100], init state:[ 2  6 18  0  0  0  0  0], end state:[ 4  6 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 712, score:[2786.00], loss:[1.24717], sequence:[159], random actions:[28], eInit:[0.0100], init state:[ 1  8 31  1  1  0  1  1], end state:[ 3  8 31  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 713, score:[2763.20], loss:[1.21890], sequence:[160], random actions:[37], eInit:[0.0100], init state:[ 0  3 32  0  0  0  0  0], end state:[ 2  3 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 714, score:[2822.40], loss:[1.14245], sequence:[161], random actions:[28], eInit:[0.0100], init state:[ 1 20 48  1  1  0  1  0], end state:[ 3 20 48  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 715, score:[2816.40], loss:[1.19711], sequence:[162], random actions:[37], eInit:[0.0100], init state:[ 6 23 30  1  0  0  1  0], end state:[ 1 23 30  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 716, score:[2790.00], loss:[1.27221], sequence:[163], random actions:[22], eInit:[0.0100], init state:[ 3  1 49  0  0  0  0  0], end state:[ 5  1 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 717, score:[2824.80], loss:[1.21930], sequence:[164], random actions:[29], eInit:[0.0100], init state:[ 0 14  9  0  0  0  0  0], end state:[ 2 14  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 718, score:[2764.40], loss:[1.19917], sequence:[165], random actions:[26], eInit:[0.0100], init state:[6 4 3 0 0 0 0 0], end state:[1 4 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 719, score:[2822.40], loss:[1.23740], sequence:[166], random actions:[30], eInit:[0.0100], init state:[ 6  2 11  0  0  0  0  0], end state:[ 1  2 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 720, score:[2727.60], loss:[1.45751], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 11 43  1  1  0  0  0], end state:[ 6 11 43  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 721, score:[2800.00], loss:[1.41397], sequence:[1], random actions:[33], eInit:[0.0100], init state:[6 7 8 0 0 0 0 0], end state:[1 7 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 722, score:[2776.00], loss:[1.55228], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 5  3 38  0  0  0  0  0], end state:[ 0  3 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 723, score:[2808.00], loss:[1.44712], sequence:[3], random actions:[18], eInit:[0.0100], init state:[ 5 14  0  0  0  0  0  0], end state:[ 0 14  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 724, score:[2821.60], loss:[1.33553], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 6 11 56  0  0  0  0  0], end state:[ 1 11 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 725, score:[2822.00], loss:[1.34846], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 5 16 59  0  0  0  0  0], end state:[ 0 16 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 726, score:[2800.40], loss:[1.45891], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 1 23 59  1  0  0  0  0], end state:[ 3 23 59  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 727, score:[2802.00], loss:[1.49925], sequence:[7], random actions:[30], eInit:[0.0100], init state:[ 6  0 16  1  0  0  0  0], end state:[ 1  0 16  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 728, score:[2800.80], loss:[1.31350], sequence:[8], random actions:[32], eInit:[0.0100], init state:[ 6  2 39  0  0  0  0  0], end state:[ 1  2 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 729, score:[2835.60], loss:[1.25262], sequence:[9], random actions:[22], eInit:[0.0100], init state:[ 2  2 26  0  0  0  0  0], end state:[ 4  2 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 730, score:[2750.40], loss:[1.44966], sequence:[10], random actions:[33], eInit:[0.0100], init state:[ 3 18 57  0  0  0  0  0], end state:[ 5 18 57  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 731, score:[2793.60], loss:[1.43712], sequence:[11], random actions:[31], eInit:[0.0100], init state:[ 4  6 38  0  0  0  0  0], end state:[ 6  6 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 732, score:[2814.00], loss:[1.29867], sequence:[12], random actions:[22], eInit:[0.0100], init state:[ 3 14 13  0  0  0  0  0], end state:[ 5 14 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 733, score:[2821.60], loss:[1.19193], sequence:[13], random actions:[29], eInit:[0.0100], init state:[3 8 9 1 0 0 0 0], end state:[5 8 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 734, score:[2786.80], loss:[1.26301], sequence:[14], random actions:[27], eInit:[0.0100], init state:[ 3 22 10  1  0  0  0  0], end state:[ 5 22 10  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 735, score:[2805.20], loss:[1.18743], sequence:[15], random actions:[35], eInit:[0.0100], init state:[ 6 18 33  0  0  0  0  0], end state:[ 1 18 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 736, score:[2798.40], loss:[1.15035], sequence:[16], random actions:[28], eInit:[0.0100], init state:[ 3 16 46  0  0  0  0  0], end state:[ 5 16 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 737, score:[2834.00], loss:[0.99848], sequence:[17], random actions:[27], eInit:[0.0100], init state:[ 2  8 39  1  1  0  1  0], end state:[ 4  8 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 738, score:[2802.80], loss:[1.16262], sequence:[18], random actions:[21], eInit:[0.0100], init state:[ 5 16 11  0  0  0  0  0], end state:[ 0 16 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 739, score:[2772.40], loss:[1.28768], sequence:[19], random actions:[40], eInit:[0.0100], init state:[ 3 18 14  0  0  0  0  0], end state:[ 5 18 14  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 740, score:[2814.80], loss:[1.21654], sequence:[20], random actions:[28], eInit:[0.0100], init state:[ 0 18 19  0  0  0  0  0], end state:[ 2 18 19  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 741, score:[2792.80], loss:[1.08055], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 1 17 46  0  0  0  0  0], end state:[ 3 17 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 742, score:[2828.80], loss:[0.91114], sequence:[22], random actions:[20], eInit:[0.0100], init state:[ 4 19 31  0  0  0  0  0], end state:[ 6 19 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 743, score:[2804.80], loss:[0.91148], sequence:[23], random actions:[33], eInit:[0.0100], init state:[ 4  1 43  0  0  0  0  0], end state:[ 6  1 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 744, score:[2804.80], loss:[1.10740], sequence:[24], random actions:[28], eInit:[0.0100], init state:[ 5 10  1  0  0  0  0  0], end state:[ 0 10  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 745, score:[2822.00], loss:[1.06751], sequence:[25], random actions:[18], eInit:[0.0100], init state:[ 4  7 57  0  0  0  0  0], end state:[ 6  7 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 746, score:[2814.80], loss:[1.08666], sequence:[26], random actions:[21], eInit:[0.0100], init state:[ 3 10 18  0  0  0  0  0], end state:[ 5 10 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 747, score:[2810.40], loss:[1.13044], sequence:[27], random actions:[20], eInit:[0.0100], init state:[ 6 11 52  0  0  0  0  0], end state:[ 1 11 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 748, score:[2828.00], loss:[0.99459], sequence:[28], random actions:[25], eInit:[0.0100], init state:[ 3 11 32  0  0  0  0  0], end state:[ 5 11 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 749, score:[2796.80], loss:[1.08188], sequence:[29], random actions:[32], eInit:[0.0100], init state:[ 4 17 11  0  0  0  0  0], end state:[ 6 17 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 750, score:[2800.80], loss:[1.00390], sequence:[30], random actions:[36], eInit:[0.0100], init state:[ 2 12  5  0  0  0  0  0], end state:[ 4 12  5  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 751, score:[2789.20], loss:[1.34662], sequence:[31], random actions:[32], eInit:[0.0100], init state:[ 5 16  3  0  0  0  0  0], end state:[ 0 16  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 752, score:[2810.40], loss:[0.98195], sequence:[32], random actions:[38], eInit:[0.0100], init state:[ 1 20  5  0  0  0  0  0], end state:[ 3 20  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 753, score:[2812.00], loss:[0.90177], sequence:[33], random actions:[25], eInit:[0.0100], init state:[ 6 19 38  0  0  0  0  0], end state:[ 1 19 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 754, score:[2806.80], loss:[0.90148], sequence:[34], random actions:[34], eInit:[0.0100], init state:[ 3 22 38  1  0  0  0  0], end state:[ 5 22 38  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 755, score:[2775.20], loss:[1.01826], sequence:[35], random actions:[39], eInit:[0.0100], init state:[ 3 20 25  0  0  0  0  0], end state:[ 5 20 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 756, score:[2775.20], loss:[1.19144], sequence:[36], random actions:[33], eInit:[0.0100], init state:[ 5  0 33  0  0  0  0  0], end state:[ 0  0 33  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 757, score:[2801.60], loss:[1.29509], sequence:[37], random actions:[40], eInit:[0.0100], init state:[ 1 19 42  0  0  0  0  0], end state:[ 3 19 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 758, score:[2827.60], loss:[1.07357], sequence:[38], random actions:[20], eInit:[0.0100], init state:[5 2 5 0 0 0 0 0], end state:[0 2 5 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 759, score:[2792.00], loss:[1.02082], sequence:[39], random actions:[35], eInit:[0.0100], init state:[ 4 19  2  0  0  0  0  0], end state:[ 6 19  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 760, score:[2822.00], loss:[1.01268], sequence:[40], random actions:[33], eInit:[0.0100], init state:[ 1  5 20  0  0  0  0  0], end state:[ 3  5 20  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 761, score:[2807.60], loss:[1.11268], sequence:[41], random actions:[35], eInit:[0.0100], init state:[ 5 14 27  0  0  0  0  0], end state:[ 0 14 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 762, score:[2824.00], loss:[0.98822], sequence:[42], random actions:[26], eInit:[0.0100], init state:[ 5  8 51  0  0  0  0  0], end state:[ 0  8 51  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 763, score:[2828.80], loss:[0.88090], sequence:[43], random actions:[24], eInit:[0.0100], init state:[ 3 10 42  0  0  0  0  0], end state:[ 5 10 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 764, score:[2816.80], loss:[0.87414], sequence:[44], random actions:[26], eInit:[0.0100], init state:[ 2  7 16  0  0  0  0  0], end state:[ 4  7 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 765, score:[2816.00], loss:[0.92133], sequence:[45], random actions:[26], eInit:[0.0100], init state:[ 5  7 29  0  0  0  0  0], end state:[ 0  7 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 766, score:[2780.40], loss:[1.03259], sequence:[46], random actions:[25], eInit:[0.0100], init state:[ 0 11 42  0  0  0  0  0], end state:[ 2 11 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 767, score:[2819.60], loss:[0.92997], sequence:[47], random actions:[27], eInit:[0.0100], init state:[ 4 21 21  0  0  0  0  0], end state:[ 6 21 21  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 768, score:[2802.00], loss:[0.91762], sequence:[48], random actions:[39], eInit:[0.0100], init state:[ 1 22 43  1  0  0  0  0], end state:[ 3 22 43  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 769, score:[2788.00], loss:[1.11183], sequence:[49], random actions:[28], eInit:[0.0100], init state:[ 5  6 56  0  0  0  0  0], end state:[ 0  6 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 770, score:[2792.00], loss:[1.28234], sequence:[50], random actions:[22], eInit:[0.0100], init state:[ 6 16 45  0  0  0  0  0], end state:[ 1 16 45  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 771, score:[2813.60], loss:[1.11956], sequence:[51], random actions:[38], eInit:[0.0100], init state:[ 0 20 36  1  1  0  0  0], end state:[ 2 20 36  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 772, score:[2784.80], loss:[1.00570], sequence:[52], random actions:[24], eInit:[0.0100], init state:[ 6 15 17  0  0  0  0  0], end state:[ 1 15 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 773, score:[2819.60], loss:[0.99631], sequence:[53], random actions:[36], eInit:[0.0100], init state:[ 1 12 19  0  0  0  0  0], end state:[ 3 12 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 774, score:[2836.40], loss:[1.00206], sequence:[54], random actions:[26], eInit:[0.0100], init state:[ 1 16 56  0  0  0  0  0], end state:[ 3 16 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 775, score:[2787.60], loss:[0.97081], sequence:[55], random actions:[29], eInit:[0.0100], init state:[ 5  1 50  0  0  0  0  0], end state:[ 0  1 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 776, score:[2747.60], loss:[1.40563], sequence:[56], random actions:[28], eInit:[0.0100], init state:[ 4  2 40  0  0  0  0  0], end state:[ 6  2 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 777, score:[2810.80], loss:[1.22484], sequence:[57], random actions:[30], eInit:[0.0100], init state:[ 5 11 10  0  0  0  0  0], end state:[ 0 11 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 778, score:[2792.40], loss:[1.19611], sequence:[58], random actions:[34], eInit:[0.0100], init state:[ 2 22 32  1  0  0  0  0], end state:[ 4 22 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 779, score:[2820.00], loss:[1.24409], sequence:[59], random actions:[32], eInit:[0.0100], init state:[ 4 23  0  0  0  0  0  0], end state:[ 6 23  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 780, score:[2764.00], loss:[1.37174], sequence:[60], random actions:[26], eInit:[0.0100], init state:[ 3 22 22  1  0  0  0  0], end state:[ 5 22 22  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 781, score:[2824.80], loss:[1.16029], sequence:[61], random actions:[26], eInit:[0.0100], init state:[ 3 18 50  0  0  0  0  0], end state:[ 5 18 50  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 782, score:[2831.60], loss:[1.09825], sequence:[62], random actions:[28], eInit:[0.0100], init state:[ 1 11 34  0  0  0  0  0], end state:[ 3 11 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 783, score:[2772.00], loss:[1.17020], sequence:[63], random actions:[28], eInit:[0.0100], init state:[ 3 19  5  0  0  0  0  0], end state:[ 5 19  5  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 784, score:[2824.80], loss:[1.80989], sequence:[64], random actions:[28], eInit:[0.0100], init state:[ 0 10 35  0  0  0  0  0], end state:[ 2 10 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 785, score:[2838.80], loss:[1.15564], sequence:[65], random actions:[24], eInit:[0.0100], init state:[ 1  7 48  0  0  0  0  0], end state:[ 3  7 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 786, score:[2780.40], loss:[1.18847], sequence:[66], random actions:[26], eInit:[0.0100], init state:[ 4 21 26  0  0  0  0  0], end state:[ 6 21 26  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 787, score:[2834.00], loss:[1.09507], sequence:[67], random actions:[24], eInit:[0.0100], init state:[ 1  0 50  0  0  1  0  0], end state:[ 3  0 50  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 788, score:[2818.00], loss:[0.95068], sequence:[68], random actions:[33], eInit:[0.0100], init state:[ 0  1 25  0  0  0  0  0], end state:[ 2  1 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 789, score:[2812.80], loss:[1.05421], sequence:[69], random actions:[18], eInit:[0.0100], init state:[ 5 13 56  0  0  0  0  0], end state:[ 0 13 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 790, score:[2809.60], loss:[1.07465], sequence:[70], random actions:[31], eInit:[0.0100], init state:[ 6 22 52  1  0  0  0  0], end state:[ 1 22 52  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 791, score:[2818.80], loss:[0.94636], sequence:[71], random actions:[29], eInit:[0.0100], init state:[ 1 16 36  0  0  0  0  0], end state:[ 3 16 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 792, score:[2816.80], loss:[1.01137], sequence:[72], random actions:[27], eInit:[0.0100], init state:[ 0  2 12  0  0  0  0  0], end state:[ 2  2 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 793, score:[2773.60], loss:[1.12567], sequence:[73], random actions:[33], eInit:[0.0100], init state:[ 4  2 20  0  0  0  0  0], end state:[ 6  2 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 794, score:[2826.80], loss:[1.09411], sequence:[74], random actions:[30], eInit:[0.0100], init state:[ 6 18 59  0  0  0  0  0], end state:[ 1 18 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 795, score:[2814.80], loss:[0.94479], sequence:[75], random actions:[28], eInit:[0.0100], init state:[ 0 23  2  1  0  0  0  0], end state:[ 2 23  2  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 796, score:[2804.00], loss:[1.10797], sequence:[76], random actions:[33], eInit:[0.0100], init state:[ 0  4 50  0  0  0  0  0], end state:[ 2  4 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 797, score:[2833.20], loss:[1.08025], sequence:[77], random actions:[31], eInit:[0.0100], init state:[ 0 15 48  0  0  0  0  0], end state:[ 2 15 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 798, score:[2820.80], loss:[1.00884], sequence:[78], random actions:[20], eInit:[0.0100], init state:[ 2  9 35  0  0  0  0  0], end state:[ 4  9 35  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 799, score:[2789.60], loss:[1.02373], sequence:[79], random actions:[32], eInit:[0.0100], init state:[ 2 18 19  0  0  0  0  0], end state:[ 4 18 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 800, score:[2796.40], loss:[1.05719], sequence:[80], random actions:[24], eInit:[0.0100], init state:[3 5 7 0 0 0 0 0], end state:[5 5 7 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 801, score:[2771.60], loss:[1.08024], sequence:[81], random actions:[31], eInit:[0.0100], init state:[ 3 21 32  1  0  0  0  0], end state:[ 5 21 32  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 802, score:[2814.80], loss:[1.18628], sequence:[82], random actions:[25], eInit:[0.0100], init state:[ 0  7 48  0  0  0  0  0], end state:[ 2  7 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 803, score:[2779.20], loss:[1.18457], sequence:[83], random actions:[32], eInit:[0.0100], init state:[ 4 14  4  0  0  0  0  0], end state:[ 6 14  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 804, score:[2806.80], loss:[1.58258], sequence:[84], random actions:[29], eInit:[0.0100], init state:[ 6 17 58  0  0  0  0  0], end state:[ 1 17 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 805, score:[2816.00], loss:[1.69559], sequence:[85], random actions:[27], eInit:[0.0100], init state:[ 1  5 58  0  0  0  0  0], end state:[ 3  5 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 806, score:[2763.20], loss:[1.55482], sequence:[86], random actions:[26], eInit:[0.0100], init state:[ 4 14 39  0  0  0  0  0], end state:[ 6 14 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 807, score:[2815.60], loss:[1.56518], sequence:[87], random actions:[24], eInit:[0.0100], init state:[ 5  7 36  0  0  0  0  0], end state:[ 0  7 36  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 808, score:[2811.60], loss:[1.50668], sequence:[88], random actions:[22], eInit:[0.0100], init state:[ 6  9 52  0  0  0  0  0], end state:[ 1  9 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 809, score:[2803.20], loss:[1.45654], sequence:[89], random actions:[24], eInit:[0.0100], init state:[ 5  4 30  0  0  0  0  0], end state:[ 0  4 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 810, score:[2809.60], loss:[1.29861], sequence:[90], random actions:[26], eInit:[0.0100], init state:[ 2  8 10  1  0  0  0  0], end state:[ 4  8 10  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 811, score:[2814.80], loss:[1.21611], sequence:[91], random actions:[22], eInit:[0.0100], init state:[ 2  1 39  0  0  0  0  0], end state:[ 4  1 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 812, score:[2773.60], loss:[1.42179], sequence:[92], random actions:[30], eInit:[0.0100], init state:[ 3 12 24  0  0  0  0  0], end state:[ 5 12 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 813, score:[2763.20], loss:[1.56248], sequence:[93], random actions:[33], eInit:[0.0100], init state:[ 4 10  0  1  1  0  1  0], end state:[ 6 10  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 814, score:[2783.20], loss:[1.60368], sequence:[94], random actions:[38], eInit:[0.0100], init state:[ 1 11 52  0  0  0  0  0], end state:[ 3 11 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 815, score:[2810.00], loss:[2.14656], sequence:[95], random actions:[32], eInit:[0.0100], init state:[ 2  9 54  0  0  0  0  0], end state:[ 4  9 54  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 816, score:[2784.80], loss:[1.88377], sequence:[96], random actions:[30], eInit:[0.0100], init state:[ 6 13 40  0  0  0  0  0], end state:[ 1 13 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 817, score:[2782.40], loss:[1.76827], sequence:[97], random actions:[29], eInit:[0.0100], init state:[ 4  5 30  0  0  0  0  0], end state:[ 6  5 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 818, score:[2834.80], loss:[1.46119], sequence:[98], random actions:[27], eInit:[0.0100], init state:[ 1 21 16  1  1  0  1  0], end state:[ 3 21 16  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 819, score:[2785.60], loss:[1.43336], sequence:[99], random actions:[26], eInit:[0.0100], init state:[ 3 22 11  1  0  0  0  0], end state:[ 5 22 11  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 820, score:[2802.80], loss:[1.29271], sequence:[100], random actions:[27], eInit:[0.0100], init state:[ 4  6 43  0  0  0  0  0], end state:[ 6  6 43  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 821, score:[2770.40], loss:[1.49707], sequence:[101], random actions:[29], eInit:[0.0100], init state:[3 7 7 0 0 0 0 0], end state:[5 7 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 822, score:[2828.40], loss:[1.20990], sequence:[102], random actions:[23], eInit:[0.0100], init state:[ 0 18  5  0  0  0  0  0], end state:[ 2 18  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 823, score:[2817.20], loss:[1.13994], sequence:[103], random actions:[26], eInit:[0.0100], init state:[ 1 14 58  0  0  0  0  0], end state:[ 3 14 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 824, score:[2727.20], loss:[1.46810], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 6  3 22  0  0  0  0  0], end state:[ 1  3 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 825, score:[2828.80], loss:[1.16213], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 6 23 22  1  0  0  1  0], end state:[ 1 23 22  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 826, score:[2744.00], loss:[1.34413], sequence:[2], random actions:[44], eInit:[0.0100], init state:[ 3  7 35  0  0  0  0  0], end state:[ 5  7 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 827, score:[2826.80], loss:[1.28356], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 0 14 58  0  0  0  0  0], end state:[ 2 14 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 828, score:[2812.80], loss:[1.16175], sequence:[4], random actions:[34], eInit:[0.0100], init state:[ 0 23 47  1  0  0  0  0], end state:[ 2 23 47  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 829, score:[2786.00], loss:[1.16808], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 2 11 35  0  0  0  0  0], end state:[ 4 11 35  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 830, score:[2834.80], loss:[1.22209], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 0 23 32  1  0  0  1  0], end state:[ 2 23 32  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 831, score:[2812.80], loss:[1.02789], sequence:[7], random actions:[30], eInit:[0.0100], init state:[ 2 10 43  0  0  0  0  0], end state:[ 4 10 43  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 832, score:[2815.60], loss:[1.15441], sequence:[8], random actions:[23], eInit:[0.0100], init state:[ 3  8 31  1  1  0  1  1], end state:[ 5  8 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 833, score:[2826.00], loss:[1.11924], sequence:[9], random actions:[29], eInit:[0.0100], init state:[ 3 12  8  0  0  0  0  0], end state:[ 5 12  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 834, score:[2751.60], loss:[1.20455], sequence:[10], random actions:[26], eInit:[0.0100], init state:[ 6  0 43  0  0  1  0  0], end state:[ 1  0 43  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 835, score:[2822.40], loss:[1.01712], sequence:[11], random actions:[25], eInit:[0.0100], init state:[ 2 10 43  0  0  0  0  0], end state:[ 4 10 43  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 836, score:[2778.80], loss:[1.27857], sequence:[12], random actions:[22], eInit:[0.0100], init state:[ 4 12 18  1  1  0  0  0], end state:[ 6 12 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 837, score:[2825.20], loss:[1.09068], sequence:[13], random actions:[25], eInit:[0.0100], init state:[ 2 22 16  1  0  0  0  0], end state:[ 4 22 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 838, score:[2717.60], loss:[1.45879], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 16 16  0  0  0  0  0], end state:[ 0 16 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 839, score:[2833.60], loss:[1.25529], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 2 20  0  0  0  0  0  0], end state:[ 4 20  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 840, score:[2820.40], loss:[1.14620], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 0  6 57  0  0  0  0  0], end state:[ 2  6 57  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 841, score:[2805.20], loss:[1.20937], sequence:[3], random actions:[37], eInit:[0.0100], init state:[ 0 19  4  0  0  0  0  0], end state:[ 2 19  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 842, score:[2781.20], loss:[1.16022], sequence:[4], random actions:[28], eInit:[0.0100], init state:[5 4 3 0 0 0 0 0], end state:[0 4 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 843, score:[2788.00], loss:[1.09578], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 4  5 55  0  0  0  0  0], end state:[ 6  5 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 844, score:[2828.40], loss:[0.95424], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 1  2 16  0  0  0  0  0], end state:[ 3  2 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 845, score:[2786.00], loss:[0.95544], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 3 21 30  1  0  0  0  0], end state:[ 5 21 30  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 846, score:[2798.80], loss:[1.07277], sequence:[8], random actions:[24], eInit:[0.0100], init state:[ 5 17 54  0  0  0  0  0], end state:[ 0 17 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 847, score:[2798.00], loss:[0.94846], sequence:[9], random actions:[28], eInit:[0.0100], init state:[ 6 10 12  0  0  0  0  0], end state:[ 1 10 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 848, score:[2795.60], loss:[0.97152], sequence:[10], random actions:[28], eInit:[0.0100], init state:[ 1 17 12  0  0  0  0  0], end state:[ 3 17 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 849, score:[2782.40], loss:[1.02864], sequence:[11], random actions:[25], eInit:[0.0100], init state:[ 3 13 27  0  0  0  0  0], end state:[ 5 13 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 850, score:[2811.20], loss:[1.04853], sequence:[12], random actions:[27], eInit:[0.0100], init state:[ 5 11 48  0  0  0  0  0], end state:[ 0 11 48  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 851, score:[2798.00], loss:[1.16492], sequence:[13], random actions:[27], eInit:[0.0100], init state:[5 9 1 0 0 0 0 0], end state:[0 9 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 852, score:[2831.60], loss:[1.00999], sequence:[14], random actions:[27], eInit:[0.0100], init state:[ 2  6 12  0  0  0  0  0], end state:[ 4  6 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 853, score:[2806.00], loss:[1.05530], sequence:[15], random actions:[22], eInit:[0.0100], init state:[ 2 11 50  0  0  0  0  0], end state:[ 4 11 50  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 854, score:[2807.20], loss:[0.94430], sequence:[16], random actions:[26], eInit:[0.0100], init state:[ 6 15 23  0  0  0  0  0], end state:[ 1 15 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 855, score:[2775.20], loss:[1.07557], sequence:[17], random actions:[32], eInit:[0.0100], init state:[ 3  5 54  0  0  0  0  0], end state:[ 5  5 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 856, score:[2808.00], loss:[1.04756], sequence:[18], random actions:[27], eInit:[0.0100], init state:[ 1  3 26  0  0  0  0  0], end state:[ 3  3 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 857, score:[2761.20], loss:[1.33681], sequence:[19], random actions:[31], eInit:[0.0100], init state:[ 5 12 36  0  0  0  0  0], end state:[ 0 12 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 858, score:[2834.40], loss:[1.14635], sequence:[20], random actions:[23], eInit:[0.0100], init state:[ 1 20 27  0  0  0  0  0], end state:[ 3 20 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 859, score:[2806.80], loss:[1.12333], sequence:[21], random actions:[24], eInit:[0.0100], init state:[ 5  8 59  0  0  0  0  0], end state:[ 0  8 59  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 860, score:[2778.00], loss:[1.12185], sequence:[22], random actions:[36], eInit:[0.0100], init state:[ 3 12  1  0  0  0  0  0], end state:[ 5 12  1  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 861, score:[2788.80], loss:[1.38686], sequence:[23], random actions:[40], eInit:[0.0100], init state:[ 6  8 47  1  1  0  0  0], end state:[ 1  8 47  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 862, score:[2832.40], loss:[1.03044], sequence:[24], random actions:[29], eInit:[0.0100], init state:[ 2  6 48  0  0  0  0  0], end state:[ 4  6 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 863, score:[2810.80], loss:[1.17504], sequence:[25], random actions:[28], eInit:[0.0100], init state:[ 1  8 13  1  0  0  0  0], end state:[ 3  8 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 864, score:[2808.40], loss:[1.29295], sequence:[26], random actions:[28], eInit:[0.0100], init state:[ 5  4 46  0  0  0  0  0], end state:[ 0  4 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 865, score:[2812.00], loss:[1.25033], sequence:[27], random actions:[27], eInit:[0.0100], init state:[ 2  1 35  0  0  0  0  0], end state:[ 4  1 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 866, score:[2807.60], loss:[1.04757], sequence:[28], random actions:[28], eInit:[0.0100], init state:[ 4 19 21  0  0  0  0  0], end state:[ 6 19 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 867, score:[2825.20], loss:[0.92140], sequence:[29], random actions:[27], eInit:[0.0100], init state:[ 2  3 26  0  0  0  0  0], end state:[ 4  3 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 868, score:[2770.40], loss:[1.07040], sequence:[30], random actions:[45], eInit:[0.0100], init state:[ 5  6 15  0  0  0  0  0], end state:[ 0  6 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 869, score:[2826.40], loss:[1.08236], sequence:[31], random actions:[25], eInit:[0.0100], init state:[ 4 15 18  0  0  0  0  0], end state:[ 6 15 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 870, score:[2815.20], loss:[1.12873], sequence:[32], random actions:[30], eInit:[0.0100], init state:[ 6  5 38  0  0  0  0  0], end state:[ 1  5 38  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 871, score:[2803.60], loss:[1.01678], sequence:[33], random actions:[33], eInit:[0.0100], init state:[ 2  9 26  0  0  0  0  0], end state:[ 4  9 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 872, score:[2831.20], loss:[1.07247], sequence:[34], random actions:[26], eInit:[0.0100], init state:[ 0 18 32  0  0  0  0  0], end state:[ 2 18 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 873, score:[2762.00], loss:[1.13041], sequence:[35], random actions:[33], eInit:[0.0100], init state:[ 2 18 59  0  0  0  0  0], end state:[ 4 18 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 874, score:[2831.20], loss:[1.13947], sequence:[36], random actions:[23], eInit:[0.0100], init state:[ 2  6 38  0  0  0  0  0], end state:[ 4  6 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 875, score:[2800.80], loss:[1.18001], sequence:[37], random actions:[22], eInit:[0.0100], init state:[ 5 16 39  0  0  0  0  0], end state:[ 0 16 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 876, score:[2822.40], loss:[1.02937], sequence:[38], random actions:[29], eInit:[0.0100], init state:[ 6 15 14  0  0  0  0  0], end state:[ 1 15 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 877, score:[2774.40], loss:[1.32659], sequence:[39], random actions:[48], eInit:[0.0100], init state:[ 6  2 29  0  0  0  0  0], end state:[ 1  2 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 878, score:[2816.00], loss:[1.20893], sequence:[40], random actions:[22], eInit:[0.0100], init state:[ 6 11 25  0  0  0  0  0], end state:[ 1 11 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 879, score:[2817.20], loss:[1.09255], sequence:[41], random actions:[26], eInit:[0.0100], init state:[ 1 18 33  0  0  0  0  0], end state:[ 3 18 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 880, score:[2790.00], loss:[1.03070], sequence:[42], random actions:[23], eInit:[0.0100], init state:[ 2 15  9  0  0  0  0  0], end state:[ 4 15  9  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 881, score:[2815.20], loss:[1.15171], sequence:[43], random actions:[32], eInit:[0.0100], init state:[ 2  2 31  0  0  0  0  0], end state:[ 4  2 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 882, score:[2769.20], loss:[1.16290], sequence:[44], random actions:[35], eInit:[0.0100], init state:[ 5 14 59  0  0  0  0  0], end state:[ 0 14 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 883, score:[2823.20], loss:[1.05679], sequence:[45], random actions:[31], eInit:[0.0100], init state:[ 1  6 46  0  0  0  0  0], end state:[ 3  6 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 884, score:[2728.00], loss:[1.17462], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 4 16 51  0  0  0  0  0], end state:[ 6 16 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 885, score:[2824.80], loss:[1.06049], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 4 11 29  1  1  0  0  0], end state:[ 6 11 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 886, score:[2825.20], loss:[1.06070], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 1 10 40  0  0  0  0  0], end state:[ 3 10 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 887, score:[2824.80], loss:[0.92150], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 6 22 37  1  0  0  0  0], end state:[ 1 22 37  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 888, score:[2832.00], loss:[0.98039], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 0  0 15  1  0  0  0  0], end state:[ 2  0 15  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 889, score:[2818.00], loss:[0.89322], sequence:[5], random actions:[34], eInit:[0.0100], init state:[ 0 13 26  0  0  0  0  0], end state:[ 2 13 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 890, score:[2809.60], loss:[0.95776], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 5  0 39  0  0  0  0  0], end state:[ 0  0 39  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 891, score:[2798.00], loss:[1.02728], sequence:[7], random actions:[27], eInit:[0.0100], init state:[4 3 7 0 0 0 0 0], end state:[6 3 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 892, score:[2792.80], loss:[0.94073], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 2 14 57  0  0  0  0  0], end state:[ 4 14 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 893, score:[2764.40], loss:[1.00329], sequence:[9], random actions:[27], eInit:[0.0100], init state:[ 3 21 56  1  0  0  0  0], end state:[ 5 21 56  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 894, score:[2806.80], loss:[1.17839], sequence:[10], random actions:[35], eInit:[0.0100], init state:[ 2  1 41  0  0  0  0  0], end state:[ 4  1 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 895, score:[2816.00], loss:[1.15208], sequence:[11], random actions:[36], eInit:[0.0100], init state:[ 6  6 43  0  0  0  0  0], end state:[ 1  6 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 896, score:[2834.80], loss:[0.94250], sequence:[12], random actions:[27], eInit:[0.0100], init state:[ 0 20 13  0  0  0  0  0], end state:[ 2 20 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 897, score:[2840.00], loss:[1.00627], sequence:[13], random actions:[26], eInit:[0.0100], init state:[ 0 22  4  1  0  0  0  0], end state:[ 2 22  4  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 898, score:[2814.40], loss:[1.01527], sequence:[14], random actions:[34], eInit:[0.0100], init state:[ 0 23  7  1  0  0  0  0], end state:[ 2 23  7  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 899, score:[2814.80], loss:[0.93845], sequence:[15], random actions:[26], eInit:[0.0100], init state:[ 0  5 46  0  0  0  0  0], end state:[ 2  5 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 900, score:[2830.40], loss:[0.93657], sequence:[16], random actions:[23], eInit:[0.0100], init state:[ 0  6 26  0  0  0  0  0], end state:[ 2  6 26  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 901, score:[2812.00], loss:[1.14295], sequence:[17], random actions:[27], eInit:[0.0100], init state:[ 1  7 43  0  0  0  0  0], end state:[ 3  7 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 902, score:[2774.00], loss:[0.99812], sequence:[18], random actions:[35], eInit:[0.0100], init state:[ 3  0 13  1  0  0  0  0], end state:[ 5  0 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 903, score:[2818.40], loss:[1.10678], sequence:[19], random actions:[26], eInit:[0.0100], init state:[ 0  5 49  0  0  0  0  0], end state:[ 2  5 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 904, score:[2816.00], loss:[1.20514], sequence:[20], random actions:[30], eInit:[0.0100], init state:[ 0 23 40  1  0  0  1  0], end state:[ 2 23 40  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 905, score:[2764.80], loss:[1.25930], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 5  1 11  0  0  0  0  0], end state:[ 0  1 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 906, score:[2829.20], loss:[1.10451], sequence:[22], random actions:[31], eInit:[0.0100], init state:[ 0 11 37  0  0  0  0  0], end state:[ 2 11 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 907, score:[2779.60], loss:[1.26937], sequence:[23], random actions:[30], eInit:[0.0100], init state:[ 4 21 54  0  0  0  0  0], end state:[ 6 21 54  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 908, score:[2842.80], loss:[1.08546], sequence:[24], random actions:[23], eInit:[0.0100], init state:[ 2  9 33  0  0  0  0  0], end state:[ 4  9 33  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 909, score:[2800.80], loss:[1.11382], sequence:[25], random actions:[21], eInit:[0.0100], init state:[4 2 4 0 0 0 0 0], end state:[6 2 4 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 910, score:[2791.20], loss:[1.26011], sequence:[26], random actions:[37], eInit:[0.0100], init state:[ 3 15 28  0  0  0  0  0], end state:[ 5 15 28  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 911, score:[2797.60], loss:[1.12863], sequence:[27], random actions:[28], eInit:[0.0100], init state:[ 3 22  8  1  0  0  0  0], end state:[ 5 22  8  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 912, score:[2794.80], loss:[1.14094], sequence:[28], random actions:[26], eInit:[0.0100], init state:[ 1 12 10  0  0  0  0  0], end state:[ 3 12 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 913, score:[2814.80], loss:[1.21572], sequence:[29], random actions:[33], eInit:[0.0100], init state:[ 6 14 36  0  0  0  0  0], end state:[ 1 14 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 914, score:[2815.60], loss:[0.93565], sequence:[30], random actions:[29], eInit:[0.0100], init state:[ 0  4 47  0  0  0  0  0], end state:[ 2  4 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 915, score:[2799.20], loss:[0.94666], sequence:[31], random actions:[29], eInit:[0.0100], init state:[ 3 11 34  0  0  0  0  0], end state:[ 5 11 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 916, score:[2794.00], loss:[0.99852], sequence:[32], random actions:[23], eInit:[0.0100], init state:[ 4 13 49  0  0  0  0  0], end state:[ 6 13 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 917, score:[2751.20], loss:[1.19894], sequence:[33], random actions:[30], eInit:[0.0100], init state:[ 2 18 29  0  0  0  0  0], end state:[ 4 18 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 918, score:[2842.00], loss:[1.35032], sequence:[34], random actions:[18], eInit:[0.0100], init state:[ 1 16 42  0  0  0  0  0], end state:[ 3 16 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 919, score:[2797.60], loss:[1.40194], sequence:[35], random actions:[29], eInit:[0.0100], init state:[ 6  0 26  1  0  0  0  0], end state:[ 1  0 26  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 920, score:[2799.20], loss:[1.46868], sequence:[36], random actions:[31], eInit:[0.0100], init state:[ 0  7 43  0  0  0  0  0], end state:[ 2  7 43  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 921, score:[2797.60], loss:[1.66910], sequence:[37], random actions:[34], eInit:[0.0100], init state:[ 3  4 17  0  0  0  0  0], end state:[ 5  4 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 922, score:[2762.40], loss:[1.51395], sequence:[38], random actions:[20], eInit:[0.0100], init state:[ 4 13 54  0  0  0  0  0], end state:[ 6 13 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 923, score:[2802.00], loss:[1.48150], sequence:[39], random actions:[35], eInit:[0.0100], init state:[ 5 18 23  1  1  0  1  0], end state:[ 0 18 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 924, score:[2832.80], loss:[1.27713], sequence:[40], random actions:[26], eInit:[0.0100], init state:[ 4 11 31  1  1  0  0  0], end state:[ 6 11 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 925, score:[2754.40], loss:[1.47960], sequence:[41], random actions:[28], eInit:[0.0100], init state:[ 5 12 35  0  0  0  0  0], end state:[ 0 12 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 926, score:[2830.00], loss:[1.39409], sequence:[42], random actions:[25], eInit:[0.0100], init state:[ 6  1 43  0  0  0  0  0], end state:[ 1  1 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 927, score:[2815.60], loss:[1.20615], sequence:[43], random actions:[23], eInit:[0.0100], init state:[ 2  7 53  0  0  0  0  0], end state:[ 4  7 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 928, score:[2785.60], loss:[1.29723], sequence:[44], random actions:[40], eInit:[0.0100], init state:[ 3 11 14  0  0  0  0  0], end state:[ 5 11 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 929, score:[2804.40], loss:[1.44616], sequence:[45], random actions:[29], eInit:[0.0100], init state:[ 3 16 36  0  0  0  0  0], end state:[ 5 16 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 930, score:[2814.00], loss:[1.53621], sequence:[46], random actions:[34], eInit:[0.0100], init state:[0 0 6 1 0 0 0 0], end state:[2 0 6 1 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 931, score:[2779.60], loss:[1.38746], sequence:[47], random actions:[36], eInit:[0.0100], init state:[5 7 4 0 0 0 0 0], end state:[0 7 4 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 932, score:[2822.40], loss:[1.31958], sequence:[48], random actions:[28], eInit:[0.0100], init state:[ 1 23  4  1  0  0  0  0], end state:[ 3 23  4  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 933, score:[2757.20], loss:[1.45181], sequence:[49], random actions:[27], eInit:[0.0100], init state:[ 2 19 42  0  0  0  0  0], end state:[ 4 19 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 934, score:[2816.00], loss:[1.47101], sequence:[50], random actions:[30], eInit:[0.0100], init state:[ 2  3 19  0  0  0  0  0], end state:[ 4  3 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 935, score:[2784.80], loss:[1.47499], sequence:[51], random actions:[26], eInit:[0.0100], init state:[ 4  7 13  0  0  0  0  0], end state:[ 6  7 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 936, score:[2801.60], loss:[1.37293], sequence:[52], random actions:[24], eInit:[0.0100], init state:[ 0 23 36  1  0  0  1  0], end state:[ 2 23 36  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 937, score:[2831.60], loss:[1.34275], sequence:[53], random actions:[24], eInit:[0.0100], init state:[ 1 16 21  0  0  0  0  0], end state:[ 3 16 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 938, score:[2835.60], loss:[1.16536], sequence:[54], random actions:[26], eInit:[0.0100], init state:[ 1  2 43  0  0  0  0  0], end state:[ 3  2 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 939, score:[2799.60], loss:[1.10594], sequence:[55], random actions:[25], eInit:[0.0100], init state:[ 5  4 21  0  0  0  0  0], end state:[ 0  4 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 940, score:[2820.80], loss:[1.15094], sequence:[56], random actions:[27], eInit:[0.0100], init state:[ 5 12 12  0  0  0  0  0], end state:[ 0 12 12  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 941, score:[2827.20], loss:[1.22329], sequence:[57], random actions:[24], eInit:[0.0100], init state:[ 0  5 29  0  0  0  0  0], end state:[ 2  5 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 942, score:[2818.80], loss:[1.15788], sequence:[58], random actions:[32], eInit:[0.0100], init state:[ 5 20 37  1  0  0  0  0], end state:[ 0 20 37  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 943, score:[2839.20], loss:[0.99350], sequence:[59], random actions:[22], eInit:[0.0100], init state:[ 0 10 20  0  0  0  0  0], end state:[ 2 10 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 944, score:[2825.20], loss:[1.09471], sequence:[60], random actions:[26], eInit:[0.0100], init state:[ 5 11  5  0  0  0  0  0], end state:[ 0 11  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 945, score:[2802.40], loss:[1.15157], sequence:[61], random actions:[23], eInit:[0.0100], init state:[ 5 15 43  0  0  0  0  0], end state:[ 0 15 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 946, score:[2795.20], loss:[1.10133], sequence:[62], random actions:[16], eInit:[0.0100], init state:[4 4 2 0 0 0 0 0], end state:[6 4 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 947, score:[2786.80], loss:[1.14903], sequence:[63], random actions:[33], eInit:[0.0100], init state:[ 0 23 42  1  0  0  1  0], end state:[ 2 23 42  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 948, score:[2824.00], loss:[1.09067], sequence:[64], random actions:[31], eInit:[0.0100], init state:[ 0  4 15  0  0  0  0  0], end state:[ 2  4 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 949, score:[2792.00], loss:[1.08545], sequence:[65], random actions:[24], eInit:[0.0100], init state:[ 3 13 36  0  0  0  0  0], end state:[ 5 13 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 950, score:[2804.40], loss:[1.02941], sequence:[66], random actions:[24], eInit:[0.0100], init state:[ 2 14  4  0  0  0  0  0], end state:[ 4 14  4  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 951, score:[2799.60], loss:[1.07191], sequence:[67], random actions:[31], eInit:[0.0100], init state:[ 5  2 10  0  0  0  0  0], end state:[ 0  2 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 952, score:[2771.20], loss:[0.97679], sequence:[68], random actions:[21], eInit:[0.0100], init state:[ 5 12 36  0  0  0  0  0], end state:[ 0 12 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 953, score:[2799.60], loss:[0.93993], sequence:[69], random actions:[24], eInit:[0.0100], init state:[ 3  9 45  0  0  0  0  0], end state:[ 5  9 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 954, score:[2802.40], loss:[1.02243], sequence:[70], random actions:[31], eInit:[0.0100], init state:[ 1 23 13  1  0  0  0  0], end state:[ 3 23 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 955, score:[2804.40], loss:[1.02576], sequence:[71], random actions:[42], eInit:[0.0100], init state:[ 2  5 19  0  0  0  0  0], end state:[ 4  5 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 956, score:[2810.80], loss:[0.91078], sequence:[72], random actions:[35], eInit:[0.0100], init state:[ 1 23  7  1  0  0  0  0], end state:[ 3 23  7  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 957, score:[2751.60], loss:[0.94840], sequence:[73], random actions:[29], eInit:[0.0100], init state:[ 2 19 31  0  0  0  0  0], end state:[ 4 19 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 958, score:[2826.00], loss:[1.15519], sequence:[74], random actions:[21], eInit:[0.0100], init state:[ 6 17  6  0  0  0  0  0], end state:[ 1 17  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 959, score:[2832.80], loss:[0.82089], sequence:[75], random actions:[31], eInit:[0.0100], init state:[ 0 12 52  0  0  0  0  0], end state:[ 2 12 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 960, score:[2787.20], loss:[0.91624], sequence:[76], random actions:[32], eInit:[0.0100], init state:[ 3 15 45  0  0  0  0  0], end state:[ 5 15 45  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 961, score:[2791.20], loss:[0.96056], sequence:[77], random actions:[29], eInit:[0.0100], init state:[5 9 2 0 0 0 0 0], end state:[0 9 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 962, score:[2828.80], loss:[1.16512], sequence:[78], random actions:[24], eInit:[0.0100], init state:[ 6 10 10  0  0  0  0  0], end state:[ 1 10 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 963, score:[2805.60], loss:[0.92851], sequence:[79], random actions:[41], eInit:[0.0100], init state:[ 1 16 11  0  0  0  0  0], end state:[ 3 16 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 964, score:[2768.40], loss:[1.00259], sequence:[80], random actions:[34], eInit:[0.0100], init state:[ 2 17 47  0  0  0  0  0], end state:[ 4 17 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 965, score:[2810.40], loss:[0.97431], sequence:[81], random actions:[34], eInit:[0.0100], init state:[ 6 19 29  0  0  0  0  0], end state:[ 1 19 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 966, score:[2750.40], loss:[1.58925], sequence:[82], random actions:[37], eInit:[0.0100], init state:[ 3 15  7  0  0  0  0  0], end state:[ 5 15  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 967, score:[2829.20], loss:[1.32372], sequence:[83], random actions:[31], eInit:[0.0100], init state:[ 2 10  0  0  0  0  0  0], end state:[ 4 10  0  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 968, score:[2812.80], loss:[1.07102], sequence:[84], random actions:[20], eInit:[0.0100], init state:[ 0  9 47  0  0  0  0  0], end state:[ 2  9 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 969, score:[2730.80], loss:[1.17376], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5  8 44  0  0  0  0  0], end state:[ 0  8 44  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 970, score:[2806.00], loss:[1.08364], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1  8 25  1  0  0  0  0], end state:[ 3  8 25  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 971, score:[2800.80], loss:[1.04224], sequence:[2], random actions:[34], eInit:[0.0100], init state:[1 5 3 0 0 0 0 0], end state:[3 5 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 972, score:[2781.20], loss:[1.23881], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 3  9 13  0  0  0  0  0], end state:[ 5  9 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 973, score:[2819.20], loss:[1.22464], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 4 21 39  0  0  0  0  0], end state:[ 6 21 39  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 974, score:[2791.60], loss:[1.40484], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 3 19  4  0  0  0  0  0], end state:[ 5 19  4  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 975, score:[2788.40], loss:[1.50454], sequence:[6], random actions:[36], eInit:[0.0100], init state:[ 5  2 25  0  0  0  0  0], end state:[ 0  2 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 976, score:[2798.80], loss:[1.41209], sequence:[7], random actions:[42], eInit:[0.0100], init state:[ 6 13 53  0  0  0  0  0], end state:[ 1 13 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 977, score:[2812.80], loss:[1.42307], sequence:[8], random actions:[21], eInit:[0.0100], init state:[ 6 14 13  0  0  0  0  0], end state:[ 1 14 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 978, score:[2794.40], loss:[1.28963], sequence:[9], random actions:[28], eInit:[0.0100], init state:[ 1  1 56  0  0  0  0  0], end state:[ 3  1 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 979, score:[2784.40], loss:[1.37868], sequence:[10], random actions:[29], eInit:[0.0100], init state:[ 5  9 28  0  0  0  0  0], end state:[ 0  9 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 980, score:[2804.00], loss:[1.63554], sequence:[11], random actions:[31], eInit:[0.0100], init state:[ 0  4 44  0  0  0  0  0], end state:[ 2  4 44  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 981, score:[2824.00], loss:[1.60876], sequence:[12], random actions:[25], eInit:[0.0100], init state:[5 9 3 0 0 0 0 0], end state:[0 9 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 982, score:[2824.00], loss:[1.40760], sequence:[13], random actions:[23], eInit:[0.0100], init state:[ 1 14 31  0  0  0  0  0], end state:[ 3 14 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 983, score:[2830.00], loss:[1.45119], sequence:[14], random actions:[28], eInit:[0.0100], init state:[ 1 19 28  0  0  0  0  0], end state:[ 3 19 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 984, score:[2814.00], loss:[1.16574], sequence:[15], random actions:[35], eInit:[0.0100], init state:[ 1 11 57  0  0  0  0  0], end state:[ 3 11 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 985, score:[2802.00], loss:[1.19213], sequence:[16], random actions:[40], eInit:[0.0100], init state:[ 1 11 39  0  0  0  0  0], end state:[ 3 11 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 986, score:[2820.40], loss:[1.13064], sequence:[17], random actions:[26], eInit:[0.0100], init state:[ 1  5 36  0  0  0  0  0], end state:[ 3  5 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 987, score:[2820.00], loss:[1.04671], sequence:[18], random actions:[30], eInit:[0.0100], init state:[ 2  3 54  0  0  0  0  0], end state:[ 4  3 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 988, score:[2771.20], loss:[1.29252], sequence:[19], random actions:[27], eInit:[0.0100], init state:[ 5 17 21  0  0  0  0  0], end state:[ 0 17 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 989, score:[2706.80], loss:[1.46336], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 19  2  0  0  0  0  0], end state:[ 5 19  2  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 990, score:[2820.00], loss:[1.39904], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1  0 21  1  0  0  0  0], end state:[ 3  0 21  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 991, score:[2819.60], loss:[1.20218], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 1 16 28  0  0  0  0  0], end state:[ 3 16 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 992, score:[2820.40], loss:[1.14607], sequence:[3], random actions:[33], eInit:[0.0100], init state:[ 1  7 49  0  0  0  0  0], end state:[ 3  7 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 993, score:[2823.20], loss:[1.03682], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 1 20 52  1  1  0  1  0], end state:[ 3 20 52  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 994, score:[2826.40], loss:[1.01522], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 1  8 13  1  0  0  0  0], end state:[ 3  8 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 995, score:[2839.60], loss:[0.95715], sequence:[6], random actions:[28], eInit:[0.0100], init state:[0 1 8 0 0 1 0 0], end state:[2 1 8 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 996, score:[2759.60], loss:[1.01686], sequence:[7], random actions:[28], eInit:[0.0100], init state:[ 4 22 36  0  0  0  0  0], end state:[ 6 22 36  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 997, score:[2800.80], loss:[0.86288], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 2 13 45  0  0  0  0  0], end state:[ 4 13 45  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 998, score:[2779.60], loss:[0.94861], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 4 21  0  0  0  0  0  0], end state:[ 6 21  0  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 999, score:[2804.80], loss:[1.04685], sequence:[10], random actions:[29], eInit:[0.0100], init state:[ 5 22  1  1  0  0  1  0], end state:[ 0 22  1  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1000, score:[2788.40], loss:[0.98837], sequence:[11], random actions:[35], eInit:[0.0100], init state:[ 2 11 57  0  0  0  0  0], end state:[ 4 11 57  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1001, score:[2840.80], loss:[0.93979], sequence:[12], random actions:[22], eInit:[0.0100], init state:[ 6 13 30  0  0  0  0  0], end state:[ 1 13 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1002, score:[2778.00], loss:[1.02026], sequence:[13], random actions:[41], eInit:[0.0100], init state:[ 5 18 39  1  1  0  1  0], end state:[ 0 18 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1003, score:[2776.80], loss:[1.11386], sequence:[14], random actions:[33], eInit:[0.0100], init state:[ 2 19 55  0  0  0  0  0], end state:[ 4 19 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1004, score:[2806.80], loss:[1.04431], sequence:[15], random actions:[24], eInit:[0.0100], init state:[2 3 8 0 0 0 0 0], end state:[4 3 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1005, score:[2834.00], loss:[0.93497], sequence:[16], random actions:[23], eInit:[0.0100], init state:[ 6 13 49  0  0  0  0  0], end state:[ 1 13 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1006, score:[2833.60], loss:[0.83869], sequence:[17], random actions:[32], eInit:[0.0100], init state:[ 0  7 29  0  0  0  0  0], end state:[ 2  7 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1007, score:[2838.40], loss:[0.84672], sequence:[18], random actions:[25], eInit:[0.0100], init state:[ 1  0 22  1  0  0  0  0], end state:[ 3  0 22  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1008, score:[2824.80], loss:[0.84332], sequence:[19], random actions:[27], eInit:[0.0100], init state:[ 5 19 13  1  0  0  1  0], end state:[ 0 19 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1009, score:[2819.60], loss:[0.85387], sequence:[20], random actions:[25], eInit:[0.0100], init state:[ 6  2 23  0  0  0  0  0], end state:[ 1  2 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1010, score:[2835.60], loss:[0.83626], sequence:[21], random actions:[26], eInit:[0.0100], init state:[ 0  9 54  0  0  0  0  0], end state:[ 2  9 54  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1011, score:[2815.60], loss:[0.85641], sequence:[22], random actions:[27], eInit:[0.0100], init state:[ 0 15 58  0  0  0  0  0], end state:[ 2 15 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1012, score:[2810.80], loss:[0.80852], sequence:[23], random actions:[34], eInit:[0.0100], init state:[ 1 23 43  1  0  0  1  0], end state:[ 3 23 43  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1013, score:[2819.20], loss:[0.78218], sequence:[24], random actions:[27], eInit:[0.0100], init state:[ 6 23 18  1  0  0  1  0], end state:[ 1 23 18  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1014, score:[2758.40], loss:[1.10019], sequence:[25], random actions:[31], eInit:[0.0100], init state:[ 3  8 37  1  1  0  1  0], end state:[ 5  8 37  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1015, score:[2810.00], loss:[1.05417], sequence:[26], random actions:[28], eInit:[0.0100], init state:[ 6  6 33  0  0  0  0  0], end state:[ 1  6 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1016, score:[2783.20], loss:[1.30981], sequence:[27], random actions:[21], eInit:[0.0100], init state:[ 3 21 23  1  1  0  1  0], end state:[ 5 21 23  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1017, score:[2812.00], loss:[1.23873], sequence:[28], random actions:[28], eInit:[0.0100], init state:[ 5 12 43  0  0  0  0  0], end state:[ 0 12 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1018, score:[2764.00], loss:[1.11768], sequence:[29], random actions:[29], eInit:[0.0100], init state:[ 3  8 16  1  0  0  0  0], end state:[ 5  8 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1019, score:[2821.20], loss:[1.06405], sequence:[30], random actions:[27], eInit:[0.0100], init state:[ 6 10 12  0  0  0  0  0], end state:[ 1 10 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1020, score:[2796.00], loss:[1.16538], sequence:[31], random actions:[26], eInit:[0.0100], init state:[ 3 14 20  0  0  0  0  0], end state:[ 5 14 20  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1021, score:[2818.80], loss:[1.16770], sequence:[32], random actions:[24], eInit:[0.0100], init state:[ 3  1 55  0  0  0  0  0], end state:[ 5  1 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1022, score:[2762.80], loss:[1.36815], sequence:[33], random actions:[21], eInit:[0.0100], init state:[ 5 16 29  0  0  0  0  0], end state:[ 0 16 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1023, score:[2787.60], loss:[1.30796], sequence:[34], random actions:[34], eInit:[0.0100], init state:[ 3 17 46  0  0  0  0  0], end state:[ 5 17 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1024, score:[2831.20], loss:[1.43290], sequence:[35], random actions:[28], eInit:[0.0100], init state:[ 0  5 16  0  0  0  0  0], end state:[ 2  5 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1025, score:[2827.60], loss:[1.18954], sequence:[36], random actions:[27], eInit:[0.0100], init state:[1 2 8 0 0 0 0 0], end state:[3 2 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1026, score:[2800.80], loss:[1.24054], sequence:[37], random actions:[36], eInit:[0.0100], init state:[ 3 11 26  0  0  0  0  0], end state:[ 5 11 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1027, score:[2806.00], loss:[1.28135], sequence:[38], random actions:[30], eInit:[0.0100], init state:[ 4 17 33  0  0  0  0  0], end state:[ 6 17 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1028, score:[2820.40], loss:[1.39784], sequence:[39], random actions:[29], eInit:[0.0100], init state:[ 3 14 32  0  0  0  0  0], end state:[ 5 14 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1029, score:[2819.20], loss:[1.34594], sequence:[40], random actions:[36], eInit:[0.0100], init state:[ 0 18 19  0  0  0  0  0], end state:[ 2 18 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1030, score:[2743.20], loss:[1.79942], sequence:[41], random actions:[34], eInit:[0.0100], init state:[ 5  3 29  0  0  0  0  0], end state:[ 0  3 29  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1031, score:[2820.80], loss:[1.56884], sequence:[42], random actions:[28], eInit:[0.0100], init state:[ 0  4 40  0  0  0  0  0], end state:[ 2  4 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1032, score:[2798.40], loss:[1.59362], sequence:[43], random actions:[27], eInit:[0.0100], init state:[ 4 11 36  1  1  0  0  0], end state:[ 6 11 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1033, score:[2790.80], loss:[1.76397], sequence:[44], random actions:[21], eInit:[0.0100], init state:[ 2 16 31  0  0  0  0  0], end state:[ 4 16 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1034, score:[2805.20], loss:[1.58232], sequence:[45], random actions:[34], eInit:[0.0100], init state:[ 0 14  6  0  0  0  0  0], end state:[ 2 14  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1035, score:[2781.60], loss:[1.75305], sequence:[46], random actions:[28], eInit:[0.0100], init state:[ 4 22 10  0  0  0  0  0], end state:[ 6 22 10  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1036, score:[2837.60], loss:[1.49686], sequence:[47], random actions:[26], eInit:[0.0100], init state:[ 3 15 35  0  0  0  0  0], end state:[ 5 15 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1037, score:[2807.60], loss:[1.30073], sequence:[48], random actions:[30], eInit:[0.0100], init state:[ 0 13 27  0  0  0  0  0], end state:[ 2 13 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1038, score:[2832.00], loss:[1.34642], sequence:[49], random actions:[22], eInit:[0.0100], init state:[ 6 23 36  1  0  0  1  0], end state:[ 1 23 36  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1039, score:[2776.00], loss:[1.47748], sequence:[50], random actions:[32], eInit:[0.0100], init state:[ 5  5 47  0  0  0  0  0], end state:[ 0  5 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1040, score:[2822.00], loss:[1.31258], sequence:[51], random actions:[33], eInit:[0.0100], init state:[1 0 8 1 0 0 0 0], end state:[3 0 8 1 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1041, score:[2775.60], loss:[1.32305], sequence:[52], random actions:[33], eInit:[0.0100], init state:[ 5  1 56  0  0  0  0  0], end state:[ 0  1 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1042, score:[2805.60], loss:[1.47207], sequence:[53], random actions:[28], eInit:[0.0100], init state:[ 2 12 18  0  0  0  0  0], end state:[ 4 12 18  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1043, score:[2823.20], loss:[1.44187], sequence:[54], random actions:[25], eInit:[0.0100], init state:[ 0 16 51  0  0  0  0  0], end state:[ 2 16 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1044, score:[2790.40], loss:[1.42528], sequence:[55], random actions:[25], eInit:[0.0100], init state:[ 5  1 24  0  0  0  0  0], end state:[ 0  1 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1045, score:[2836.00], loss:[1.31260], sequence:[56], random actions:[19], eInit:[0.0100], init state:[ 1 21  7  1  1  0  1  1], end state:[ 3 21  7  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 1046, score:[2814.40], loss:[1.34591], sequence:[57], random actions:[33], eInit:[0.0100], init state:[3 7 0 0 0 0 0 0], end state:[5 7 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1047, score:[2826.40], loss:[1.18682], sequence:[58], random actions:[19], eInit:[0.0100], init state:[ 6 21 46  1  0  0  0  0], end state:[ 1 21 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1048, score:[2798.00], loss:[1.34212], sequence:[59], random actions:[28], eInit:[0.0100], init state:[ 5  6 19  0  0  0  0  0], end state:[ 0  6 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1049, score:[2837.60], loss:[1.22959], sequence:[60], random actions:[23], eInit:[0.0100], init state:[ 2 12 39  0  0  0  0  0], end state:[ 4 12 39  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1050, score:[2802.80], loss:[1.25691], sequence:[61], random actions:[35], eInit:[0.0100], init state:[ 2 17 50  0  0  0  0  0], end state:[ 4 17 50  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1051, score:[2821.20], loss:[1.18437], sequence:[62], random actions:[34], eInit:[0.0100], init state:[ 3 15 25  0  0  0  0  0], end state:[ 5 15 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1052, score:[2702.00], loss:[1.45643], sequence:[0], random actions:[37], eInit:[0.0100], init state:[ 5 15 37  0  0  0  0  0], end state:[ 0 15 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1053, score:[2766.00], loss:[1.46143], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 4  4 45  0  0  0  0  0], end state:[ 6  4 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1054, score:[2799.60], loss:[1.42666], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 2 17 46  0  0  0  0  0], end state:[ 4 17 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1055, score:[2822.00], loss:[1.35636], sequence:[3], random actions:[15], eInit:[0.0100], init state:[ 2 20 39  1  1  0  0  0], end state:[ 4 20 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1056, score:[2833.60], loss:[1.27200], sequence:[4], random actions:[21], eInit:[0.0100], init state:[ 1 13 39  0  0  0  0  0], end state:[ 3 13 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1057, score:[2795.20], loss:[1.35804], sequence:[5], random actions:[36], eInit:[0.0100], init state:[ 2 23 10  1  0  0  0  0], end state:[ 4 23 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1058, score:[2794.80], loss:[1.46487], sequence:[6], random actions:[38], eInit:[0.0100], init state:[ 3 13 32  0  0  0  0  0], end state:[ 5 13 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1059, score:[2814.40], loss:[1.44685], sequence:[7], random actions:[34], eInit:[0.0100], init state:[2 9 9 0 0 0 0 0], end state:[4 9 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1060, score:[2792.80], loss:[1.49062], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 6 18 33  0  0  0  0  0], end state:[ 1 18 33  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1061, score:[2792.40], loss:[1.58290], sequence:[9], random actions:[33], eInit:[0.0100], init state:[5 0 3 0 0 0 0 0], end state:[0 0 3 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1062, score:[2796.40], loss:[1.45513], sequence:[10], random actions:[37], eInit:[0.0100], init state:[ 2  0 16  1  0  0  0  0], end state:[ 4  0 16  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1063, score:[2782.80], loss:[1.53698], sequence:[11], random actions:[31], eInit:[0.0100], init state:[5 8 2 0 0 0 0 0], end state:[0 8 2 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1064, score:[2833.60], loss:[1.29535], sequence:[12], random actions:[28], eInit:[0.0100], init state:[ 0 17 30  0  0  0  0  0], end state:[ 2 17 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1065, score:[2831.20], loss:[1.25329], sequence:[13], random actions:[30], eInit:[0.0100], init state:[ 2  8 18  1  0  0  0  0], end state:[ 4  8 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1066, score:[2796.80], loss:[1.47132], sequence:[14], random actions:[23], eInit:[0.0100], init state:[ 3 21 26  1  1  0  1  0], end state:[ 5 21 26  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1067, score:[2805.60], loss:[1.40801], sequence:[15], random actions:[33], eInit:[0.0100], init state:[ 6 19 51  0  0  0  0  0], end state:[ 1 19 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1068, score:[2825.20], loss:[1.39389], sequence:[16], random actions:[36], eInit:[0.0100], init state:[0 8 4 1 0 0 0 0], end state:[2 8 4 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1069, score:[2815.60], loss:[1.26522], sequence:[17], random actions:[38], eInit:[0.0100], init state:[ 1  8 45  1  1  0  0  0], end state:[ 3  8 45  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1070, score:[2803.60], loss:[1.20291], sequence:[18], random actions:[33], eInit:[0.0100], init state:[ 6 21 48  1  0  0  0  0], end state:[ 1 21 48  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1071, score:[2790.80], loss:[1.40739], sequence:[19], random actions:[27], eInit:[0.0100], init state:[ 4  5 42  0  0  0  0  0], end state:[ 6  5 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1072, score:[2808.80], loss:[1.38513], sequence:[20], random actions:[30], eInit:[0.0100], init state:[ 6 18  4  0  0  0  0  0], end state:[ 1 18  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1073, score:[2796.80], loss:[1.52139], sequence:[21], random actions:[31], eInit:[0.0100], init state:[ 1 19 35  0  0  0  0  0], end state:[ 3 19 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1074, score:[2787.60], loss:[1.37807], sequence:[22], random actions:[27], eInit:[0.0100], init state:[ 4  4 38  0  0  0  0  0], end state:[ 6  4 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1075, score:[2770.00], loss:[1.68932], sequence:[23], random actions:[31], eInit:[0.0100], init state:[ 4 19 26  0  0  0  0  0], end state:[ 6 19 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1076, score:[2804.00], loss:[1.62722], sequence:[24], random actions:[28], eInit:[0.0100], init state:[ 0 23  8  1  0  0  0  0], end state:[ 2 23  8  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1077, score:[2819.60], loss:[1.51344], sequence:[25], random actions:[30], eInit:[0.0100], init state:[ 1 20 49  1  1  0  1  0], end state:[ 3 20 49  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1078, score:[2787.20], loss:[1.44621], sequence:[26], random actions:[35], eInit:[0.0100], init state:[ 2 15  2  0  0  0  0  0], end state:[ 4 15  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1079, score:[2839.20], loss:[1.69926], sequence:[27], random actions:[20], eInit:[0.0100], init state:[ 0  5 44  0  0  0  0  0], end state:[ 2  5 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1080, score:[2789.60], loss:[1.59072], sequence:[28], random actions:[29], eInit:[0.0100], init state:[ 3 21 43  1  0  0  0  0], end state:[ 5 21 43  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1081, score:[2822.00], loss:[1.68711], sequence:[29], random actions:[20], eInit:[0.0100], init state:[ 3 10 19  0  0  0  0  0], end state:[ 5 10 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1082, score:[2812.40], loss:[1.64568], sequence:[30], random actions:[32], eInit:[0.0100], init state:[ 0 10 30  0  0  0  0  0], end state:[ 2 10 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1083, score:[2806.00], loss:[1.63589], sequence:[31], random actions:[33], eInit:[0.0100], init state:[ 5 22 35  1  0  0  1  0], end state:[ 0 22 35  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1084, score:[2792.00], loss:[1.46909], sequence:[32], random actions:[29], eInit:[0.0100], init state:[ 3  5 32  0  0  0  0  0], end state:[ 5  5 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1085, score:[2812.80], loss:[1.37125], sequence:[33], random actions:[32], eInit:[0.0100], init state:[ 2 23 42  1  0  0  1  0], end state:[ 4 23 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1086, score:[2842.40], loss:[1.33449], sequence:[34], random actions:[26], eInit:[0.0100], init state:[ 3 14 16  0  0  0  0  0], end state:[ 5 14 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1087, score:[2779.60], loss:[1.41758], sequence:[35], random actions:[31], eInit:[0.0100], init state:[ 4 21 15  0  0  0  0  0], end state:[ 6 21 15  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1088, score:[2759.60], loss:[1.44162], sequence:[36], random actions:[34], eInit:[0.0100], init state:[ 4  2 47  0  0  0  0  0], end state:[ 6  2 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1089, score:[2807.20], loss:[1.34184], sequence:[37], random actions:[29], eInit:[0.0100], init state:[ 1 17 39  0  0  0  0  0], end state:[ 3 17 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1090, score:[2819.60], loss:[1.31284], sequence:[38], random actions:[28], eInit:[0.0100], init state:[ 4  6 46  0  0  0  0  0], end state:[ 6  6 46  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1091, score:[2795.20], loss:[1.30153], sequence:[39], random actions:[27], eInit:[0.0100], init state:[ 2  0 16  1  0  0  0  0], end state:[ 4  0 16  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1092, score:[2830.00], loss:[1.17321], sequence:[40], random actions:[32], eInit:[0.0100], init state:[ 1  6 33  0  0  0  0  0], end state:[ 3  6 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1093, score:[2825.60], loss:[1.04568], sequence:[41], random actions:[29], eInit:[0.0100], init state:[ 0 20 43  1  1  0  0  0], end state:[ 2 20 43  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1094, score:[2730.00], loss:[1.22873], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 3 23 10  1  0  0  0  0], end state:[ 5 23 10  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1095, score:[2826.00], loss:[1.37223], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 1  7 18  0  0  0  0  0], end state:[ 3  7 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1096, score:[2817.60], loss:[1.34458], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3  0 11  1  0  0  0  0], end state:[ 5  0 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1097, score:[2828.00], loss:[1.38275], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 0 15 52  0  0  0  0  0], end state:[ 2 15 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1098, score:[2836.40], loss:[1.42195], sequence:[4], random actions:[18], eInit:[0.0100], init state:[ 0 19 38  0  0  0  0  0], end state:[ 2 19 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1099, score:[2816.00], loss:[1.33917], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 0  0 25  1  0  0  0  0], end state:[ 2  0 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1100, score:[2800.40], loss:[1.41296], sequence:[6], random actions:[28], eInit:[0.0100], init state:[ 4 13 16  1  1  0  0  0], end state:[ 6 13 16  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1101, score:[2798.80], loss:[1.75748], sequence:[7], random actions:[34], eInit:[0.0100], init state:[ 4  1 51  0  0  0  0  0], end state:[ 6  1 51  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1102, score:[2824.00], loss:[1.52829], sequence:[8], random actions:[33], eInit:[0.0100], init state:[ 4  7 51  0  0  0  0  0], end state:[ 6  7 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1103, score:[2819.60], loss:[1.40224], sequence:[9], random actions:[28], eInit:[0.0100], init state:[1 8 4 1 0 0 0 0], end state:[3 8 4 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1104, score:[2757.60], loss:[1.79850], sequence:[10], random actions:[34], eInit:[0.0100], init state:[ 6  2 51  0  0  0  0  0], end state:[ 1  2 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1105, score:[2801.60], loss:[1.61715], sequence:[11], random actions:[35], eInit:[0.0100], init state:[ 2  8 56  1  1  0  0  0], end state:[ 4  8 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1106, score:[2820.80], loss:[1.39393], sequence:[12], random actions:[26], eInit:[0.0100], init state:[4 7 5 0 0 0 0 0], end state:[6 7 5 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1107, score:[2806.80], loss:[1.43437], sequence:[13], random actions:[30], eInit:[0.0100], init state:[ 3 20  4  0  0  0  0  0], end state:[ 5 20  4  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1108, score:[2817.20], loss:[1.18465], sequence:[14], random actions:[31], eInit:[0.0100], init state:[ 1  1 47  0  0  0  0  0], end state:[ 3  1 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1109, score:[2815.60], loss:[1.35684], sequence:[15], random actions:[23], eInit:[0.0100], init state:[3 4 2 0 0 0 0 0], end state:[5 4 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1110, score:[2821.20], loss:[1.16769], sequence:[16], random actions:[26], eInit:[0.0100], init state:[ 3  1 32  0  0  0  0  0], end state:[ 5  1 32  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1111, score:[2790.40], loss:[1.64180], sequence:[17], random actions:[22], eInit:[0.0100], init state:[ 6 19 33  0  0  0  0  0], end state:[ 1 19 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1112, score:[2832.00], loss:[1.28066], sequence:[18], random actions:[27], eInit:[0.0100], init state:[ 2 22 13  1  0  0  0  0], end state:[ 4 22 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1113, score:[2769.20], loss:[1.55250], sequence:[19], random actions:[33], eInit:[0.0100], init state:[ 5 21 52  1  0  0  1  0], end state:[ 0 21 52  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1114, score:[2836.80], loss:[1.49405], sequence:[20], random actions:[21], eInit:[0.0100], init state:[ 0 18 35  0  0  0  0  0], end state:[ 2 18 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1115, score:[2751.60], loss:[1.53845], sequence:[21], random actions:[31], eInit:[0.0100], init state:[ 4 12 38  1  1  0  0  0], end state:[ 6 12 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1116, score:[2804.00], loss:[1.66900], sequence:[22], random actions:[35], eInit:[0.0100], init state:[6 1 7 0 0 1 0 0], end state:[1 1 7 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 1117, score:[2754.80], loss:[1.89766], sequence:[23], random actions:[29], eInit:[0.0100], init state:[ 5 12 17  0  0  0  0  0], end state:[ 0 12 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1118, score:[2813.20], loss:[1.87490], sequence:[24], random actions:[32], eInit:[0.0100], init state:[ 6 17 45  0  0  0  0  0], end state:[ 1 17 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1119, score:[2819.60], loss:[1.69338], sequence:[25], random actions:[25], eInit:[0.0100], init state:[ 3  3 47  0  0  0  0  0], end state:[ 5  3 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1120, score:[2834.00], loss:[1.61974], sequence:[26], random actions:[22], eInit:[0.0100], init state:[ 5 14 45  0  0  0  0  0], end state:[ 0 14 45  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1121, score:[2818.00], loss:[1.64257], sequence:[27], random actions:[33], eInit:[0.0100], init state:[ 2  4 27  0  0  0  0  0], end state:[ 4  4 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1122, score:[2812.80], loss:[1.52935], sequence:[28], random actions:[29], eInit:[0.0100], init state:[ 3  3 28  0  0  0  0  0], end state:[ 5  3 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1123, score:[2804.80], loss:[1.75382], sequence:[29], random actions:[15], eInit:[0.0100], init state:[ 5 23  3  1  0  0  1  0], end state:[ 0 23  3  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1124, score:[2813.20], loss:[1.60760], sequence:[30], random actions:[24], eInit:[0.0100], init state:[ 5 18 20  1  1  0  1  0], end state:[ 0 18 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1125, score:[2821.20], loss:[1.48323], sequence:[31], random actions:[24], eInit:[0.0100], init state:[ 6 15  0  0  0  0  0  0], end state:[ 1 15  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1126, score:[2788.40], loss:[1.54393], sequence:[32], random actions:[24], eInit:[0.0100], init state:[ 4 11 34  1  1  0  0  0], end state:[ 6 11 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1127, score:[2814.80], loss:[1.74446], sequence:[33], random actions:[32], eInit:[0.0100], init state:[ 1 15 54  0  0  0  0  0], end state:[ 3 15 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1128, score:[2822.80], loss:[1.44613], sequence:[34], random actions:[24], eInit:[0.0100], init state:[ 0 20 38  1  1  0  0  0], end state:[ 2 20 38  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1129, score:[2779.60], loss:[1.45308], sequence:[35], random actions:[36], eInit:[0.0100], init state:[ 2 23  5  1  0  0  0  0], end state:[ 4 23  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1130, score:[2816.80], loss:[1.31904], sequence:[36], random actions:[22], eInit:[0.0100], init state:[ 4 17 46  0  0  0  0  0], end state:[ 6 17 46  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1131, score:[2802.40], loss:[1.21150], sequence:[37], random actions:[30], eInit:[0.0100], init state:[ 3 17 48  0  0  0  0  0], end state:[ 5 17 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1132, score:[2790.00], loss:[1.45559], sequence:[38], random actions:[29], eInit:[0.0100], init state:[ 6 10 39  0  0  0  0  0], end state:[ 1 10 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1133, score:[2787.60], loss:[1.38414], sequence:[39], random actions:[34], eInit:[0.0100], init state:[ 4 20 11  0  0  0  0  0], end state:[ 6 20 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1134, score:[2795.60], loss:[1.62647], sequence:[40], random actions:[30], eInit:[0.0100], init state:[ 6  9 15  0  0  0  0  0], end state:[ 1  9 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1135, score:[2830.80], loss:[1.40204], sequence:[41], random actions:[27], eInit:[0.0100], init state:[ 1 18 49  0  0  0  0  0], end state:[ 3 18 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1136, score:[2812.80], loss:[1.32865], sequence:[42], random actions:[25], eInit:[0.0100], init state:[ 3  1 27  0  0  0  0  0], end state:[ 5  1 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1137, score:[2794.00], loss:[1.24099], sequence:[43], random actions:[34], eInit:[0.0100], init state:[ 6  0 39  0  0  1  0  0], end state:[ 1  0 39  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1138, score:[2728.80], loss:[1.52432], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 10  4  1  1  0  1  0], end state:[ 6 10  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1139, score:[2808.80], loss:[1.80870], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 6 17 21  0  0  0  0  0], end state:[ 1 17 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1140, score:[2828.80], loss:[1.48655], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 1  2 21  0  0  0  0  0], end state:[ 3  2 21  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1141, score:[2808.80], loss:[1.43756], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 6  5 38  0  0  0  0  0], end state:[ 1  5 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1142, score:[2798.40], loss:[1.49796], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 0 22 44  1  0  0  0  0], end state:[ 2 22 44  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1143, score:[2800.40], loss:[1.58745], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 6 15 29  0  0  0  0  0], end state:[ 1 15 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1144, score:[2805.20], loss:[1.69352], sequence:[6], random actions:[47], eInit:[0.0100], init state:[ 1  0 56  0  0  1  0  0], end state:[ 3  0 56  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1145, score:[2804.40], loss:[1.65755], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 0  1 19  0  0  0  0  0], end state:[ 2  1 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1146, score:[2768.80], loss:[1.85505], sequence:[8], random actions:[35], eInit:[0.0100], init state:[ 6  0 56  0  0  1  0  0], end state:[ 1  0 56  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1147, score:[2819.20], loss:[1.61369], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 1  6 21  0  0  0  0  0], end state:[ 3  6 21  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1148, score:[2688.40], loss:[2.05287], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 4 10 11  1  1  0  1  1], end state:[ 6 10 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1149, score:[2745.20], loss:[2.04443], sequence:[1], random actions:[37], eInit:[0.0100], init state:[ 3  2 13  0  0  0  0  0], end state:[ 5  2 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1150, score:[2835.20], loss:[1.78940], sequence:[2], random actions:[28], eInit:[0.0100], init state:[ 0 22  7  1  0  0  0  0], end state:[ 2 22  7  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1151, score:[2802.40], loss:[1.42469], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1 11 21  0  0  0  0  0], end state:[ 3 11 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1152, score:[2777.60], loss:[1.52026], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 3  8 31  1  1  0  1  1], end state:[ 5  8 31  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 1153, score:[2818.80], loss:[1.38496], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 2 22 13  1  0  0  0  0], end state:[ 4 22 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1154, score:[2769.60], loss:[1.55933], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 1 21 25  1  1  0  1  0], end state:[ 3 21 25  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1155, score:[2810.40], loss:[1.76920], sequence:[7], random actions:[25], eInit:[0.0100], init state:[6 8 5 1 0 0 0 0], end state:[1 8 5 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1156, score:[2833.20], loss:[1.35498], sequence:[8], random actions:[24], eInit:[0.0100], init state:[ 1 21 16  1  1  0  1  0], end state:[ 3 21 16  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1157, score:[2740.80], loss:[1.70484], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 5  1 15  0  0  0  0  0], end state:[ 0  1 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1158, score:[2823.60], loss:[1.37890], sequence:[10], random actions:[28], eInit:[0.0100], init state:[ 0 21  7  1  1  0  1  1], end state:[ 2 21  7  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 1159, score:[2758.00], loss:[1.48602], sequence:[11], random actions:[33], eInit:[0.0100], init state:[ 4  4 23  0  0  0  0  0], end state:[ 6  4 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1160, score:[2793.60], loss:[1.59651], sequence:[12], random actions:[31], eInit:[0.0100], init state:[ 2 18 18  0  0  0  0  0], end state:[ 4 18 18  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1161, score:[2816.80], loss:[1.58083], sequence:[13], random actions:[35], eInit:[0.0100], init state:[ 0 23 54  1  0  0  0  0], end state:[ 2 23 54  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1162, score:[2806.00], loss:[1.37453], sequence:[14], random actions:[29], eInit:[0.0100], init state:[ 1  2 24  0  0  0  0  0], end state:[ 3  2 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1163, score:[2832.40], loss:[1.21250], sequence:[15], random actions:[19], eInit:[0.0100], init state:[ 2 18 21  0  0  0  0  0], end state:[ 4 18 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1164, score:[2798.40], loss:[1.15679], sequence:[16], random actions:[29], eInit:[0.0100], init state:[ 2 20 10  0  0  0  0  0], end state:[ 4 20 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1165, score:[2769.20], loss:[1.51160], sequence:[17], random actions:[36], eInit:[0.0100], init state:[ 5  7 54  0  0  0  0  0], end state:[ 0  7 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1166, score:[2832.00], loss:[1.28527], sequence:[18], random actions:[24], eInit:[0.0100], init state:[ 0 21 35  1  0  0  0  0], end state:[ 2 21 35  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1167, score:[2731.20], loss:[1.67412], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5 12  7  0  0  0  0  0], end state:[ 0 12  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1168, score:[2828.40], loss:[1.65418], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3  1 43  0  0  0  0  0], end state:[ 5  1 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1169, score:[2806.80], loss:[1.53174], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 6 23  6  1  0  0  0  0], end state:[ 1 23  6  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1170, score:[2825.60], loss:[1.34522], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 0  7 38  0  0  0  0  0], end state:[ 2  7 38  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1171, score:[2812.00], loss:[1.33553], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 2 23 16  1  0  0  1  0], end state:[ 4 23 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1172, score:[2800.00], loss:[1.40593], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 5 11  4  0  0  0  0  0], end state:[ 0 11  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1173, score:[2821.20], loss:[1.30285], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 2  1 30  0  0  0  0  0], end state:[ 4  1 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1174, score:[2820.00], loss:[1.21355], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 3 21 37  1  0  0  0  0], end state:[ 5 21 37  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1175, score:[2824.40], loss:[1.13110], sequence:[8], random actions:[30], eInit:[0.0100], init state:[ 2  8 17  1  0  0  0  0], end state:[ 4  8 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1176, score:[2840.00], loss:[1.03861], sequence:[9], random actions:[22], eInit:[0.0100], init state:[ 0 13  9  0  0  0  0  0], end state:[ 2 13  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1177, score:[2786.00], loss:[1.37866], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 4  4 18  0  0  0  0  0], end state:[ 6  4 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1178, score:[2810.00], loss:[1.41431], sequence:[11], random actions:[26], eInit:[0.0100], init state:[ 6 20 12  0  0  0  0  0], end state:[ 1 20 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1179, score:[2818.80], loss:[1.22935], sequence:[12], random actions:[38], eInit:[0.0100], init state:[ 0 11  7  0  0  0  0  0], end state:[ 2 11  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1180, score:[2798.80], loss:[1.36223], sequence:[13], random actions:[26], eInit:[0.0100], init state:[ 3 23 20  1  0  0  1  0], end state:[ 5 23 20  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1181, score:[2832.00], loss:[1.28618], sequence:[14], random actions:[25], eInit:[0.0100], init state:[ 2  7 50  0  0  0  0  0], end state:[ 4  7 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1182, score:[2818.00], loss:[1.13668], sequence:[15], random actions:[34], eInit:[0.0100], init state:[ 1  3 56  0  0  0  0  0], end state:[ 3  3 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1183, score:[2776.00], loss:[1.65874], sequence:[16], random actions:[27], eInit:[0.0100], init state:[ 3 22  1  1  0  0  0  0], end state:[ 5 22  1  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1184, score:[2834.00], loss:[1.50611], sequence:[17], random actions:[19], eInit:[0.0100], init state:[ 2  1 46  0  0  0  0  0], end state:[ 4  1 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1185, score:[2771.20], loss:[1.54392], sequence:[18], random actions:[32], eInit:[0.0100], init state:[ 5  1 21  0  0  0  0  0], end state:[ 0  1 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1186, score:[2837.60], loss:[1.30629], sequence:[19], random actions:[23], eInit:[0.0100], init state:[ 3 16 27  0  0  0  0  0], end state:[ 5 16 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1187, score:[2837.60], loss:[1.26036], sequence:[20], random actions:[19], eInit:[0.0100], init state:[1 2 1 0 0 0 0 0], end state:[3 2 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1188, score:[2798.40], loss:[1.30583], sequence:[21], random actions:[31], eInit:[0.0100], init state:[ 4  0 10  1  0  0  0  0], end state:[ 6  0 10  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1189, score:[2766.80], loss:[1.58147], sequence:[22], random actions:[33], eInit:[0.0100], init state:[ 6 18 58  0  0  0  0  0], end state:[ 1 18 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1190, score:[2832.40], loss:[1.29724], sequence:[23], random actions:[29], eInit:[0.0100], init state:[ 3 17 17  0  0  0  0  0], end state:[ 5 17 17  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1191, score:[2806.80], loss:[1.28210], sequence:[24], random actions:[28], eInit:[0.0100], init state:[ 4 14 11  0  0  0  0  0], end state:[ 6 14 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1192, score:[2824.80], loss:[1.14368], sequence:[25], random actions:[35], eInit:[0.0100], init state:[ 2  8 48  1  1  0  0  0], end state:[ 4  8 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1193, score:[2780.40], loss:[1.30864], sequence:[26], random actions:[36], eInit:[0.0100], init state:[ 4  0 29  1  0  0  0  0], end state:[ 6  0 29  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1194, score:[2794.80], loss:[1.40324], sequence:[27], random actions:[34], eInit:[0.0100], init state:[ 0 20 36  1  1  0  0  0], end state:[ 2 20 36  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1195, score:[2795.20], loss:[1.37328], sequence:[28], random actions:[26], eInit:[0.0100], init state:[ 5 22 55  1  0  0  1  0], end state:[ 0 22 55  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1196, score:[2805.20], loss:[1.25359], sequence:[29], random actions:[28], eInit:[0.0100], init state:[ 5 19 52  1  0  0  1  0], end state:[ 0 19 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1197, score:[2811.20], loss:[1.29731], sequence:[30], random actions:[27], eInit:[0.0100], init state:[ 5  2 40  0  0  0  0  0], end state:[ 0  2 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1198, score:[2778.80], loss:[1.56660], sequence:[31], random actions:[33], eInit:[0.0100], init state:[ 5  8 18  0  0  0  0  0], end state:[ 0  8 18  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1199, score:[2808.40], loss:[1.48865], sequence:[32], random actions:[36], eInit:[0.0100], init state:[ 1  1 26  0  0  0  0  0], end state:[ 3  1 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1200, score:[2826.80], loss:[1.41461], sequence:[33], random actions:[29], eInit:[0.0100], init state:[ 3  1 46  0  0  0  0  0], end state:[ 5  1 46  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1201, score:[2822.80], loss:[1.23385], sequence:[34], random actions:[30], eInit:[0.0100], init state:[ 6 23 32  1  0  0  1  0], end state:[ 1 23 32  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1202, score:[2777.20], loss:[1.47230], sequence:[35], random actions:[34], eInit:[0.0100], init state:[ 5  6 40  0  0  0  0  0], end state:[ 0  6 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1203, score:[2824.80], loss:[1.31065], sequence:[36], random actions:[21], eInit:[0.0100], init state:[ 6  3 52  0  0  0  0  0], end state:[ 1  3 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1204, score:[2801.60], loss:[1.31382], sequence:[37], random actions:[21], eInit:[0.0100], init state:[ 3 17  7  0  0  0  0  0], end state:[ 5 17  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1205, score:[2797.20], loss:[1.27931], sequence:[38], random actions:[31], eInit:[0.0100], init state:[ 0  4 43  0  0  0  0  0], end state:[ 2  4 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1206, score:[2840.00], loss:[1.09867], sequence:[39], random actions:[21], eInit:[0.0100], init state:[ 2 11 44  0  0  0  0  0], end state:[ 4 11 44  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1207, score:[2817.60], loss:[1.29409], sequence:[40], random actions:[25], eInit:[0.0100], init state:[ 1  6 14  0  0  0  0  0], end state:[ 3  6 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1208, score:[2818.80], loss:[1.19327], sequence:[41], random actions:[24], eInit:[0.0100], init state:[ 1  2 27  0  0  0  0  0], end state:[ 3  2 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1209, score:[2773.60], loss:[1.47054], sequence:[42], random actions:[37], eInit:[0.0100], init state:[ 5 20 13  1  0  0  0  0], end state:[ 0 20 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1210, score:[2782.80], loss:[1.37444], sequence:[43], random actions:[30], eInit:[0.0100], init state:[ 3 18 15  0  0  0  0  0], end state:[ 5 18 15  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1211, score:[2827.20], loss:[1.21290], sequence:[44], random actions:[16], eInit:[0.0100], init state:[ 6  2 47  0  0  0  0  0], end state:[ 1  2 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1212, score:[2790.80], loss:[1.26856], sequence:[45], random actions:[29], eInit:[0.0100], init state:[4 3 1 0 0 0 0 0], end state:[6 3 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1213, score:[2803.20], loss:[1.16866], sequence:[46], random actions:[29], eInit:[0.0100], init state:[0 9 3 0 0 0 0 0], end state:[2 9 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1214, score:[2806.00], loss:[1.22158], sequence:[47], random actions:[30], eInit:[0.0100], init state:[ 5  6 48  0  0  0  0  0], end state:[ 0  6 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1215, score:[2761.20], loss:[1.36007], sequence:[48], random actions:[35], eInit:[0.0100], init state:[ 6 14  3  0  0  0  0  0], end state:[ 1 14  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1216, score:[2814.40], loss:[1.32093], sequence:[49], random actions:[35], eInit:[0.0100], init state:[ 2 16  3  0  0  0  0  0], end state:[ 4 16  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1217, score:[2826.80], loss:[1.27390], sequence:[50], random actions:[33], eInit:[0.0100], init state:[ 2 23 11  1  0  0  0  0], end state:[ 4 23 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1218, score:[2840.80], loss:[1.17459], sequence:[51], random actions:[25], eInit:[0.0100], init state:[ 0 19 25  0  0  0  0  0], end state:[ 2 19 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1219, score:[2839.20], loss:[1.14043], sequence:[52], random actions:[21], eInit:[0.0100], init state:[ 6 22 25  1  0  0  0  0], end state:[ 1 22 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1220, score:[2839.60], loss:[1.14804], sequence:[53], random actions:[19], eInit:[0.0100], init state:[ 0 17 38  0  0  0  0  0], end state:[ 2 17 38  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1221, score:[2826.00], loss:[1.07251], sequence:[54], random actions:[25], eInit:[0.0100], init state:[ 1  4 44  0  0  0  0  0], end state:[ 3  4 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1222, score:[2813.60], loss:[0.99608], sequence:[55], random actions:[34], eInit:[0.0100], init state:[ 2 16 17  0  0  0  0  0], end state:[ 4 16 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1223, score:[2802.80], loss:[1.11410], sequence:[56], random actions:[42], eInit:[0.0100], init state:[ 0  4 34  0  0  0  0  0], end state:[ 2  4 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1224, score:[2804.00], loss:[1.21654], sequence:[57], random actions:[29], eInit:[0.0100], init state:[ 3  8 47  1  1  0  0  0], end state:[ 5  8 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1225, score:[2826.00], loss:[1.27851], sequence:[58], random actions:[26], eInit:[0.0100], init state:[ 2 20 15  0  0  0  0  0], end state:[ 4 20 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1226, score:[2754.40], loss:[1.37837], sequence:[59], random actions:[27], eInit:[0.0100], init state:[ 5  9 10  0  0  0  0  0], end state:[ 0  9 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1227, score:[2824.80], loss:[1.46007], sequence:[60], random actions:[19], eInit:[0.0100], init state:[ 4 16 53  0  0  0  0  0], end state:[ 6 16 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1228, score:[2796.80], loss:[1.37254], sequence:[61], random actions:[25], eInit:[0.0100], init state:[ 5 13 16  0  0  0  0  0], end state:[ 0 13 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1229, score:[2795.20], loss:[1.36948], sequence:[62], random actions:[33], eInit:[0.0100], init state:[ 4  9 42  1  0  0  0  0], end state:[ 6  9 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1230, score:[2819.60], loss:[1.29828], sequence:[63], random actions:[29], eInit:[0.0100], init state:[ 4 20  1  0  0  0  0  0], end state:[ 6 20  1  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1231, score:[2831.60], loss:[1.08482], sequence:[64], random actions:[22], eInit:[0.0100], init state:[ 2  5 57  0  0  0  0  0], end state:[ 4  5 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1232, score:[2797.20], loss:[1.08909], sequence:[65], random actions:[38], eInit:[0.0100], init state:[ 1 19 23  0  0  0  0  0], end state:[ 3 19 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1233, score:[2816.80], loss:[0.98891], sequence:[66], random actions:[30], eInit:[0.0100], init state:[ 2  0 11  1  0  0  0  0], end state:[ 4  0 11  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1234, score:[2830.00], loss:[0.85580], sequence:[67], random actions:[30], eInit:[0.0100], init state:[ 0  9 24  0  0  0  0  0], end state:[ 2  9 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1235, score:[2787.60], loss:[1.09290], sequence:[68], random actions:[27], eInit:[0.0100], init state:[ 5 14 55  0  0  0  0  0], end state:[ 0 14 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1236, score:[2796.40], loss:[1.02735], sequence:[69], random actions:[33], eInit:[0.0100], init state:[ 5 17 15  0  0  0  0  0], end state:[ 0 17 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1237, score:[2826.00], loss:[0.92331], sequence:[70], random actions:[19], eInit:[0.0100], init state:[ 2 18 46  0  0  0  0  0], end state:[ 4 18 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1238, score:[2767.20], loss:[1.12468], sequence:[71], random actions:[31], eInit:[0.0100], init state:[ 3  1 21  0  0  0  0  0], end state:[ 5  1 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1239, score:[2822.40], loss:[0.92220], sequence:[72], random actions:[39], eInit:[0.0100], init state:[ 2  3 12  0  0  0  0  0], end state:[ 4  3 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1240, score:[2783.60], loss:[1.10316], sequence:[73], random actions:[31], eInit:[0.0100], init state:[ 0  3 42  0  0  0  0  0], end state:[ 2  3 42  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1241, score:[2812.00], loss:[0.93297], sequence:[74], random actions:[31], eInit:[0.0100], init state:[ 1 18 45  0  0  0  0  0], end state:[ 3 18 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1242, score:[2751.20], loss:[1.14326], sequence:[75], random actions:[29], eInit:[0.0100], init state:[ 3 19 35  0  0  0  0  0], end state:[ 5 19 35  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1243, score:[2808.00], loss:[1.08985], sequence:[76], random actions:[22], eInit:[0.0100], init state:[ 6  3 46  0  0  0  0  0], end state:[ 1  3 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1244, score:[2781.20], loss:[1.06056], sequence:[77], random actions:[29], eInit:[0.0100], init state:[ 3  6 49  0  0  0  0  0], end state:[ 5  6 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1245, score:[2800.80], loss:[1.18428], sequence:[78], random actions:[23], eInit:[0.0100], init state:[ 4  6 21  0  0  0  0  0], end state:[ 6  6 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1246, score:[2793.20], loss:[1.15004], sequence:[79], random actions:[28], eInit:[0.0100], init state:[ 4  1 45  0  0  0  0  0], end state:[ 6  1 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1247, score:[2816.40], loss:[1.04077], sequence:[80], random actions:[26], eInit:[0.0100], init state:[ 1 20  6  0  0  0  0  0], end state:[ 3 20  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1248, score:[2834.40], loss:[0.99299], sequence:[81], random actions:[17], eInit:[0.0100], init state:[ 6 19 44  0  0  0  0  0], end state:[ 1 19 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1249, score:[2759.20], loss:[1.02451], sequence:[82], random actions:[28], eInit:[0.0100], init state:[ 4 14  3  0  0  0  0  0], end state:[ 6 14  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1250, score:[2760.00], loss:[1.23165], sequence:[83], random actions:[42], eInit:[0.0100], init state:[ 3 14 18  0  0  0  0  0], end state:[ 5 14 18  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1251, score:[2769.60], loss:[1.37742], sequence:[84], random actions:[44], eInit:[0.0100], init state:[ 3 22  2  1  0  0  0  0], end state:[ 5 22  2  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1252, score:[2766.40], loss:[1.55550], sequence:[85], random actions:[42], eInit:[0.0100], init state:[ 5 12 28  0  0  0  0  0], end state:[ 0 12 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1253, score:[2819.60], loss:[1.30222], sequence:[86], random actions:[34], eInit:[0.0100], init state:[3 4 7 0 0 0 0 0], end state:[5 4 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1254, score:[2802.00], loss:[1.33590], sequence:[87], random actions:[33], eInit:[0.0100], init state:[3 8 8 1 0 0 0 0], end state:[5 8 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1255, score:[2792.40], loss:[1.38000], sequence:[88], random actions:[33], eInit:[0.0100], init state:[ 4 11 13  1  1  0  0  0], end state:[ 6 11 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1256, score:[2820.00], loss:[1.20277], sequence:[89], random actions:[29], eInit:[0.0100], init state:[ 2 12  2  0  0  0  0  0], end state:[ 4 12  2  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1257, score:[2831.60], loss:[1.12026], sequence:[90], random actions:[23], eInit:[0.0100], init state:[ 1 14  1  0  0  0  0  0], end state:[ 3 14  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1258, score:[2773.60], loss:[1.34638], sequence:[91], random actions:[22], eInit:[0.0100], init state:[ 5 13 33  0  0  0  0  0], end state:[ 0 13 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1259, score:[2838.40], loss:[1.17614], sequence:[92], random actions:[15], eInit:[0.0100], init state:[ 4 19 55  0  0  0  0  0], end state:[ 6 19 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1260, score:[2819.20], loss:[1.13581], sequence:[93], random actions:[23], eInit:[0.0100], init state:[ 1  7 17  0  0  0  0  0], end state:[ 3  7 17  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1261, score:[2774.80], loss:[1.28171], sequence:[94], random actions:[30], eInit:[0.0100], init state:[ 5 12 24  0  0  0  0  0], end state:[ 0 12 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1262, score:[2824.00], loss:[1.20361], sequence:[95], random actions:[23], eInit:[0.0100], init state:[ 3 15 23  0  0  0  0  0], end state:[ 5 15 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1263, score:[2780.40], loss:[1.24384], sequence:[96], random actions:[39], eInit:[0.0100], init state:[ 4  7 35  0  0  0  0  0], end state:[ 6  7 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1264, score:[2808.00], loss:[1.28745], sequence:[97], random actions:[40], eInit:[0.0100], init state:[ 4  6 11  0  0  0  0  0], end state:[ 6  6 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1265, score:[2782.80], loss:[1.34444], sequence:[98], random actions:[30], eInit:[0.0100], init state:[ 6 17  2  0  0  0  0  0], end state:[ 1 17  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1266, score:[2808.40], loss:[1.31740], sequence:[99], random actions:[30], eInit:[0.0100], init state:[ 2  6 18  0  0  0  0  0], end state:[ 4  6 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1267, score:[2815.20], loss:[1.32341], sequence:[100], random actions:[27], eInit:[0.0100], init state:[ 6 11 35  0  0  0  0  0], end state:[ 1 11 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1268, score:[2820.80], loss:[1.09813], sequence:[101], random actions:[35], eInit:[0.0100], init state:[ 3  7 30  0  0  0  0  0], end state:[ 5  7 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1269, score:[2816.40], loss:[1.12325], sequence:[102], random actions:[31], eInit:[0.0100], init state:[ 5 21 24  1  0  0  1  1], end state:[ 0 21 24  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1270, score:[2787.20], loss:[1.19553], sequence:[103], random actions:[29], eInit:[0.0100], init state:[ 3  3 27  0  0  0  0  0], end state:[ 5  3 27  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1271, score:[2804.80], loss:[1.15945], sequence:[104], random actions:[29], eInit:[0.0100], init state:[ 1 23 29  1  0  0  1  0], end state:[ 3 23 29  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1272, score:[2823.60], loss:[1.16500], sequence:[105], random actions:[17], eInit:[0.0100], init state:[ 4  2 32  0  0  0  0  0], end state:[ 6  2 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1273, score:[2804.00], loss:[1.18700], sequence:[106], random actions:[41], eInit:[0.0100], init state:[ 0 17 41  0  0  0  0  0], end state:[ 2 17 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1274, score:[2797.20], loss:[1.29149], sequence:[107], random actions:[34], eInit:[0.0100], init state:[ 6  6 23  0  0  0  0  0], end state:[ 1  6 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1275, score:[2810.00], loss:[1.30495], sequence:[108], random actions:[35], eInit:[0.0100], init state:[ 2 12 16  0  0  0  0  0], end state:[ 4 12 16  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1276, score:[2805.60], loss:[1.38763], sequence:[109], random actions:[40], eInit:[0.0100], init state:[ 0 18  1  0  0  0  0  0], end state:[ 2 18  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1277, score:[2803.20], loss:[1.37075], sequence:[110], random actions:[42], eInit:[0.0100], init state:[ 1  0 41  0  0  1  0  0], end state:[ 3  0 41  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1278, score:[2790.40], loss:[1.63453], sequence:[111], random actions:[23], eInit:[0.0100], init state:[ 5  7 46  0  0  0  0  0], end state:[ 0  7 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1279, score:[2844.40], loss:[1.53359], sequence:[112], random actions:[23], eInit:[0.0100], init state:[ 1  8 22  1  0  0  0  0], end state:[ 3  8 22  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1280, score:[2771.20], loss:[1.60336], sequence:[113], random actions:[34], eInit:[0.0100], init state:[ 3  4 14  0  0  0  0  0], end state:[ 5  4 14  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1281, score:[2798.40], loss:[1.63847], sequence:[114], random actions:[31], eInit:[0.0100], init state:[ 4 11 20  1  1  0  0  0], end state:[ 6 11 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1282, score:[2795.60], loss:[1.85669], sequence:[115], random actions:[35], eInit:[0.0100], init state:[ 2 23 12  1  0  0  0  0], end state:[ 4 23 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1283, score:[2812.40], loss:[1.67443], sequence:[116], random actions:[23], eInit:[0.0100], init state:[ 1  9 17  0  0  0  0  0], end state:[ 3  9 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1284, score:[2817.20], loss:[1.61523], sequence:[117], random actions:[41], eInit:[0.0100], init state:[ 0 19 23  0  0  0  0  0], end state:[ 2 19 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1285, score:[2812.40], loss:[1.53975], sequence:[118], random actions:[28], eInit:[0.0100], init state:[ 2  7 35  0  0  0  0  0], end state:[ 4  7 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1286, score:[2783.60], loss:[1.73189], sequence:[119], random actions:[35], eInit:[0.0100], init state:[ 4 10 21  1  1  0  1  0], end state:[ 6 10 21  0  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1287, score:[2814.00], loss:[1.72605], sequence:[120], random actions:[26], eInit:[0.0100], init state:[ 0 18  4  0  0  0  0  0], end state:[ 2 18  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1288, score:[2772.00], loss:[1.73316], sequence:[121], random actions:[31], eInit:[0.0100], init state:[ 3 19 53  0  0  0  0  0], end state:[ 5 19 53  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1289, score:[2791.60], loss:[1.92135], sequence:[122], random actions:[20], eInit:[0.0100], init state:[ 1  1 11  0  0  0  0  0], end state:[ 3  1 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1290, score:[2765.60], loss:[1.79386], sequence:[123], random actions:[27], eInit:[0.0100], init state:[ 3 21 55  1  0  0  0  0], end state:[ 5 21 55  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1291, score:[2829.20], loss:[1.77402], sequence:[124], random actions:[26], eInit:[0.0100], init state:[ 1 20 36  1  1  0  0  0], end state:[ 3 20 36  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1292, score:[2800.00], loss:[1.82954], sequence:[125], random actions:[26], eInit:[0.0100], init state:[ 1 22 24  1  0  0  0  0], end state:[ 3 22 24  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1293, score:[2822.00], loss:[1.58157], sequence:[126], random actions:[30], eInit:[0.0100], init state:[ 1 17 58  0  0  0  0  0], end state:[ 3 17 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1294, score:[2795.20], loss:[1.69706], sequence:[127], random actions:[30], eInit:[0.0100], init state:[ 5 20 59  1  0  0  0  0], end state:[ 0 20 59  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1295, score:[2807.20], loss:[1.71871], sequence:[128], random actions:[36], eInit:[0.0100], init state:[ 3 10 14  0  0  0  0  0], end state:[ 5 10 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1296, score:[2828.00], loss:[1.74843], sequence:[129], random actions:[25], eInit:[0.0100], init state:[ 0 17  9  0  0  0  0  0], end state:[ 2 17  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1297, score:[2804.40], loss:[1.87929], sequence:[130], random actions:[28], eInit:[0.0100], init state:[ 5 10  2  0  0  0  0  0], end state:[ 0 10  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1298, score:[2814.00], loss:[1.88712], sequence:[131], random actions:[26], eInit:[0.0100], init state:[ 4  2 38  0  0  0  0  0], end state:[ 6  2 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1299, score:[2836.40], loss:[1.80748], sequence:[132], random actions:[27], eInit:[0.0100], init state:[ 1  8 19  1  0  0  0  0], end state:[ 3  8 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1300, score:[2834.80], loss:[1.75118], sequence:[133], random actions:[27], eInit:[0.0100], init state:[ 2  9 49  0  0  0  0  0], end state:[ 4  9 49  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1301, score:[2822.40], loss:[1.56102], sequence:[134], random actions:[30], eInit:[0.0100], init state:[ 0 11 48  0  0  0  0  0], end state:[ 2 11 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1302, score:[2806.40], loss:[1.74751], sequence:[135], random actions:[34], eInit:[0.0100], init state:[ 0 18 18  0  0  0  0  0], end state:[ 2 18 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1303, score:[2820.40], loss:[1.81808], sequence:[136], random actions:[29], eInit:[0.0100], init state:[ 6  9 31  0  0  0  0  0], end state:[ 1  9 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1304, score:[2814.40], loss:[1.55455], sequence:[137], random actions:[30], eInit:[0.0100], init state:[ 2  2 13  0  0  0  0  0], end state:[ 4  2 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1305, score:[2784.00], loss:[1.74384], sequence:[138], random actions:[35], eInit:[0.0100], init state:[ 4 17 21  0  0  0  0  0], end state:[ 6 17 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1306, score:[2822.00], loss:[1.44667], sequence:[139], random actions:[26], eInit:[0.0100], init state:[ 1  7 26  0  0  0  0  0], end state:[ 3  7 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1307, score:[2782.80], loss:[1.67034], sequence:[140], random actions:[34], eInit:[0.0100], init state:[ 5  8 22  0  0  0  0  0], end state:[ 0  8 22  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1308, score:[2758.40], loss:[1.77771], sequence:[141], random actions:[37], eInit:[0.0100], init state:[ 3 22 35  1  0  0  0  0], end state:[ 5 22 35  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1309, score:[2809.20], loss:[1.83222], sequence:[142], random actions:[26], eInit:[0.0100], init state:[ 3  7 31  0  0  0  0  0], end state:[ 5  7 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1310, score:[2804.00], loss:[1.73455], sequence:[143], random actions:[34], eInit:[0.0100], init state:[ 3  2 51  0  0  0  0  0], end state:[ 5  2 51  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1311, score:[2818.40], loss:[1.62952], sequence:[144], random actions:[26], eInit:[0.0100], init state:[ 1 15 42  0  0  0  0  0], end state:[ 3 15 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1312, score:[2754.40], loss:[1.96983], sequence:[145], random actions:[26], eInit:[0.0100], init state:[5 8 1 0 0 0 0 0], end state:[0 8 1 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1313, score:[2828.00], loss:[2.05322], sequence:[146], random actions:[27], eInit:[0.0100], init state:[ 2  3 46  0  0  0  0  0], end state:[ 4  3 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1314, score:[2788.00], loss:[1.76737], sequence:[147], random actions:[30], eInit:[0.0100], init state:[ 0  6 41  0  0  0  0  0], end state:[ 2  6 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1315, score:[2827.20], loss:[1.70005], sequence:[148], random actions:[28], eInit:[0.0100], init state:[ 0 18 19  0  0  0  0  0], end state:[ 2 18 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1316, score:[2818.80], loss:[1.53149], sequence:[149], random actions:[25], eInit:[0.0100], init state:[ 6  3 16  0  0  0  0  0], end state:[ 1  3 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1317, score:[2753.20], loss:[1.82719], sequence:[150], random actions:[39], eInit:[0.0100], init state:[ 5  2 36  0  0  0  0  0], end state:[ 0  2 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1318, score:[2799.60], loss:[1.81951], sequence:[151], random actions:[28], eInit:[0.0100], init state:[ 4 14 50  0  0  0  0  0], end state:[ 6 14 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1319, score:[2778.80], loss:[2.27162], sequence:[152], random actions:[26], eInit:[0.0100], init state:[ 5 17 49  0  0  0  0  0], end state:[ 0 17 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1320, score:[2830.80], loss:[2.17956], sequence:[153], random actions:[21], eInit:[0.0100], init state:[ 6 20  1  0  0  0  0  0], end state:[ 1 20  1  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1321, score:[2796.00], loss:[2.22737], sequence:[154], random actions:[29], eInit:[0.0100], init state:[ 6 18 56  0  0  0  0  0], end state:[ 1 18 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1322, score:[2806.40], loss:[2.14471], sequence:[155], random actions:[25], eInit:[0.0100], init state:[ 0  7 48  0  0  0  0  0], end state:[ 2  7 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1323, score:[2800.80], loss:[1.83554], sequence:[156], random actions:[28], eInit:[0.0100], init state:[ 4 22 18  0  0  0  0  0], end state:[ 6 22 18  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1324, score:[2784.40], loss:[1.98147], sequence:[157], random actions:[21], eInit:[0.0100], init state:[ 4  1 14  0  0  0  0  0], end state:[ 6  1 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1325, score:[2806.40], loss:[1.97820], sequence:[158], random actions:[30], eInit:[0.0100], init state:[ 2  8 24  1  0  0  0  0], end state:[ 4  8 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1326, score:[2808.40], loss:[1.93449], sequence:[159], random actions:[38], eInit:[0.0100], init state:[ 1 12 31  0  0  0  0  0], end state:[ 3 12 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1327, score:[2748.80], loss:[2.13411], sequence:[160], random actions:[34], eInit:[0.0100], init state:[ 5  2 30  0  0  0  0  0], end state:[ 0  2 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1328, score:[2817.60], loss:[2.18104], sequence:[161], random actions:[33], eInit:[0.0100], init state:[ 6 12 48  0  0  0  0  0], end state:[ 1 12 48  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1329, score:[2794.40], loss:[1.95462], sequence:[162], random actions:[26], eInit:[0.0100], init state:[ 6 19 34  0  0  0  0  0], end state:[ 1 19 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1330, score:[2810.00], loss:[1.92174], sequence:[163], random actions:[20], eInit:[0.0100], init state:[ 2 10 21  0  0  0  0  0], end state:[ 4 10 21  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(166, [719])
INFO:Reinforcement.Functions:episode: 1331, score:[2811.20], loss:[1.89024], sequence:[164], random actions:[37], eInit:[0.0100], init state:[ 0 11 37  0  0  0  0  0], end state:[ 2 11 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1332, score:[2825.20], loss:[1.82104], sequence:[165], random actions:[27], eInit:[0.0100], init state:[ 0 16 33  0  0  0  0  0], end state:[ 2 16 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1333, score:[2827.60], loss:[1.72426], sequence:[166], random actions:[29], eInit:[0.0100], init state:[ 6 13 54  0  0  0  0  0], end state:[ 1 13 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1334, score:[2839.60], loss:[1.78561], sequence:[167], random actions:[20], eInit:[0.0100], init state:[ 6 18 16  0  0  0  0  0], end state:[ 1 18 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1335, score:[2818.80], loss:[1.72780], sequence:[168], random actions:[36], eInit:[0.0100], init state:[ 6 17  5  0  0  0  0  0], end state:[ 1 17  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1336, score:[2785.60], loss:[1.65441], sequence:[169], random actions:[34], eInit:[0.0100], init state:[ 6 11 54  0  0  0  0  0], end state:[ 1 11 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1337, score:[2817.20], loss:[1.58501], sequence:[170], random actions:[32], eInit:[0.0100], init state:[2 0 2 1 0 0 0 0], end state:[4 0 2 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1338, score:[2812.00], loss:[1.47248], sequence:[171], random actions:[39], eInit:[0.0100], init state:[ 2  7 15  0  0  0  0  0], end state:[ 4  7 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1339, score:[2838.80], loss:[1.39175], sequence:[172], random actions:[25], eInit:[0.0100], init state:[ 0 23 44  1  0  0  1  0], end state:[ 2 23 44  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1340, score:[2778.40], loss:[1.53560], sequence:[173], random actions:[29], eInit:[0.0100], init state:[ 4 13  7  1  1  0  1  0], end state:[ 6 13  7  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(173, [1340])
INFO:Reinforcement.Functions:episode: 1341, score:[2787.60], loss:[1.55891], sequence:[174], random actions:[33], eInit:[0.0100], init state:[ 4 20 32  0  0  0  0  0], end state:[ 6 20 32  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1342, score:[2755.20], loss:[1.76392], sequence:[175], random actions:[27], eInit:[0.0100], init state:[ 2 23 27  1  0  0  1  0], end state:[ 4 23 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1343, score:[2794.80], loss:[1.84063], sequence:[176], random actions:[25], eInit:[0.0100], init state:[ 2 21 34  1  0  0  0  0], end state:[ 4 21 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1344, score:[2790.40], loss:[2.08501], sequence:[177], random actions:[31], eInit:[0.0100], init state:[ 0  2 32  0  0  0  0  0], end state:[ 2  2 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1345, score:[2810.00], loss:[1.72896], sequence:[178], random actions:[28], eInit:[0.0100], init state:[ 3  6 33  0  0  0  0  0], end state:[ 5  6 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1346, score:[2784.80], loss:[1.86626], sequence:[179], random actions:[34], eInit:[0.0100], init state:[ 3 21 18  1  1  0  1  0], end state:[ 5 21 18  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1347, score:[2826.00], loss:[2.04358], sequence:[180], random actions:[23], eInit:[0.0100], init state:[ 6 22 21  1  0  0  0  0], end state:[ 1 22 21  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1348, score:[2811.20], loss:[2.07272], sequence:[181], random actions:[24], eInit:[0.0100], init state:[ 4 16 56  0  0  0  0  0], end state:[ 6 16 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1349, score:[2763.20], loss:[2.30678], sequence:[182], random actions:[23], eInit:[0.0100], init state:[ 6 17 36  0  0  0  0  0], end state:[ 1 17 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1350, score:[2806.40], loss:[2.22660], sequence:[183], random actions:[28], eInit:[0.0100], init state:[ 3  3 12  0  0  0  0  0], end state:[ 5  3 12  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(183, [1350])
INFO:Reinforcement.Functions:episode: 1351, score:[2747.20], loss:[2.47695], sequence:[184], random actions:[34], eInit:[0.0100], init state:[6 0 6 1 0 0 0 0], end state:[1 0 6 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1352, score:[2829.60], loss:[2.24139], sequence:[185], random actions:[30], eInit:[0.0100], init state:[1 7 9 0 0 0 0 0], end state:[3 7 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1353, score:[2852.00], loss:[2.07995], sequence:[186], random actions:[18], eInit:[0.0100], init state:[ 1 15 22  0  0  0  0  0], end state:[ 3 15 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1354, score:[2740.80], loss:[2.45289], sequence:[187], random actions:[25], eInit:[0.0100], init state:[ 5  8 57  0  0  0  0  0], end state:[ 0  8 57  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1355, score:[2786.40], loss:[2.49839], sequence:[188], random actions:[38], eInit:[0.0100], init state:[ 2 20 14  0  0  0  0  0], end state:[ 4 20 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1356, score:[2775.60], loss:[2.69809], sequence:[189], random actions:[35], eInit:[0.0100], init state:[ 6 14  4  0  0  0  0  0], end state:[ 1 14  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1357, score:[2818.00], loss:[2.37989], sequence:[190], random actions:[25], eInit:[0.0100], init state:[ 0 10  8  0  0  0  0  0], end state:[ 2 10  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1358, score:[2830.00], loss:[2.28022], sequence:[191], random actions:[30], eInit:[0.0100], init state:[ 0 11 13  0  0  0  0  0], end state:[ 2 11 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1359, score:[2821.20], loss:[2.08757], sequence:[192], random actions:[35], eInit:[0.0100], init state:[ 1  8 19  1  0  0  0  0], end state:[ 3  8 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1360, score:[2795.20], loss:[1.87091], sequence:[193], random actions:[31], eInit:[0.0100], init state:[ 0  5 36  0  0  0  0  0], end state:[ 2  5 36  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(193, [1360])
INFO:Reinforcement.Functions:episode: 1361, score:[2820.80], loss:[1.74823], sequence:[194], random actions:[32], eInit:[0.0100], init state:[ 1 13 53  0  0  0  0  0], end state:[ 3 13 53  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1362, score:[2791.60], loss:[2.09285], sequence:[195], random actions:[36], eInit:[0.0100], init state:[ 0 17 14  0  0  0  0  0], end state:[ 2 17 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1363, score:[2794.00], loss:[1.81893], sequence:[196], random actions:[30], eInit:[0.0100], init state:[ 2 17 28  0  0  0  0  0], end state:[ 4 17 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1364, score:[2839.60], loss:[1.57865], sequence:[197], random actions:[26], eInit:[0.0100], init state:[ 1  8 17  1  0  0  0  0], end state:[ 3  8 17  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1365, score:[2776.80], loss:[1.61227], sequence:[198], random actions:[33], eInit:[0.0100], init state:[ 3 23 13  1  0  0  0  0], end state:[ 5 23 13  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1366, score:[2726.40], loss:[2.17940], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 5 14  2  0  0  0  0  0], end state:[ 0 14  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1367, score:[2831.20], loss:[1.73845], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 0 15 52  0  0  0  0  0], end state:[ 2 15 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1368, score:[2697.20], loss:[1.99315], sequence:[0], random actions:[33], eInit:[0.0100], init state:[ 6  1 24  0  0  0  0  0], end state:[ 1  1 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1369, score:[2821.20], loss:[1.66192], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 0 14 49  0  0  0  0  0], end state:[ 2 14 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1370, score:[2778.00], loss:[1.76279], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 4 13 38  0  0  0  0  0], end state:[ 6 13 38  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1371, score:[2745.60], loss:[1.90477], sequence:[3], random actions:[38], eInit:[0.0100], init state:[ 4 13 20  1  1  0  0  0], end state:[ 6 13 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1372, score:[2808.00], loss:[1.77106], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 6 10 21  0  0  0  0  0], end state:[ 1 10 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1373, score:[2821.60], loss:[1.80712], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 2  3 19  0  0  0  0  0], end state:[ 4  3 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1374, score:[2818.80], loss:[1.54978], sequence:[6], random actions:[34], eInit:[0.0100], init state:[ 6 23 48  1  0  0  0  0], end state:[ 1 23 48  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1375, score:[2776.40], loss:[1.79696], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 4 10 20  1  1  0  1  0], end state:[ 6 10 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1376, score:[2792.00], loss:[1.97832], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 2 18 46  0  0  0  0  0], end state:[ 4 18 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1377, score:[2826.00], loss:[1.84123], sequence:[9], random actions:[25], eInit:[0.0100], init state:[ 3  6 24  0  0  0  0  0], end state:[ 5  6 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1378, score:[2784.40], loss:[1.93187], sequence:[10], random actions:[33], eInit:[0.0100], init state:[ 3 19 21  0  0  0  0  0], end state:[ 5 19 21  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1379, score:[2781.60], loss:[2.15153], sequence:[11], random actions:[30], eInit:[0.0100], init state:[ 4  8 14  0  0  0  0  0], end state:[ 6  8 14  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1380, score:[2827.20], loss:[2.03709], sequence:[12], random actions:[22], eInit:[0.0100], init state:[ 1  1 30  0  0  0  0  0], end state:[ 3  1 30  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1381, score:[2806.00], loss:[1.92127], sequence:[13], random actions:[39], eInit:[0.0100], init state:[ 1 16 48  0  0  0  0  0], end state:[ 3 16 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1382, score:[2844.00], loss:[1.81380], sequence:[14], random actions:[20], eInit:[0.0100], init state:[ 1 20 43  1  1  0  0  0], end state:[ 3 20 43  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1383, score:[2805.60], loss:[1.73365], sequence:[15], random actions:[20], eInit:[0.0100], init state:[ 6 16 46  0  0  0  0  0], end state:[ 1 16 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1384, score:[2802.00], loss:[1.76812], sequence:[16], random actions:[28], eInit:[0.0100], init state:[ 6 14  0  0  0  0  0  0], end state:[ 1 14  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1385, score:[2808.00], loss:[1.87461], sequence:[17], random actions:[25], eInit:[0.0100], init state:[ 3 19 31  0  0  0  0  0], end state:[ 5 19 31  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1386, score:[2802.80], loss:[1.88943], sequence:[18], random actions:[25], eInit:[0.0100], init state:[ 5  8 19  0  0  0  0  0], end state:[ 0  8 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1387, score:[2810.00], loss:[1.68469], sequence:[19], random actions:[27], eInit:[0.0100], init state:[ 2 23  8  1  0  0  0  0], end state:[ 4 23  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1388, score:[2803.20], loss:[1.84477], sequence:[20], random actions:[33], eInit:[0.0100], init state:[ 4 11 41  1  1  0  0  0], end state:[ 6 11 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1389, score:[2832.40], loss:[1.77140], sequence:[21], random actions:[29], eInit:[0.0100], init state:[ 3 13  7  0  0  0  0  0], end state:[ 5 13  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1390, score:[2827.60], loss:[1.69436], sequence:[22], random actions:[29], eInit:[0.0100], init state:[ 0 13  3  0  0  0  0  0], end state:[ 2 13  3  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1391, score:[2824.80], loss:[1.80575], sequence:[23], random actions:[24], eInit:[0.0100], init state:[ 4  6 19  0  0  0  0  0], end state:[ 6  6 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1392, score:[2818.00], loss:[1.60035], sequence:[24], random actions:[38], eInit:[0.0100], init state:[ 3 17 43  0  0  0  0  0], end state:[ 5 17 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1393, score:[2812.40], loss:[1.59870], sequence:[25], random actions:[24], eInit:[0.0100], init state:[ 6 15 42  0  0  0  0  0], end state:[ 1 15 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1394, score:[2792.40], loss:[1.46279], sequence:[26], random actions:[30], eInit:[0.0100], init state:[ 3  7 20  0  0  0  0  0], end state:[ 5  7 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1395, score:[2796.40], loss:[1.88971], sequence:[27], random actions:[31], eInit:[0.0100], init state:[ 1  5 36  0  0  0  0  0], end state:[ 3  5 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1396, score:[2809.60], loss:[1.50014], sequence:[28], random actions:[31], eInit:[0.0100], init state:[1 3 6 0 0 0 0 0], end state:[3 3 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1397, score:[2748.80], loss:[1.88092], sequence:[29], random actions:[34], eInit:[0.0100], init state:[ 5 17 34  0  0  0  0  0], end state:[ 0 17 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1398, score:[2737.20], loss:[2.04213], sequence:[30], random actions:[35], eInit:[0.0100], init state:[ 5 15 54  0  0  0  0  0], end state:[ 0 15 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1399, score:[2774.80], loss:[2.11738], sequence:[31], random actions:[31], eInit:[0.0100], init state:[ 4 22 35  0  0  0  0  0], end state:[ 6 22 35  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1400, score:[2746.80], loss:[2.43729], sequence:[32], random actions:[36], eInit:[0.0100], init state:[ 1 16 56  0  0  0  0  0], end state:[ 3 16 56  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1401, score:[2822.80], loss:[2.07857], sequence:[33], random actions:[27], eInit:[0.0100], init state:[ 1  7 21  0  0  0  0  0], end state:[ 3  7 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1402, score:[2808.80], loss:[1.96354], sequence:[34], random actions:[32], eInit:[0.0100], init state:[ 6  1 18  0  0  0  0  0], end state:[ 1  1 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1403, score:[2789.20], loss:[1.83902], sequence:[35], random actions:[24], eInit:[0.0100], init state:[ 2 12 40  0  0  0  0  0], end state:[ 4 12 40  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1404, score:[2812.00], loss:[2.21472], sequence:[36], random actions:[29], eInit:[0.0100], init state:[4 0 3 1 0 0 0 0], end state:[6 0 3 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1405, score:[2773.20], loss:[1.98832], sequence:[37], random actions:[30], eInit:[0.0100], init state:[ 3 22 53  1  0  0  0  0], end state:[ 5 22 53  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1406, score:[2780.40], loss:[2.33276], sequence:[38], random actions:[33], eInit:[0.0100], init state:[ 3  9 52  0  0  0  0  0], end state:[ 5  9 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1407, score:[2822.00], loss:[1.91032], sequence:[39], random actions:[28], eInit:[0.0100], init state:[ 2 23 19  1  0  0  1  0], end state:[ 4 23 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1408, score:[2798.40], loss:[1.83446], sequence:[40], random actions:[28], eInit:[0.0100], init state:[ 5  3 21  0  0  0  0  0], end state:[ 0  3 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1409, score:[2782.40], loss:[1.88552], sequence:[41], random actions:[21], eInit:[0.0100], init state:[ 3 17 48  0  0  0  0  0], end state:[ 5 17 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1410, score:[2793.20], loss:[1.99275], sequence:[42], random actions:[37], eInit:[0.0100], init state:[ 0 19 52  0  0  0  0  0], end state:[ 2 19 52  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1411, score:[2798.80], loss:[2.09904], sequence:[43], random actions:[36], eInit:[0.0100], init state:[ 6  5 17  0  0  0  0  0], end state:[ 1  5 17  0  0  0  1  1]
INFO:Reinforcement.Functions:episode: 1412, score:[2747.60], loss:[1.93761], sequence:[44], random actions:[32], eInit:[0.0100], init state:[ 2 21 10  1  1  0  1  0], end state:[ 4 21 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1413, score:[2810.00], loss:[1.96951], sequence:[45], random actions:[27], eInit:[0.0100], init state:[ 0  3 59  0  0  0  0  0], end state:[ 2  3 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1414, score:[2770.40], loss:[2.36016], sequence:[46], random actions:[24], eInit:[0.0100], init state:[ 5 17 14  0  0  0  0  0], end state:[ 0 17 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1415, score:[2809.60], loss:[2.18410], sequence:[47], random actions:[24], eInit:[0.0100], init state:[ 2  7 32  0  0  0  0  0], end state:[ 4  7 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1416, score:[2804.00], loss:[1.93303], sequence:[48], random actions:[25], eInit:[0.0100], init state:[ 1 19 44  0  0  0  0  0], end state:[ 3 19 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1417, score:[2809.20], loss:[1.68778], sequence:[49], random actions:[28], eInit:[0.0100], init state:[ 0 10 23  0  0  0  0  0], end state:[ 2 10 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1418, score:[2766.00], loss:[2.07948], sequence:[50], random actions:[37], eInit:[0.0100], init state:[ 5 10  4  0  0  0  0  0], end state:[ 0 10  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1419, score:[2784.40], loss:[2.08111], sequence:[51], random actions:[30], eInit:[0.0100], init state:[ 5 21 46  1  0  0  1  0], end state:[ 0 21 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1420, score:[2819.60], loss:[1.83438], sequence:[52], random actions:[23], eInit:[0.0100], init state:[ 3 13 59  0  0  0  0  0], end state:[ 5 13 59  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1421, score:[2778.80], loss:[2.00619], sequence:[53], random actions:[30], eInit:[0.0100], init state:[ 3  4 51  0  0  0  0  0], end state:[ 5  4 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1422, score:[2812.00], loss:[2.15802], sequence:[54], random actions:[16], eInit:[0.0100], init state:[ 6 11 31  0  0  0  0  0], end state:[ 1 11 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1423, score:[2734.40], loss:[2.21290], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 22 48  0  0  0  0  0], end state:[ 6 22 48  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1424, score:[2797.60], loss:[2.19343], sequence:[1], random actions:[38], eInit:[0.0100], init state:[ 6 19 35  0  0  0  0  0], end state:[ 1 19 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1425, score:[2826.40], loss:[1.87314], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 3 12 27  0  0  0  0  0], end state:[ 5 12 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1426, score:[2807.20], loss:[1.88659], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 2 12  1  0  0  0  0  0], end state:[ 4 12  1  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1427, score:[2806.00], loss:[1.91465], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 4  1 51  0  0  0  0  0], end state:[ 6  1 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1428, score:[2829.60], loss:[1.84262], sequence:[5], random actions:[23], eInit:[0.0100], init state:[ 1 17 56  0  0  0  0  0], end state:[ 3 17 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1429, score:[2822.00], loss:[1.84362], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 1 20 56  1  1  0  1  0], end state:[ 3 20 56  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1430, score:[2820.80], loss:[1.76766], sequence:[7], random actions:[33], eInit:[0.0100], init state:[3 6 7 0 0 0 0 0], end state:[5 6 7 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1431, score:[2793.20], loss:[1.88728], sequence:[8], random actions:[34], eInit:[0.0100], init state:[ 6  0 54  0  0  1  0  0], end state:[ 1  0 54  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1432, score:[2822.40], loss:[1.71879], sequence:[9], random actions:[29], eInit:[0.0100], init state:[ 6 10 17  0  0  0  0  0], end state:[ 1 10 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1433, score:[2808.80], loss:[1.73383], sequence:[10], random actions:[27], eInit:[0.0100], init state:[ 2  8 15  1  0  0  0  0], end state:[ 4  8 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1434, score:[2844.40], loss:[1.60421], sequence:[11], random actions:[18], eInit:[0.0100], init state:[ 3 10 55  0  0  0  0  0], end state:[ 5 10 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1435, score:[2834.80], loss:[1.47943], sequence:[12], random actions:[24], eInit:[0.0100], init state:[ 2  4 23  0  0  0  0  0], end state:[ 4  4 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1436, score:[2832.80], loss:[1.43358], sequence:[13], random actions:[28], eInit:[0.0100], init state:[ 1 19  1  0  0  0  0  0], end state:[ 3 19  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1437, score:[2810.80], loss:[1.47422], sequence:[14], random actions:[29], eInit:[0.0100], init state:[ 6  9 30  0  0  0  0  0], end state:[ 1  9 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1438, score:[2794.00], loss:[1.42619], sequence:[15], random actions:[29], eInit:[0.0100], init state:[2 7 9 0 0 0 0 0], end state:[4 7 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1439, score:[2813.60], loss:[1.36291], sequence:[16], random actions:[29], eInit:[0.0100], init state:[0 7 9 0 0 0 0 0], end state:[2 7 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1440, score:[2772.00], loss:[1.68079], sequence:[17], random actions:[30], eInit:[0.0100], init state:[ 4 15 13  0  0  0  0  0], end state:[ 6 15 13  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1441, score:[2830.80], loss:[1.47888], sequence:[18], random actions:[23], eInit:[0.0100], init state:[ 0  5 14  0  0  0  0  0], end state:[ 2  5 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1442, score:[2835.20], loss:[1.32223], sequence:[19], random actions:[29], eInit:[0.0100], init state:[ 0  8 44  1  1  0  1  0], end state:[ 2  8 44  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1443, score:[2764.40], loss:[1.34791], sequence:[20], random actions:[28], eInit:[0.0100], init state:[ 3 21  1  1  1  0  1  0], end state:[ 5 21  1  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1444, score:[2792.00], loss:[1.44013], sequence:[21], random actions:[29], eInit:[0.0100], init state:[ 5 11 34  0  0  0  0  0], end state:[ 0 11 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1445, score:[2801.20], loss:[1.58927], sequence:[22], random actions:[25], eInit:[0.0100], init state:[ 6  8 27  1  0  0  0  0], end state:[ 1  8 27  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1446, score:[2742.40], loss:[1.62823], sequence:[23], random actions:[22], eInit:[0.0100], init state:[ 3 20 16  0  0  0  0  0], end state:[ 5 20 16  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1447, score:[2798.40], loss:[1.80761], sequence:[24], random actions:[34], eInit:[0.0100], init state:[ 4 22 25  0  0  0  0  0], end state:[ 6 22 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1448, score:[2799.60], loss:[1.91300], sequence:[25], random actions:[28], eInit:[0.0100], init state:[ 2 18 10  0  0  0  0  0], end state:[ 4 18 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1449, score:[2813.20], loss:[1.89763], sequence:[26], random actions:[29], eInit:[0.0100], init state:[ 6 23  2  1  0  0  0  0], end state:[ 1 23  2  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1450, score:[2779.20], loss:[2.08186], sequence:[27], random actions:[39], eInit:[0.0100], init state:[ 6  1 35  0  0  0  0  0], end state:[ 1  1 35  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1451, score:[2806.40], loss:[1.93191], sequence:[28], random actions:[35], eInit:[0.0100], init state:[ 3 10 45  0  0  0  0  0], end state:[ 5 10 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1452, score:[2803.60], loss:[1.88965], sequence:[29], random actions:[32], eInit:[0.0100], init state:[ 3 15  8  0  0  0  0  0], end state:[ 5 15  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1453, score:[2728.00], loss:[1.96043], sequence:[0], random actions:[24], eInit:[0.0100], init state:[5 0 8 0 0 0 0 0], end state:[0 0 8 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1454, score:[2823.20], loss:[2.16419], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 23  2  1  0  0  0  0], end state:[ 3 23  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1455, score:[2814.00], loss:[2.06231], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 4 23 39  0  0  0  0  0], end state:[ 6 23 39  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1456, score:[2831.60], loss:[1.92705], sequence:[3], random actions:[24], eInit:[0.0100], init state:[ 3 15 40  0  0  0  0  0], end state:[ 5 15 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1457, score:[2800.00], loss:[1.85821], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 0  6 47  0  0  0  0  0], end state:[ 2  6 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1458, score:[2817.60], loss:[1.69631], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 6 12 47  0  0  0  0  0], end state:[ 1 12 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1459, score:[2773.20], loss:[1.91033], sequence:[6], random actions:[34], eInit:[0.0100], init state:[ 4  9 14  0  0  0  0  0], end state:[ 6  9 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1460, score:[2788.80], loss:[2.16843], sequence:[7], random actions:[28], eInit:[0.0100], init state:[ 3 18 35  0  0  0  0  0], end state:[ 5 18 35  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1461, score:[2816.40], loss:[1.96999], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 6 20  6  0  0  0  0  0], end state:[ 1 20  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1462, score:[2828.80], loss:[1.76848], sequence:[9], random actions:[29], eInit:[0.0100], init state:[ 0  6 47  0  0  0  0  0], end state:[ 2  6 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1463, score:[2804.00], loss:[1.63175], sequence:[10], random actions:[27], eInit:[0.0100], init state:[ 1 18 57  0  0  0  0  0], end state:[ 3 18 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1464, score:[2827.20], loss:[1.52230], sequence:[11], random actions:[23], eInit:[0.0100], init state:[ 6 11 50  0  0  0  0  0], end state:[ 1 11 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1465, score:[2823.60], loss:[1.56194], sequence:[12], random actions:[27], eInit:[0.0100], init state:[ 0  9 22  0  0  0  0  0], end state:[ 2  9 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1466, score:[2834.00], loss:[1.49544], sequence:[13], random actions:[24], eInit:[0.0100], init state:[ 1  5 59  0  0  0  0  0], end state:[ 3  5 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1467, score:[2771.20], loss:[1.47656], sequence:[14], random actions:[35], eInit:[0.0100], init state:[ 2 16 31  0  0  0  0  0], end state:[ 4 16 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1468, score:[2818.40], loss:[1.48620], sequence:[15], random actions:[33], eInit:[0.0100], init state:[2 0 1 1 0 0 0 0], end state:[4 0 1 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1469, score:[2776.40], loss:[1.84547], sequence:[16], random actions:[39], eInit:[0.0100], init state:[ 5 20 13  1  0  0  0  0], end state:[ 0 20 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1470, score:[2827.60], loss:[1.68657], sequence:[17], random actions:[30], eInit:[0.0100], init state:[ 6 23 20  1  0  0  1  0], end state:[ 1 23 20  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1471, score:[2809.60], loss:[1.60608], sequence:[18], random actions:[32], eInit:[0.0100], init state:[ 1 12 37  0  0  0  0  0], end state:[ 3 12 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1472, score:[2781.60], loss:[1.58825], sequence:[19], random actions:[39], eInit:[0.0100], init state:[ 6  1 49  0  0  0  0  0], end state:[ 1  1 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1473, score:[2810.80], loss:[1.34717], sequence:[20], random actions:[36], eInit:[0.0100], init state:[ 1  3 13  0  0  0  0  0], end state:[ 3  3 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1474, score:[2718.00], loss:[1.61980], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 5  7 42  0  0  0  0  0], end state:[ 0  7 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1475, score:[2749.60], loss:[1.67880], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 4  3 18  0  0  0  0  0], end state:[ 6  3 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1476, score:[2787.60], loss:[1.80060], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 0 15 10  0  0  0  0  0], end state:[ 2 15 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1477, score:[2804.80], loss:[1.64032], sequence:[3], random actions:[38], eInit:[0.0100], init state:[ 1  4 47  0  0  0  0  0], end state:[ 3  4 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1478, score:[2777.20], loss:[1.82249], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 5  1 29  0  0  0  0  0], end state:[ 0  1 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1479, score:[2788.00], loss:[1.78817], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 2 19 59  0  0  0  0  0], end state:[ 4 19 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1480, score:[2829.20], loss:[1.65142], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 2  9 28  0  0  0  0  0], end state:[ 4  9 28  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1481, score:[2812.00], loss:[1.52527], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 3 19 32  0  0  0  0  0], end state:[ 5 19 32  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1482, score:[2823.20], loss:[1.60539], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 0  2 11  0  0  0  0  0], end state:[ 2  2 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1483, score:[2804.40], loss:[1.58283], sequence:[9], random actions:[27], eInit:[0.0100], init state:[ 4 18 10  0  0  0  0  0], end state:[ 6 18 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1484, score:[2778.80], loss:[1.72569], sequence:[10], random actions:[29], eInit:[0.0100], init state:[ 3 20 43  1  1  0  0  0], end state:[ 5 20 43  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1485, score:[2792.00], loss:[1.69916], sequence:[11], random actions:[25], eInit:[0.0100], init state:[ 6 14 37  0  0  0  0  0], end state:[ 1 14 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1486, score:[2802.00], loss:[1.75166], sequence:[12], random actions:[22], eInit:[0.0100], init state:[ 4 12 34  1  1  0  0  0], end state:[ 6 12 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1487, score:[2797.20], loss:[1.55838], sequence:[13], random actions:[29], eInit:[0.0100], init state:[ 4 18 40  0  0  0  0  0], end state:[ 6 18 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1488, score:[2779.60], loss:[1.41279], sequence:[14], random actions:[35], eInit:[0.0100], init state:[ 2 11 10  0  0  0  0  0], end state:[ 4 11 10  0  0  1  1  0]
INFO:Reinforcement.Functions:episode: 1489, score:[2805.20], loss:[1.78551], sequence:[15], random actions:[24], eInit:[0.0100], init state:[ 6  6 30  0  0  0  0  0], end state:[ 1  6 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1490, score:[2797.60], loss:[1.62201], sequence:[16], random actions:[24], eInit:[0.0100], init state:[ 5  6 12  0  0  0  0  0], end state:[ 0  6 12  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1491, score:[2774.80], loss:[1.82328], sequence:[17], random actions:[35], eInit:[0.0100], init state:[ 4  0 19  1  0  0  0  0], end state:[ 6  0 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1492, score:[2805.20], loss:[1.72983], sequence:[18], random actions:[40], eInit:[0.0100], init state:[ 6 18 51  0  0  0  0  0], end state:[ 1 18 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1493, score:[2808.80], loss:[1.61356], sequence:[19], random actions:[22], eInit:[0.0100], init state:[6 7 4 0 0 0 0 0], end state:[1 7 4 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1494, score:[2826.40], loss:[1.43290], sequence:[20], random actions:[26], eInit:[0.0100], init state:[ 1  9 14  0  0  0  0  0], end state:[ 3  9 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1495, score:[2783.20], loss:[1.70987], sequence:[21], random actions:[31], eInit:[0.0100], init state:[ 4  4 13  0  0  0  0  0], end state:[ 6  4 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1496, score:[2847.20], loss:[1.46195], sequence:[22], random actions:[23], eInit:[0.0100], init state:[ 2 22 58  1  0  0  0  0], end state:[ 4 22 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1497, score:[2791.60], loss:[1.54620], sequence:[23], random actions:[25], eInit:[0.0100], init state:[ 5  6 42  0  0  0  0  0], end state:[ 0  6 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1498, score:[2814.80], loss:[1.53068], sequence:[24], random actions:[30], eInit:[0.0100], init state:[ 1 19  0  0  0  0  0  0], end state:[ 3 19  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1499, score:[2809.20], loss:[1.56118], sequence:[25], random actions:[25], eInit:[0.0100], init state:[ 0  0 42  0  0  1  0  0], end state:[ 2  0 42  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1500, score:[2788.80], loss:[1.62959], sequence:[26], random actions:[30], eInit:[0.0100], init state:[ 4 11 34  1  1  0  0  0], end state:[ 6 11 34  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1501, score:[2822.40], loss:[1.75375], sequence:[27], random actions:[29], eInit:[0.0100], init state:[5 5 3 0 0 0 0 0], end state:[0 5 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1502, score:[2818.00], loss:[1.88334], sequence:[28], random actions:[29], eInit:[0.0100], init state:[ 0  6 21  0  0  0  0  0], end state:[ 2  6 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1503, score:[2793.20], loss:[1.76260], sequence:[29], random actions:[33], eInit:[0.0100], init state:[ 0 14 50  0  0  0  0  0], end state:[ 2 14 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1504, score:[2826.40], loss:[1.61135], sequence:[30], random actions:[22], eInit:[0.0100], init state:[ 0  6 15  0  0  0  0  0], end state:[ 2  6 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1505, score:[2813.20], loss:[1.69256], sequence:[31], random actions:[33], eInit:[0.0100], init state:[ 2 14 33  0  0  0  0  0], end state:[ 4 14 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1506, score:[2719.60], loss:[2.24941], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 22 47  0  0  0  0  0], end state:[ 6 22 47  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1507, score:[2758.00], loss:[1.92550], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 4 11 19  1  1  0  0  0], end state:[ 6 11 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1508, score:[2827.20], loss:[1.70159], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 1 22 14  1  0  0  0  0], end state:[ 3 22 14  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1509, score:[2769.20], loss:[2.00261], sequence:[3], random actions:[21], eInit:[0.0100], init state:[ 5  7 55  0  0  0  0  0], end state:[ 0  7 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1510, score:[2826.80], loss:[1.72698], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 3 23 10  1  0  0  0  0], end state:[ 5 23 10  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1511, score:[2811.60], loss:[1.73375], sequence:[5], random actions:[26], eInit:[0.0100], init state:[ 6 14 27  0  0  0  0  0], end state:[ 1 14 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1512, score:[2828.40], loss:[1.74198], sequence:[6], random actions:[24], eInit:[0.0100], init state:[ 0  5 45  0  0  0  0  0], end state:[ 2  5 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1513, score:[2831.60], loss:[1.77821], sequence:[7], random actions:[27], eInit:[0.0100], init state:[ 2  5 13  0  0  0  0  0], end state:[ 4  5 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1514, score:[2800.00], loss:[2.17722], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 0  1 56  0  0  0  0  0], end state:[ 2  1 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1515, score:[2782.40], loss:[1.92332], sequence:[9], random actions:[30], eInit:[0.0100], init state:[ 6 16 15  0  0  0  0  0], end state:[ 1 16 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1516, score:[2830.00], loss:[1.83038], sequence:[10], random actions:[26], eInit:[0.0100], init state:[ 1 16 17  0  0  0  0  0], end state:[ 3 16 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1517, score:[2831.20], loss:[1.65023], sequence:[11], random actions:[26], eInit:[0.0100], init state:[ 1 14 49  0  0  0  0  0], end state:[ 3 14 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1518, score:[2768.80], loss:[1.64552], sequence:[12], random actions:[31], eInit:[0.0100], init state:[ 4 16 44  0  0  0  0  0], end state:[ 6 16 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1519, score:[2837.20], loss:[1.52668], sequence:[13], random actions:[24], eInit:[0.0100], init state:[ 0 13 20  0  0  0  0  0], end state:[ 2 13 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1520, score:[2789.60], loss:[1.92293], sequence:[14], random actions:[46], eInit:[0.0100], init state:[ 6 11 42  0  0  0  0  0], end state:[ 1 11 42  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1521, score:[2816.80], loss:[1.76702], sequence:[15], random actions:[33], eInit:[0.0100], init state:[ 6 11 42  0  0  0  0  0], end state:[ 1 11 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1522, score:[2801.20], loss:[1.70762], sequence:[16], random actions:[34], eInit:[0.0100], init state:[ 6 21 56  1  0  0  0  0], end state:[ 1 21 56  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1523, score:[2752.40], loss:[2.02670], sequence:[17], random actions:[29], eInit:[0.0100], init state:[4 5 8 0 0 0 0 0], end state:[6 5 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1524, score:[2835.60], loss:[2.05265], sequence:[18], random actions:[19], eInit:[0.0100], init state:[1 8 7 1 0 0 0 0], end state:[3 8 7 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1525, score:[2828.00], loss:[1.75866], sequence:[19], random actions:[32], eInit:[0.0100], init state:[ 0  9 15  0  0  0  0  0], end state:[ 2  9 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1526, score:[2771.60], loss:[1.81137], sequence:[20], random actions:[30], eInit:[0.0100], init state:[ 5  3 56  0  0  0  0  0], end state:[ 0  3 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1527, score:[2828.00], loss:[1.73508], sequence:[21], random actions:[30], eInit:[0.0100], init state:[6 9 6 0 0 0 0 0], end state:[1 9 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1528, score:[2792.40], loss:[1.72904], sequence:[22], random actions:[35], eInit:[0.0100], init state:[ 3  8 20  1  0  0  0  0], end state:[ 5  8 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1529, score:[2824.40], loss:[1.53609], sequence:[23], random actions:[28], eInit:[0.0100], init state:[ 1  7 13  0  0  0  0  0], end state:[ 3  7 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1530, score:[2809.20], loss:[1.40217], sequence:[24], random actions:[20], eInit:[0.0100], init state:[ 6 16 15  0  0  0  0  0], end state:[ 1 16 15  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1531, score:[2812.80], loss:[1.43871], sequence:[25], random actions:[34], eInit:[0.0100], init state:[ 1 19  6  0  0  0  0  0], end state:[ 3 19  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1532, score:[2735.20], loss:[1.98538], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 6  2 23  0  0  0  0  0], end state:[ 1  2 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1533, score:[2830.40], loss:[1.62428], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 0  6 21  0  0  0  0  0], end state:[ 2  6 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1534, score:[2794.00], loss:[1.73379], sequence:[2], random actions:[30], eInit:[0.0100], init state:[5 2 7 0 0 0 0 0], end state:[0 2 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1535, score:[2822.80], loss:[1.79848], sequence:[3], random actions:[25], eInit:[0.0100], init state:[1 6 2 0 0 0 0 0], end state:[3 6 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1536, score:[2773.60], loss:[1.82301], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 4 12 11  1  1  0  0  0], end state:[ 6 12 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1537, score:[2790.00], loss:[1.73240], sequence:[5], random actions:[24], eInit:[0.0100], init state:[5 9 7 0 0 0 0 0], end state:[0 9 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1538, score:[2802.00], loss:[1.70216], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 2  2 22  0  0  0  0  0], end state:[ 4  2 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1539, score:[2810.80], loss:[1.75251], sequence:[7], random actions:[38], eInit:[0.0100], init state:[ 0 12 23  0  0  0  0  0], end state:[ 2 12 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1540, score:[2790.40], loss:[1.71645], sequence:[8], random actions:[37], eInit:[0.0100], init state:[ 2 11 16  0  0  0  0  0], end state:[ 4 11 16  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1541, score:[2806.80], loss:[1.84869], sequence:[9], random actions:[27], eInit:[0.0100], init state:[ 2 12 26  0  0  0  0  0], end state:[ 4 12 26  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1542, score:[2755.60], loss:[1.99602], sequence:[10], random actions:[20], eInit:[0.0100], init state:[ 2 16 52  0  0  0  0  0], end state:[ 4 16 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1543, score:[2766.80], loss:[2.37691], sequence:[11], random actions:[16], eInit:[0.0100], init state:[ 4  7 42  0  0  0  0  0], end state:[ 6  7 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1544, score:[2823.20], loss:[2.20873], sequence:[12], random actions:[26], eInit:[0.0100], init state:[ 5 22 39  1  0  0  1  0], end state:[ 0 22 39  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1545, score:[2782.80], loss:[1.89861], sequence:[13], random actions:[36], eInit:[0.0100], init state:[ 1 15 23  0  0  0  0  0], end state:[ 3 15 23  1  0  1  1  1]
INFO:Reinforcement.Functions:episode: 1546, score:[2783.20], loss:[1.95240], sequence:[14], random actions:[30], eInit:[0.0100], init state:[ 3 12 28  0  0  0  0  0], end state:[ 5 12 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1547, score:[2798.00], loss:[1.91143], sequence:[15], random actions:[38], eInit:[0.0100], init state:[ 3  4 46  0  0  0  0  0], end state:[ 5  4 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1548, score:[2760.00], loss:[1.89578], sequence:[16], random actions:[34], eInit:[0.0100], init state:[ 2 16 10  0  0  0  0  0], end state:[ 4 16 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1549, score:[2788.40], loss:[2.00504], sequence:[17], random actions:[42], eInit:[0.0100], init state:[ 3  0 54  0  0  1  0  0], end state:[ 5  0 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1550, score:[2758.80], loss:[2.07898], sequence:[18], random actions:[31], eInit:[0.0100], init state:[ 4 17 28  0  0  0  0  0], end state:[ 6 17 28  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1551, score:[2824.00], loss:[2.02005], sequence:[19], random actions:[31], eInit:[0.0100], init state:[ 2  5 28  0  0  0  0  0], end state:[ 4  5 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1552, score:[2753.20], loss:[2.12705], sequence:[20], random actions:[37], eInit:[0.0100], init state:[ 6  3 18  0  0  0  0  0], end state:[ 1  3 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1553, score:[2820.00], loss:[2.09518], sequence:[21], random actions:[25], eInit:[0.0100], init state:[ 2 22 35  1  0  0  0  0], end state:[ 4 22 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1554, score:[2834.40], loss:[2.02575], sequence:[22], random actions:[25], eInit:[0.0100], init state:[ 0 15 14  0  0  0  0  0], end state:[ 2 15 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1555, score:[2776.80], loss:[2.24272], sequence:[23], random actions:[25], eInit:[0.0100], init state:[ 5 12 38  0  0  0  0  0], end state:[ 0 12 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1556, score:[2762.80], loss:[2.29798], sequence:[24], random actions:[27], eInit:[0.0100], init state:[ 2 18 11  0  0  0  0  0], end state:[ 4 18 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1557, score:[2822.00], loss:[2.22957], sequence:[25], random actions:[34], eInit:[0.0100], init state:[ 2 20 31  1  1  0  0  0], end state:[ 4 20 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1558, score:[2792.00], loss:[2.41764], sequence:[26], random actions:[22], eInit:[0.0100], init state:[ 5 23 34  1  0  0  0  0], end state:[ 0 23 34  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1559, score:[2834.40], loss:[2.11491], sequence:[27], random actions:[26], eInit:[0.0100], init state:[ 0 22 13  1  0  0  0  0], end state:[ 2 22 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1560, score:[2768.00], loss:[2.07746], sequence:[28], random actions:[32], eInit:[0.0100], init state:[ 4 21 19  0  0  0  0  0], end state:[ 6 21 19  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1561, score:[2772.00], loss:[2.08945], sequence:[29], random actions:[39], eInit:[0.0100], init state:[ 6  0 29  1  0  0  0  0], end state:[ 1  0 29  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1562, score:[2772.00], loss:[2.19601], sequence:[30], random actions:[30], eInit:[0.0100], init state:[ 6  6 17  0  0  0  0  0], end state:[ 1  6 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1563, score:[2820.00], loss:[2.02436], sequence:[31], random actions:[27], eInit:[0.0100], init state:[ 1  1 25  0  0  0  0  0], end state:[ 3  1 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1564, score:[2812.80], loss:[2.09287], sequence:[32], random actions:[27], eInit:[0.0100], init state:[ 1 13 18  0  0  0  0  0], end state:[ 3 13 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1565, score:[2782.40], loss:[2.13382], sequence:[33], random actions:[33], eInit:[0.0100], init state:[ 4 14 38  0  0  0  0  0], end state:[ 6 14 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1566, score:[2755.20], loss:[2.23193], sequence:[34], random actions:[25], eInit:[0.0100], init state:[ 4  1 55  0  0  0  0  0], end state:[ 6  1 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1567, score:[2808.40], loss:[2.26881], sequence:[35], random actions:[37], eInit:[0.0100], init state:[ 2  5 17  0  0  0  0  0], end state:[ 4  5 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1568, score:[2752.80], loss:[2.40261], sequence:[36], random actions:[28], eInit:[0.0100], init state:[ 6  4 27  0  0  0  0  0], end state:[ 1  4 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1569, score:[2823.20], loss:[2.25019], sequence:[37], random actions:[35], eInit:[0.0100], init state:[ 2 10 54  0  0  0  0  0], end state:[ 4 10 54  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1570, score:[2796.00], loss:[2.39187], sequence:[38], random actions:[37], eInit:[0.0100], init state:[ 6  9 24  0  0  0  0  0], end state:[ 1  9 24  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1571, score:[2683.20], loss:[2.85604], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 11 38  1  1  0  0  0], end state:[ 6 11 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1572, score:[2832.00], loss:[2.61929], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 1 22 52  1  0  0  0  0], end state:[ 3 22 52  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1573, score:[2787.20], loss:[2.14089], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 5 19 16  1  0  0  1  0], end state:[ 0 19 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1574, score:[2815.60], loss:[2.13156], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 2  0 45  0  0  1  0  0], end state:[ 4  0 45  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1575, score:[2839.60], loss:[1.96090], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 2  3 36  0  0  0  0  0], end state:[ 4  3 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1576, score:[2828.40], loss:[1.92581], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 2 12 42  0  0  0  0  0], end state:[ 4 12 42  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1577, score:[2781.20], loss:[2.33849], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 6 10 43  0  0  0  0  0], end state:[ 1 10 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1578, score:[2827.20], loss:[2.07753], sequence:[7], random actions:[24], eInit:[0.0100], init state:[ 1 22 13  1  0  0  0  0], end state:[ 3 22 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1579, score:[2823.20], loss:[1.87349], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 3  2 21  0  0  0  0  0], end state:[ 5  2 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1580, score:[2762.40], loss:[2.01991], sequence:[9], random actions:[31], eInit:[0.0100], init state:[5 4 1 0 0 0 0 0], end state:[0 4 1 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1581, score:[2825.20], loss:[2.03127], sequence:[10], random actions:[27], eInit:[0.0100], init state:[ 0 15 54  0  0  0  0  0], end state:[ 2 15 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1582, score:[2819.60], loss:[1.77858], sequence:[11], random actions:[27], eInit:[0.0100], init state:[ 1 14 34  0  0  0  0  0], end state:[ 3 14 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1583, score:[2811.20], loss:[1.89824], sequence:[12], random actions:[18], eInit:[0.0100], init state:[ 5 19 18  1  0  0  1  0], end state:[ 0 19 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1584, score:[2778.00], loss:[1.78045], sequence:[13], random actions:[19], eInit:[0.0100], init state:[ 5 12 27  0  0  0  0  0], end state:[ 0 12 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1585, score:[2808.80], loss:[1.69498], sequence:[14], random actions:[34], eInit:[0.0100], init state:[ 2  7 58  0  0  0  0  0], end state:[ 4  7 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1586, score:[2759.20], loss:[1.80352], sequence:[15], random actions:[31], eInit:[0.0100], init state:[ 4 12 52  1  1  0  1  0], end state:[ 6 12 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1587, score:[2836.00], loss:[1.62687], sequence:[16], random actions:[24], eInit:[0.0100], init state:[ 3  9 20  0  0  0  0  0], end state:[ 5  9 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1588, score:[2805.60], loss:[1.55640], sequence:[17], random actions:[28], eInit:[0.0100], init state:[ 3 14 11  0  0  0  0  0], end state:[ 5 14 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1589, score:[2828.00], loss:[1.43094], sequence:[18], random actions:[31], eInit:[0.0100], init state:[ 1 23 27  1  0  0  1  0], end state:[ 3 23 27  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1590, score:[2801.60], loss:[1.56688], sequence:[19], random actions:[26], eInit:[0.0100], init state:[ 1 10 13  0  0  0  0  0], end state:[ 3 10 13  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1591, score:[2827.20], loss:[1.36213], sequence:[20], random actions:[31], eInit:[0.0100], init state:[ 1 14 38  0  0  0  0  0], end state:[ 3 14 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1592, score:[2818.00], loss:[1.51874], sequence:[21], random actions:[32], eInit:[0.0100], init state:[ 2  1 26  0  0  0  0  0], end state:[ 4  1 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1593, score:[2833.20], loss:[1.42055], sequence:[22], random actions:[23], eInit:[0.0100], init state:[ 0 14 58  0  0  0  0  0], end state:[ 2 14 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1594, score:[2816.80], loss:[2.09561], sequence:[23], random actions:[34], eInit:[0.0100], init state:[1 3 2 0 0 0 0 0], end state:[3 3 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1595, score:[2655.60], loss:[2.15430], sequence:[0], random actions:[39], eInit:[0.0100], init state:[ 4 19  1  0  0  0  0  0], end state:[ 6 19  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1596, score:[2771.60], loss:[1.94738], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 1 20 18  0  0  0  0  0], end state:[ 3 20 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1597, score:[2796.40], loss:[1.69595], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 4  0 27  1  0  0  0  0], end state:[ 6  0 27  0  1  0  0  1]
INFO:Reinforcement.Functions:episode: 1598, score:[2826.00], loss:[1.56310], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 1 13 38  0  0  0  0  0], end state:[ 3 13 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1599, score:[2830.00], loss:[1.37316], sequence:[4], random actions:[37], eInit:[0.0100], init state:[ 1 22  0  1  0  0  0  0], end state:[ 3 22  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1600, score:[2832.80], loss:[1.31382], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 1  1 34  0  0  0  0  0], end state:[ 3  1 34  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1601, score:[2760.00], loss:[1.37427], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 4 23 33  0  0  0  0  0], end state:[ 6 23 33  1  1  1  1  1]
INFO:Reinforcement.Functions:episode: 1602, score:[2812.80], loss:[1.43157], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 1 17 57  0  0  0  0  0], end state:[ 3 17 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1603, score:[2799.20], loss:[1.60763], sequence:[8], random actions:[25], eInit:[0.0100], init state:[ 5 18 56  1  1  0  1  0], end state:[ 0 18 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1604, score:[2797.20], loss:[1.64027], sequence:[9], random actions:[31], eInit:[0.0100], init state:[ 6  3 30  0  0  0  0  0], end state:[ 1  3 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1605, score:[2842.80], loss:[1.56180], sequence:[10], random actions:[21], eInit:[0.0100], init state:[ 1 22 44  1  0  0  0  0], end state:[ 3 22 44  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1606, score:[2826.80], loss:[1.47284], sequence:[11], random actions:[32], eInit:[0.0100], init state:[ 1  6 48  0  0  0  0  0], end state:[ 3  6 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1607, score:[2824.80], loss:[1.42157], sequence:[12], random actions:[29], eInit:[0.0100], init state:[ 6 15 11  0  0  0  0  0], end state:[ 1 15 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1608, score:[2846.80], loss:[1.29087], sequence:[13], random actions:[24], eInit:[0.0100], init state:[ 1 16 49  0  0  0  0  0], end state:[ 3 16 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1609, score:[2787.60], loss:[1.28251], sequence:[14], random actions:[29], eInit:[0.0100], init state:[ 2 18 30  0  0  0  0  0], end state:[ 4 18 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1610, score:[2770.40], loss:[1.66396], sequence:[15], random actions:[41], eInit:[0.0100], init state:[ 3 18 49  0  0  0  0  0], end state:[ 5 18 49  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1611, score:[2820.40], loss:[1.59964], sequence:[16], random actions:[33], eInit:[0.0100], init state:[ 6  9 16  0  0  0  0  0], end state:[ 1  9 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1612, score:[2769.20], loss:[1.83891], sequence:[17], random actions:[30], eInit:[0.0100], init state:[ 5 12  3  0  0  0  0  0], end state:[ 0 12  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1613, score:[2820.80], loss:[1.62483], sequence:[18], random actions:[25], eInit:[0.0100], init state:[ 5  6 30  0  0  0  0  0], end state:[ 0  6 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1614, score:[2709.60], loss:[1.73086], sequence:[0], random actions:[31], eInit:[0.0100], init state:[ 2 17 15  0  0  0  0  0], end state:[ 4 17 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1615, score:[2806.80], loss:[2.02699], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 3  7 57  0  0  0  0  0], end state:[ 5  7 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1616, score:[2838.80], loss:[1.77250], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 1 14 19  0  0  0  0  0], end state:[ 3 14 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1617, score:[2798.80], loss:[1.94582], sequence:[3], random actions:[32], eInit:[0.0100], init state:[ 0 11 24  0  0  0  0  0], end state:[ 2 11 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1618, score:[2739.20], loss:[1.89286], sequence:[4], random actions:[41], eInit:[0.0100], init state:[ 3 22 43  1  0  0  0  0], end state:[ 5 22 43  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1619, score:[2738.00], loss:[2.31200], sequence:[5], random actions:[31], eInit:[0.0100], init state:[ 4  5 39  0  0  0  0  0], end state:[ 6  5 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1620, score:[2788.80], loss:[2.38257], sequence:[6], random actions:[25], eInit:[0.0100], init state:[ 6  1 45  0  0  0  0  0], end state:[ 1  1 45  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1621, score:[2745.60], loss:[2.38063], sequence:[7], random actions:[33], eInit:[0.0100], init state:[ 5  8 20  0  0  0  0  0], end state:[ 0  8 20  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1622, score:[2828.00], loss:[2.24191], sequence:[8], random actions:[23], eInit:[0.0100], init state:[ 5 14 51  0  0  0  0  0], end state:[ 0 14 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1623, score:[2828.00], loss:[2.14166], sequence:[9], random actions:[32], eInit:[0.0100], init state:[ 2 22 16  1  0  0  0  0], end state:[ 4 22 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1624, score:[2742.80], loss:[2.55530], sequence:[10], random actions:[40], eInit:[0.0100], init state:[4 6 8 0 0 0 0 0], end state:[6 6 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1625, score:[2787.60], loss:[2.68940], sequence:[11], random actions:[27], eInit:[0.0100], init state:[ 2 16 40  0  0  0  0  0], end state:[ 4 16 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1626, score:[2760.00], loss:[2.79522], sequence:[12], random actions:[42], eInit:[0.0100], init state:[ 5 21 57  1  0  0  1  0], end state:[ 0 21 57  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1627, score:[2831.60], loss:[2.65295], sequence:[13], random actions:[20], eInit:[0.0100], init state:[ 0 17  0  0  0  0  0  0], end state:[ 2 17  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1628, score:[2806.40], loss:[2.41117], sequence:[14], random actions:[23], eInit:[0.0100], init state:[ 2 14 19  0  0  0  0  0], end state:[ 4 14 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1629, score:[2838.80], loss:[2.35789], sequence:[15], random actions:[16], eInit:[0.0100], init state:[ 1 13  0  0  0  0  0  0], end state:[ 3 13  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1630, score:[2805.60], loss:[2.54065], sequence:[16], random actions:[24], eInit:[0.0100], init state:[ 0 16 45  0  0  0  0  0], end state:[ 2 16 45  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1631, score:[2750.80], loss:[2.41760], sequence:[17], random actions:[36], eInit:[0.0100], init state:[ 5  3 19  0  0  0  0  0], end state:[ 0  3 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1632, score:[2796.40], loss:[2.46496], sequence:[18], random actions:[28], eInit:[0.0100], init state:[ 5 22 31  1  0  0  1  0], end state:[ 0 22 31  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1633, score:[2810.00], loss:[2.57259], sequence:[19], random actions:[26], eInit:[0.0100], init state:[ 5 11 51  0  0  0  0  0], end state:[ 0 11 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1634, score:[2825.60], loss:[2.30519], sequence:[20], random actions:[29], eInit:[0.0100], init state:[1 9 8 0 0 0 0 0], end state:[3 9 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1635, score:[2788.40], loss:[2.28677], sequence:[21], random actions:[27], eInit:[0.0100], init state:[ 4  3 34  0  0  0  0  0], end state:[ 6  3 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1636, score:[2811.20], loss:[2.35117], sequence:[22], random actions:[24], eInit:[0.0100], init state:[ 6 15 32  0  0  0  0  0], end state:[ 1 15 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1637, score:[2774.80], loss:[2.41278], sequence:[23], random actions:[34], eInit:[0.0100], init state:[ 5 22 39  1  0  0  1  0], end state:[ 0 22 39  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1638, score:[2793.60], loss:[2.37285], sequence:[24], random actions:[37], eInit:[0.0100], init state:[ 1  5 48  0  0  0  0  0], end state:[ 3  5 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1639, score:[2752.00], loss:[2.82106], sequence:[25], random actions:[44], eInit:[0.0100], init state:[ 5  2 17  0  0  0  0  0], end state:[ 0  2 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1640, score:[2778.40], loss:[2.87002], sequence:[26], random actions:[34], eInit:[0.0100], init state:[ 3 18 21  0  0  0  0  0], end state:[ 5 18 21  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1641, score:[2775.60], loss:[2.67943], sequence:[27], random actions:[24], eInit:[0.0100], init state:[ 2 18  9  0  0  0  0  0], end state:[ 4 18  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1642, score:[2786.00], loss:[2.58124], sequence:[28], random actions:[25], eInit:[0.0100], init state:[ 5 19 18  1  0  0  1  0], end state:[ 0 19 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1643, score:[2843.20], loss:[2.20109], sequence:[29], random actions:[26], eInit:[0.0100], init state:[ 0  0 51  0  0  1  0  0], end state:[ 2  0 51  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1644, score:[2834.40], loss:[1.87733], sequence:[30], random actions:[27], eInit:[0.0100], init state:[ 1 22 57  1  0  0  0  0], end state:[ 3 22 57  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1645, score:[2787.60], loss:[1.96010], sequence:[31], random actions:[26], eInit:[0.0100], init state:[ 6  3 30  0  0  0  0  0], end state:[ 1  3 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1646, score:[2799.60], loss:[2.05950], sequence:[32], random actions:[22], eInit:[0.0100], init state:[ 3 12 38  0  0  0  0  0], end state:[ 5 12 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1647, score:[2783.20], loss:[1.95243], sequence:[33], random actions:[24], eInit:[0.0100], init state:[ 3  4 38  0  0  0  0  0], end state:[ 5  4 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1648, score:[2819.20], loss:[2.01972], sequence:[34], random actions:[31], eInit:[0.0100], init state:[2 7 6 0 0 0 0 0], end state:[4 7 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1649, score:[2804.40], loss:[2.00883], sequence:[35], random actions:[31], eInit:[0.0100], init state:[ 6 19 41  0  0  0  0  0], end state:[ 1 19 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1650, score:[2815.60], loss:[2.16087], sequence:[36], random actions:[31], eInit:[0.0100], init state:[6 7 3 0 0 0 0 0], end state:[1 7 3 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1651, score:[2722.00], loss:[2.29482], sequence:[0], random actions:[22], eInit:[0.0100], init state:[ 4 19 35  0  0  0  0  0], end state:[ 6 19 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1652, score:[2821.20], loss:[2.13421], sequence:[1], random actions:[29], eInit:[0.0100], init state:[ 1 20 21  0  0  0  0  0], end state:[ 3 20 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1653, score:[2831.60], loss:[1.88535], sequence:[2], random actions:[22], eInit:[0.0100], init state:[2 5 5 0 0 0 0 0], end state:[4 5 5 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1654, score:[2743.20], loss:[2.04364], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 5  6 20  0  0  0  0  0], end state:[ 0  6 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1655, score:[2814.80], loss:[1.95677], sequence:[4], random actions:[20], eInit:[0.0100], init state:[ 6  6 28  0  0  0  0  0], end state:[ 1  6 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1656, score:[2810.80], loss:[1.93476], sequence:[5], random actions:[18], eInit:[0.0100], init state:[ 5  6 46  0  0  0  0  0], end state:[ 0  6 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1657, score:[2764.80], loss:[1.75821], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 4 22 25  0  0  0  0  0], end state:[ 6 22 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1658, score:[2768.80], loss:[2.11409], sequence:[7], random actions:[35], eInit:[0.0100], init state:[ 5  1 39  0  0  0  0  0], end state:[ 0  1 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1659, score:[2738.80], loss:[2.16436], sequence:[8], random actions:[28], eInit:[0.0100], init state:[3 6 2 0 0 0 0 0], end state:[5 6 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1660, score:[2810.80], loss:[2.36858], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 2 23  7  1  0  0  0  0], end state:[ 4 23  7  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1661, score:[2826.80], loss:[2.18566], sequence:[10], random actions:[25], eInit:[0.0100], init state:[ 0 16 30  0  0  0  0  0], end state:[ 2 16 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1662, score:[2805.60], loss:[2.18886], sequence:[11], random actions:[34], eInit:[0.0100], init state:[ 4 20  5  0  0  0  0  0], end state:[ 6 20  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1663, score:[2812.00], loss:[2.00995], sequence:[12], random actions:[29], eInit:[0.0100], init state:[ 6 22 46  1  0  0  0  0], end state:[ 1 22 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1664, score:[2768.80], loss:[2.25928], sequence:[13], random actions:[30], eInit:[0.0100], init state:[ 2 21 37  1  0  0  0  0], end state:[ 4 21 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1665, score:[2797.60], loss:[2.43500], sequence:[14], random actions:[30], eInit:[0.0100], init state:[ 3 15 44  0  0  0  0  0], end state:[ 5 15 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1666, score:[2831.60], loss:[2.19440], sequence:[15], random actions:[23], eInit:[0.0100], init state:[ 2  5 15  0  0  0  0  0], end state:[ 4  5 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1667, score:[2806.40], loss:[2.12489], sequence:[16], random actions:[30], eInit:[0.0100], init state:[ 0  7 21  0  0  0  0  0], end state:[ 2  7 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1668, score:[2715.60], loss:[2.55778], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 4 21 59  0  0  0  0  0], end state:[ 6 21 59  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1669, score:[2772.80], loss:[2.53276], sequence:[1], random actions:[30], eInit:[0.0100], init state:[ 3 14 22  0  0  0  0  0], end state:[ 5 14 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1670, score:[2828.00], loss:[2.25666], sequence:[2], random actions:[20], eInit:[0.0100], init state:[0 7 7 0 0 0 0 0], end state:[2 7 7 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1671, score:[2797.60], loss:[2.31154], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 3  3 13  0  0  0  0  0], end state:[ 5  3 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1672, score:[2833.60], loss:[2.10677], sequence:[4], random actions:[19], eInit:[0.0100], init state:[ 0 21 43  1  0  0  0  0], end state:[ 2 21 43  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1673, score:[2704.80], loss:[2.39523], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 16 54  0  0  0  0  0], end state:[ 0 16 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1674, score:[2820.80], loss:[2.29055], sequence:[1], random actions:[24], eInit:[0.0100], init state:[1 3 8 0 0 0 0 0], end state:[3 3 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1675, score:[2784.80], loss:[2.06673], sequence:[2], random actions:[30], eInit:[0.0100], init state:[ 2 21 33  1  0  0  0  0], end state:[ 4 21 33  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1676, score:[2759.20], loss:[2.31102], sequence:[3], random actions:[38], eInit:[0.0100], init state:[ 3 10 57  0  0  0  0  0], end state:[ 5 10 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1677, score:[2768.00], loss:[2.40293], sequence:[4], random actions:[32], eInit:[0.0100], init state:[ 6  3 30  0  0  0  0  0], end state:[ 1  3 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1678, score:[2826.00], loss:[2.14267], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 2  6 54  0  0  0  0  0], end state:[ 4  6 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1679, score:[2816.40], loss:[1.87405], sequence:[6], random actions:[19], eInit:[0.0100], init state:[ 3  6 17  0  0  0  0  0], end state:[ 5  6 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1680, score:[2826.00], loss:[1.84211], sequence:[7], random actions:[19], eInit:[0.0100], init state:[ 6 18 22  0  0  0  0  0], end state:[ 1 18 22  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1681, score:[2712.80], loss:[2.02098], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  8 54  0  0  0  0  0], end state:[ 0  8 54  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1682, score:[2741.20], loss:[2.35669], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 5 15 18  0  0  0  0  0], end state:[ 0 15 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1683, score:[2806.40], loss:[2.03328], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 2 11 24  0  0  0  0  0], end state:[ 4 11 24  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1684, score:[2810.00], loss:[2.07300], sequence:[3], random actions:[34], eInit:[0.0100], init state:[ 0 10 25  0  0  0  0  0], end state:[ 2 10 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1685, score:[2786.40], loss:[1.97253], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 5  2 49  0  0  0  0  0], end state:[ 0  2 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1686, score:[2803.20], loss:[1.99874], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 6 12 35  0  0  0  0  0], end state:[ 1 12 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1687, score:[2814.40], loss:[1.85026], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 3  9 24  0  0  0  0  0], end state:[ 5  9 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1688, score:[2786.00], loss:[1.95855], sequence:[7], random actions:[39], eInit:[0.0100], init state:[ 5 19 19  1  0  0  1  0], end state:[ 0 19 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1689, score:[2815.60], loss:[2.03595], sequence:[8], random actions:[30], eInit:[0.0100], init state:[ 6 23  1  1  0  0  0  0], end state:[ 1 23  1  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1690, score:[2771.20], loss:[2.18629], sequence:[9], random actions:[27], eInit:[0.0100], init state:[ 4  7 21  0  0  0  0  0], end state:[ 6  7 21  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1691, score:[2828.80], loss:[2.05557], sequence:[10], random actions:[27], eInit:[0.0100], init state:[ 3 11 33  0  0  0  0  0], end state:[ 5 11 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1692, score:[2738.00], loss:[2.19719], sequence:[11], random actions:[26], eInit:[0.0100], init state:[ 5 15 59  0  0  0  0  0], end state:[ 0 15 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1693, score:[2814.80], loss:[2.08648], sequence:[12], random actions:[22], eInit:[0.0100], init state:[5 3 3 0 0 0 0 0], end state:[0 3 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1694, score:[2826.40], loss:[2.12962], sequence:[13], random actions:[20], eInit:[0.0100], init state:[1 7 0 0 0 0 0 0], end state:[3 7 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1695, score:[2824.00], loss:[2.15191], sequence:[14], random actions:[30], eInit:[0.0100], init state:[ 1 17 58  0  0  0  0  0], end state:[ 3 17 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1696, score:[2776.40], loss:[2.18906], sequence:[15], random actions:[44], eInit:[0.0100], init state:[ 3  6 15  0  0  0  0  0], end state:[ 5  6 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1697, score:[2791.20], loss:[2.00350], sequence:[16], random actions:[34], eInit:[0.0100], init state:[ 0  3 10  0  0  0  0  0], end state:[ 2  3 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1698, score:[2776.00], loss:[2.07781], sequence:[17], random actions:[21], eInit:[0.0100], init state:[ 4 14  1  0  0  0  0  0], end state:[ 6 14  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1699, score:[2807.60], loss:[1.92672], sequence:[18], random actions:[32], eInit:[0.0100], init state:[ 1 23 26  1  0  0  1  0], end state:[ 3 23 26  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1700, score:[2825.20], loss:[1.84668], sequence:[19], random actions:[29], eInit:[0.0100], init state:[ 2  0 45  0  0  1  0  0], end state:[ 4  0 45  1  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1701, score:[2773.60], loss:[1.79922], sequence:[20], random actions:[30], eInit:[0.0100], init state:[ 4 10 12  1  1  0  1  1], end state:[ 6 10 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1702, score:[2786.80], loss:[2.15827], sequence:[21], random actions:[25], eInit:[0.0100], init state:[ 5 18 34  1  1  0  1  0], end state:[ 0 18 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1703, score:[2817.60], loss:[2.08018], sequence:[22], random actions:[25], eInit:[0.0100], init state:[ 2  0 29  1  0  0  0  0], end state:[ 4  0 29  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1704, score:[2775.20], loss:[2.05295], sequence:[23], random actions:[33], eInit:[0.0100], init state:[ 2 22 36  1  0  0  0  0], end state:[ 4 22 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1705, score:[2827.20], loss:[2.05198], sequence:[24], random actions:[29], eInit:[0.0100], init state:[ 1 21  2  1  1  0  1  0], end state:[ 3 21  2  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1706, score:[2821.20], loss:[2.00730], sequence:[25], random actions:[34], eInit:[0.0100], init state:[ 1 21  2  1  1  0  1  0], end state:[ 3 21  2  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1707, score:[2791.20], loss:[2.08983], sequence:[26], random actions:[36], eInit:[0.0100], init state:[ 5 23 31  1  0  0  0  0], end state:[ 0 23 31  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1708, score:[2823.60], loss:[2.08578], sequence:[27], random actions:[25], eInit:[0.0100], init state:[ 6 19  2  0  0  0  0  0], end state:[ 1 19  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1709, score:[2818.00], loss:[1.89934], sequence:[28], random actions:[29], eInit:[0.0100], init state:[ 0 19 20  0  0  0  0  0], end state:[ 2 19 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1710, score:[2802.00], loss:[1.83229], sequence:[29], random actions:[28], eInit:[0.0100], init state:[ 6  6 18  0  0  0  0  0], end state:[ 1  6 18  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1711, score:[2768.40], loss:[2.10938], sequence:[30], random actions:[47], eInit:[0.0100], init state:[ 3 17 20  0  0  0  0  0], end state:[ 5 17 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1712, score:[2807.60], loss:[1.98335], sequence:[31], random actions:[34], eInit:[0.0100], init state:[ 2  2 42  0  0  0  0  0], end state:[ 4  2 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1713, score:[2810.80], loss:[2.00918], sequence:[32], random actions:[18], eInit:[0.0100], init state:[ 3  2 47  0  0  0  0  0], end state:[ 5  2 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1714, score:[2794.80], loss:[1.94909], sequence:[33], random actions:[25], eInit:[0.0100], init state:[ 4 13 40  0  0  0  0  0], end state:[ 6 13 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1715, score:[2797.20], loss:[1.87163], sequence:[34], random actions:[20], eInit:[0.0100], init state:[ 3 22 26  1  0  0  0  0], end state:[ 5 22 26  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1716, score:[2834.00], loss:[1.71686], sequence:[35], random actions:[26], eInit:[0.0100], init state:[ 0  0 47  0  0  1  0  0], end state:[ 2  0 47  1  1  0  1  1]
INFO:Reinforcement.Functions:episode: 1717, score:[2834.00], loss:[1.58894], sequence:[36], random actions:[31], eInit:[0.0100], init state:[2 7 2 0 0 0 0 0], end state:[4 7 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1718, score:[2821.60], loss:[1.58502], sequence:[37], random actions:[30], eInit:[0.0100], init state:[2 6 8 0 0 0 0 0], end state:[4 6 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1719, score:[2818.00], loss:[1.61039], sequence:[38], random actions:[24], eInit:[0.0100], init state:[ 3 13 18  0  0  0  0  0], end state:[ 5 13 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1720, score:[2838.80], loss:[1.51814], sequence:[39], random actions:[28], eInit:[0.0100], init state:[ 0  7 44  0  0  0  0  0], end state:[ 2  7 44  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1721, score:[2831.60], loss:[1.45291], sequence:[40], random actions:[22], eInit:[0.0100], init state:[ 1 15 26  0  0  0  0  0], end state:[ 3 15 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1722, score:[2834.80], loss:[1.40423], sequence:[41], random actions:[26], eInit:[0.0100], init state:[ 2  6 28  0  0  0  0  0], end state:[ 4  6 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1723, score:[2844.80], loss:[1.26620], sequence:[42], random actions:[16], eInit:[0.0100], init state:[ 0  3 53  0  0  0  0  0], end state:[ 2  3 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1724, score:[2836.00], loss:[1.23599], sequence:[43], random actions:[29], eInit:[0.0100], init state:[2 5 6 0 0 0 0 0], end state:[4 5 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1725, score:[2772.40], loss:[1.40415], sequence:[44], random actions:[29], eInit:[0.0100], init state:[ 4 19  8  0  0  0  0  0], end state:[ 6 19  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1726, score:[2764.80], loss:[1.55641], sequence:[45], random actions:[37], eInit:[0.0100], init state:[ 3 20 31  1  1  0  0  0], end state:[ 5 20 31  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1727, score:[2785.60], loss:[1.53552], sequence:[46], random actions:[29], eInit:[0.0100], init state:[ 2 16 30  0  0  0  0  0], end state:[ 4 16 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1728, score:[2793.60], loss:[1.99496], sequence:[47], random actions:[22], eInit:[0.0100], init state:[ 4 15 17  0  0  0  0  0], end state:[ 6 15 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1729, score:[2756.00], loss:[1.91602], sequence:[48], random actions:[28], eInit:[0.0100], init state:[ 6  0 30  0  0  1  0  0], end state:[ 1  0 30  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1730, score:[2810.00], loss:[1.85645], sequence:[49], random actions:[35], eInit:[0.0100], init state:[ 6 21 50  1  0  0  0  0], end state:[ 1 21 50  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1731, score:[2801.60], loss:[1.67231], sequence:[50], random actions:[31], eInit:[0.0100], init state:[ 3  6 43  0  0  0  0  0], end state:[ 5  6 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1732, score:[2745.60], loss:[1.87929], sequence:[51], random actions:[28], eInit:[0.0100], init state:[ 5 17 46  0  0  0  0  0], end state:[ 0 17 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1733, score:[2799.60], loss:[1.66174], sequence:[52], random actions:[43], eInit:[0.0100], init state:[ 0 20 30  1  1  0  0  0], end state:[ 2 20 30  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1734, score:[2820.80], loss:[1.73033], sequence:[53], random actions:[35], eInit:[0.0100], init state:[ 1 20  1  0  0  0  0  0], end state:[ 3 20  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1735, score:[2738.80], loss:[1.94132], sequence:[54], random actions:[31], eInit:[0.0100], init state:[ 5 23 17  1  0  0  0  0], end state:[ 0 23 17  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1736, score:[2821.60], loss:[1.85746], sequence:[55], random actions:[26], eInit:[0.0100], init state:[ 0  6 21  0  0  0  0  0], end state:[ 2  6 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1737, score:[2827.20], loss:[1.66897], sequence:[56], random actions:[27], eInit:[0.0100], init state:[ 1 17  6  0  0  0  0  0], end state:[ 3 17  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1738, score:[2765.60], loss:[1.95629], sequence:[57], random actions:[26], eInit:[0.0100], init state:[ 5  4 51  0  0  0  0  0], end state:[ 0  4 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1739, score:[2797.60], loss:[1.82353], sequence:[58], random actions:[23], eInit:[0.0100], init state:[ 4 21 22  0  0  0  0  0], end state:[ 6 21 22  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1740, score:[2824.40], loss:[1.79668], sequence:[59], random actions:[27], eInit:[0.0100], init state:[ 3  0 42  0  0  1  0  0], end state:[ 5  0 42  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1741, score:[2802.40], loss:[1.97117], sequence:[60], random actions:[36], eInit:[0.0100], init state:[ 0 17 40  0  0  0  0  0], end state:[ 2 17 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1742, score:[2844.40], loss:[1.73052], sequence:[61], random actions:[21], eInit:[0.0100], init state:[ 1 15 33  0  0  0  0  0], end state:[ 3 15 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1743, score:[2789.60], loss:[1.70534], sequence:[62], random actions:[23], eInit:[0.0100], init state:[ 5 23 38  1  0  0  0  0], end state:[ 0 23 38  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1744, score:[2788.80], loss:[1.78495], sequence:[63], random actions:[28], eInit:[0.0100], init state:[ 3  9 55  0  0  0  0  0], end state:[ 5  9 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1745, score:[2807.20], loss:[1.83780], sequence:[64], random actions:[30], eInit:[0.0100], init state:[ 2  6 15  0  0  0  0  0], end state:[ 4  6 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1746, score:[2841.20], loss:[1.56645], sequence:[65], random actions:[23], eInit:[0.0100], init state:[0 9 0 0 0 0 0 0], end state:[2 9 0 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1747, score:[2762.80], loss:[1.61392], sequence:[66], random actions:[26], eInit:[0.0100], init state:[ 4  3 30  0  0  0  0  0], end state:[ 6  3 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1748, score:[2725.60], loss:[1.93745], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5 17 34  0  0  0  0  0], end state:[ 0 17 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1749, score:[2786.00], loss:[1.66070], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 2  3 51  0  0  0  0  0], end state:[ 4  3 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1750, score:[2776.00], loss:[1.92186], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 6 17 20  0  0  0  0  0], end state:[ 1 17 20  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1751, score:[2826.40], loss:[1.67627], sequence:[3], random actions:[30], eInit:[0.0100], init state:[ 2  9 54  0  0  0  0  0], end state:[ 4  9 54  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1752, score:[2794.00], loss:[1.81751], sequence:[4], random actions:[46], eInit:[0.0100], init state:[ 1 16 17  0  0  0  0  0], end state:[ 3 16 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1753, score:[2794.00], loss:[1.84120], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 6 11  2  0  0  0  0  0], end state:[ 1 11  2  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1754, score:[2836.00], loss:[1.71291], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 1 10  8  0  0  0  0  0], end state:[ 3 10  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1755, score:[2812.80], loss:[1.62683], sequence:[7], random actions:[34], eInit:[0.0100], init state:[ 0  2 20  0  0  0  0  0], end state:[ 2  2 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1756, score:[2800.40], loss:[1.67808], sequence:[8], random actions:[33], eInit:[0.0100], init state:[ 6 20 18  0  0  0  0  0], end state:[ 1 20 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1757, score:[2840.00], loss:[1.51031], sequence:[9], random actions:[21], eInit:[0.0100], init state:[ 0  4 23  0  0  0  0  0], end state:[ 2  4 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1758, score:[2815.60], loss:[1.45191], sequence:[10], random actions:[33], eInit:[0.0100], init state:[ 2  8 29  1  0  0  0  0], end state:[ 4  8 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1759, score:[2711.60], loss:[1.81411], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 4  3 18  0  0  0  0  0], end state:[ 6  3 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1760, score:[2764.00], loss:[2.42766], sequence:[1], random actions:[21], eInit:[0.0100], init state:[ 4  3 51  0  0  0  0  0], end state:[ 6  3 51  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1761, score:[2823.60], loss:[2.17701], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 1  8 56  1  1  0  0  0], end state:[ 3  8 56  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1762, score:[2733.20], loss:[1.95492], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  0 41  0  0  0  0  0], end state:[ 0  0 41  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1763, score:[2793.60], loss:[2.23598], sequence:[1], random actions:[32], eInit:[0.0100], init state:[ 2 14 57  0  0  0  0  0], end state:[ 4 14 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1764, score:[2823.20], loss:[1.95895], sequence:[2], random actions:[27], eInit:[0.0100], init state:[ 2  5 40  0  0  0  0  0], end state:[ 4  5 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1765, score:[2829.20], loss:[1.72460], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 1  6 37  0  0  0  0  0], end state:[ 3  6 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1766, score:[2831.20], loss:[1.55497], sequence:[4], random actions:[24], eInit:[0.0100], init state:[ 0  4 47  0  0  0  0  0], end state:[ 2  4 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1767, score:[2770.00], loss:[1.54860], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 2 18 48  0  0  0  0  0], end state:[ 4 18 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1768, score:[2797.20], loss:[1.68098], sequence:[6], random actions:[24], eInit:[0.0100], init state:[ 4 17 56  0  0  0  0  0], end state:[ 6 17 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1769, score:[2763.60], loss:[1.89487], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 4  4 27  0  0  0  0  0], end state:[ 6  4 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1770, score:[2816.40], loss:[1.83588], sequence:[8], random actions:[29], eInit:[0.0100], init state:[0 6 1 0 0 0 0 0], end state:[2 6 1 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1771, score:[2834.00], loss:[1.53516], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 1  0 33  0  0  1  0  0], end state:[ 3  0 33  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1772, score:[2828.80], loss:[1.40731], sequence:[10], random actions:[30], eInit:[0.0100], init state:[ 1  6 50  0  0  0  0  0], end state:[ 3  6 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1773, score:[2792.40], loss:[1.61251], sequence:[11], random actions:[29], eInit:[0.0100], init state:[ 4  2 46  0  0  0  0  0], end state:[ 6  2 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1774, score:[2826.80], loss:[1.61945], sequence:[12], random actions:[26], eInit:[0.0100], init state:[ 1 10 22  0  0  0  0  0], end state:[ 3 10 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1775, score:[2821.20], loss:[1.72663], sequence:[13], random actions:[28], eInit:[0.0100], init state:[ 2  2 35  0  0  0  0  0], end state:[ 4  2 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1776, score:[2786.40], loss:[1.66556], sequence:[14], random actions:[31], eInit:[0.0100], init state:[ 2 15 19  0  0  0  0  0], end state:[ 4 15 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1777, score:[2813.60], loss:[1.68041], sequence:[15], random actions:[29], eInit:[0.0100], init state:[ 0  6 28  0  0  0  0  0], end state:[ 2  6 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1778, score:[2814.00], loss:[1.72517], sequence:[16], random actions:[32], eInit:[0.0100], init state:[2 9 4 0 0 0 0 0], end state:[4 9 4 1 1 0 1 0]
INFO:Reinforcement.Functions:episode: 1779, score:[2769.20], loss:[2.02200], sequence:[17], random actions:[26], eInit:[0.0100], init state:[ 5  2 55  0  0  0  0  0], end state:[ 0  2 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1780, score:[2824.40], loss:[1.90448], sequence:[18], random actions:[23], eInit:[0.0100], init state:[ 2  6 58  0  0  0  0  0], end state:[ 4  6 58  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1781, score:[2845.60], loss:[1.59879], sequence:[19], random actions:[15], eInit:[0.0100], init state:[ 0 17 15  0  0  0  0  0], end state:[ 2 17 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1782, score:[2784.00], loss:[1.59244], sequence:[20], random actions:[29], eInit:[0.0100], init state:[ 4 12 16  1  1  0  0  0], end state:[ 6 12 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1783, score:[2816.00], loss:[1.61483], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 1  0 39  0  0  1  0  0], end state:[ 3  0 39  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1784, score:[2784.40], loss:[1.89554], sequence:[22], random actions:[35], eInit:[0.0100], init state:[ 0 18 17  0  0  0  0  0], end state:[ 2 18 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1785, score:[2819.20], loss:[1.63216], sequence:[23], random actions:[33], eInit:[0.0100], init state:[ 6 22 54  1  0  0  0  0], end state:[ 1 22 54  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1786, score:[2779.60], loss:[1.67987], sequence:[24], random actions:[32], eInit:[0.0100], init state:[ 3  4 58  0  0  0  0  0], end state:[ 5  4 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1787, score:[2732.00], loss:[2.14494], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 4 13 53  0  0  0  0  0], end state:[ 6 13 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1788, score:[2842.00], loss:[1.97305], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 0 11 56  0  0  0  0  0], end state:[ 2 11 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1789, score:[2804.80], loss:[1.99173], sequence:[2], random actions:[25], eInit:[0.0100], init state:[ 6 13 39  0  0  0  0  0], end state:[ 1 13 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1790, score:[2794.00], loss:[1.71240], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 2 18 14  0  0  0  0  0], end state:[ 4 18 14  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1791, score:[2749.20], loss:[2.36503], sequence:[4], random actions:[44], eInit:[0.0100], init state:[ 6 18 52  0  0  0  0  0], end state:[ 1 18 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1792, score:[2745.20], loss:[2.42447], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 5 12 46  0  0  0  0  0], end state:[ 0 12 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1793, score:[2692.40], loss:[2.61267], sequence:[0], random actions:[26], eInit:[0.0100], init state:[ 4 12 44  1  1  0  0  0], end state:[ 6 12 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1794, score:[2804.40], loss:[2.42752], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 4 12 20  1  1  0  0  0], end state:[ 6 12 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1795, score:[2782.00], loss:[2.38587], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 2 18  5  0  0  0  0  0], end state:[ 4 18  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1796, score:[2822.80], loss:[2.43870], sequence:[3], random actions:[26], eInit:[0.0100], init state:[ 1 18 35  0  0  0  0  0], end state:[ 3 18 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1797, score:[2804.80], loss:[2.03632], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 0 22 17  1  0  0  0  0], end state:[ 2 22 17  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1798, score:[2828.00], loss:[1.91441], sequence:[5], random actions:[19], eInit:[0.0100], init state:[ 6 22 17  1  0  0  0  0], end state:[ 1 22 17  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1799, score:[2700.40], loss:[2.35190], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 22 11  0  0  0  0  0], end state:[ 6 22 11  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1800, score:[2805.20], loss:[2.37735], sequence:[1], random actions:[20], eInit:[0.0100], init state:[ 1 23 14  1  0  0  0  0], end state:[ 3 23 14  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1801, score:[2758.40], loss:[2.49872], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 4 15  5  0  0  0  0  0], end state:[ 6 15  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1802, score:[2809.60], loss:[2.51291], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 3  5 15  0  0  0  0  0], end state:[ 5  5 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1803, score:[2725.60], loss:[2.64254], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 3 19 52  0  0  0  0  0], end state:[ 5 19 52  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1804, score:[2812.00], loss:[2.57740], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 1 17 39  0  0  0  0  0], end state:[ 3 17 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1805, score:[2790.00], loss:[2.44956], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 6  3 22  0  0  0  0  0], end state:[ 1  3 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1806, score:[2800.40], loss:[2.44901], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 2 17 16  0  0  0  0  0], end state:[ 4 17 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1807, score:[2818.80], loss:[2.35508], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 1 10 55  0  0  0  0  0], end state:[ 3 10 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1808, score:[2822.00], loss:[2.18283], sequence:[5], random actions:[25], eInit:[0.0100], init state:[ 0  4 39  0  0  0  0  0], end state:[ 2  4 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1809, score:[2817.20], loss:[1.87202], sequence:[6], random actions:[27], eInit:[0.0100], init state:[ 1 18 22  0  0  0  0  0], end state:[ 3 18 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1810, score:[2807.20], loss:[1.86727], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 1 23  6  1  0  0  0  0], end state:[ 3 23  6  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1811, score:[2756.40], loss:[1.86442], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 4  3 38  0  0  0  0  0], end state:[ 6  3 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1812, score:[2821.20], loss:[1.86895], sequence:[9], random actions:[24], eInit:[0.0100], init state:[ 6 22 32  1  0  0  0  0], end state:[ 1 22 32  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1813, score:[2782.00], loss:[2.11621], sequence:[10], random actions:[41], eInit:[0.0100], init state:[ 3  4 43  0  0  0  0  0], end state:[ 5  4 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1814, score:[2809.20], loss:[2.01452], sequence:[11], random actions:[28], eInit:[0.0100], init state:[ 6  3 34  0  0  0  0  0], end state:[ 1  3 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1815, score:[2823.60], loss:[1.91354], sequence:[12], random actions:[25], eInit:[0.0100], init state:[ 6 21 20  1  1  0  1  0], end state:[ 1 21 20  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1816, score:[2818.00], loss:[1.79740], sequence:[13], random actions:[26], eInit:[0.0100], init state:[ 0 22 41  1  0  0  0  0], end state:[ 2 22 41  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1817, score:[2816.40], loss:[1.81391], sequence:[14], random actions:[32], eInit:[0.0100], init state:[ 1 17 44  0  0  0  0  0], end state:[ 3 17 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1818, score:[2752.80], loss:[1.84086], sequence:[15], random actions:[43], eInit:[0.0100], init state:[ 6 11 19  0  0  0  0  0], end state:[ 1 11 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1819, score:[2785.20], loss:[1.94917], sequence:[16], random actions:[29], eInit:[0.0100], init state:[ 5 10 58  0  0  0  0  0], end state:[ 0 10 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1820, score:[2806.00], loss:[1.84341], sequence:[17], random actions:[22], eInit:[0.0100], init state:[ 5 21 28  1  0  0  1  1], end state:[ 0 21 28  0  1  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1821, score:[2791.60], loss:[1.94823], sequence:[18], random actions:[26], eInit:[0.0100], init state:[4 6 7 0 0 0 0 0], end state:[6 6 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1822, score:[2821.60], loss:[2.01935], sequence:[19], random actions:[30], eInit:[0.0100], init state:[ 3 16 24  0  0  0  0  0], end state:[ 5 16 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1823, score:[2796.00], loss:[1.90102], sequence:[20], random actions:[32], eInit:[0.0100], init state:[ 0 16 43  0  0  0  0  0], end state:[ 2 16 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1824, score:[2814.00], loss:[1.81420], sequence:[21], random actions:[25], eInit:[0.0100], init state:[ 3  7 26  0  0  0  0  0], end state:[ 5  7 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1825, score:[2772.40], loss:[1.89572], sequence:[22], random actions:[28], eInit:[0.0100], init state:[ 4 20 28  0  0  0  0  0], end state:[ 6 20 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1826, score:[2821.60], loss:[2.00493], sequence:[23], random actions:[32], eInit:[0.0100], init state:[ 0 17 49  0  0  0  0  0], end state:[ 2 17 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1827, score:[2781.20], loss:[2.13592], sequence:[24], random actions:[34], eInit:[0.0100], init state:[ 4  8 22  0  0  0  0  0], end state:[ 6  8 22  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1828, score:[2794.80], loss:[2.18135], sequence:[25], random actions:[29], eInit:[0.0100], init state:[ 3 19 15  0  0  0  0  0], end state:[ 5 19 15  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1829, score:[2832.80], loss:[2.00341], sequence:[26], random actions:[19], eInit:[0.0100], init state:[ 2  7 31  0  0  0  0  0], end state:[ 4  7 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1830, score:[2835.60], loss:[1.81555], sequence:[27], random actions:[20], eInit:[0.0100], init state:[ 0 12  1  0  0  0  0  0], end state:[ 2 12  1  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1831, score:[2818.00], loss:[1.75013], sequence:[28], random actions:[31], eInit:[0.0100], init state:[ 0  4 36  0  0  0  0  0], end state:[ 2  4 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1832, score:[2802.00], loss:[1.78143], sequence:[29], random actions:[23], eInit:[0.0100], init state:[ 4 12 35  1  1  0  0  0], end state:[ 6 12 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1833, score:[2830.40], loss:[1.76925], sequence:[30], random actions:[32], eInit:[0.0100], init state:[ 0  4 31  0  0  0  0  0], end state:[ 2  4 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1834, score:[2797.60], loss:[1.95714], sequence:[31], random actions:[27], eInit:[0.0100], init state:[ 2 23 20  1  0  0  1  0], end state:[ 4 23 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1835, score:[2831.20], loss:[1.77600], sequence:[32], random actions:[34], eInit:[0.0100], init state:[ 1 16 17  0  0  0  0  0], end state:[ 3 16 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1836, score:[2788.40], loss:[1.82856], sequence:[33], random actions:[39], eInit:[0.0100], init state:[ 6 23 59  1  0  0  0  0], end state:[ 1 23 59  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1837, score:[2804.00], loss:[1.91166], sequence:[34], random actions:[35], eInit:[0.0100], init state:[3 2 1 0 0 0 0 0], end state:[5 2 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1838, score:[2830.80], loss:[1.84672], sequence:[35], random actions:[25], eInit:[0.0100], init state:[ 2 14 37  0  0  0  0  0], end state:[ 4 14 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1839, score:[2747.20], loss:[2.13766], sequence:[36], random actions:[39], eInit:[0.0100], init state:[ 6 19 58  0  0  0  0  0], end state:[ 1 19 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1840, score:[2754.40], loss:[2.31585], sequence:[37], random actions:[31], eInit:[0.0100], init state:[ 3  6 46  0  0  0  0  0], end state:[ 5  6 46  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1841, score:[2834.80], loss:[2.06220], sequence:[38], random actions:[20], eInit:[0.0100], init state:[0 5 7 0 0 0 0 0], end state:[2 5 7 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1842, score:[2783.60], loss:[1.90433], sequence:[39], random actions:[30], eInit:[0.0100], init state:[ 3 20 59  1  1  0  1  0], end state:[ 5 20 59  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1843, score:[2833.20], loss:[2.66556], sequence:[40], random actions:[17], eInit:[0.0100], init state:[ 0  7 44  0  0  0  0  0], end state:[ 2  7 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1844, score:[2759.20], loss:[2.35509], sequence:[41], random actions:[40], eInit:[0.0100], init state:[ 5 14  5  0  0  0  0  0], end state:[ 0 14  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1845, score:[2834.80], loss:[2.23491], sequence:[42], random actions:[25], eInit:[0.0100], init state:[ 1 15 31  0  0  0  0  0], end state:[ 3 15 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1846, score:[2810.40], loss:[2.13839], sequence:[43], random actions:[32], eInit:[0.0100], init state:[ 6  1 11  0  0  0  0  0], end state:[ 1  1 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1847, score:[2790.40], loss:[1.88680], sequence:[44], random actions:[34], eInit:[0.0100], init state:[ 2 13 40  0  0  0  0  0], end state:[ 4 13 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1848, score:[2828.00], loss:[1.86667], sequence:[45], random actions:[34], eInit:[0.0100], init state:[ 0 10 15  0  0  0  0  0], end state:[ 2 10 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1849, score:[2788.40], loss:[1.97571], sequence:[46], random actions:[26], eInit:[0.0100], init state:[ 4  4 46  0  0  0  0  0], end state:[ 6  4 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1850, score:[2772.80], loss:[2.15546], sequence:[47], random actions:[23], eInit:[0.0100], init state:[ 3  9 55  0  0  0  0  0], end state:[ 5  9 55  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1851, score:[2801.60], loss:[2.06981], sequence:[48], random actions:[23], eInit:[0.0100], init state:[ 5 22 46  1  0  0  1  0], end state:[ 0 22 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1852, score:[2760.00], loss:[2.14385], sequence:[49], random actions:[28], eInit:[0.0100], init state:[ 5  3 10  0  0  0  0  0], end state:[ 0  3 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1853, score:[2717.20], loss:[2.37478], sequence:[0], random actions:[35], eInit:[0.0100], init state:[ 3 20 48  1  1  0  1  0], end state:[ 5 20 48  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1854, score:[2823.60], loss:[2.23088], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1 12  3  0  0  0  0  0], end state:[ 3 12  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1855, score:[2836.40], loss:[1.98413], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 1  3 13  0  0  0  0  0], end state:[ 3  3 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1856, score:[2793.60], loss:[1.86797], sequence:[3], random actions:[23], eInit:[0.0100], init state:[ 4  2 49  0  0  0  0  0], end state:[ 6  2 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1857, score:[2802.40], loss:[1.94200], sequence:[4], random actions:[30], eInit:[0.0100], init state:[ 5 14 24  0  0  0  0  0], end state:[ 0 14 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1858, score:[2806.00], loss:[1.89966], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 2  9 37  0  0  0  0  0], end state:[ 4  9 37  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1859, score:[2834.80], loss:[1.73467], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 0 23 26  1  0  0  1  0], end state:[ 2 23 26  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1860, score:[2811.60], loss:[1.75175], sequence:[7], random actions:[34], eInit:[0.0100], init state:[ 2  4 14  0  0  0  0  0], end state:[ 4  4 14  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1861, score:[2818.40], loss:[1.86045], sequence:[8], random actions:[31], eInit:[0.0100], init state:[ 3 16 54  0  0  0  0  0], end state:[ 5 16 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1862, score:[2815.20], loss:[1.80871], sequence:[9], random actions:[25], eInit:[0.0100], init state:[ 2  6 55  0  0  0  0  0], end state:[ 4  6 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1863, score:[2818.40], loss:[1.64945], sequence:[10], random actions:[30], eInit:[0.0100], init state:[ 3  1 46  0  0  0  0  0], end state:[ 5  1 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1864, score:[2823.60], loss:[1.91907], sequence:[11], random actions:[19], eInit:[0.0100], init state:[ 5 22 49  1  0  0  1  0], end state:[ 0 22 49  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1865, score:[2830.80], loss:[1.94628], sequence:[12], random actions:[23], eInit:[0.0100], init state:[ 2  3 35  0  0  0  0  0], end state:[ 4  3 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1866, score:[2813.20], loss:[1.78277], sequence:[13], random actions:[22], eInit:[0.0100], init state:[ 4  8 53  0  0  0  0  0], end state:[ 6  8 53  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1867, score:[2732.00], loss:[1.92665], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6  6 57  0  0  0  0  0], end state:[ 1  6 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1868, score:[2790.80], loss:[1.92462], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 3 23 23  1  0  0  1  0], end state:[ 5 23 23  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1869, score:[2792.80], loss:[2.14892], sequence:[2], random actions:[35], eInit:[0.0100], init state:[ 1  8 50  1  1  0  0  0], end state:[ 3  8 50  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1870, score:[2795.60], loss:[2.00967], sequence:[3], random actions:[35], eInit:[0.0100], init state:[ 2 12 27  0  0  0  0  0], end state:[ 4 12 27  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1871, score:[2752.40], loss:[2.27355], sequence:[4], random actions:[33], eInit:[0.0100], init state:[ 5 17 22  0  0  0  0  0], end state:[ 0 17 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1872, score:[2783.60], loss:[2.24588], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 4 11 58  1  1  0  0  0], end state:[ 6 11 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1873, score:[2815.60], loss:[2.19488], sequence:[6], random actions:[30], eInit:[0.0100], init state:[ 3  9 12  0  0  0  0  0], end state:[ 5  9 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1874, score:[2805.60], loss:[2.10792], sequence:[7], random actions:[30], eInit:[0.0100], init state:[ 4 23 20  0  0  0  0  0], end state:[ 6 23 20  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1875, score:[2805.20], loss:[2.19697], sequence:[8], random actions:[23], eInit:[0.0100], init state:[ 0  2 48  0  0  0  0  0], end state:[ 2  2 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1876, score:[2818.40], loss:[1.95792], sequence:[9], random actions:[33], eInit:[0.0100], init state:[ 0  4 16  0  0  0  0  0], end state:[ 2  4 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1877, score:[2799.60], loss:[2.38662], sequence:[10], random actions:[28], eInit:[0.0100], init state:[ 6  4 20  0  0  0  0  0], end state:[ 1  4 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1878, score:[2812.40], loss:[2.45564], sequence:[11], random actions:[28], eInit:[0.0100], init state:[ 3 15 39  0  0  0  0  0], end state:[ 5 15 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1879, score:[2801.20], loss:[2.16771], sequence:[12], random actions:[24], eInit:[0.0100], init state:[ 2 20 58  1  1  0  1  0], end state:[ 4 20 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1880, score:[2824.80], loss:[2.11061], sequence:[13], random actions:[34], eInit:[0.0100], init state:[1 5 7 0 0 0 0 0], end state:[3 5 7 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1881, score:[2781.20], loss:[2.29434], sequence:[14], random actions:[28], eInit:[0.0100], init state:[ 5 23 13  1  0  0  1  0], end state:[ 0 23 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1882, score:[2769.60], loss:[2.51295], sequence:[15], random actions:[37], eInit:[0.0100], init state:[5 0 8 0 0 0 0 0], end state:[0 0 8 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1883, score:[2800.80], loss:[2.52997], sequence:[16], random actions:[25], eInit:[0.0100], init state:[ 4  0 32  1  0  1  0  0], end state:[ 6  0 32  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1884, score:[2843.20], loss:[2.34807], sequence:[17], random actions:[17], eInit:[0.0100], init state:[ 3 12 51  0  0  0  0  0], end state:[ 5 12 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1885, score:[2813.60], loss:[2.21152], sequence:[18], random actions:[29], eInit:[0.0100], init state:[ 1  8 19  1  0  0  0  0], end state:[ 3  8 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1886, score:[2816.80], loss:[1.99537], sequence:[19], random actions:[25], eInit:[0.0100], init state:[ 2  6 49  0  0  0  0  0], end state:[ 4  6 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1887, score:[2827.60], loss:[1.88541], sequence:[20], random actions:[20], eInit:[0.0100], init state:[ 0 10 13  0  0  0  0  0], end state:[ 2 10 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1888, score:[2823.20], loss:[1.76633], sequence:[21], random actions:[25], eInit:[0.0100], init state:[ 3  8 18  1  0  0  0  0], end state:[ 5  8 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1889, score:[2769.20], loss:[1.95446], sequence:[22], random actions:[29], eInit:[0.0100], init state:[ 5  9 15  0  0  0  0  0], end state:[ 0  9 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1890, score:[2781.20], loss:[1.86469], sequence:[23], random actions:[29], eInit:[0.0100], init state:[ 2 15 32  0  0  0  0  0], end state:[ 4 15 32  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1891, score:[2812.00], loss:[1.90408], sequence:[24], random actions:[24], eInit:[0.0100], init state:[5 2 1 0 0 0 0 0], end state:[0 2 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1892, score:[2816.80], loss:[1.95297], sequence:[25], random actions:[35], eInit:[0.0100], init state:[ 1 20 40  1  1  0  0  0], end state:[ 3 20 40  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1893, score:[2820.40], loss:[1.88730], sequence:[26], random actions:[28], eInit:[0.0100], init state:[ 0 10 34  0  0  0  0  0], end state:[ 2 10 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1894, score:[2805.20], loss:[1.76424], sequence:[27], random actions:[29], eInit:[0.0100], init state:[ 5 14 59  0  0  0  0  0], end state:[ 0 14 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1895, score:[2808.00], loss:[1.87809], sequence:[28], random actions:[30], eInit:[0.0100], init state:[ 1 19 35  0  0  0  0  0], end state:[ 3 19 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1896, score:[2827.60], loss:[1.73135], sequence:[29], random actions:[24], eInit:[0.0100], init state:[ 0 20 35  1  1  0  0  0], end state:[ 2 20 35  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1897, score:[2830.00], loss:[1.58977], sequence:[30], random actions:[27], eInit:[0.0100], init state:[ 0 17 55  0  0  0  0  0], end state:[ 2 17 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1898, score:[2798.40], loss:[1.69106], sequence:[31], random actions:[20], eInit:[0.0100], init state:[ 5 16 51  0  0  0  0  0], end state:[ 0 16 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1899, score:[2838.00], loss:[1.71375], sequence:[32], random actions:[15], eInit:[0.0100], init state:[ 1  3 58  0  0  0  0  0], end state:[ 3  3 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1900, score:[2822.00], loss:[1.57553], sequence:[33], random actions:[29], eInit:[0.0100], init state:[0 4 6 0 0 0 0 0], end state:[2 4 6 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1901, score:[2814.00], loss:[1.73695], sequence:[34], random actions:[31], eInit:[0.0100], init state:[ 1 13 45  0  0  0  0  0], end state:[ 3 13 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1902, score:[2758.80], loss:[1.83994], sequence:[35], random actions:[32], eInit:[0.0100], init state:[ 4  9 32  1  0  0  0  0], end state:[ 6  9 32  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1903, score:[2816.40], loss:[2.04188], sequence:[36], random actions:[22], eInit:[0.0100], init state:[ 2 18  4  0  0  0  0  0], end state:[ 4 18  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1904, score:[2811.60], loss:[2.07699], sequence:[37], random actions:[30], eInit:[0.0100], init state:[ 3  9 16  0  0  0  0  0], end state:[ 5  9 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1905, score:[2794.00], loss:[2.16940], sequence:[38], random actions:[32], eInit:[0.0100], init state:[ 5 22 49  1  0  0  1  0], end state:[ 0 22 49  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1906, score:[2751.60], loss:[2.23883], sequence:[39], random actions:[21], eInit:[0.0100], init state:[ 4 21 52  0  0  0  0  0], end state:[ 6 21 52  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1907, score:[2805.60], loss:[2.23741], sequence:[40], random actions:[40], eInit:[0.0100], init state:[ 1 19 50  0  0  0  0  0], end state:[ 3 19 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1908, score:[2775.20], loss:[2.11136], sequence:[41], random actions:[25], eInit:[0.0100], init state:[5 5 0 0 0 0 0 0], end state:[0 5 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1909, score:[2777.60], loss:[2.35436], sequence:[42], random actions:[34], eInit:[0.0100], init state:[ 5 20 36  1  0  0  0  0], end state:[ 0 20 36  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1910, score:[2817.20], loss:[2.15191], sequence:[43], random actions:[28], eInit:[0.0100], init state:[ 0  7 24  0  0  0  0  0], end state:[ 2  7 24  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1911, score:[2804.40], loss:[2.33715], sequence:[44], random actions:[27], eInit:[0.0100], init state:[ 4  4 20  0  0  0  0  0], end state:[ 6  4 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1912, score:[2815.60], loss:[2.32401], sequence:[45], random actions:[30], eInit:[0.0100], init state:[ 0 23 34  1  0  0  1  0], end state:[ 2 23 34  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 1913, score:[2807.60], loss:[2.33657], sequence:[46], random actions:[30], eInit:[0.0100], init state:[3 1 2 0 0 1 0 0], end state:[5 1 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1914, score:[2750.80], loss:[2.61258], sequence:[47], random actions:[36], eInit:[0.0100], init state:[ 5 10 52  0  0  0  0  0], end state:[ 0 10 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1915, score:[2809.60], loss:[2.68430], sequence:[48], random actions:[23], eInit:[0.0100], init state:[ 1 10 50  0  0  0  0  0], end state:[ 3 10 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1916, score:[2830.40], loss:[2.18328], sequence:[49], random actions:[33], eInit:[0.0100], init state:[ 1 11 57  0  0  0  0  0], end state:[ 3 11 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1917, score:[2816.40], loss:[2.12249], sequence:[50], random actions:[29], eInit:[0.0100], init state:[ 0  8 26  1  0  0  0  0], end state:[ 2  8 26  0  1  1  0  0]
INFO:Reinforcement.Functions:episode: 1918, score:[2737.60], loss:[2.29700], sequence:[51], random actions:[33], eInit:[0.0100], init state:[ 6 16 26  0  0  0  0  0], end state:[ 1 16 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1919, score:[2783.60], loss:[2.52110], sequence:[52], random actions:[30], eInit:[0.0100], init state:[ 5 20 53  1  0  0  0  0], end state:[ 0 20 53  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1920, score:[2774.00], loss:[2.47308], sequence:[53], random actions:[43], eInit:[0.0100], init state:[ 0 14 15  0  0  0  0  0], end state:[ 2 14 15  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1921, score:[2798.80], loss:[2.20909], sequence:[54], random actions:[19], eInit:[0.0100], init state:[ 1 14  4  0  0  0  0  0], end state:[ 3 14  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1922, score:[2794.80], loss:[2.13302], sequence:[55], random actions:[27], eInit:[0.0100], init state:[ 0 15 42  0  0  0  0  0], end state:[ 2 15 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1923, score:[2734.40], loss:[2.44026], sequence:[0], random actions:[27], eInit:[0.0100], init state:[ 6  3 13  0  0  0  0  0], end state:[ 1  3 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1924, score:[2738.80], loss:[2.73583], sequence:[1], random actions:[35], eInit:[0.0100], init state:[ 4 10 16  1  1  0  1  1], end state:[ 6 10 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1925, score:[2790.00], loss:[2.49439], sequence:[2], random actions:[34], eInit:[0.0100], init state:[ 2 12 57  0  0  0  0  0], end state:[ 4 12 57  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 1926, score:[2799.60], loss:[2.50413], sequence:[3], random actions:[29], eInit:[0.0100], init state:[ 1 13 35  0  0  0  0  0], end state:[ 3 13 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1927, score:[2730.40], loss:[2.41712], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 2 18 11  0  0  0  0  0], end state:[ 4 18 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1928, score:[2712.80], loss:[2.88378], sequence:[0], random actions:[21], eInit:[0.0100], init state:[ 5  1 53  0  0  0  0  0], end state:[ 0  1 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1929, score:[2788.80], loss:[2.61703], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 1  6 27  0  0  0  0  0], end state:[ 3  6 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1930, score:[2823.60], loss:[2.42932], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 3 13 51  0  0  0  0  0], end state:[ 5 13 51  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1931, score:[2796.80], loss:[2.54926], sequence:[3], random actions:[19], eInit:[0.0100], init state:[ 6 19 12  0  0  0  0  0], end state:[ 1 19 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1932, score:[2794.00], loss:[2.43203], sequence:[4], random actions:[29], eInit:[0.0100], init state:[6 9 1 0 0 0 0 0], end state:[1 9 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1933, score:[2788.80], loss:[2.67447], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 5 13  0  0  0  0  0  0], end state:[ 0 13  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1934, score:[2788.80], loss:[2.70382], sequence:[6], random actions:[34], eInit:[0.0100], init state:[ 3  5 40  0  0  0  0  0], end state:[ 5  5 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1935, score:[2804.80], loss:[2.69519], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 3 23 48  1  0  0  0  0], end state:[ 5 23 48  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1936, score:[2805.60], loss:[2.51231], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 0 11 10  0  0  0  0  0], end state:[ 2 11 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1937, score:[2772.40], loss:[2.62489], sequence:[9], random actions:[35], eInit:[0.0100], init state:[ 2 19 28  0  0  0  0  0], end state:[ 4 19 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1938, score:[2806.80], loss:[2.38836], sequence:[10], random actions:[28], eInit:[0.0100], init state:[ 1  4 42  0  0  0  0  0], end state:[ 3  4 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1939, score:[2818.40], loss:[2.24210], sequence:[11], random actions:[29], eInit:[0.0100], init state:[ 0 20 40  1  1  0  0  0], end state:[ 2 20 40  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1940, score:[2809.60], loss:[2.37050], sequence:[12], random actions:[32], eInit:[0.0100], init state:[ 0  7 54  0  0  0  0  0], end state:[ 2  7 54  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1941, score:[2816.40], loss:[2.24910], sequence:[13], random actions:[26], eInit:[0.0100], init state:[ 0  6 21  0  0  0  0  0], end state:[ 2  6 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1942, score:[2784.40], loss:[2.35537], sequence:[14], random actions:[34], eInit:[0.0100], init state:[4 1 1 0 0 1 0 0], end state:[6 1 1 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 1943, score:[2808.80], loss:[2.34224], sequence:[15], random actions:[32], eInit:[0.0100], init state:[ 1 23 58  1  0  0  0  0], end state:[ 3 23 58  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1944, score:[2795.20], loss:[2.28142], sequence:[16], random actions:[32], eInit:[0.0100], init state:[ 1 23 45  1  0  0  0  0], end state:[ 3 23 45  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1945, score:[2798.40], loss:[2.65519], sequence:[17], random actions:[25], eInit:[0.0100], init state:[ 1  2 43  0  0  0  0  0], end state:[ 3  2 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1946, score:[2770.80], loss:[2.23280], sequence:[18], random actions:[28], eInit:[0.0100], init state:[ 4 21 20  0  0  0  0  0], end state:[ 6 21 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1947, score:[2803.60], loss:[2.30744], sequence:[19], random actions:[29], eInit:[0.0100], init state:[ 2 22 58  1  0  0  0  0], end state:[ 4 22 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1948, score:[2810.40], loss:[2.16376], sequence:[20], random actions:[33], eInit:[0.0100], init state:[ 2  0 40  0  0  1  0  0], end state:[ 4  0 40  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1949, score:[2720.00], loss:[2.49699], sequence:[0], random actions:[31], eInit:[0.0100], init state:[5 2 3 0 0 0 0 0], end state:[0 2 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1950, score:[2780.40], loss:[2.56600], sequence:[1], random actions:[42], eInit:[0.0100], init state:[ 2 18 26  0  0  0  0  0], end state:[ 4 18 26  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1951, score:[2800.00], loss:[2.41554], sequence:[2], random actions:[33], eInit:[0.0100], init state:[ 3 23 33  1  0  0  1  0], end state:[ 5 23 33  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1952, score:[2812.40], loss:[2.29569], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 4 23 59  0  0  0  0  0], end state:[ 6 23 59  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1953, score:[2813.20], loss:[2.18214], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 3 23 20  1  0  0  1  0], end state:[ 5 23 20  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1954, score:[2764.40], loss:[2.23394], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 5  0 30  0  0  0  0  0], end state:[ 0  0 30  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 1955, score:[2784.80], loss:[2.01377], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 1 13 21  0  0  0  0  0], end state:[ 3 13 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1956, score:[2816.80], loss:[2.01090], sequence:[7], random actions:[23], eInit:[0.0100], init state:[ 4  5 37  0  0  0  0  0], end state:[ 6  5 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1957, score:[2765.60], loss:[2.25959], sequence:[8], random actions:[24], eInit:[0.0100], init state:[ 5 12 55  0  0  0  0  0], end state:[ 0 12 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1958, score:[2807.60], loss:[2.18692], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 1  6 25  0  0  0  0  0], end state:[ 3  6 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1959, score:[2789.60], loss:[2.17121], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 4 23 10  0  0  0  0  0], end state:[ 6 23 10  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1960, score:[2802.40], loss:[2.17207], sequence:[11], random actions:[21], eInit:[0.0100], init state:[ 3 19 37  0  0  0  0  0], end state:[ 5 19 37  1  0  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1961, score:[2794.40], loss:[2.19159], sequence:[12], random actions:[21], eInit:[0.0100], init state:[ 6  6 38  0  0  0  0  0], end state:[ 1  6 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1962, score:[2818.80], loss:[2.10359], sequence:[13], random actions:[22], eInit:[0.0100], init state:[ 1  3 43  0  0  0  0  0], end state:[ 3  3 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1963, score:[2833.60], loss:[2.09432], sequence:[14], random actions:[24], eInit:[0.0100], init state:[ 3 11 30  0  0  0  0  0], end state:[ 5 11 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1964, score:[2815.20], loss:[1.78665], sequence:[15], random actions:[35], eInit:[0.0100], init state:[ 0  2 17  0  0  0  0  0], end state:[ 2  2 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1965, score:[2809.20], loss:[1.84778], sequence:[16], random actions:[25], eInit:[0.0100], init state:[ 5 23 12  1  0  0  1  0], end state:[ 0 23 12  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1966, score:[2795.60], loss:[1.95255], sequence:[17], random actions:[36], eInit:[0.0100], init state:[ 0  4 41  0  0  0  0  0], end state:[ 2  4 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1967, score:[2807.20], loss:[1.84579], sequence:[18], random actions:[30], eInit:[0.0100], init state:[ 2 20 39  1  1  0  0  0], end state:[ 4 20 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1968, score:[2788.00], loss:[2.18075], sequence:[19], random actions:[41], eInit:[0.0100], init state:[ 3 10  3  0  0  0  0  0], end state:[ 5 10  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1969, score:[2836.40], loss:[1.93012], sequence:[20], random actions:[19], eInit:[0.0100], init state:[ 3 16 11  0  0  0  0  0], end state:[ 5 16 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1970, score:[2782.40], loss:[1.94658], sequence:[21], random actions:[27], eInit:[0.0100], init state:[ 5 12  8  0  0  0  0  0], end state:[ 0 12  8  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1971, score:[2772.80], loss:[2.10317], sequence:[22], random actions:[34], eInit:[0.0100], init state:[ 4  2 14  0  0  0  0  0], end state:[ 6  2 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1972, score:[2808.80], loss:[2.03283], sequence:[23], random actions:[24], eInit:[0.0100], init state:[ 6 23 14  1  0  0  0  0], end state:[ 1 23 14  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1973, score:[2792.40], loss:[1.95140], sequence:[24], random actions:[35], eInit:[0.0100], init state:[ 4  3 24  0  0  0  0  0], end state:[ 6  3 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1974, score:[2823.20], loss:[1.91223], sequence:[25], random actions:[28], eInit:[0.0100], init state:[ 1 19 17  0  0  0  0  0], end state:[ 3 19 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1975, score:[2767.60], loss:[1.93505], sequence:[26], random actions:[31], eInit:[0.0100], init state:[ 5 11  4  0  0  0  0  0], end state:[ 0 11  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1976, score:[2780.40], loss:[2.06935], sequence:[27], random actions:[28], eInit:[0.0100], init state:[ 3 14 31  0  0  0  0  0], end state:[ 5 14 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1977, score:[2804.00], loss:[1.94913], sequence:[28], random actions:[22], eInit:[0.0100], init state:[ 4 16 48  0  0  0  0  0], end state:[ 6 16 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1978, score:[2779.20], loss:[2.02079], sequence:[29], random actions:[26], eInit:[0.0100], init state:[ 4 18 49  0  0  0  0  0], end state:[ 6 18 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1979, score:[2761.60], loss:[2.05909], sequence:[30], random actions:[28], eInit:[0.0100], init state:[ 3 20  7  0  0  0  0  0], end state:[ 5 20  7  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1980, score:[2796.80], loss:[1.97764], sequence:[31], random actions:[30], eInit:[0.0100], init state:[ 2 14 56  0  0  0  0  0], end state:[ 4 14 56  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1981, score:[2744.00], loss:[2.27897], sequence:[32], random actions:[21], eInit:[0.0100], init state:[ 5  7 37  0  0  0  0  0], end state:[ 0  7 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1982, score:[2786.40], loss:[2.23252], sequence:[33], random actions:[29], eInit:[0.0100], init state:[ 4 22 23  0  0  0  0  0], end state:[ 6 22 23  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1983, score:[2816.80], loss:[2.40338], sequence:[34], random actions:[22], eInit:[0.0100], init state:[ 1 20 31  1  1  0  0  0], end state:[ 3 20 31  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 1984, score:[2778.80], loss:[2.22352], sequence:[35], random actions:[21], eInit:[0.0100], init state:[ 6 17 15  0  0  0  0  0], end state:[ 1 17 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1985, score:[2758.40], loss:[1.93034], sequence:[36], random actions:[31], eInit:[0.0100], init state:[ 3 23 49  1  0  0  0  0], end state:[ 5 23 49  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1986, score:[2749.20], loss:[3.04654], sequence:[37], random actions:[34], eInit:[0.0100], init state:[ 3 20 13  0  0  0  0  0], end state:[ 5 20 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1987, score:[2808.00], loss:[2.67132], sequence:[38], random actions:[36], eInit:[0.0100], init state:[ 3 12 20  0  0  0  0  0], end state:[ 5 12 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1988, score:[2797.60], loss:[2.31877], sequence:[39], random actions:[24], eInit:[0.0100], init state:[6 6 5 0 0 0 0 0], end state:[1 6 5 0 1 0 0 1]
INFO:Reinforcement.Functions:episode: 1989, score:[2773.20], loss:[2.11834], sequence:[40], random actions:[33], eInit:[0.0100], init state:[ 4 14  1  0  0  0  0  0], end state:[ 6 14  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1990, score:[2781.60], loss:[2.26593], sequence:[41], random actions:[26], eInit:[0.0100], init state:[ 6  7 27  0  0  0  0  0], end state:[ 1  7 27  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 1991, score:[2826.00], loss:[1.89059], sequence:[42], random actions:[15], eInit:[0.0100], init state:[ 4 19  5  0  0  0  0  0], end state:[ 6 19  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1992, score:[2784.40], loss:[2.05835], sequence:[43], random actions:[38], eInit:[0.0100], init state:[ 2 17  8  0  0  0  0  0], end state:[ 4 17  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1993, score:[2820.40], loss:[1.92104], sequence:[44], random actions:[27], eInit:[0.0100], init state:[0 3 9 0 0 0 0 0], end state:[2 3 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1994, score:[2784.00], loss:[2.10728], sequence:[45], random actions:[26], eInit:[0.0100], init state:[ 5 21 57  1  0  0  1  0], end state:[ 0 21 57  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1995, score:[2801.20], loss:[1.93203], sequence:[46], random actions:[31], eInit:[0.0100], init state:[2 9 5 0 0 0 0 0], end state:[4 9 5 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 1996, score:[2766.40], loss:[2.09497], sequence:[47], random actions:[43], eInit:[0.0100], init state:[ 5  6 24  0  0  0  0  0], end state:[ 0  6 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1997, score:[2786.00], loss:[2.20766], sequence:[48], random actions:[30], eInit:[0.0100], init state:[ 5 14  4  0  0  0  0  0], end state:[ 0 14  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1998, score:[2806.80], loss:[2.32774], sequence:[49], random actions:[32], eInit:[0.0100], init state:[ 6 23 53  1  0  0  0  0], end state:[ 1 23 53  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 1999, score:[2786.80], loss:[2.39313], sequence:[50], random actions:[29], eInit:[0.0100], init state:[ 5 12 52  0  0  0  0  0], end state:[ 0 12 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2000, score:[2806.00], loss:[2.40939], sequence:[51], random actions:[23], eInit:[0.0100], init state:[ 2  6 59  0  0  0  0  0], end state:[ 4  6 59  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2001, score:[2791.20], loss:[2.42990], sequence:[52], random actions:[24], eInit:[0.0100], init state:[3 6 1 0 0 0 0 0], end state:[5 6 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2002, score:[2781.60], loss:[2.31561], sequence:[53], random actions:[34], eInit:[0.0100], init state:[ 3 17 37  0  0  0  0  0], end state:[ 5 17 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2003, score:[2799.20], loss:[2.07964], sequence:[54], random actions:[37], eInit:[0.0100], init state:[ 0 16 22  0  0  0  0  0], end state:[ 2 16 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2004, score:[2780.40], loss:[2.07598], sequence:[55], random actions:[34], eInit:[0.0100], init state:[ 4 13 32  0  0  0  0  0], end state:[ 6 13 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2005, score:[2807.60], loss:[2.38841], sequence:[56], random actions:[28], eInit:[0.0100], init state:[ 2 20  3  0  0  0  0  0], end state:[ 4 20  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2006, score:[2806.00], loss:[2.31941], sequence:[57], random actions:[25], eInit:[0.0100], init state:[ 5  2 52  0  0  0  0  0], end state:[ 0  2 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2007, score:[2830.80], loss:[2.03287], sequence:[58], random actions:[17], eInit:[0.0100], init state:[ 6  9 10  0  0  0  0  0], end state:[ 1  9 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2008, score:[2764.80], loss:[2.27476], sequence:[59], random actions:[26], eInit:[0.0100], init state:[ 4  3 32  0  0  0  0  0], end state:[ 6  3 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2009, score:[2815.60], loss:[2.25828], sequence:[60], random actions:[31], eInit:[0.0100], init state:[ 0  8 26  1  0  0  0  0], end state:[ 2  8 26  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2010, score:[2740.00], loss:[2.79754], sequence:[61], random actions:[28], eInit:[0.0100], init state:[ 5  6 39  0  0  0  0  0], end state:[ 0  6 39  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2011, score:[2829.20], loss:[2.47958], sequence:[62], random actions:[32], eInit:[0.0100], init state:[ 4 17 18  0  0  0  0  0], end state:[ 6 17 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2012, score:[2761.20], loss:[2.51449], sequence:[63], random actions:[27], eInit:[0.0100], init state:[ 3 23 59  1  0  0  0  0], end state:[ 5 23 59  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2013, score:[2820.00], loss:[2.78773], sequence:[64], random actions:[30], eInit:[0.0100], init state:[ 1 21 46  1  0  0  0  0], end state:[ 3 21 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2014, score:[2736.00], loss:[2.68303], sequence:[65], random actions:[37], eInit:[0.0100], init state:[ 3 13  1  0  0  0  0  0], end state:[ 5 13  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2015, score:[2770.00], loss:[3.08239], sequence:[66], random actions:[39], eInit:[0.0100], init state:[ 6  3 14  0  0  0  0  0], end state:[ 1  3 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2016, score:[2763.60], loss:[2.88713], sequence:[67], random actions:[29], eInit:[0.0100], init state:[ 5  5 59  0  0  0  0  0], end state:[ 0  5 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2017, score:[2802.80], loss:[2.90240], sequence:[68], random actions:[36], eInit:[0.0100], init state:[ 3 14 32  0  0  0  0  0], end state:[ 5 14 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2018, score:[2807.60], loss:[2.62498], sequence:[69], random actions:[45], eInit:[0.0100], init state:[ 1  5 10  0  0  0  0  0], end state:[ 3  5 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2019, score:[2818.80], loss:[2.55465], sequence:[70], random actions:[24], eInit:[0.0100], init state:[ 3 18 10  0  0  0  0  0], end state:[ 5 18 10  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2020, score:[2818.80], loss:[2.44573], sequence:[71], random actions:[27], eInit:[0.0100], init state:[ 6 23 11  1  0  0  0  0], end state:[ 1 23 11  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2021, score:[2795.20], loss:[2.39848], sequence:[72], random actions:[27], eInit:[0.0100], init state:[ 2 18 26  0  0  0  0  0], end state:[ 4 18 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2022, score:[2802.40], loss:[2.60313], sequence:[73], random actions:[30], eInit:[0.0100], init state:[ 5 19 39  1  0  0  1  0], end state:[ 0 19 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2023, score:[2816.80], loss:[2.53160], sequence:[74], random actions:[26], eInit:[0.0100], init state:[ 6  2 58  0  0  0  0  0], end state:[ 1  2 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2024, score:[2797.20], loss:[2.36739], sequence:[75], random actions:[38], eInit:[0.0100], init state:[ 1 22 37  1  0  0  0  0], end state:[ 3 22 37  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2025, score:[2792.80], loss:[2.53267], sequence:[76], random actions:[30], eInit:[0.0100], init state:[ 5  4 18  0  0  0  0  0], end state:[ 0  4 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2026, score:[2807.60], loss:[2.67996], sequence:[77], random actions:[30], eInit:[0.0100], init state:[ 2  8 35  1  1  0  1  0], end state:[ 4  8 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2027, score:[2829.60], loss:[2.55778], sequence:[78], random actions:[28], eInit:[0.0100], init state:[ 3  9 41  0  0  0  0  0], end state:[ 5  9 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2028, score:[2823.60], loss:[2.51130], sequence:[79], random actions:[22], eInit:[0.0100], init state:[ 6 10 41  0  0  0  0  0], end state:[ 1 10 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2029, score:[2813.60], loss:[2.14318], sequence:[80], random actions:[27], eInit:[0.0100], init state:[ 3 15 54  0  0  0  0  0], end state:[ 5 15 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2030, score:[2796.40], loss:[2.06706], sequence:[81], random actions:[29], eInit:[0.0100], init state:[ 6  7 11  0  0  0  0  0], end state:[ 1  7 11  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2031, score:[2796.80], loss:[1.93081], sequence:[82], random actions:[35], eInit:[0.0100], init state:[ 1  2 56  0  0  0  0  0], end state:[ 3  2 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2032, score:[2831.60], loss:[1.89737], sequence:[83], random actions:[25], eInit:[0.0100], init state:[ 6 12 59  0  0  0  0  0], end state:[ 1 12 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2033, score:[2816.40], loss:[1.83185], sequence:[84], random actions:[27], eInit:[0.0100], init state:[ 3 17 49  0  0  0  0  0], end state:[ 5 17 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2034, score:[2804.80], loss:[1.66398], sequence:[85], random actions:[29], eInit:[0.0100], init state:[ 6 19 26  0  0  0  0  0], end state:[ 1 19 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2035, score:[2774.40], loss:[1.73784], sequence:[86], random actions:[34], eInit:[0.0100], init state:[ 4  5 12  0  0  0  0  0], end state:[ 6  5 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2036, score:[2801.60], loss:[1.84225], sequence:[87], random actions:[29], eInit:[0.0100], init state:[ 2  8 51  1  1  0  0  0], end state:[ 4  8 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2037, score:[2815.60], loss:[1.84657], sequence:[88], random actions:[23], eInit:[0.0100], init state:[ 3  2 17  0  0  0  0  0], end state:[ 5  2 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2038, score:[2780.00], loss:[1.99922], sequence:[89], random actions:[33], eInit:[0.0100], init state:[ 5 21 50  1  0  0  1  0], end state:[ 0 21 50  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2039, score:[2764.40], loss:[1.92119], sequence:[90], random actions:[29], eInit:[0.0100], init state:[ 4  1 39  0  0  0  0  0], end state:[ 6  1 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2040, score:[2799.20], loss:[2.00608], sequence:[91], random actions:[28], eInit:[0.0100], init state:[ 2 11 26  0  0  0  0  0], end state:[ 4 11 26  1  1  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2041, score:[2806.80], loss:[2.13994], sequence:[92], random actions:[24], eInit:[0.0100], init state:[ 1  0 23  1  0  0  0  0], end state:[ 3  0 23  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2042, score:[2807.60], loss:[1.95199], sequence:[93], random actions:[26], eInit:[0.0100], init state:[ 1  8 26  1  0  0  0  0], end state:[ 3  8 26  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2043, score:[2792.40], loss:[2.11601], sequence:[94], random actions:[33], eInit:[0.0100], init state:[ 6  3 55  0  0  0  0  0], end state:[ 1  3 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2044, score:[2801.20], loss:[1.90681], sequence:[95], random actions:[21], eInit:[0.0100], init state:[ 4 14 32  0  0  0  0  0], end state:[ 6 14 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2045, score:[2796.00], loss:[2.15889], sequence:[96], random actions:[29], eInit:[0.0100], init state:[ 3 12 28  0  0  0  0  0], end state:[ 5 12 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2046, score:[2823.60], loss:[2.05175], sequence:[97], random actions:[19], eInit:[0.0100], init state:[ 6  3 53  0  0  0  0  0], end state:[ 1  3 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2047, score:[2813.60], loss:[1.97795], sequence:[98], random actions:[31], eInit:[0.0100], init state:[ 1 19 21  0  0  0  0  0], end state:[ 3 19 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2048, score:[2820.40], loss:[1.73865], sequence:[99], random actions:[25], eInit:[0.0100], init state:[ 1  4 48  0  0  0  0  0], end state:[ 3  4 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2049, score:[2774.80], loss:[1.99765], sequence:[100], random actions:[26], eInit:[0.0100], init state:[ 5 11 56  0  0  0  0  0], end state:[ 0 11 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2050, score:[2832.00], loss:[1.80782], sequence:[101], random actions:[23], eInit:[0.0100], init state:[ 6 16 15  0  0  0  0  0], end state:[ 1 16 15  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2051, score:[2824.80], loss:[1.88247], sequence:[102], random actions:[29], eInit:[0.0100], init state:[ 6 18 52  0  0  0  0  0], end state:[ 1 18 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2052, score:[2808.40], loss:[1.95802], sequence:[103], random actions:[25], eInit:[0.0100], init state:[ 2 22 22  1  0  0  0  0], end state:[ 4 22 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2053, score:[2808.40], loss:[2.02477], sequence:[104], random actions:[33], eInit:[0.0100], init state:[ 3  2 55  0  0  0  0  0], end state:[ 5  2 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2054, score:[2802.00], loss:[2.04115], sequence:[105], random actions:[34], eInit:[0.0100], init state:[1 2 6 0 0 0 0 0], end state:[3 2 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2055, score:[2812.40], loss:[2.06974], sequence:[106], random actions:[31], eInit:[0.0100], init state:[3 2 0 0 0 0 0 0], end state:[5 2 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2056, score:[2804.80], loss:[1.74096], sequence:[107], random actions:[26], eInit:[0.0100], init state:[ 4  0 54  1  0  1  0  0], end state:[ 6  0 54  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2057, score:[2775.60], loss:[1.64623], sequence:[108], random actions:[34], eInit:[0.0100], init state:[ 6 23 32  1  0  0  1  0], end state:[ 1 23 32  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2058, score:[2838.40], loss:[1.65182], sequence:[109], random actions:[17], eInit:[0.0100], init state:[ 1 10 41  0  0  0  0  0], end state:[ 3 10 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2059, score:[2816.40], loss:[1.53050], sequence:[110], random actions:[31], eInit:[0.0100], init state:[ 0 19 38  0  0  0  0  0], end state:[ 2 19 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2060, score:[2815.60], loss:[1.50365], sequence:[111], random actions:[27], eInit:[0.0100], init state:[ 6  4 35  0  0  0  0  0], end state:[ 1  4 35  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2061, score:[2813.60], loss:[1.47745], sequence:[112], random actions:[21], eInit:[0.0100], init state:[ 6  2 49  0  0  0  0  0], end state:[ 1  2 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2062, score:[2794.80], loss:[1.65353], sequence:[113], random actions:[30], eInit:[0.0100], init state:[ 3 16 13  0  0  0  0  0], end state:[ 5 16 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2063, score:[2721.60], loss:[2.09575], sequence:[0], random actions:[40], eInit:[0.0100], init state:[ 5 12 44  0  0  0  0  0], end state:[ 0 12 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2064, score:[2782.00], loss:[1.87811], sequence:[1], random actions:[39], eInit:[0.0100], init state:[ 6  2 34  0  0  0  0  0], end state:[ 1  2 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2065, score:[2776.40], loss:[1.97066], sequence:[2], random actions:[23], eInit:[0.0100], init state:[ 5 15 53  0  0  0  0  0], end state:[ 0 15 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2066, score:[2778.40], loss:[2.03790], sequence:[3], random actions:[20], eInit:[0.0100], init state:[ 4 22 32  0  0  0  0  0], end state:[ 6 22 32  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2067, score:[2828.40], loss:[2.07259], sequence:[4], random actions:[25], eInit:[0.0100], init state:[ 3 14  5  0  0  0  0  0], end state:[ 5 14  5  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2068, score:[2831.60], loss:[1.92801], sequence:[5], random actions:[21], eInit:[0.0100], init state:[ 3  1 53  0  0  0  0  0], end state:[ 5  1 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2069, score:[2778.80], loss:[1.99344], sequence:[6], random actions:[35], eInit:[0.0100], init state:[ 4 22 19  0  0  0  0  0], end state:[ 6 22 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2070, score:[2810.00], loss:[1.81327], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 1 20 55  1  1  0  1  0], end state:[ 3 20 55  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2071, score:[2784.40], loss:[1.82813], sequence:[8], random actions:[36], eInit:[0.0100], init state:[ 4  3 47  0  0  0  0  0], end state:[ 6  3 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2072, score:[2813.20], loss:[1.85825], sequence:[9], random actions:[26], eInit:[0.0100], init state:[ 5 23  0  1  0  0  1  0], end state:[ 0 23  0  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2073, score:[2830.40], loss:[1.72396], sequence:[10], random actions:[26], eInit:[0.0100], init state:[ 2 10 43  0  0  0  0  0], end state:[ 4 10 43  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2074, score:[2838.80], loss:[1.63085], sequence:[11], random actions:[26], eInit:[0.0100], init state:[ 0 22 55  1  0  0  0  0], end state:[ 2 22 55  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2075, score:[2813.20], loss:[1.55233], sequence:[12], random actions:[38], eInit:[0.0100], init state:[ 1  3 39  0  0  0  0  0], end state:[ 3  3 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2076, score:[2773.60], loss:[1.80158], sequence:[13], random actions:[35], eInit:[0.0100], init state:[ 5 16 44  0  0  0  0  0], end state:[ 0 16 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2077, score:[2815.20], loss:[1.71390], sequence:[14], random actions:[19], eInit:[0.0100], init state:[ 6 10 30  0  0  0  0  0], end state:[ 1 10 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2078, score:[2790.40], loss:[1.63746], sequence:[15], random actions:[27], eInit:[0.0100], init state:[ 4  6 34  0  0  0  0  0], end state:[ 6  6 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2079, score:[2794.40], loss:[2.01761], sequence:[16], random actions:[31], eInit:[0.0100], init state:[ 1 18 56  0  0  0  0  0], end state:[ 3 18 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2080, score:[2794.80], loss:[1.98693], sequence:[17], random actions:[27], eInit:[0.0100], init state:[ 4 23  0  0  0  0  0  0], end state:[ 6 23  0  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2081, score:[2788.40], loss:[2.60669], sequence:[18], random actions:[35], eInit:[0.0100], init state:[ 6 13 42  0  0  0  0  0], end state:[ 1 13 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2082, score:[2835.60], loss:[2.21069], sequence:[19], random actions:[28], eInit:[0.0100], init state:[ 3 13 59  0  0  0  0  0], end state:[ 5 13 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2083, score:[2840.00], loss:[2.18290], sequence:[20], random actions:[23], eInit:[0.0100], init state:[ 2 15 56  0  0  0  0  0], end state:[ 4 15 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2084, score:[2806.80], loss:[2.02972], sequence:[21], random actions:[33], eInit:[0.0100], init state:[ 3  3 31  0  0  0  0  0], end state:[ 5  3 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2085, score:[2806.40], loss:[2.24008], sequence:[22], random actions:[37], eInit:[0.0100], init state:[ 3  9 25  0  0  0  0  0], end state:[ 5  9 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2086, score:[2750.00], loss:[2.39394], sequence:[23], random actions:[36], eInit:[0.0100], init state:[5 2 1 0 0 0 0 0], end state:[0 2 1 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2087, score:[2738.00], loss:[2.43062], sequence:[24], random actions:[27], eInit:[0.0100], init state:[ 4 23 50  0  0  0  0  0], end state:[ 6 23 50  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2088, score:[2783.20], loss:[2.72027], sequence:[25], random actions:[35], eInit:[0.0100], init state:[2 6 6 0 0 0 0 0], end state:[4 6 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2089, score:[2806.40], loss:[2.34091], sequence:[26], random actions:[27], eInit:[0.0100], init state:[ 5 22 11  1  0  0  1  0], end state:[ 0 22 11  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2090, score:[2815.60], loss:[2.28813], sequence:[27], random actions:[28], eInit:[0.0100], init state:[ 6  0 58  0  0  1  0  0], end state:[ 1  0 58  0  0  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2091, score:[2784.40], loss:[2.28019], sequence:[28], random actions:[29], eInit:[0.0100], init state:[ 3 15 41  0  0  0  0  0], end state:[ 5 15 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2092, score:[2817.60], loss:[2.12340], sequence:[29], random actions:[27], eInit:[0.0100], init state:[ 0 12 52  0  0  0  0  0], end state:[ 2 12 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2093, score:[2818.40], loss:[2.41643], sequence:[30], random actions:[28], eInit:[0.0100], init state:[2 8 2 1 0 0 0 0], end state:[4 8 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2094, score:[2815.20], loss:[2.10332], sequence:[31], random actions:[32], eInit:[0.0100], init state:[ 1  1 11  0  0  0  0  0], end state:[ 3  1 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2095, score:[2807.60], loss:[1.95124], sequence:[32], random actions:[40], eInit:[0.0100], init state:[ 0 21 12  1  1  0  1  0], end state:[ 2 21 12  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2096, score:[2790.00], loss:[1.88724], sequence:[33], random actions:[25], eInit:[0.0100], init state:[ 5  3 39  0  0  0  0  0], end state:[ 0  3 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2097, score:[2799.60], loss:[2.32963], sequence:[34], random actions:[20], eInit:[0.0100], init state:[ 6 13 16  0  0  0  0  0], end state:[ 1 13 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2098, score:[2828.40], loss:[2.29394], sequence:[35], random actions:[21], eInit:[0.0100], init state:[ 1  0 24  1  0  0  0  0], end state:[ 3  0 24  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2099, score:[2793.20], loss:[1.81832], sequence:[36], random actions:[28], eInit:[0.0100], init state:[ 5  3 31  0  0  0  0  0], end state:[ 0  3 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2100, score:[2795.60], loss:[2.00932], sequence:[37], random actions:[24], eInit:[0.0100], init state:[ 6  4 26  0  0  0  0  0], end state:[ 1  4 26  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2101, score:[2834.00], loss:[2.07558], sequence:[38], random actions:[25], eInit:[0.0100], init state:[ 6 10 29  0  0  0  0  0], end state:[ 1 10 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2102, score:[2814.80], loss:[1.98519], sequence:[39], random actions:[28], eInit:[0.0100], init state:[ 0 23  3  1  0  0  0  0], end state:[ 2 23  3  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2103, score:[2812.00], loss:[1.90692], sequence:[40], random actions:[18], eInit:[0.0100], init state:[ 1  0 27  1  0  0  0  0], end state:[ 3  0 27  0  1  0  1  1]
INFO:Reinforcement.Functions:episode: 2104, score:[2827.20], loss:[1.78723], sequence:[41], random actions:[32], eInit:[0.0100], init state:[1 9 5 0 0 0 0 0], end state:[3 9 5 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2105, score:[2822.00], loss:[1.66196], sequence:[42], random actions:[26], eInit:[0.0100], init state:[ 2  0 45  0  0  1  0  0], end state:[ 4  0 45  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2106, score:[2821.60], loss:[1.59173], sequence:[43], random actions:[26], eInit:[0.0100], init state:[ 2  9 34  0  0  0  0  0], end state:[ 4  9 34  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2107, score:[2794.00], loss:[1.87092], sequence:[44], random actions:[32], eInit:[0.0100], init state:[ 6  5 56  0  0  0  0  0], end state:[ 1  5 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2108, score:[2690.00], loss:[2.25227], sequence:[0], random actions:[34], eInit:[0.0100], init state:[ 4 17 54  0  0  0  0  0], end state:[ 6 17 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2109, score:[2809.60], loss:[1.93963], sequence:[1], random actions:[18], eInit:[0.0100], init state:[3 2 9 0 0 0 0 0], end state:[5 2 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2110, score:[2810.40], loss:[1.98999], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 1 17 30  0  0  0  0  0], end state:[ 3 17 30  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2111, score:[2820.40], loss:[1.84403], sequence:[3], random actions:[19], eInit:[0.0100], init state:[6 8 0 1 0 0 0 0], end state:[1 8 0 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2112, score:[2816.80], loss:[1.74227], sequence:[4], random actions:[22], eInit:[0.0100], init state:[0 4 3 0 0 0 0 0], end state:[2 4 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2113, score:[2826.00], loss:[1.87364], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 6 15 40  0  0  0  0  0], end state:[ 1 15 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2114, score:[2762.00], loss:[2.02883], sequence:[6], random actions:[34], eInit:[0.0100], init state:[ 3 17 55  0  0  0  0  0], end state:[ 5 17 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2115, score:[2800.00], loss:[2.06587], sequence:[7], random actions:[29], eInit:[0.0100], init state:[ 1  4 40  0  0  0  0  0], end state:[ 3  4 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2116, score:[2737.60], loss:[2.50007], sequence:[8], random actions:[29], eInit:[0.0100], init state:[ 5  9 59  0  0  0  0  0], end state:[ 0  9 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2117, score:[2771.20], loss:[2.16341], sequence:[9], random actions:[28], eInit:[0.0100], init state:[ 4 16 57  0  0  0  0  0], end state:[ 6 16 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2118, score:[2814.40], loss:[2.04260], sequence:[10], random actions:[30], eInit:[0.0100], init state:[ 0  2 14  0  0  0  0  0], end state:[ 2  2 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2119, score:[2807.20], loss:[1.97617], sequence:[11], random actions:[34], eInit:[0.0100], init state:[ 1 21 59  1  0  0  0  0], end state:[ 3 21 59  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2120, score:[2734.40], loss:[2.17676], sequence:[0], random actions:[38], eInit:[0.0100], init state:[ 4 19 43  0  0  0  0  0], end state:[ 6 19 43  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2121, score:[2817.20], loss:[2.15819], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 1 22 58  1  0  0  0  0], end state:[ 3 22 58  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2122, score:[2766.00], loss:[2.46157], sequence:[2], random actions:[22], eInit:[0.0100], init state:[ 4 23  8  0  0  0  0  0], end state:[ 6 23  8  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2123, score:[2754.40], loss:[2.60964], sequence:[3], random actions:[46], eInit:[0.0100], init state:[ 4  8 43  0  0  0  0  0], end state:[ 6  8 43  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2124, score:[2819.20], loss:[2.74993], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 5 21 26  1  0  0  1  1], end state:[ 0 21 26  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2125, score:[2769.60], loss:[2.90388], sequence:[5], random actions:[29], eInit:[0.0100], init state:[ 3 18 43  0  0  0  0  0], end state:[ 5 18 43  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2126, score:[2800.80], loss:[2.93082], sequence:[6], random actions:[22], eInit:[0.0100], init state:[ 1 12 18  0  0  0  0  0], end state:[ 3 12 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2127, score:[2775.60], loss:[2.49164], sequence:[7], random actions:[33], eInit:[0.0100], init state:[ 2 14 45  0  0  0  0  0], end state:[ 4 14 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2128, score:[2800.80], loss:[2.65889], sequence:[8], random actions:[27], eInit:[0.0100], init state:[ 5  8 18  0  0  0  0  0], end state:[ 0  8 18  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2129, score:[2767.20], loss:[2.52859], sequence:[9], random actions:[35], eInit:[0.0100], init state:[ 3 19 44  0  0  0  0  0], end state:[ 5 19 44  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2130, score:[2786.40], loss:[2.57699], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 5 15  7  0  0  0  0  0], end state:[ 0 15  7  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2131, score:[2820.40], loss:[2.52613], sequence:[11], random actions:[35], eInit:[0.0100], init state:[ 1  8 30  1  1  0  1  1], end state:[ 3  8 30  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2132, score:[2805.60], loss:[2.40835], sequence:[12], random actions:[29], eInit:[0.0100], init state:[ 2 13 38  0  0  0  0  0], end state:[ 4 13 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2133, score:[2825.20], loss:[2.33128], sequence:[13], random actions:[18], eInit:[0.0100], init state:[ 0 13 38  0  0  0  0  0], end state:[ 2 13 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2134, score:[2802.40], loss:[2.24435], sequence:[14], random actions:[27], eInit:[0.0100], init state:[ 0 10  1  0  0  0  0  0], end state:[ 2 10  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2135, score:[2765.60], loss:[2.18908], sequence:[15], random actions:[29], eInit:[0.0100], init state:[ 4 10 28  1  1  0  1  0], end state:[ 6 10 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2136, score:[2800.00], loss:[2.17343], sequence:[16], random actions:[34], eInit:[0.0100], init state:[ 6 10 49  0  0  0  0  0], end state:[ 1 10 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2137, score:[2798.00], loss:[2.27354], sequence:[17], random actions:[24], eInit:[0.0100], init state:[ 2 10 53  0  0  0  0  0], end state:[ 4 10 53  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2138, score:[2792.40], loss:[2.11975], sequence:[18], random actions:[28], eInit:[0.0100], init state:[ 4 14  7  0  0  0  0  0], end state:[ 6 14  7  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2139, score:[2833.20], loss:[2.10956], sequence:[19], random actions:[22], eInit:[0.0100], init state:[ 0 15 17  0  0  0  0  0], end state:[ 2 15 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2140, score:[2774.40], loss:[2.00864], sequence:[20], random actions:[24], eInit:[0.0100], init state:[ 4  5 29  0  0  0  0  0], end state:[ 6  5 29  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2141, score:[2789.60], loss:[2.28733], sequence:[21], random actions:[40], eInit:[0.0100], init state:[3 2 5 0 0 0 0 0], end state:[5 2 5 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2142, score:[2821.60], loss:[2.35347], sequence:[22], random actions:[33], eInit:[0.0100], init state:[ 3 12 41  0  0  0  0  0], end state:[ 5 12 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2143, score:[2731.60], loss:[2.48812], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4 10 15  1  1  0  1  1], end state:[ 6 10 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2144, score:[2780.80], loss:[2.72600], sequence:[1], random actions:[33], eInit:[0.0100], init state:[ 4  4 19  0  0  0  0  0], end state:[ 6  4 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2145, score:[2812.40], loss:[2.72585], sequence:[2], random actions:[32], eInit:[0.0100], init state:[ 6 23 47  1  0  0  0  0], end state:[ 1 23 47  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2146, score:[2825.60], loss:[2.35067], sequence:[3], random actions:[27], eInit:[0.0100], init state:[ 1  6 55  0  0  0  0  0], end state:[ 3  6 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2147, score:[2824.40], loss:[2.23887], sequence:[4], random actions:[31], eInit:[0.0100], init state:[ 1  6 51  0  0  0  0  0], end state:[ 3  6 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2148, score:[2780.80], loss:[2.14477], sequence:[5], random actions:[27], eInit:[0.0100], init state:[ 6 20 11  0  0  0  0  0], end state:[ 1 20 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2149, score:[2800.00], loss:[2.15880], sequence:[6], random actions:[42], eInit:[0.0100], init state:[ 6 16 17  0  0  0  0  0], end state:[ 1 16 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2150, score:[2817.60], loss:[2.07194], sequence:[7], random actions:[22], eInit:[0.0100], init state:[ 3 16 54  0  0  0  0  0], end state:[ 5 16 54  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2151, score:[2761.20], loss:[2.28813], sequence:[8], random actions:[32], eInit:[0.0100], init state:[ 5 10 41  0  0  0  0  0], end state:[ 0 10 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2152, score:[2806.00], loss:[2.53588], sequence:[9], random actions:[33], eInit:[0.0100], init state:[ 3 14 22  0  0  0  0  0], end state:[ 5 14 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2153, score:[2810.00], loss:[2.36165], sequence:[10], random actions:[32], eInit:[0.0100], init state:[ 0 15 43  0  0  0  0  0], end state:[ 2 15 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2154, score:[2806.40], loss:[2.65866], sequence:[11], random actions:[35], eInit:[0.0100], init state:[ 6 19 44  0  0  0  0  0], end state:[ 1 19 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2155, score:[2828.80], loss:[2.32029], sequence:[12], random actions:[24], eInit:[0.0100], init state:[ 1 13  7  0  0  0  0  0], end state:[ 3 13  7  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2156, score:[2820.40], loss:[2.52659], sequence:[13], random actions:[33], eInit:[0.0100], init state:[ 1 23 20  1  0  0  1  0], end state:[ 3 23 20  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2157, score:[2766.40], loss:[2.63906], sequence:[14], random actions:[40], eInit:[0.0100], init state:[ 4  4 12  0  0  0  0  0], end state:[ 6  4 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2158, score:[2780.40], loss:[2.63895], sequence:[15], random actions:[37], eInit:[0.0100], init state:[ 3 21 12  1  1  0  1  0], end state:[ 5 21 12  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2159, score:[2830.80], loss:[2.45753], sequence:[16], random actions:[26], eInit:[0.0100], init state:[ 2  6 30  0  0  0  0  0], end state:[ 4  6 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2160, score:[2800.00], loss:[2.39941], sequence:[17], random actions:[27], eInit:[0.0100], init state:[ 3  0 32  0  0  1  0  0], end state:[ 5  0 32  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2161, score:[2831.60], loss:[2.12905], sequence:[18], random actions:[27], eInit:[0.0100], init state:[ 0 17 25  0  0  0  0  0], end state:[ 2 17 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2162, score:[2809.60], loss:[2.05460], sequence:[19], random actions:[40], eInit:[0.0100], init state:[ 1 22 23  1  0  0  0  0], end state:[ 3 22 23  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2163, score:[2759.20], loss:[2.32613], sequence:[20], random actions:[24], eInit:[0.0100], init state:[5 4 3 0 0 0 0 0], end state:[0 4 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2164, score:[2818.40], loss:[2.39263], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 6  4 50  0  0  0  0  0], end state:[ 1  4 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2165, score:[2824.80], loss:[2.17549], sequence:[22], random actions:[27], eInit:[0.0100], init state:[ 0  5 23  0  0  0  0  0], end state:[ 2  5 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2166, score:[2748.00], loss:[2.53078], sequence:[23], random actions:[26], eInit:[0.0100], init state:[ 5  9 14  0  0  0  0  0], end state:[ 0  9 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2167, score:[2778.00], loss:[2.79242], sequence:[24], random actions:[26], eInit:[0.0100], init state:[ 6  1 42  0  0  0  0  0], end state:[ 1  1 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2168, score:[2796.00], loss:[2.80169], sequence:[25], random actions:[34], eInit:[0.0100], init state:[ 0  3 30  0  0  0  0  0], end state:[ 2  3 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2169, score:[2719.20], loss:[2.91262], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 16 27  0  0  0  0  0], end state:[ 0 16 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2170, score:[2819.60], loss:[2.63417], sequence:[1], random actions:[26], eInit:[0.0100], init state:[ 0  4 12  0  0  0  0  0], end state:[ 2  4 12  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2171, score:[2780.80], loss:[2.72733], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 3 12 58  0  0  0  0  0], end state:[ 5 12 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2172, score:[2790.00], loss:[2.48412], sequence:[3], random actions:[41], eInit:[0.0100], init state:[ 1 21 20  1  1  0  1  0], end state:[ 3 21 20  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2173, score:[2828.80], loss:[2.72377], sequence:[4], random actions:[20], eInit:[0.0100], init state:[ 2 18 33  0  0  0  0  0], end state:[ 4 18 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2174, score:[2793.20], loss:[2.54738], sequence:[5], random actions:[23], eInit:[0.0100], init state:[5 0 1 0 0 0 0 0], end state:[0 0 1 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2175, score:[2806.80], loss:[2.39938], sequence:[6], random actions:[31], eInit:[0.0100], init state:[ 3  0 52  0  0  1  0  0], end state:[ 5  0 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2176, score:[2737.60], loss:[2.93162], sequence:[7], random actions:[31], eInit:[0.0100], init state:[ 2 20  0  0  0  0  0  0], end state:[ 4 20  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2177, score:[2795.20], loss:[3.44751], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 6  4 30  0  0  0  0  0], end state:[ 1  4 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2178, score:[2777.20], loss:[3.29310], sequence:[9], random actions:[30], eInit:[0.0100], init state:[ 5 19 29  1  0  0  1  0], end state:[ 0 19 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2179, score:[2739.60], loss:[3.28220], sequence:[10], random actions:[30], eInit:[0.0100], init state:[ 4 10  0  1  1  0  1  0], end state:[ 6 10  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2180, score:[2805.20], loss:[3.25623], sequence:[11], random actions:[25], eInit:[0.0100], init state:[ 6  7 44  0  0  0  0  0], end state:[ 1  7 44  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2181, score:[2823.20], loss:[3.12278], sequence:[12], random actions:[25], eInit:[0.0100], init state:[ 0  1 28  0  0  0  0  0], end state:[ 2  1 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2182, score:[2798.80], loss:[2.92828], sequence:[13], random actions:[24], eInit:[0.0100], init state:[ 5  0 48  0  0  0  0  0], end state:[ 0  0 48  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2183, score:[2829.20], loss:[2.85816], sequence:[14], random actions:[20], eInit:[0.0100], init state:[ 2 16  8  0  0  0  0  0], end state:[ 4 16  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2184, score:[2798.80], loss:[2.71820], sequence:[15], random actions:[24], eInit:[0.0100], init state:[ 2  2 20  0  0  0  0  0], end state:[ 4  2 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2185, score:[2781.20], loss:[3.01846], sequence:[16], random actions:[40], eInit:[0.0100], init state:[ 6 16 53  0  0  0  0  0], end state:[ 1 16 53  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2186, score:[2774.40], loss:[2.64816], sequence:[17], random actions:[29], eInit:[0.0100], init state:[ 4  0 30  1  0  1  0  0], end state:[ 6  0 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2187, score:[2780.40], loss:[2.47249], sequence:[18], random actions:[34], eInit:[0.0100], init state:[ 6 10 34  0  0  0  0  0], end state:[ 1 10 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2188, score:[2800.00], loss:[2.62429], sequence:[19], random actions:[34], eInit:[0.0100], init state:[ 0 22 15  1  0  0  0  0], end state:[ 2 22 15  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2189, score:[2786.00], loss:[2.57225], sequence:[20], random actions:[26], eInit:[0.0100], init state:[ 4  7 12  0  0  0  0  0], end state:[ 6  7 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2190, score:[2785.60], loss:[2.62971], sequence:[21], random actions:[20], eInit:[0.0100], init state:[ 1  7 32  0  0  0  0  0], end state:[ 3  7 32  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2191, score:[2815.60], loss:[2.68359], sequence:[22], random actions:[32], eInit:[0.0100], init state:[ 3  5 28  0  0  0  0  0], end state:[ 5  5 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2192, score:[2762.00], loss:[3.00523], sequence:[23], random actions:[29], eInit:[0.0100], init state:[ 6  6 12  0  0  0  0  0], end state:[ 1  6 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2193, score:[2786.80], loss:[2.86050], sequence:[24], random actions:[31], eInit:[0.0100], init state:[ 3  1 36  0  0  0  0  0], end state:[ 5  1 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2194, score:[2791.60], loss:[2.66989], sequence:[25], random actions:[33], eInit:[0.0100], init state:[0 4 3 0 0 0 0 0], end state:[2 4 3 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2195, score:[2822.40], loss:[2.33293], sequence:[26], random actions:[30], eInit:[0.0100], init state:[ 2  5 46  0  0  0  0  0], end state:[ 4  5 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2196, score:[2752.80], loss:[2.55124], sequence:[27], random actions:[33], eInit:[0.0100], init state:[ 5  6 13  0  0  0  0  0], end state:[ 0  6 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2197, score:[2823.20], loss:[2.36764], sequence:[28], random actions:[18], eInit:[0.0100], init state:[1 0 4 1 0 0 0 0], end state:[3 0 4 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2198, score:[2817.20], loss:[2.57998], sequence:[29], random actions:[36], eInit:[0.0100], init state:[ 1  7 23  0  0  0  0  0], end state:[ 3  7 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2199, score:[2785.60], loss:[2.50775], sequence:[30], random actions:[29], eInit:[0.0100], init state:[ 1  8 46  1  1  0  0  0], end state:[ 3  8 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2200, score:[2800.80], loss:[3.04518], sequence:[31], random actions:[28], eInit:[0.0100], init state:[ 1  7 49  0  0  0  0  0], end state:[ 3  7 49  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2201, score:[2807.20], loss:[3.14414], sequence:[32], random actions:[19], eInit:[0.0100], init state:[ 6  8 54  1  1  0  0  0], end state:[ 1  8 54  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2202, score:[2785.20], loss:[2.92475], sequence:[33], random actions:[16], eInit:[0.0100], init state:[ 3 20 25  0  0  0  0  0], end state:[ 5 20 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2203, score:[2822.40], loss:[2.67847], sequence:[34], random actions:[30], eInit:[0.0100], init state:[ 0 23 36  1  0  0  1  0], end state:[ 2 23 36  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2204, score:[2729.60], loss:[3.03078], sequence:[0], random actions:[24], eInit:[0.0100], init state:[ 5  9 49  0  0  0  0  0], end state:[ 0  9 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2205, score:[2801.60], loss:[2.85652], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 3 22 46  1  0  0  0  0], end state:[ 5 22 46  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2206, score:[2824.80], loss:[2.51376], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 0 23 57  1  0  0  0  0], end state:[ 2 23 57  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2207, score:[2820.40], loss:[2.52290], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 0 12 47  0  0  0  0  0], end state:[ 2 12 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2208, score:[2814.80], loss:[2.38578], sequence:[4], random actions:[36], eInit:[0.0100], init state:[ 0 20 20  0  0  0  0  0], end state:[ 2 20 20  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2209, score:[2813.20], loss:[2.45423], sequence:[5], random actions:[24], eInit:[0.0100], init state:[ 0 18 49  0  0  0  0  0], end state:[ 2 18 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2210, score:[2806.80], loss:[1.89802], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 0 16 28  0  0  0  0  0], end state:[ 2 16 28  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2211, score:[2683.60], loss:[1.95547], sequence:[0], random actions:[36], eInit:[0.0100], init state:[ 4  0 54  1  0  1  0  0], end state:[ 6  0 54  0  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2212, score:[2819.60], loss:[1.87769], sequence:[1], random actions:[25], eInit:[0.0100], init state:[ 6  3 28  0  0  0  0  0], end state:[ 1  3 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2213, score:[2766.00], loss:[2.03674], sequence:[2], random actions:[26], eInit:[0.0100], init state:[ 3 12 54  0  0  0  0  0], end state:[ 5 12 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2214, score:[2788.40], loss:[1.96862], sequence:[3], random actions:[28], eInit:[0.0100], init state:[ 3  2 59  0  0  0  0  0], end state:[ 5  2 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2215, score:[2802.40], loss:[1.99211], sequence:[4], random actions:[29], eInit:[0.0100], init state:[ 2 23  6  1  0  0  0  0], end state:[ 4 23  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2216, score:[2823.20], loss:[1.86967], sequence:[5], random actions:[32], eInit:[0.0100], init state:[ 1  5 34  0  0  0  0  0], end state:[ 3  5 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2217, score:[2788.80], loss:[1.74891], sequence:[6], random actions:[32], eInit:[0.0100], init state:[ 2 14 16  0  0  0  0  0], end state:[ 4 14 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2218, score:[2828.00], loss:[1.67694], sequence:[7], random actions:[28], eInit:[0.0100], init state:[0 4 6 0 0 0 0 0], end state:[2 4 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2219, score:[2778.00], loss:[1.79796], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 4 11 30  1  1  0  0  0], end state:[ 6 11 30  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2220, score:[2821.20], loss:[2.01170], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 1 20  5  0  0  0  0  0], end state:[ 3 20  5  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2221, score:[2812.80], loss:[1.91514], sequence:[10], random actions:[18], eInit:[0.0100], init state:[ 3 12 59  0  0  0  0  0], end state:[ 5 12 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2222, score:[2738.00], loss:[1.86307], sequence:[11], random actions:[27], eInit:[0.0100], init state:[ 4  8 20  0  0  0  0  0], end state:[ 6  8 20  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2223, score:[2783.20], loss:[2.15300], sequence:[12], random actions:[30], eInit:[0.0100], init state:[ 4  0 30  1  0  1  0  0], end state:[ 6  0 30  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2224, score:[2816.00], loss:[1.81742], sequence:[13], random actions:[34], eInit:[0.0100], init state:[ 0 14 40  0  0  0  0  0], end state:[ 2 14 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2225, score:[2696.80], loss:[2.11474], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5 11 36  0  0  0  0  0], end state:[ 0 11 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2226, score:[2832.80], loss:[1.97000], sequence:[1], random actions:[27], eInit:[0.0100], init state:[ 1  9 10  0  0  0  0  0], end state:[ 3  9 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2227, score:[2777.60], loss:[2.26429], sequence:[2], random actions:[29], eInit:[0.0100], init state:[ 4  6 57  0  0  0  0  0], end state:[ 6  6 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2228, score:[2807.60], loss:[2.27646], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 2 19 50  0  0  0  0  0], end state:[ 4 19 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2229, score:[2795.20], loss:[2.18723], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 6 17 16  0  0  0  0  0], end state:[ 1 17 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2230, score:[2836.80], loss:[1.95956], sequence:[5], random actions:[23], eInit:[0.0100], init state:[0 2 3 0 0 0 0 0], end state:[2 2 3 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2231, score:[2815.60], loss:[1.99059], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 0  6 33  0  0  0  0  0], end state:[ 2  6 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2232, score:[2825.20], loss:[1.83320], sequence:[7], random actions:[32], eInit:[0.0100], init state:[ 1 10 21  0  0  0  0  0], end state:[ 3 10 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2233, score:[2826.00], loss:[1.93328], sequence:[8], random actions:[28], eInit:[0.0100], init state:[ 1 14  8  0  0  0  0  0], end state:[ 3 14  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2234, score:[2837.60], loss:[1.75748], sequence:[9], random actions:[23], eInit:[0.0100], init state:[ 2  0 37  0  0  1  0  0], end state:[ 4  0 37  1  0  1  0  0]
INFO:Reinforcement.Functions:episode: 2235, score:[2775.20], loss:[1.80542], sequence:[10], random actions:[27], eInit:[0.0100], init state:[ 4 22 37  0  0  0  0  0], end state:[ 6 22 37  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2236, score:[2803.20], loss:[1.79188], sequence:[11], random actions:[26], eInit:[0.0100], init state:[ 3  7 35  0  0  0  0  0], end state:[ 5  7 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2237, score:[2800.40], loss:[1.77635], sequence:[12], random actions:[28], eInit:[0.0100], init state:[ 4  1 35  0  0  0  0  0], end state:[ 6  1 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2238, score:[2808.00], loss:[2.05614], sequence:[13], random actions:[27], eInit:[0.0100], init state:[ 1 16 57  0  0  0  0  0], end state:[ 3 16 57  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2239, score:[2829.60], loss:[1.75596], sequence:[14], random actions:[27], eInit:[0.0100], init state:[ 0 14  8  0  0  0  0  0], end state:[ 2 14  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2240, score:[2808.80], loss:[1.68987], sequence:[15], random actions:[31], eInit:[0.0100], init state:[3 0 0 1 0 0 0 0], end state:[5 0 0 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2241, score:[2813.20], loss:[1.87786], sequence:[16], random actions:[28], eInit:[0.0100], init state:[ 2 18 37  0  0  0  0  0], end state:[ 4 18 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2242, score:[2806.00], loss:[1.70738], sequence:[17], random actions:[36], eInit:[0.0100], init state:[ 4  7 21  0  0  0  0  0], end state:[ 6  7 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2243, score:[2819.60], loss:[1.72235], sequence:[18], random actions:[34], eInit:[0.0100], init state:[1 1 8 0 0 1 0 0], end state:[3 1 8 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 2244, score:[2787.20], loss:[1.82196], sequence:[19], random actions:[24], eInit:[0.0100], init state:[ 4 12  9  1  1  0  0  0], end state:[ 6 12  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2245, score:[2826.40], loss:[1.65575], sequence:[20], random actions:[28], eInit:[0.0100], init state:[ 2 12  9  0  0  0  0  0], end state:[ 4 12  9  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2246, score:[2780.80], loss:[1.69831], sequence:[21], random actions:[34], eInit:[0.0100], init state:[ 3 23 56  1  0  0  0  0], end state:[ 5 23 56  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2247, score:[2806.40], loss:[1.70194], sequence:[22], random actions:[34], eInit:[0.0100], init state:[ 1 18 22  0  0  0  0  0], end state:[ 3 18 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2248, score:[2800.00], loss:[1.74809], sequence:[23], random actions:[35], eInit:[0.0100], init state:[ 4 14 33  0  0  0  0  0], end state:[ 6 14 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2249, score:[2825.60], loss:[1.89326], sequence:[24], random actions:[21], eInit:[0.0100], init state:[ 5 22 25  1  0  0  1  0], end state:[ 0 22 25  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2250, score:[2820.40], loss:[1.87304], sequence:[25], random actions:[33], eInit:[0.0100], init state:[ 0  8 33  1  1  0  1  1], end state:[ 2  8 33  1  0  0  1  1]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2251, score:[2790.40], loss:[1.71962], sequence:[26], random actions:[28], eInit:[0.0100], init state:[ 2 12 20  0  0  0  0  0], end state:[ 4 12 20  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2252, score:[2762.40], loss:[1.87616], sequence:[27], random actions:[39], eInit:[0.0100], init state:[ 6 10  9  0  0  0  0  0], end state:[ 1 10  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2253, score:[2765.60], loss:[2.76720], sequence:[28], random actions:[24], eInit:[0.0100], init state:[ 4  4 25  0  0  0  0  0], end state:[ 6  4 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2254, score:[2771.60], loss:[2.10260], sequence:[29], random actions:[31], eInit:[0.0100], init state:[ 5  4 56  0  0  0  0  0], end state:[ 0  4 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2255, score:[2800.80], loss:[2.35422], sequence:[30], random actions:[23], eInit:[0.0100], init state:[ 6  2 34  0  0  0  0  0], end state:[ 1  2 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2256, score:[2775.20], loss:[2.56221], sequence:[31], random actions:[32], eInit:[0.0100], init state:[ 6  8 45  1  1  0  0  0], end state:[ 1  8 45  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2257, score:[2816.40], loss:[2.26645], sequence:[32], random actions:[31], eInit:[0.0100], init state:[ 2  2 47  0  0  0  0  0], end state:[ 4  2 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2258, score:[2799.60], loss:[2.50128], sequence:[33], random actions:[34], eInit:[0.0100], init state:[3 2 2 0 0 0 0 0], end state:[5 2 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2259, score:[2789.20], loss:[2.51356], sequence:[34], random actions:[27], eInit:[0.0100], init state:[ 4 22 46  0  0  0  0  0], end state:[ 6 22 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2260, score:[2810.40], loss:[2.61209], sequence:[35], random actions:[32], eInit:[0.0100], init state:[6 3 1 0 0 0 0 0], end state:[1 3 1 0 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2261, score:[2798.00], loss:[2.49567], sequence:[36], random actions:[27], eInit:[0.0100], init state:[ 6 10 13  0  0  0  0  0], end state:[ 1 10 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2262, score:[2788.40], loss:[2.12417], sequence:[37], random actions:[25], eInit:[0.0100], init state:[ 4 19 59  0  0  0  0  0], end state:[ 6 19 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2263, score:[2814.80], loss:[1.95686], sequence:[38], random actions:[27], eInit:[0.0100], init state:[ 0  2 41  0  0  0  0  0], end state:[ 2  2 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2264, score:[2832.80], loss:[1.83097], sequence:[39], random actions:[24], eInit:[0.0100], init state:[ 0  9 18  0  0  0  0  0], end state:[ 2  9 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2265, score:[2787.60], loss:[1.87618], sequence:[40], random actions:[34], eInit:[0.0100], init state:[ 2 15  0  0  0  0  0  0], end state:[ 4 15  0  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2266, score:[2760.80], loss:[2.36053], sequence:[41], random actions:[33], eInit:[0.0100], init state:[ 4  6 12  0  0  0  0  0], end state:[ 6  6 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2267, score:[2728.80], loss:[2.38838], sequence:[0], random actions:[29], eInit:[0.0100], init state:[ 5  2 39  0  0  0  0  0], end state:[ 0  2 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2268, score:[2811.60], loss:[2.66293], sequence:[1], random actions:[31], eInit:[0.0100], init state:[ 3  4 31  0  0  0  0  0], end state:[ 5  4 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2269, score:[2828.80], loss:[2.33008], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 0  2 59  0  0  0  0  0], end state:[ 2  2 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2270, score:[2827.60], loss:[2.22526], sequence:[3], random actions:[22], eInit:[0.0100], init state:[ 0  4 57  0  0  0  0  0], end state:[ 2  4 57  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2271, score:[2776.40], loss:[2.25371], sequence:[4], random actions:[28], eInit:[0.0100], init state:[ 5 13  6  0  0  0  0  0], end state:[ 0 13  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2272, score:[2781.60], loss:[2.07624], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 5 12 44  0  0  0  0  0], end state:[ 0 12 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2273, score:[2808.80], loss:[1.94554], sequence:[6], random actions:[21], eInit:[0.0100], init state:[ 4 22  2  0  0  0  0  0], end state:[ 6 22  2  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2274, score:[2808.80], loss:[1.94108], sequence:[7], random actions:[34], eInit:[0.0100], init state:[ 4 12 37  1  1  0  0  0], end state:[ 6 12 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2275, score:[2822.40], loss:[1.95150], sequence:[8], random actions:[20], eInit:[0.0100], init state:[ 0  6 11  0  0  0  0  0], end state:[ 2  6 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2276, score:[2839.20], loss:[1.99560], sequence:[9], random actions:[24], eInit:[0.0100], init state:[ 3 23 42  1  0  0  1  0], end state:[ 5 23 42  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2277, score:[2766.40], loss:[2.09314], sequence:[10], random actions:[28], eInit:[0.0100], init state:[ 3 18 56  0  0  0  0  0], end state:[ 5 18 56  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2278, score:[2808.00], loss:[2.14402], sequence:[11], random actions:[32], eInit:[0.0100], init state:[ 3  5 11  0  0  0  0  0], end state:[ 5  5 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2279, score:[2823.60], loss:[2.04385], sequence:[12], random actions:[28], eInit:[0.0100], init state:[ 1 21 19  1  1  0  1  0], end state:[ 3 21 19  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2280, score:[2834.00], loss:[2.00068], sequence:[13], random actions:[30], eInit:[0.0100], init state:[ 3 12 44  0  0  0  0  0], end state:[ 5 12 44  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2281, score:[2802.40], loss:[1.84023], sequence:[14], random actions:[30], eInit:[0.0100], init state:[ 6 15 41  0  0  0  0  0], end state:[ 1 15 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2282, score:[2799.60], loss:[1.88197], sequence:[15], random actions:[26], eInit:[0.0100], init state:[ 5 12 23  0  0  0  0  0], end state:[ 0 12 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2283, score:[2795.20], loss:[1.85896], sequence:[16], random actions:[27], eInit:[0.0100], init state:[ 5 10 50  0  0  0  0  0], end state:[ 0 10 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2284, score:[2830.80], loss:[1.75814], sequence:[17], random actions:[22], eInit:[0.0100], init state:[ 1 13 45  0  0  0  0  0], end state:[ 3 13 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2285, score:[2790.00], loss:[1.61681], sequence:[18], random actions:[29], eInit:[0.0100], init state:[ 5 18 22  1  1  0  1  0], end state:[ 0 18 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2286, score:[2806.80], loss:[1.61820], sequence:[19], random actions:[28], eInit:[0.0100], init state:[ 0  4 17  0  0  0  0  0], end state:[ 2  4 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2287, score:[2698.40], loss:[1.91386], sequence:[0], random actions:[30], eInit:[0.0100], init state:[ 5  9 19  0  0  0  0  0], end state:[ 0  9 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2288, score:[2743.60], loss:[1.98417], sequence:[1], random actions:[36], eInit:[0.0100], init state:[ 5  9 14  0  0  0  0  0], end state:[ 0  9 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2289, score:[2794.00], loss:[2.05721], sequence:[2], random actions:[39], eInit:[0.0100], init state:[ 2 18 10  0  0  0  0  0], end state:[ 4 18 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2290, score:[2812.40], loss:[1.91129], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 0 10 31  0  0  0  0  0], end state:[ 2 10 31  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2291, score:[2831.20], loss:[1.65700], sequence:[4], random actions:[27], eInit:[0.0100], init state:[ 1 12 33  0  0  0  0  0], end state:[ 3 12 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2292, score:[2828.80], loss:[1.55273], sequence:[5], random actions:[30], eInit:[0.0100], init state:[ 0 20  9  0  0  0  0  0], end state:[ 2 20  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2293, score:[2759.60], loss:[1.61046], sequence:[6], random actions:[26], eInit:[0.0100], init state:[ 5  6 50  0  0  0  0  0], end state:[ 0  6 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2294, score:[2836.40], loss:[1.51489], sequence:[7], random actions:[26], eInit:[0.0100], init state:[ 0  6 36  0  0  0  0  0], end state:[ 2  6 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2295, score:[2817.60], loss:[1.38333], sequence:[8], random actions:[30], eInit:[0.0100], init state:[ 2  5 46  0  0  0  0  0], end state:[ 4  5 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2296, score:[2811.60], loss:[1.38927], sequence:[9], random actions:[38], eInit:[0.0100], init state:[ 0  5 23  0  0  0  0  0], end state:[ 2  5 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2297, score:[2827.60], loss:[1.47484], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 0  7 58  0  0  0  0  0], end state:[ 2  7 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2298, score:[2774.00], loss:[1.84639], sequence:[11], random actions:[34], eInit:[0.0100], init state:[ 3 10 20  0  0  0  0  0], end state:[ 5 10 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2299, score:[2799.20], loss:[1.92718], sequence:[12], random actions:[28], eInit:[0.0100], init state:[5 6 8 0 0 0 0 0], end state:[0 6 8 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2300, score:[2822.00], loss:[1.94420], sequence:[13], random actions:[28], eInit:[0.0100], init state:[ 1 14  9  0  0  0  0  0], end state:[ 3 14  9  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2301, score:[2823.20], loss:[1.89170], sequence:[14], random actions:[35], eInit:[0.0100], init state:[ 0 11 41  0  0  0  0  0], end state:[ 2 11 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2302, score:[2806.40], loss:[1.84045], sequence:[15], random actions:[27], eInit:[0.0100], init state:[ 4 10 37  1  1  0  1  0], end state:[ 6 10 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2303, score:[2838.40], loss:[1.75691], sequence:[16], random actions:[23], eInit:[0.0100], init state:[ 3  9 39  0  0  0  0  0], end state:[ 5  9 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2304, score:[2798.80], loss:[1.79657], sequence:[17], random actions:[19], eInit:[0.0100], init state:[ 5 15 48  0  0  0  0  0], end state:[ 0 15 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2305, score:[2816.80], loss:[2.02610], sequence:[18], random actions:[32], eInit:[0.0100], init state:[ 2  5 16  0  0  0  0  0], end state:[ 4  5 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2306, score:[2838.00], loss:[1.97475], sequence:[19], random actions:[22], eInit:[0.0100], init state:[ 6 21 56  1  0  0  0  0], end state:[ 1 21 56  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2307, score:[2830.00], loss:[1.66729], sequence:[20], random actions:[23], eInit:[0.0100], init state:[ 2  8 28  1  0  0  0  0], end state:[ 4  8 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2308, score:[2821.60], loss:[1.51348], sequence:[21], random actions:[16], eInit:[0.0100], init state:[ 5 20 15  1  0  0  0  0], end state:[ 0 20 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2309, score:[2736.40], loss:[1.92841], sequence:[22], random actions:[29], eInit:[0.0100], init state:[ 4  1 50  0  0  0  0  0], end state:[ 6  1 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2310, score:[2801.60], loss:[1.78448], sequence:[23], random actions:[28], eInit:[0.0100], init state:[ 1 16 27  0  0  0  0  0], end state:[ 3 16 27  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2311, score:[2768.40], loss:[2.05187], sequence:[24], random actions:[36], eInit:[0.0100], init state:[ 5  5 15  0  0  0  0  0], end state:[ 0  5 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2312, score:[2790.40], loss:[2.12614], sequence:[25], random actions:[28], eInit:[0.0100], init state:[ 6  5 31  0  0  0  0  0], end state:[ 1  5 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2313, score:[2794.80], loss:[2.11638], sequence:[26], random actions:[31], eInit:[0.0100], init state:[6 4 6 0 0 0 0 0], end state:[1 4 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2314, score:[2781.20], loss:[2.11946], sequence:[27], random actions:[29], eInit:[0.0100], init state:[ 4 10 42  1  1  0  1  0], end state:[ 6 10 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2315, score:[2804.00], loss:[2.28760], sequence:[28], random actions:[35], eInit:[0.0100], init state:[ 6 15 29  0  0  0  0  0], end state:[ 1 15 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2316, score:[2827.20], loss:[1.84762], sequence:[29], random actions:[32], eInit:[0.0100], init state:[ 1 16 22  0  0  0  0  0], end state:[ 3 16 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2317, score:[2706.80], loss:[2.22844], sequence:[0], random actions:[34], eInit:[0.0100], init state:[4 0 3 1 0 0 0 0], end state:[6 0 3 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2318, score:[2738.80], loss:[2.44909], sequence:[1], random actions:[28], eInit:[0.0100], init state:[ 5 16  9  0  0  0  0  0], end state:[ 0 16  9  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2319, score:[2783.60], loss:[2.24332], sequence:[2], random actions:[30], eInit:[0.0100], init state:[5 4 6 0 0 0 0 0], end state:[0 4 6 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2320, score:[2800.00], loss:[2.13860], sequence:[3], random actions:[29], eInit:[0.0100], init state:[6 1 4 0 0 1 0 0], end state:[1 1 4 0 0 1 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2321, score:[2786.80], loss:[2.39981], sequence:[4], random actions:[22], eInit:[0.0100], init state:[ 3 14 33  0  0  0  0  0], end state:[ 5 14 33  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2322, score:[2776.80], loss:[2.46556], sequence:[5], random actions:[40], eInit:[0.0100], init state:[ 6  7 49  0  0  0  0  0], end state:[ 1  7 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2323, score:[2800.00], loss:[2.43317], sequence:[6], random actions:[37], eInit:[0.0100], init state:[ 2 16 14  0  0  0  0  0], end state:[ 4 16 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2324, score:[2825.20], loss:[2.37454], sequence:[7], random actions:[19], eInit:[0.0100], init state:[ 2 14 51  0  0  0  0  0], end state:[ 4 14 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2325, score:[2811.20], loss:[2.36112], sequence:[8], random actions:[34], eInit:[0.0100], init state:[ 2 22 14  1  0  0  0  0], end state:[ 4 22 14  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2326, score:[2788.80], loss:[2.57223], sequence:[9], random actions:[30], eInit:[0.0100], init state:[ 5 14 18  0  0  0  0  0], end state:[ 0 14 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2327, score:[2824.80], loss:[2.48248], sequence:[10], random actions:[23], eInit:[0.0100], init state:[ 3 14 36  0  0  0  0  0], end state:[ 5 14 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2328, score:[2770.00], loss:[2.63742], sequence:[11], random actions:[24], eInit:[0.0100], init state:[ 4 10  1  1  1  0  1  0], end state:[ 6 10  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2329, score:[2808.80], loss:[2.45115], sequence:[12], random actions:[30], eInit:[0.0100], init state:[ 2 19 26  0  0  0  0  0], end state:[ 4 19 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2330, score:[2776.80], loss:[2.59639], sequence:[13], random actions:[27], eInit:[0.0100], init state:[ 3 23 33  1  0  0  1  0], end state:[ 5 23 33  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2331, score:[2812.40], loss:[2.62081], sequence:[14], random actions:[29], eInit:[0.0100], init state:[ 0 20 34  1  1  0  0  0], end state:[ 2 20 34  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2332, score:[2824.40], loss:[2.51375], sequence:[15], random actions:[27], eInit:[0.0100], init state:[ 3 16  3  0  0  0  0  0], end state:[ 5 16  3  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2333, score:[2817.60], loss:[2.54039], sequence:[16], random actions:[39], eInit:[0.0100], init state:[ 1 18 59  0  0  0  0  0], end state:[ 3 18 59  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2334, score:[2790.80], loss:[2.44352], sequence:[17], random actions:[24], eInit:[0.0100], init state:[ 3  3 34  0  0  0  0  0], end state:[ 5  3 34  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2335, score:[2772.00], loss:[2.62044], sequence:[18], random actions:[17], eInit:[0.0100], init state:[ 6 17 37  0  0  0  0  0], end state:[ 1 17 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2336, score:[2803.20], loss:[2.38612], sequence:[19], random actions:[36], eInit:[0.0100], init state:[ 2 16 22  0  0  0  0  0], end state:[ 4 16 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2337, score:[2829.20], loss:[2.38552], sequence:[20], random actions:[30], eInit:[0.0100], init state:[ 0 19 23  0  0  0  0  0], end state:[ 2 19 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2338, score:[2806.40], loss:[2.36187], sequence:[21], random actions:[36], eInit:[0.0100], init state:[ 1 19 16  0  0  0  0  0], end state:[ 3 19 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2339, score:[2807.60], loss:[2.20268], sequence:[22], random actions:[31], eInit:[0.0100], init state:[ 2 19  6  0  0  0  0  0], end state:[ 4 19  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2340, score:[2786.00], loss:[2.26397], sequence:[23], random actions:[31], eInit:[0.0100], init state:[ 4 21 26  0  0  0  0  0], end state:[ 6 21 26  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2341, score:[2746.00], loss:[2.15352], sequence:[24], random actions:[28], eInit:[0.0100], init state:[ 5  3 28  0  0  0  0  0], end state:[ 0  3 28  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2342, score:[2817.60], loss:[2.58653], sequence:[25], random actions:[34], eInit:[0.0100], init state:[ 1  2 48  0  0  0  0  0], end state:[ 3  2 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2343, score:[2824.80], loss:[2.29131], sequence:[26], random actions:[35], eInit:[0.0100], init state:[ 0 14 20  0  0  0  0  0], end state:[ 2 14 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2344, score:[2836.00], loss:[2.01049], sequence:[27], random actions:[26], eInit:[0.0100], init state:[ 1  1 37  0  0  0  0  0], end state:[ 3  1 37  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2345, score:[2832.40], loss:[1.91577], sequence:[28], random actions:[28], eInit:[0.0100], init state:[ 1 14 27  0  0  0  0  0], end state:[ 3 14 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2346, score:[2789.60], loss:[1.95165], sequence:[29], random actions:[28], eInit:[0.0100], init state:[ 4 22 28  0  0  0  0  0], end state:[ 6 22 28  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2347, score:[2808.80], loss:[2.16894], sequence:[30], random actions:[24], eInit:[0.0100], init state:[ 4  7 56  0  0  0  0  0], end state:[ 6  7 56  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2348, score:[2836.00], loss:[2.02656], sequence:[31], random actions:[28], eInit:[0.0100], init state:[ 1  5 47  0  0  0  0  0], end state:[ 3  5 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2349, score:[2782.80], loss:[2.13720], sequence:[32], random actions:[27], eInit:[0.0100], init state:[ 5 11 43  0  0  0  0  0], end state:[ 0 11 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2350, score:[2837.20], loss:[2.00334], sequence:[33], random actions:[28], eInit:[0.0100], init state:[ 6 12 37  0  0  0  0  0], end state:[ 1 12 37  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2351, score:[2810.80], loss:[1.96728], sequence:[34], random actions:[45], eInit:[0.0100], init state:[ 6 21 35  1  0  0  0  0], end state:[ 1 21 35  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2352, score:[2808.80], loss:[1.87719], sequence:[35], random actions:[35], eInit:[0.0100], init state:[ 6 16 45  0  0  0  0  0], end state:[ 1 16 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2353, score:[2819.60], loss:[1.87284], sequence:[36], random actions:[26], eInit:[0.0100], init state:[ 6  1 50  0  0  0  0  0], end state:[ 1  1 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2354, score:[2762.00], loss:[2.02512], sequence:[37], random actions:[31], eInit:[0.0100], init state:[ 4  8 38  0  0  0  0  0], end state:[ 6  8 38  1  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2355, score:[2749.20], loss:[2.18251], sequence:[38], random actions:[27], eInit:[0.0100], init state:[ 5  8 46  0  0  0  0  0], end state:[ 0  8 46  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2356, score:[2774.00], loss:[2.31566], sequence:[39], random actions:[33], eInit:[0.0100], init state:[ 2  4 49  0  0  0  0  0], end state:[ 4  4 49  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2357, score:[2817.20], loss:[2.21424], sequence:[40], random actions:[34], eInit:[0.0100], init state:[ 1  3 50  0  0  0  0  0], end state:[ 3  3 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2358, score:[2792.40], loss:[1.93346], sequence:[41], random actions:[36], eInit:[0.0100], init state:[ 2 13 25  0  0  0  0  0], end state:[ 4 13 25  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2359, score:[2814.00], loss:[2.01290], sequence:[42], random actions:[38], eInit:[0.0100], init state:[ 6  1 38  0  0  0  0  0], end state:[ 1  1 38  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2360, score:[2796.40], loss:[1.96192], sequence:[43], random actions:[15], eInit:[0.0100], init state:[ 3  2 33  0  0  0  0  0], end state:[ 5  2 33  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2361, score:[2776.00], loss:[2.58832], sequence:[44], random actions:[32], eInit:[0.0100], init state:[ 2 22 11  1  0  0  0  0], end state:[ 4 22 11  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2362, score:[2829.20], loss:[2.77804], sequence:[45], random actions:[21], eInit:[0.0100], init state:[ 6 16 25  0  0  0  0  0], end state:[ 1 16 25  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2363, score:[2838.80], loss:[2.38707], sequence:[46], random actions:[22], eInit:[0.0100], init state:[ 1  9 15  0  0  0  0  0], end state:[ 3  9 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2364, score:[2730.80], loss:[2.55926], sequence:[0], random actions:[28], eInit:[0.0100], init state:[ 4 23  8  0  0  0  0  0], end state:[ 6 23  8  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2365, score:[2771.60], loss:[2.44946], sequence:[1], random actions:[34], eInit:[0.0100], init state:[ 3  9 21  0  0  0  0  0], end state:[ 5  9 21  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2366, score:[2814.80], loss:[2.49534], sequence:[2], random actions:[31], eInit:[0.0100], init state:[ 3 11 36  0  0  0  0  0], end state:[ 5 11 36  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2367, score:[2793.60], loss:[2.41972], sequence:[3], random actions:[31], eInit:[0.0100], init state:[ 3  7 12  0  0  0  0  0], end state:[ 5  7 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2368, score:[2840.00], loss:[2.37236], sequence:[4], random actions:[23], eInit:[0.0100], init state:[ 2  9 57  0  0  0  0  0], end state:[ 4  9 57  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2369, score:[2817.60], loss:[2.29926], sequence:[5], random actions:[28], eInit:[0.0100], init state:[ 2 15  4  0  0  0  0  0], end state:[ 4 15  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2370, score:[2813.60], loss:[2.36179], sequence:[6], random actions:[29], eInit:[0.0100], init state:[ 6  3 10  0  0  0  0  0], end state:[ 1  3 10  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2371, score:[2795.20], loss:[2.32961], sequence:[7], random actions:[25], eInit:[0.0100], init state:[ 4 18 58  0  0  0  0  0], end state:[ 6 18 58  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2372, score:[2784.40], loss:[2.40277], sequence:[8], random actions:[33], eInit:[0.0100], init state:[ 5 16 39  0  0  0  0  0], end state:[ 0 16 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2373, score:[2760.80], loss:[2.34511], sequence:[9], random actions:[28], eInit:[0.0100], init state:[ 4 16 42  0  0  0  0  0], end state:[ 6 16 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2374, score:[2792.00], loss:[2.21391], sequence:[10], random actions:[31], eInit:[0.0100], init state:[ 6  6 42  0  0  0  0  0], end state:[ 1  6 42  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2375, score:[2819.20], loss:[2.19181], sequence:[11], random actions:[34], eInit:[0.0100], init state:[ 2  5 15  0  0  0  0  0], end state:[ 4  5 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2376, score:[2828.80], loss:[2.00120], sequence:[12], random actions:[26], eInit:[0.0100], init state:[ 1 19 24  0  0  0  0  0], end state:[ 3 19 24  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2377, score:[2773.20], loss:[2.06716], sequence:[13], random actions:[23], eInit:[0.0100], init state:[ 5  7 19  0  0  0  0  0], end state:[ 0  7 19  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2378, score:[2817.20], loss:[1.92298], sequence:[14], random actions:[28], eInit:[0.0100], init state:[ 4  3 27  0  0  0  0  0], end state:[ 6  3 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2379, score:[2817.20], loss:[1.87321], sequence:[15], random actions:[24], eInit:[0.0100], init state:[ 6  5 13  0  0  0  0  0], end state:[ 1  5 13  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2380, score:[2800.80], loss:[1.82473], sequence:[16], random actions:[32], eInit:[0.0100], init state:[ 6 21 28  1  1  0  1  0], end state:[ 1 21 28  1  1  0  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2381, score:[2739.20], loss:[1.99803], sequence:[17], random actions:[31], eInit:[0.0100], init state:[ 4 10 20  1  1  0  1  0], end state:[ 6 10 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2382, score:[2795.20], loss:[2.28653], sequence:[18], random actions:[23], eInit:[0.0100], init state:[ 3 19  6  0  0  0  0  0], end state:[ 5 19  6  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2383, score:[2814.00], loss:[2.03799], sequence:[19], random actions:[27], eInit:[0.0100], init state:[ 2  2 43  0  0  0  0  0], end state:[ 4  2 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2384, score:[2805.20], loss:[1.91874], sequence:[20], random actions:[34], eInit:[0.0100], init state:[ 0 14 47  0  0  0  0  0], end state:[ 2 14 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2385, score:[2794.00], loss:[2.10736], sequence:[21], random actions:[30], eInit:[0.0100], init state:[ 3 12 51  0  0  0  0  0], end state:[ 5 12 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2386, score:[2808.80], loss:[1.90554], sequence:[22], random actions:[33], eInit:[0.0100], init state:[ 3 11 31  0  0  0  0  0], end state:[ 5 11 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2387, score:[2714.80], loss:[2.37528], sequence:[0], random actions:[32], eInit:[0.0100], init state:[ 5 14 23  0  0  0  0  0], end state:[ 0 14 23  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2388, score:[2818.40], loss:[2.27787], sequence:[1], random actions:[24], eInit:[0.0100], init state:[ 2 15  1  0  0  0  0  0], end state:[ 4 15  1  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2389, score:[2804.40], loss:[2.46770], sequence:[2], random actions:[24], eInit:[0.0100], init state:[ 3  3 17  0  0  0  0  0], end state:[ 5  3 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2390, score:[2845.60], loss:[2.25197], sequence:[3], random actions:[25], eInit:[0.0100], init state:[ 1  7 29  0  0  0  0  0], end state:[ 3  7 29  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2391, score:[2790.40], loss:[2.37068], sequence:[4], random actions:[35], eInit:[0.0100], init state:[ 4  4 54  0  0  0  0  0], end state:[ 6  4 54  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2392, score:[2807.60], loss:[2.23307], sequence:[5], random actions:[38], eInit:[0.0100], init state:[ 1 18 26  0  0  0  0  0], end state:[ 3 18 26  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2393, score:[2829.20], loss:[2.12414], sequence:[6], random actions:[24], eInit:[0.0100], init state:[ 1 13 15  0  0  0  0  0], end state:[ 3 13 15  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2394, score:[2798.40], loss:[2.09805], sequence:[7], random actions:[32], eInit:[0.0100], init state:[ 4 14 52  0  0  0  0  0], end state:[ 6 14 52  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2395, score:[2820.00], loss:[1.99534], sequence:[8], random actions:[26], eInit:[0.0100], init state:[ 2 13 55  0  0  0  0  0], end state:[ 4 13 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2396, score:[2815.20], loss:[2.16629], sequence:[9], random actions:[22], eInit:[0.0100], init state:[ 6  2 10  0  0  0  0  0], end state:[ 1  2 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2397, score:[2778.00], loss:[2.12378], sequence:[10], random actions:[36], eInit:[0.0100], init state:[ 4  6 51  0  0  0  0  0], end state:[ 6  6 51  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2398, score:[2818.00], loss:[2.18352], sequence:[11], random actions:[28], eInit:[0.0100], init state:[ 6  9 55  0  0  0  0  0], end state:[ 1  9 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2399, score:[2825.60], loss:[2.11890], sequence:[12], random actions:[37], eInit:[0.0100], init state:[0 5 2 0 0 0 0 0], end state:[2 5 2 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2400, score:[2787.20], loss:[2.10747], sequence:[13], random actions:[32], eInit:[0.0100], init state:[ 3  4 40  0  0  0  0  0], end state:[ 5  4 40  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2401, score:[2788.40], loss:[2.21843], sequence:[14], random actions:[26], eInit:[0.0100], init state:[ 2 22 41  1  0  0  0  0], end state:[ 4 22 41  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2402, score:[2800.80], loss:[2.58020], sequence:[15], random actions:[35], eInit:[0.0100], init state:[ 3 10  4  0  0  0  0  0], end state:[ 5 10  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2403, score:[2828.80], loss:[2.52462], sequence:[16], random actions:[28], eInit:[0.0100], init state:[2 9 9 0 0 0 0 0], end state:[4 9 9 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2404, score:[2799.60], loss:[2.34175], sequence:[17], random actions:[36], eInit:[0.0100], init state:[ 3  4 50  0  0  0  0  0], end state:[ 5  4 50  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2405, score:[2824.40], loss:[2.58277], sequence:[18], random actions:[19], eInit:[0.0100], init state:[ 6 17 39  0  0  0  0  0], end state:[ 1 17 39  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2406, score:[2831.60], loss:[2.12986], sequence:[19], random actions:[29], eInit:[0.0100], init state:[ 2 11 43  0  0  0  0  0], end state:[ 4 11 43  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2407, score:[2770.00], loss:[2.32456], sequence:[20], random actions:[28], eInit:[0.0100], init state:[ 3 23  8  1  0  0  0  0], end state:[ 5 23  8  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 2408, score:[2820.40], loss:[2.27099], sequence:[21], random actions:[34], eInit:[0.0100], init state:[ 0 13 47  0  0  0  0  0], end state:[ 2 13 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2409, score:[2805.60], loss:[2.23055], sequence:[22], random actions:[23], eInit:[0.0100], init state:[ 3  9 45  0  0  0  0  0], end state:[ 5  9 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2410, score:[2831.60], loss:[2.56852], sequence:[23], random actions:[29], eInit:[0.0100], init state:[ 3 17 30  0  0  0  0  0], end state:[ 5 17 30  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2411, score:[2794.40], loss:[2.43078], sequence:[24], random actions:[29], eInit:[0.0100], init state:[ 6 15 46  0  0  0  0  0], end state:[ 1 15 46  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2412, score:[2780.80], loss:[2.37875], sequence:[25], random actions:[26], eInit:[0.0100], init state:[ 4 18 17  0  0  0  0  0], end state:[ 6 18 17  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2413, score:[2803.60], loss:[2.45892], sequence:[26], random actions:[28], eInit:[0.0100], init state:[ 2  5 18  0  0  0  0  0], end state:[ 4  5 18  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2414, score:[2848.00], loss:[2.29568], sequence:[27], random actions:[19], eInit:[0.0100], init state:[ 0 18 43  0  0  0  0  0], end state:[ 2 18 43  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2415, score:[2767.20], loss:[2.48663], sequence:[28], random actions:[41], eInit:[0.0100], init state:[ 5 23 55  1  0  0  0  0], end state:[ 0 23 55  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2416, score:[2814.40], loss:[2.27696], sequence:[29], random actions:[27], eInit:[0.0100], init state:[ 1  2 10  0  0  0  0  0], end state:[ 3  2 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2417, score:[2824.80], loss:[2.11440], sequence:[30], random actions:[36], eInit:[0.0100], init state:[ 2  3 44  0  0  0  0  0], end state:[ 4  3 44  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2418, score:[2839.20], loss:[1.94320], sequence:[31], random actions:[30], eInit:[0.0100], init state:[ 6 15 35  0  0  0  0  0], end state:[ 1 15 35  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2419, score:[2831.20], loss:[1.80359], sequence:[32], random actions:[23], eInit:[0.0100], init state:[ 3 10 45  0  0  0  0  0], end state:[ 5 10 45  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2420, score:[2826.40], loss:[1.60818], sequence:[33], random actions:[29], eInit:[0.0100], init state:[ 3 15 23  0  0  0  0  0], end state:[ 5 15 23  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2421, score:[2831.60], loss:[1.68010], sequence:[34], random actions:[30], eInit:[0.0100], init state:[ 2 23 16  1  0  0  1  0], end state:[ 4 23 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2422, score:[2832.80], loss:[1.61687], sequence:[35], random actions:[28], eInit:[0.0100], init state:[ 0  7 29  0  0  0  0  0], end state:[ 2  7 29  1  1  0  0  1]
INFO:Reinforcement.Functions:episode: 2423, score:[2747.20], loss:[1.89709], sequence:[36], random actions:[28], eInit:[0.0100], init state:[ 5 14 10  0  0  0  0  0], end state:[ 0 14 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2424, score:[2806.80], loss:[1.68794], sequence:[37], random actions:[31], eInit:[0.0100], init state:[ 6 21  4  1  1  0  1  0], end state:[ 1 21  4  0  1  0  1  0]
INFO:Reinforcement.Functions:episode: 2425, score:[2752.00], loss:[2.40459], sequence:[38], random actions:[30], eInit:[0.0100], init state:[ 6  8 28  1  0  0  0  0], end state:[ 1  8 28  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2426, score:[2792.00], loss:[2.29159], sequence:[39], random actions:[34], eInit:[0.0100], init state:[ 2  7 32  0  0  0  0  0], end state:[ 4  7 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2427, score:[2775.20], loss:[2.20787], sequence:[40], random actions:[27], eInit:[0.0100], init state:[ 3  1 55  0  0  0  0  0], end state:[ 5  1 55  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2428, score:[2768.80], loss:[2.22779], sequence:[41], random actions:[28], eInit:[0.0100], init state:[5 8 1 0 0 0 0 0], end state:[0 8 1 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2429, score:[2820.80], loss:[1.89997], sequence:[42], random actions:[42], eInit:[0.0100], init state:[ 1 17 27  0  0  0  0  0], end state:[ 3 17 27  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2430, score:[2810.40], loss:[1.84456], sequence:[43], random actions:[33], eInit:[0.0100], init state:[ 3  0 49  0  0  1  0  0], end state:[ 5  0 49  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2431, score:[2802.00], loss:[1.86223], sequence:[44], random actions:[29], eInit:[0.0100], init state:[ 4  8 24  0  0  0  0  0], end state:[ 6  8 24  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2432, score:[2815.20], loss:[1.80202], sequence:[45], random actions:[24], eInit:[0.0100], init state:[ 1  4 10  0  0  0  0  0], end state:[ 3  4 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2433, score:[2782.40], loss:[1.96143], sequence:[46], random actions:[45], eInit:[0.0100], init state:[ 2  1 32  0  0  0  0  0], end state:[ 4  1 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2434, score:[2747.20], loss:[2.38258], sequence:[47], random actions:[28], eInit:[0.0100], init state:[ 4  9 29  0  0  0  0  0], end state:[ 6  9 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2435, score:[2822.80], loss:[2.45175], sequence:[48], random actions:[23], eInit:[0.0100], init state:[ 6 22 46  1  0  0  0  0], end state:[ 1 22 46  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2436, score:[2750.40], loss:[2.29264], sequence:[49], random actions:[28], eInit:[0.0100], init state:[5 0 4 0 0 0 0 0], end state:[0 0 4 1 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2437, score:[2764.40], loss:[2.45518], sequence:[50], random actions:[44], eInit:[0.0100], init state:[ 2 22 10  1  0  0  0  0], end state:[ 4 22 10  1  0  0  1  1]
INFO:Reinforcement.Functions:episode: 2438, score:[2821.20], loss:[2.52310], sequence:[51], random actions:[25], eInit:[0.0100], init state:[ 2 23 12  1  0  0  0  0], end state:[ 4 23 12  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2439, score:[2815.60], loss:[2.37778], sequence:[52], random actions:[39], eInit:[0.0100], init state:[ 1 22 13  1  0  0  0  0], end state:[ 3 22 13  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2440, score:[2824.80], loss:[2.51382], sequence:[53], random actions:[19], eInit:[0.0100], init state:[ 5 22 39  1  0  0  1  0], end state:[ 0 22 39  1  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])
INFO:Reinforcement.Functions:episode: 2441, score:[2789.60], loss:[2.74699], sequence:[54], random actions:[37], eInit:[0.0100], init state:[ 6  8 45  1  1  0  0  0], end state:[ 1  8 45  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2442, score:[2795.60], loss:[2.67287], sequence:[55], random actions:[34], eInit:[0.0100], init state:[5 6 0 0 0 0 0 0], end state:[0 6 0 0 0 0 0 0]
INFO:Reinforcement.Functions:episode: 2443, score:[2824.40], loss:[2.56779], sequence:[56], random actions:[27], eInit:[0.0100], init state:[ 5 21 30  1  0  0  1  1], end state:[ 0 21 30  1  1  0  0  0]
INFO:Reinforcement.Functions:episode: 2444, score:[2801.20], loss:[2.53912], sequence:[57], random actions:[34], eInit:[0.0100], init state:[ 6  0 19  1  0  0  0  0], end state:[ 1  0 19  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2445, score:[2761.60], loss:[2.52158], sequence:[58], random actions:[31], eInit:[0.0100], init state:[ 3 16  6  0  0  0  0  0], end state:[ 5 16  6  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2446, score:[2838.00], loss:[2.25868], sequence:[59], random actions:[19], eInit:[0.0100], init state:[ 0 17 29  0  0  0  0  0], end state:[ 2 17 29  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2447, score:[2797.60], loss:[2.24241], sequence:[60], random actions:[35], eInit:[0.0100], init state:[ 3 23 23  1  0  0  1  0], end state:[ 5 23 23  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2448, score:[2792.00], loss:[2.32942], sequence:[61], random actions:[31], eInit:[0.0100], init state:[ 5 13 47  0  0  0  0  0], end state:[ 0 13 47  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2449, score:[2818.40], loss:[2.20110], sequence:[62], random actions:[26], eInit:[0.0100], init state:[ 2 17  8  0  0  0  0  0], end state:[ 4 17  8  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2450, score:[2781.60], loss:[2.25648], sequence:[63], random actions:[37], eInit:[0.0100], init state:[ 4 15 36  0  0  0  0  0], end state:[ 6 15 36  0  0  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-40-6/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-40-6/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-40-6/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-40-6/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2853.9999999999995, [340]) , maxSequence:(198, [1365])

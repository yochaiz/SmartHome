INFO:Reinforcement.Functions:args:[{'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json', 'gpuFrac': 0.9, 'desc': '"deep model with 0.85 score ratio"', 'gpuNum': 0, 'k': 32, 'random': True, 'sequential': False}]
INFO:Reinforcement.Functions:settings:[{'dequeSize': 50000, 'minGameScore': 2448, 'batchSize': 64, 'gameMinutesLength': 2880, 'gamma': 0.95, 'TAU': 0.001, 'minGameScoreRatio': 0.85, 'trainSetSize': 64, 'learningRate': 0.001, 'minGameSequence': 500, 'nEpochs': 1, 'nModelBackups': 3, 'nGamesPerSave': 10}]
INFO:Reinforcement.Functions:results:[{'score': [], 'baseFolder': '/home/yochaiz/SmartHome/Reinforcement/DDPG', 'fullPath': '/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12', 'actionDim': 'actionDim-5', 'loss': [], 'folderName': 'D-8-4-H-18-32-12'}]
INFO:Reinforcement.Functions:Critic:[{'actionDim': 5, 'TAU': 0.001, 'curBackupIdx': 0, 'nBackups': 3}]
INFO:Reinforcement.Functions:policy:[{'stateDim': (1, 8), 'rewardScaleFactor': 1, 'numOfDevices': 5, 'seqLen': 1, 'fname': '/home/yochaiz/SmartHome/Reinforcement/Policies/Week/policy2.json'}]
INFO:Reinforcement.Functions:Actor:[{'TAU': 0.001, 'nActions': 32, 'actionDim': 5, 'epsilon': 1.0, 'curBackupIdx': 0, 'k': 32, 'epsilon_min': 0.01, 'nBackups': 3, 'epsilon_decay': 0.99}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:===== DESCRIPTIONS =====
INFO:Reinforcement.Functions:[General]: "deep model with 0.85 score ratio"
INFO:Reinforcement.Functions:[Actor]: Try deeper architecture
INFO:Reinforcement.Functions:[Actor]: Fixed bug where future reward (step 13) used continuous action instead of discrete action
INFO:Reinforcement.Functions:[Actor]: No more threading during replays
INFO:Reinforcement.Functions:[Critic]: Try deeper architecture
INFO:Reinforcement.Functions:===== ============ =====
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 8)              0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 256)            2304      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)              (None, 1, 5)              1285      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 5)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 266,757
INFO:Reinforcement.Functions:Trainable params: 266,757
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 8)         0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 256)       2304        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 5)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_8 (Dense)                 (None, 1, 256)       65792       dense_7[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_9 (Dense)                 (None, 256)          1536        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_8[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_9[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_10 (Dense)                (None, 1, 256)       65792       activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_11 (Dense)                (None, 1, 256)       65792       dense_10[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_12 (Dense)                (None, 1, 256)       65792       dense_11[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_13 (Dense)                (None, 1, 1)         257         dense_12[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_13[0][0]                   
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 267,265
INFO:Reinforcement.Functions:Trainable params: 267,265
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[2200.80], loss:[61.25347], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.65], optActionInPoolButNotSelected:[0.32], random actions:[115], eInit:[1.0000], init state:[ 6  6 54  0  0  0  0  0], end state:[ 1  6 54  0  0  0  0  0], runtime(seconds):[312.16]
INFO:Reinforcement.Functions:episode: 2, score:[2202.00], loss:[48.02797], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.64], optActionInPoolButNotSelected:[0.34], random actions:[119], eInit:[0.9900], init state:[ 3 16 31  0  0  0  0  0], end state:[ 5 16 31  0  0  0  0  0], runtime(seconds):[310.61]
INFO:Reinforcement.Functions:episode: 3, score:[2410.40], loss:[33.93557], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.77], optActionInPoolButNotSelected:[0.20], random actions:[119], eInit:[0.9801], init state:[ 3 18  4  0  0  0  0  0], end state:[ 5 18  4  0  0  0  0  0], runtime(seconds):[311.48]
INFO:Reinforcement.Functions:episode: 4, score:[2220.40], loss:[39.82871], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.65], optActionInPoolButNotSelected:[0.32], random actions:[117], eInit:[0.9703], init state:[ 2 18 35  0  0  0  0  0], end state:[ 4 18 35  0  0  0  0  0], runtime(seconds):[311.14]
INFO:Reinforcement.Functions:episode: 5, score:[2337.60], loss:[34.73786], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.71], optActionInPoolButNotSelected:[0.26], random actions:[136], eInit:[0.9606], init state:[2 2 5 0 0 0 0 0], end state:[4 2 5 0 0 0 0 0], runtime(seconds):[312.00]
INFO:Reinforcement.Functions:episode: 6, score:[2295.20], loss:[35.10528], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.71], optActionInPoolButNotSelected:[0.26], random actions:[127], eInit:[0.9510], init state:[ 5 21 43  1  0  0  1  0], end state:[ 0 21 43  1  0  0  0  0], runtime(seconds):[311.23]
INFO:Reinforcement.Functions:episode: 7, score:[2447.60], loss:[34.92057], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.78], optActionInPoolButNotSelected:[0.19], random actions:[111], eInit:[0.9415], init state:[ 5 21  8  1  0  0  1  0], end state:[ 0 21  8  0  0  0  0  0], runtime(seconds):[312.08]
INFO:Reinforcement.Functions:episode: 8, score:[2487.20], loss:[31.95953], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.81], optActionInPoolButNotSelected:[0.16], random actions:[110], eInit:[0.9321], init state:[ 0 13 31  0  0  0  0  0], end state:[ 2 13 31  0  0  0  0  0], runtime(seconds):[310.26]
INFO:Reinforcement.Functions:episode: 9, score:[2417.60], loss:[30.22306], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.75], optActionInPoolButNotSelected:[0.22], random actions:[110], eInit:[0.9227], init state:[ 5  2 37  0  0  0  0  0], end state:[ 0  2 37  0  0  0  0  0], runtime(seconds):[303.93]
INFO:Reinforcement.Functions:episode: 10, score:[2606.00], loss:[26.57964], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.10], random actions:[116], eInit:[0.9135], init state:[ 0  1 31  0  0  0  0  0], end state:[ 2  1 31  0  0  0  0  0], runtime(seconds):[302.10]
INFO:Reinforcement.Functions:maxScore:(2605.9999999999905, [10]) , maxSequence:(1, [8, 10])
INFO:Reinforcement.Functions:Optimal models save history:[(1, [('Actor', 1), ('Critic', 1)]), (2, [('Actor', 2), ('Critic', 2)]), (3, [('Actor', 0), ('Critic', 0)]), (7, [('Actor', 1), ('Critic', 1)]), (8, [('Actor', 2), ('Critic', 2)]), (10, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:episode: 11, score:[2569.20], loss:[22.65075], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.84], optActionInPoolButNotSelected:[0.12], random actions:[122], eInit:[0.9044], init state:[ 6 12  0  0  0  0  0  0], end state:[ 1 12  0  0  0  0  0  0], runtime(seconds):[302.49]
INFO:Reinforcement.Functions:episode: 12, score:[2632.80], loss:[24.13926], sequence:[3], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.09], random actions:[112], eInit:[0.8953], init state:[ 1  6 26  0  0  0  0  0], end state:[ 3  6 26  0  0  0  0  0], runtime(seconds):[301.47]
INFO:Reinforcement.Functions:episode: 13, score:[2638.40], loss:[29.64540], sequence:[4], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[104], eInit:[0.8864], init state:[ 1  1 44  0  0  0  0  0], end state:[ 3  1 44  0  0  0  0  0], runtime(seconds):[302.49]
INFO:Reinforcement.Functions:episode: 14, score:[2476.00], loss:[21.35350], sequence:[5], isInPoolRatio:[1.00], optActionSelectedRatio:[0.79], optActionInPoolButNotSelected:[0.18], random actions:[114], eInit:[0.8775], init state:[ 4 10 42  1  1  0  1  0], end state:[ 6 10 42  0  0  0  0  0], runtime(seconds):[301.09]
INFO:Reinforcement.Functions:episode: 15, score:[2488.00], loss:[24.88245], sequence:[6], isInPoolRatio:[1.00], optActionSelectedRatio:[0.81], optActionInPoolButNotSelected:[0.15], random actions:[125], eInit:[0.8687], init state:[ 2 21 35  1  0  0  0  0], end state:[ 4 21 35  0  0  0  0  0], runtime(seconds):[302.48]
INFO:Reinforcement.Functions:episode: 16, score:[2679.60], loss:[18.20639], sequence:[7], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[110], eInit:[0.8601], init state:[ 0  9 43  0  0  0  0  0], end state:[ 2  9 43  0  0  0  0  0], runtime(seconds):[301.91]
INFO:Reinforcement.Functions:episode: 17, score:[2630.80], loss:[20.30579], sequence:[8], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.09], random actions:[107], eInit:[0.8515], init state:[ 1 18 42  0  0  0  0  0], end state:[ 3 18 42  0  0  0  0  0], runtime(seconds):[302.79]
INFO:Reinforcement.Functions:episode: 18, score:[2636.40], loss:[18.28871], sequence:[9], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[115], eInit:[0.8429], init state:[ 6 18 40  0  0  0  0  0], end state:[ 1 18 40  0  0  0  0  0], runtime(seconds):[301.65]
INFO:Reinforcement.Functions:episode: 19, score:[2683.20], loss:[17.22204], sequence:[10], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[100], eInit:[0.8345], init state:[ 6 22 30  1  0  0  0  0], end state:[ 1 22 30  1  0  0  0  0], runtime(seconds):[302.33]
INFO:Reinforcement.Functions:episode: 20, score:[2686.80], loss:[16.94910], sequence:[11], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[103], eInit:[0.8262], init state:[ 0 16  1  0  0  0  0  0], end state:[ 2 16  1  0  0  0  0  0], runtime(seconds):[301.52]
INFO:Reinforcement.Functions:maxScore:(2686.7999999999956, [20]) , maxSequence:(11, [20])
INFO:Reinforcement.Functions:Optimal models save history:[(12, [('Actor', 1), ('Critic', 1)]), (13, [('Actor', 2), ('Critic', 2)]), (16, [('Actor', 0), ('Critic', 0)]), (19, [('Actor', 1), ('Critic', 1)]), (20, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:episode: 21, score:[2506.40], loss:[17.60186], sequence:[12], isInPoolRatio:[1.00], optActionSelectedRatio:[0.82], optActionInPoolButNotSelected:[0.15], random actions:[117], eInit:[0.8179], init state:[ 5 10  7  0  0  0  0  0], end state:[ 0 10  7  0  0  0  0  0], runtime(seconds):[301.94]
INFO:Reinforcement.Functions:episode: 22, score:[2703.60], loss:[17.28223], sequence:[13], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[113], eInit:[0.8097], init state:[ 1 13 43  0  0  0  0  0], end state:[ 3 13 43  0  0  0  0  0], runtime(seconds):[301.31]
INFO:Reinforcement.Functions:episode: 23, score:[2704.40], loss:[16.48505], sequence:[14], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[101], eInit:[0.8016], init state:[ 1  1 22  0  0  0  0  0], end state:[ 3  1 22  0  0  0  0  0], runtime(seconds):[302.60]
INFO:Reinforcement.Functions:episode: 24, score:[2702.40], loss:[15.09537], sequence:[15], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.04], random actions:[113], eInit:[0.7936], init state:[ 0  6 36  0  0  0  0  0], end state:[ 2  6 36  0  0  0  0  0], runtime(seconds):[301.39]
INFO:Reinforcement.Functions:episode: 25, score:[2493.20], loss:[13.50183], sequence:[16], isInPoolRatio:[1.00], optActionSelectedRatio:[0.80], optActionInPoolButNotSelected:[0.17], random actions:[101], eInit:[0.7857], init state:[ 3 22 30  1  0  0  0  0], end state:[ 5 22 30  1  0  0  1  0], runtime(seconds):[301.43]
INFO:Reinforcement.Functions:episode: 26, score:[2608.80], loss:[14.46645], sequence:[17], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.10], random actions:[115], eInit:[0.7778], init state:[ 5 16 13  0  0  0  0  0], end state:[ 0 16 13  0  0  0  0  0], runtime(seconds):[301.67]
INFO:Reinforcement.Functions:episode: 27, score:[2568.80], loss:[13.65461], sequence:[18], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.12], random actions:[115], eInit:[0.7700], init state:[ 3 21 10  1  1  0  1  0], end state:[ 5 21 10  1  0  0  1  0], runtime(seconds):[302.29]
INFO:Reinforcement.Functions:episode: 28, score:[2682.40], loss:[11.95420], sequence:[19], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[110], eInit:[0.7623], init state:[ 6 10 51  0  0  0  0  0], end state:[ 1 10 51  0  0  0  0  0], runtime(seconds):[302.24]
INFO:Reinforcement.Functions:episode: 29, score:[2694.00], loss:[13.35832], sequence:[20], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[111], eInit:[0.7547], init state:[ 0  9 17  0  0  0  0  0], end state:[ 2  9 17  0  0  0  0  0], runtime(seconds):[302.15]
INFO:Reinforcement.Functions:episode: 30, score:[2604.40], loss:[11.92531], sequence:[21], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.10], random actions:[89], eInit:[0.7472], init state:[ 4 23 55  0  0  0  0  0], end state:[ 6 23 55  1  0  0  0  0], runtime(seconds):[300.39]
INFO:Reinforcement.Functions:maxScore:(2704.399999999998, [23]) , maxSequence:(21, [30])
INFO:Reinforcement.Functions:Optimal models save history:[(22, [('Actor', 0), ('Critic', 0)]), (23, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:episode: 31, score:[2693.20], loss:[12.05385], sequence:[22], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[95], eInit:[0.7397], init state:[ 3 12 36  0  0  0  0  0], end state:[ 5 12 36  0  0  0  0  0], runtime(seconds):[301.39]
INFO:Reinforcement.Functions:episode: 32, score:[2602.00], loss:[11.74600], sequence:[23], isInPoolRatio:[1.00], optActionSelectedRatio:[0.86], optActionInPoolButNotSelected:[0.11], random actions:[99], eInit:[0.7323], init state:[ 4  3 31  0  0  0  0  0], end state:[ 6  3 31  1  1  1  0  1], runtime(seconds):[300.17]
INFO:Reinforcement.Functions:episode: 33, score:[2676.80], loss:[11.11910], sequence:[24], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[94], eInit:[0.7250], init state:[ 6  5 35  0  0  0  0  0], end state:[ 1  5 35  0  0  0  0  0], runtime(seconds):[301.91]
INFO:Reinforcement.Functions:episode: 34, score:[2643.60], loss:[10.38238], sequence:[25], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[95], eInit:[0.7177], init state:[ 2 23 37  1  0  0  1  0], end state:[ 4 23 37  0  0  0  0  0], runtime(seconds):[300.73]
INFO:Reinforcement.Functions:episode: 35, score:[2726.00], loss:[10.03426], sequence:[26], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[90], eInit:[0.7106], init state:[ 6  0 48  0  0  1  0  0], end state:[ 1  0 48  0  0  1  0  0], runtime(seconds):[301.92]
INFO:Reinforcement.Functions:episode: 36, score:[2695.60], loss:[11.60740], sequence:[27], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[97], eInit:[0.7034], init state:[ 0  9 37  0  0  0  0  0], end state:[ 2  9 37  0  0  0  0  0], runtime(seconds):[301.19]
INFO:Reinforcement.Functions:episode: 37, score:[2654.00], loss:[10.68982], sequence:[28], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[96], eInit:[0.6964], init state:[ 2 16  7  0  0  0  0  0], end state:[ 4 16  7  0  0  0  0  0], runtime(seconds):[302.09]
INFO:Reinforcement.Functions:episode: 38, score:[2687.20], loss:[9.67230], sequence:[29], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[90], eInit:[0.6894], init state:[4 2 6 0 0 0 0 0], end state:[6 2 6 0 0 0 0 0], runtime(seconds):[300.52]
INFO:Reinforcement.Functions:episode: 39, score:[2720.80], loss:[10.06738], sequence:[30], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[90], eInit:[0.6826], init state:[ 2  1 35  0  0  0  0  0], end state:[ 4  1 35  0  0  0  0  0], runtime(seconds):[302.19]
INFO:Reinforcement.Functions:episode: 40, score:[2675.60], loss:[10.34764], sequence:[31], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[96], eInit:[0.6757], init state:[ 5 20 40  1  0  0  0  0], end state:[ 0 20 40  1  1  0  0  0], runtime(seconds):[301.10]
INFO:Reinforcement.Functions:maxScore:(2725.9999999999955, [35]) , maxSequence:(31, [40])
INFO:Reinforcement.Functions:Optimal models save history:[(35, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:episode: 41, score:[2694.80], loss:[9.49603], sequence:[32], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[86], eInit:[0.6690], init state:[ 5  7 45  0  0  0  0  0], end state:[ 0  7 45  0  0  0  0  0], runtime(seconds):[301.61]
INFO:Reinforcement.Functions:episode: 42, score:[2709.20], loss:[10.40012], sequence:[33], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[95], eInit:[0.6623], init state:[ 1  6 46  0  0  0  0  0], end state:[ 3  6 46  0  0  0  0  0], runtime(seconds):[301.30]
INFO:Reinforcement.Functions:episode: 43, score:[2712.40], loss:[9.53816], sequence:[34], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[88], eInit:[0.6557], init state:[ 3 12 29  0  0  0  0  0], end state:[ 5 12 29  0  0  0  0  0], runtime(seconds):[301.60]
INFO:Reinforcement.Functions:episode: 44, score:[2716.80], loss:[8.27492], sequence:[35], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[99], eInit:[0.6491], init state:[ 0  3 23  0  0  0  0  0], end state:[ 2  3 23  0  0  0  0  0], runtime(seconds):[301.03]
INFO:Reinforcement.Functions:episode: 45, score:[2701.60], loss:[10.35762], sequence:[36], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[93], eInit:[0.6426], init state:[ 4 17 19  0  0  0  0  0], end state:[ 6 17 19  0  0  0  0  0], runtime(seconds):[301.55]
INFO:Reinforcement.Functions:episode: 46, score:[2729.20], loss:[8.53463], sequence:[37], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[89], eInit:[0.6362], init state:[ 0  0 36  0  0  1  0  0], end state:[ 2  0 36  0  0  1  0  0], runtime(seconds):[301.06]
INFO:Reinforcement.Functions:episode: 47, score:[2720.40], loss:[7.89977], sequence:[38], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[91], eInit:[0.6298], init state:[ 1 14 47  0  0  0  0  0], end state:[ 3 14 47  0  0  0  0  0], runtime(seconds):[301.88]
INFO:Reinforcement.Functions:episode: 48, score:[2722.00], loss:[8.30933], sequence:[39], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[88], eInit:[0.6235], init state:[ 0  6 37  0  0  0  0  0], end state:[ 2  6 37  0  0  0  0  0], runtime(seconds):[301.13]
INFO:Reinforcement.Functions:episode: 49, score:[2616.40], loss:[9.83099], sequence:[40], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.11], random actions:[70], eInit:[0.6173], init state:[ 5 13 37  0  0  0  0  0], end state:[ 0 13 37  0  0  0  0  0], runtime(seconds):[302.11]
INFO:Reinforcement.Functions:episode: 50, score:[2660.00], loss:[9.45075], sequence:[41], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[91], eInit:[0.6111], init state:[ 3  5 12  0  0  0  0  0], end state:[ 5  5 12  0  0  0  0  0], runtime(seconds):[300.77]
INFO:Reinforcement.Functions:maxScore:(2729.1999999999975, [46]) , maxSequence:(41, [50])
INFO:Reinforcement.Functions:Optimal models save history:[(46, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:episode: 51, score:[2682.80], loss:[8.20456], sequence:[42], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[75], eInit:[0.6050], init state:[ 5  9 55  0  0  0  0  0], end state:[ 0  9 55  0  0  0  0  0], runtime(seconds):[301.59]
INFO:Reinforcement.Functions:episode: 52, score:[2714.40], loss:[9.09834], sequence:[43], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[86], eInit:[0.5990], init state:[ 3  5 55  0  0  0  0  0], end state:[ 5  5 55  0  0  0  0  0], runtime(seconds):[300.66]
INFO:Reinforcement.Functions:episode: 53, score:[2699.20], loss:[8.00075], sequence:[44], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[93], eInit:[0.5930], init state:[ 5  2 18  0  0  0  0  0], end state:[ 0  2 18  0  0  0  0  0], runtime(seconds):[301.63]
INFO:Reinforcement.Functions:episode: 54, score:[2738.80], loss:[8.65626], sequence:[45], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[84], eInit:[0.5870], init state:[0 4 6 0 0 0 0 0], end state:[2 4 6 0 0 0 0 0], runtime(seconds):[301.13]
INFO:Reinforcement.Functions:episode: 55, score:[2698.40], loss:[7.38169], sequence:[46], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[76], eInit:[0.5812], init state:[ 6 23  2  1  0  0  0  0], end state:[ 1 23  2  1  0  0  0  0], runtime(seconds):[301.91]
INFO:Reinforcement.Functions:episode: 56, score:[2738.80], loss:[7.72589], sequence:[47], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[89], eInit:[0.5754], init state:[ 6 11 56  0  0  0  0  0], end state:[ 1 11 56  0  0  0  0  0], runtime(seconds):[301.09]
INFO:Reinforcement.Functions:episode: 57, score:[2745.20], loss:[6.68250], sequence:[48], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[73], eInit:[0.5696], init state:[ 0  9 52  0  0  0  0  0], end state:[ 2  9 52  0  0  0  0  0], runtime(seconds):[302.12]
INFO:Reinforcement.Functions:episode: 58, score:[2647.60], loss:[8.43352], sequence:[49], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.09], random actions:[66], eInit:[0.5639], init state:[ 3  6 35  0  0  0  0  0], end state:[ 5  6 35  0  0  0  0  0], runtime(seconds):[300.59]
INFO:Reinforcement.Functions:episode: 59, score:[2612.40], loss:[8.27481], sequence:[50], isInPoolRatio:[1.00], optActionSelectedRatio:[0.86], optActionInPoolButNotSelected:[0.12], random actions:[75], eInit:[0.5583], init state:[ 4 10 27  1  1  0  1  0], end state:[ 6 10 27  0  0  0  0  0], runtime(seconds):[301.21]
INFO:Reinforcement.Functions:episode: 60, score:[2783.60], loss:[7.32359], sequence:[51], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[58], eInit:[0.5527], init state:[ 1 15 42  0  0  0  0  0], end state:[ 3 15 42  0  0  0  0  0], runtime(seconds):[300.90]
INFO:Reinforcement.Functions:maxScore:(2783.599999999998, [60]) , maxSequence:(51, [60])
INFO:Reinforcement.Functions:Optimal models save history:[(54, [('Actor', 1), ('Critic', 1)]), (56, [('Actor', 2), ('Critic', 2)]), (57, [('Actor', 0), ('Critic', 0)]), (60, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:episode: 61, score:[2690.40], loss:[6.98264], sequence:[52], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[82], eInit:[0.5472], init state:[ 3 17 30  0  0  0  0  0], end state:[ 5 17 30  0  0  0  0  0], runtime(seconds):[301.06]
INFO:Reinforcement.Functions:episode: 62, score:[2718.00], loss:[7.76967], sequence:[53], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[71], eInit:[0.5417], init state:[6 9 8 0 0 0 0 0], end state:[1 9 8 0 0 0 0 0], runtime(seconds):[300.80]
INFO:Reinforcement.Functions:episode: 63, score:[2682.00], loss:[8.11277], sequence:[54], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[65], eInit:[0.5363], init state:[ 5 21  0  1  0  0  1  0], end state:[ 0 21  0  1  1  0  1  0], runtime(seconds):[301.75]
INFO:Reinforcement.Functions:episode: 64, score:[2695.60], loss:[8.11319], sequence:[55], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[84], eInit:[0.5309], init state:[ 6  7 46  0  0  0  0  0], end state:[ 1  7 46  0  0  0  0  0], runtime(seconds):[300.76]
INFO:Reinforcement.Functions:episode: 65, score:[2774.40], loss:[7.91736], sequence:[56], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[73], eInit:[0.5256], init state:[ 0  5 51  0  0  0  0  0], end state:[ 2  5 51  0  0  0  0  0], runtime(seconds):[301.83]
INFO:Reinforcement.Functions:episode: 66, score:[2708.80], loss:[6.61576], sequence:[57], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[83], eInit:[0.5203], init state:[ 5  0 14  0  0  0  0  0], end state:[ 0  0 14  1  0  0  0  0], runtime(seconds):[300.28]
INFO:Reinforcement.Functions:episode: 67, score:[2726.00], loss:[7.12941], sequence:[58], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[66], eInit:[0.5151], init state:[1 6 2 0 0 0 0 0], end state:[3 6 2 0 0 0 0 0], runtime(seconds):[301.69]
INFO:Reinforcement.Functions:episode: 68, score:[2782.40], loss:[6.78587], sequence:[59], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[74], eInit:[0.5100], init state:[ 3 13 47  0  0  0  0  0], end state:[ 5 13 47  0  0  0  0  0], runtime(seconds):[300.30]
INFO:Reinforcement.Functions:episode: 69, score:[2771.20], loss:[6.31443], sequence:[60], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[65], eInit:[0.5049], init state:[ 5 23 21  1  0  0  0  0], end state:[ 0 23 21  1  0  0  1  0], runtime(seconds):[301.95]
INFO:Reinforcement.Functions:episode: 70, score:[2747.60], loss:[7.66583], sequence:[61], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[71], eInit:[0.4998], init state:[ 4 14 45  0  0  0  0  0], end state:[ 6 14 45  0  0  0  0  0], runtime(seconds):[300.29]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2783.599999999998, [60]) , maxSequence:(61, [70])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 71, score:[2736.00], loss:[6.99326], sequence:[62], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[76], eInit:[0.4948], init state:[ 6 21  4  1  1  0  1  0], end state:[ 1 21  4  0  0  0  0  0], runtime(seconds):[301.71]
INFO:Reinforcement.Functions:episode: 72, score:[2674.00], loss:[8.34081], sequence:[63], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[70], eInit:[0.4899], init state:[ 2 20 10  0  0  0  0  0], end state:[ 4 20 10  0  0  0  0  0], runtime(seconds):[300.86]
INFO:Reinforcement.Functions:episode: 73, score:[2614.40], loss:[8.48027], sequence:[64], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[73], eInit:[0.4850], init state:[ 4 11 35  1  1  0  0  0], end state:[ 6 11 35  0  0  0  0  0], runtime(seconds):[307.43]
INFO:Reinforcement.Functions:episode: 74, score:[2748.40], loss:[7.59652], sequence:[65], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[54], eInit:[0.4801], init state:[ 6 17 54  0  0  0  0  0], end state:[ 1 17 54  0  0  0  0  0], runtime(seconds):[301.65]
INFO:Reinforcement.Functions:episode: 75, score:[2763.20], loss:[6.41519], sequence:[66], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[75], eInit:[0.4753], init state:[ 2  0 36  0  0  1  0  0], end state:[ 4  0 36  1  0  0  0  0], runtime(seconds):[301.69]
INFO:Reinforcement.Functions:episode: 76, score:[2737.20], loss:[8.44773], sequence:[67], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[74], eInit:[0.4706], init state:[ 4  9 56  1  0  0  0  0], end state:[ 6  9 56  0  0  0  0  0], runtime(seconds):[300.56]
INFO:Reinforcement.Functions:episode: 77, score:[2764.00], loss:[5.96948], sequence:[68], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[76], eInit:[0.4659], init state:[1 6 1 0 0 0 0 0], end state:[3 6 1 0 0 0 0 0], runtime(seconds):[301.43]
INFO:Reinforcement.Functions:episode: 78, score:[2738.00], loss:[7.35738], sequence:[69], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[77], eInit:[0.4612], init state:[ 4 23 24  0  0  0  0  0], end state:[ 6 23 24  1  0  0  1  0], runtime(seconds):[300.35]
INFO:Reinforcement.Functions:episode: 79, score:[2761.60], loss:[5.68275], sequence:[70], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[72], eInit:[0.4566], init state:[ 6  1 14  0  0  0  0  0], end state:[ 1  1 14  0  0  0  0  0], runtime(seconds):[301.51]
INFO:Reinforcement.Functions:episode: 80, score:[2757.20], loss:[6.25350], sequence:[71], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[57], eInit:[0.4520], init state:[ 3 23 37  1  0  0  1  0], end state:[ 5 23 37  1  0  0  0  0], runtime(seconds):[300.11]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2783.599999999998, [60]) , maxSequence:(71, [80])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 81, score:[2749.20], loss:[6.73166], sequence:[72], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[69], eInit:[0.4475], init state:[ 5  8 44  0  0  0  0  0], end state:[ 0  8 44  1  1  0  1  0], runtime(seconds):[300.85]
INFO:Reinforcement.Functions:episode: 82, score:[2734.40], loss:[6.24367], sequence:[73], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[78], eInit:[0.4430], init state:[ 5  8 17  0  0  0  0  0], end state:[ 0  8 17  1  0  0  0  0], runtime(seconds):[300.32]
INFO:Reinforcement.Functions:episode: 83, score:[2776.40], loss:[6.25878], sequence:[74], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[56], eInit:[0.4386], init state:[ 5 21 21  1  0  0  1  1], end state:[ 0 21 21  1  1  0  1  0], runtime(seconds):[301.17]
INFO:Reinforcement.Functions:episode: 84, score:[2722.40], loss:[6.36353], sequence:[75], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[70], eInit:[0.4342], init state:[ 2 13 27  0  0  0  0  0], end state:[ 4 13 27  1  1  0  0  0], runtime(seconds):[300.48]
INFO:Reinforcement.Functions:episode: 85, score:[2788.00], loss:[5.51629], sequence:[76], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[60], eInit:[0.4299], init state:[ 6 15 52  0  0  0  0  0], end state:[ 1 15 52  0  0  0  0  0], runtime(seconds):[301.31]
INFO:Reinforcement.Functions:episode: 86, score:[2781.60], loss:[5.45614], sequence:[77], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[72], eInit:[0.4256], init state:[ 0 15 37  0  0  0  0  0], end state:[ 2 15 37  0  0  0  0  0], runtime(seconds):[300.85]
INFO:Reinforcement.Functions:episode: 87, score:[2752.80], loss:[6.15101], sequence:[78], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[72], eInit:[0.4213], init state:[4 9 2 0 0 0 0 0], end state:[6 9 2 0 0 0 0 0], runtime(seconds):[300.87]
INFO:Reinforcement.Functions:episode: 88, score:[2739.60], loss:[7.12166], sequence:[79], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[73], eInit:[0.4171], init state:[ 0 16  7  0  0  0  0  0], end state:[ 2 16  7  0  0  0  0  0], runtime(seconds):[300.91]
INFO:Reinforcement.Functions:episode: 89, score:[2758.40], loss:[5.86055], sequence:[80], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[72], eInit:[0.4129], init state:[ 2 20 58  1  1  0  1  0], end state:[ 4 20 58  0  0  0  0  0], runtime(seconds):[301.32]
INFO:Reinforcement.Functions:episode: 90, score:[2761.20], loss:[5.58452], sequence:[81], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[59], eInit:[0.4088], init state:[3 6 6 0 0 0 0 0], end state:[5 6 6 0 0 0 0 0], runtime(seconds):[300.49]
INFO:Reinforcement.Functions:maxScore:(2787.999999999997, [85]) , maxSequence:(81, [90])
INFO:Reinforcement.Functions:Optimal models save history:[(85, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:episode: 91, score:[2768.40], loss:[5.72361], sequence:[82], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[75], eInit:[0.4047], init state:[ 2  7 21  0  0  0  0  0], end state:[ 4  7 21  0  0  0  0  0], runtime(seconds):[301.27]
INFO:Reinforcement.Functions:episode: 92, score:[2762.00], loss:[5.62411], sequence:[83], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[51], eInit:[0.4007], init state:[ 6  8 46  1  1  0  0  0], end state:[ 1  8 46  1  1  0  0  0], runtime(seconds):[300.84]
INFO:Reinforcement.Functions:episode: 93, score:[2798.80], loss:[5.34731], sequence:[84], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[52], eInit:[0.3967], init state:[0 4 6 0 0 0 0 0], end state:[2 4 6 0 0 0 0 0], runtime(seconds):[301.50]
INFO:Reinforcement.Functions:episode: 94, score:[2765.20], loss:[5.24334], sequence:[85], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[66], eInit:[0.3927], init state:[ 2 14 24  0  0  0  0  0], end state:[ 4 14 24  0  0  0  0  0], runtime(seconds):[300.52]
INFO:Reinforcement.Functions:episode: 95, score:[2780.80], loss:[5.55618], sequence:[86], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[55], eInit:[0.3888], init state:[ 6  3 32  0  0  0  0  0], end state:[ 1  3 32  0  0  0  0  0], runtime(seconds):[301.20]
INFO:Reinforcement.Functions:episode: 96, score:[2766.40], loss:[5.50808], sequence:[87], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[58], eInit:[0.3849], init state:[ 0 19 29  0  0  0  0  0], end state:[ 2 19 29  0  0  0  0  0], runtime(seconds):[300.68]
INFO:Reinforcement.Functions:episode: 97, score:[2803.20], loss:[4.80468], sequence:[88], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[53], eInit:[0.3810], init state:[ 1  0 35  0  0  1  0  0], end state:[ 3  0 35  0  0  1  0  0], runtime(seconds):[301.20]
INFO:Reinforcement.Functions:episode: 98, score:[2783.20], loss:[5.01752], sequence:[89], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[59], eInit:[0.3772], init state:[3 5 9 0 0 0 0 0], end state:[5 5 9 0 0 0 0 0], runtime(seconds):[300.29]
INFO:Reinforcement.Functions:episode: 99, score:[2697.20], loss:[5.95528], sequence:[90], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[55], eInit:[0.3735], init state:[ 5  7 14  0  0  0  0  0], end state:[ 0  7 14  0  0  0  0  0], runtime(seconds):[300.87]
INFO:Reinforcement.Functions:episode: 100, score:[2770.40], loss:[5.63560], sequence:[91], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[62], eInit:[0.3697], init state:[ 6 19 32  0  0  0  0  0], end state:[ 1 19 32  0  0  0  0  0], runtime(seconds):[300.72]
INFO:Reinforcement.Functions:maxScore:(2803.1999999999985, [97]) , maxSequence:(91, [100])
INFO:Reinforcement.Functions:Optimal models save history:[(93, [('Actor', 2), ('Critic', 2)]), (97, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:episode: 101, score:[2741.60], loss:[5.25451], sequence:[92], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[49], eInit:[0.3660], init state:[ 4  0 49  1  0  1  0  0], end state:[ 6  0 49  0  0  1  0  0], runtime(seconds):[300.51]
INFO:Reinforcement.Functions:episode: 102, score:[2700.80], loss:[4.96054], sequence:[93], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[76], eInit:[0.3624], init state:[ 3  4 18  0  0  0  0  0], end state:[ 5  4 18  0  0  0  0  0], runtime(seconds):[300.42]
INFO:Reinforcement.Functions:episode: 103, score:[2665.60], loss:[6.82984], sequence:[94], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.09], random actions:[63], eInit:[0.3587], init state:[ 4  3 16  0  0  0  0  0], end state:[ 6  3 16  0  0  0  0  0], runtime(seconds):[300.51]
INFO:Reinforcement.Functions:episode: 104, score:[2739.60], loss:[6.27836], sequence:[95], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[60], eInit:[0.3552], init state:[ 2 23 26  1  0  0  1  0], end state:[ 4 23 26  0  0  0  0  0], runtime(seconds):[300.76]
INFO:Reinforcement.Functions:episode: 105, score:[2784.80], loss:[5.32339], sequence:[96], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[47], eInit:[0.3516], init state:[ 4  0 35  1  0  1  0  0], end state:[ 6  0 35  0  0  1  0  0], runtime(seconds):[300.77]
INFO:Reinforcement.Functions:episode: 106, score:[2795.20], loss:[5.39119], sequence:[97], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[49], eInit:[0.3481], init state:[ 6  8 35  1  1  0  1  0], end state:[ 1  8 35  1  1  0  1  0], runtime(seconds):[301.31]
INFO:Reinforcement.Functions:episode: 107, score:[2794.00], loss:[4.42375], sequence:[98], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[58], eInit:[0.3446], init state:[ 3 11 27  0  0  0  0  0], end state:[ 5 11 27  0  0  0  0  0], runtime(seconds):[300.73]
INFO:Reinforcement.Functions:episode: 108, score:[2748.00], loss:[5.44884], sequence:[99], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[63], eInit:[0.3412], init state:[ 1  4 43  0  0  0  0  0], end state:[ 3  4 43  0  0  0  0  0], runtime(seconds):[300.89]
INFO:Reinforcement.Functions:episode: 109, score:[2783.60], loss:[5.11367], sequence:[100], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[51], eInit:[0.3378], init state:[ 2 21 35  1  0  0  0  0], end state:[ 4 21 35  0  0  0  0  0], runtime(seconds):[300.65]
INFO:Reinforcement.Functions:episode: 110, score:[2802.80], loss:[4.87091], sequence:[101], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[45], eInit:[0.3344], init state:[ 2  3 33  0  0  0  0  0], end state:[ 4  3 33  0  0  0  0  0], runtime(seconds):[301.05]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2803.1999999999985, [97]) , maxSequence:(101, [110])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 111, score:[2770.40], loss:[5.66746], sequence:[102], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[55], eInit:[0.3310], init state:[ 4 19 27  0  0  0  0  0], end state:[ 6 19 27  0  0  0  0  0], runtime(seconds):[300.37]
INFO:Reinforcement.Functions:episode: 112, score:[2782.80], loss:[4.77717], sequence:[103], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[55], eInit:[0.3277], init state:[ 4  8 21  0  0  0  0  0], end state:[ 6  8 21  1  0  0  0  0], runtime(seconds):[300.27]
INFO:Reinforcement.Functions:episode: 113, score:[2740.80], loss:[6.60029], sequence:[104], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[63], eInit:[0.3244], init state:[ 4 23 58  0  0  0  0  0], end state:[ 6 23 58  1  0  0  0  0], runtime(seconds):[300.65]
INFO:Reinforcement.Functions:episode: 114, score:[2768.00], loss:[5.92131], sequence:[105], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[59], eInit:[0.3212], init state:[ 3  4 23  0  0  0  0  0], end state:[ 5  4 23  0  0  0  0  0], runtime(seconds):[300.64]
INFO:Reinforcement.Functions:episode: 115, score:[2744.00], loss:[6.22035], sequence:[106], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[57], eInit:[0.3180], init state:[ 3  8 53  1  1  0  0  0], end state:[ 5  8 53  0  0  0  0  0], runtime(seconds):[300.77]
INFO:Reinforcement.Functions:episode: 116, score:[2791.20], loss:[5.72811], sequence:[107], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[49], eInit:[0.3148], init state:[ 1 17 42  0  0  0  0  0], end state:[ 3 17 42  0  0  0  0  0], runtime(seconds):[301.01]
INFO:Reinforcement.Functions:episode: 117, score:[2784.40], loss:[5.23462], sequence:[108], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.3117], init state:[ 4 16 56  0  0  0  0  0], end state:[ 6 16 56  0  0  0  0  0], runtime(seconds):[300.34]
INFO:Reinforcement.Functions:episode: 118, score:[2729.20], loss:[5.16038], sequence:[109], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[74], eInit:[0.3085], init state:[ 4 11 28  1  1  0  0  0], end state:[ 6 11 28  0  0  0  0  0], runtime(seconds):[300.19]
INFO:Reinforcement.Functions:episode: 119, score:[2774.40], loss:[5.29482], sequence:[110], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[52], eInit:[0.3055], init state:[ 1 12  1  0  0  0  0  0], end state:[ 3 12  1  0  0  0  0  0], runtime(seconds):[301.06]
INFO:Reinforcement.Functions:episode: 120, score:[2764.40], loss:[4.97680], sequence:[111], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[56], eInit:[0.3024], init state:[ 5 23  7  1  0  0  1  0], end state:[ 0 23  7  1  0  0  0  0], runtime(seconds):[301.09]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2803.1999999999985, [97]) , maxSequence:(111, [120])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 121, score:[2765.20], loss:[5.03486], sequence:[112], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[60], eInit:[0.2994], init state:[2 6 3 0 0 0 0 0], end state:[4 6 3 0 0 0 0 0], runtime(seconds):[301.09]
INFO:Reinforcement.Functions:episode: 122, score:[2736.80], loss:[5.79152], sequence:[113], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[55], eInit:[0.2964], init state:[ 0 17 52  0  0  0  0  0], end state:[ 2 17 52  0  0  0  0  0], runtime(seconds):[301.79]
INFO:Reinforcement.Functions:episode: 123, score:[2772.40], loss:[5.73861], sequence:[114], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[46], eInit:[0.2934], init state:[ 2  0 37  0  0  1  0  0], end state:[ 4  0 37  1  0  1  0  0], runtime(seconds):[301.28]
INFO:Reinforcement.Functions:episode: 124, score:[2622.00], loss:[6.87108], sequence:[115], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[60], eInit:[0.2905], init state:[ 4  9 36  1  0  0  0  0], end state:[ 6  9 36  0  0  0  0  0], runtime(seconds):[301.07]
INFO:Reinforcement.Functions:episode: 125, score:[2789.20], loss:[6.06531], sequence:[116], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[51], eInit:[0.2876], init state:[ 1  5 31  0  0  0  0  0], end state:[ 3  5 31  0  0  0  0  0], runtime(seconds):[300.90]
INFO:Reinforcement.Functions:episode: 126, score:[2788.80], loss:[5.27465], sequence:[117], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[50], eInit:[0.2847], init state:[ 2 11 31  0  0  0  0  0], end state:[ 4 11 31  1  1  0  0  0], runtime(seconds):[301.12]
INFO:Reinforcement.Functions:episode: 127, score:[2789.60], loss:[5.38368], sequence:[118], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[53], eInit:[0.2819], init state:[ 1 19 26  0  0  0  0  0], end state:[ 3 19 26  0  0  0  0  0], runtime(seconds):[300.65]
INFO:Reinforcement.Functions:episode: 128, score:[2821.60], loss:[4.56091], sequence:[119], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[45], eInit:[0.2790], init state:[ 1 15 31  0  0  0  0  0], end state:[ 3 15 31  0  0  0  0  0], runtime(seconds):[301.30]
INFO:Reinforcement.Functions:episode: 129, score:[2779.60], loss:[4.97930], sequence:[120], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[34], eInit:[0.2763], init state:[ 4  1 41  0  0  0  0  0], end state:[ 6  1 41  0  0  0  0  0], runtime(seconds):[299.83]
INFO:Reinforcement.Functions:episode: 130, score:[2796.00], loss:[4.98446], sequence:[121], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[55], eInit:[0.2735], init state:[ 0  0 55  0  0  1  0  0], end state:[ 2  0 55  0  0  1  0  0], runtime(seconds):[301.09]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999995, [128]) , maxSequence:(121, [130])
INFO:Reinforcement.Functions:Optimal models save history:[(128, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:episode: 131, score:[2767.60], loss:[5.39417], sequence:[122], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.2708], init state:[ 6 19  8  0  0  0  0  0], end state:[ 1 19  8  0  0  0  0  0], runtime(seconds):[300.63]
INFO:Reinforcement.Functions:episode: 132, score:[2788.00], loss:[4.99750], sequence:[123], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[61], eInit:[0.2680], init state:[ 1  7 47  0  0  0  0  0], end state:[ 3  7 47  0  0  0  0  0], runtime(seconds):[301.12]
INFO:Reinforcement.Functions:episode: 133, score:[2813.20], loss:[4.62087], sequence:[124], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[55], eInit:[0.2654], init state:[ 0  1 19  0  0  0  0  0], end state:[ 2  1 19  0  0  0  0  0], runtime(seconds):[300.71]
INFO:Reinforcement.Functions:episode: 134, score:[2745.60], loss:[4.90496], sequence:[125], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[56], eInit:[0.2627], init state:[ 5 18 15  1  1  0  1  0], end state:[ 0 18 15  0  0  0  0  0], runtime(seconds):[301.03]
INFO:Reinforcement.Functions:episode: 135, score:[2769.20], loss:[5.63885], sequence:[126], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[47], eInit:[0.2601], init state:[ 4  3 33  0  0  0  0  0], end state:[ 6  3 33  0  0  0  0  0], runtime(seconds):[299.84]
INFO:Reinforcement.Functions:episode: 136, score:[2763.60], loss:[4.86491], sequence:[127], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[59], eInit:[0.2575], init state:[ 2  5 59  0  0  0  0  0], end state:[ 4  5 59  0  0  0  0  0], runtime(seconds):[300.87]
INFO:Reinforcement.Functions:episode: 137, score:[2763.60], loss:[4.05498], sequence:[128], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[51], eInit:[0.2549], init state:[ 5  6 22  0  0  0  0  0], end state:[ 0  6 22  0  0  0  0  0], runtime(seconds):[300.09]
INFO:Reinforcement.Functions:episode: 138, score:[2778.40], loss:[4.44959], sequence:[129], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[52], eInit:[0.2524], init state:[ 3  1 22  0  0  0  0  0], end state:[ 5  1 22  0  0  0  0  0], runtime(seconds):[300.73]
INFO:Reinforcement.Functions:episode: 139, score:[2784.80], loss:[4.39758], sequence:[130], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[41], eInit:[0.2498], init state:[ 3 12 35  0  0  0  0  0], end state:[ 5 12 35  0  0  0  0  0], runtime(seconds):[300.44]
INFO:Reinforcement.Functions:episode: 140, score:[2754.80], loss:[4.73380], sequence:[131], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[51], eInit:[0.2473], init state:[ 4 19  0  0  0  0  0  0], end state:[ 6 19  0  0  0  0  0  0], runtime(seconds):[300.84]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999995, [128]) , maxSequence:(131, [140])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 141, score:[2772.80], loss:[4.42534], sequence:[132], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[49], eInit:[0.2449], init state:[ 5  0 36  0  0  0  0  0], end state:[ 0  0 36  0  0  1  0  0], runtime(seconds):[300.56]
INFO:Reinforcement.Functions:episode: 142, score:[2799.20], loss:[3.99068], sequence:[133], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[53], eInit:[0.2424], init state:[ 1  7 17  0  0  0  0  0], end state:[ 3  7 17  0  0  0  0  0], runtime(seconds):[301.41]
INFO:Reinforcement.Functions:episode: 143, score:[2798.80], loss:[4.32606], sequence:[134], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[40], eInit:[0.2400], init state:[ 1 19 27  0  0  0  0  0], end state:[ 3 19 27  0  0  0  0  0], runtime(seconds):[300.87]
INFO:Reinforcement.Functions:episode: 144, score:[2808.80], loss:[4.18550], sequence:[135], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[49], eInit:[0.2376], init state:[ 1 23 29  1  0  0  1  0], end state:[ 3 23 29  1  0  0  1  0], runtime(seconds):[301.33]
INFO:Reinforcement.Functions:episode: 145, score:[2804.00], loss:[4.06394], sequence:[136], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[53], eInit:[0.2352], init state:[ 2  6 42  0  0  0  0  0], end state:[ 4  6 42  0  0  0  0  0], runtime(seconds):[301.03]
INFO:Reinforcement.Functions:episode: 146, score:[2742.80], loss:[4.04007], sequence:[137], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[41], eInit:[0.2329], init state:[ 5  1 16  0  0  0  0  0], end state:[ 0  1 16  0  0  0  0  0], runtime(seconds):[300.67]
INFO:Reinforcement.Functions:episode: 147, score:[2777.20], loss:[4.38941], sequence:[138], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[57], eInit:[0.2305], init state:[ 6 20 11  0  0  0  0  0], end state:[ 1 20 11  0  0  0  0  0], runtime(seconds):[300.89]
INFO:Reinforcement.Functions:episode: 148, score:[2786.00], loss:[4.09151], sequence:[139], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[56], eInit:[0.2282], init state:[ 3  1 27  0  0  0  0  0], end state:[ 5  1 27  0  0  0  0  0], runtime(seconds):[301.07]
INFO:Reinforcement.Functions:episode: 149, score:[2807.60], loss:[3.78331], sequence:[140], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[42], eInit:[0.2259], init state:[ 6 13  9  0  0  0  0  0], end state:[ 1 13  9  0  0  0  0  0], runtime(seconds):[301.04]
INFO:Reinforcement.Functions:episode: 150, score:[2774.00], loss:[3.83084], sequence:[141], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[56], eInit:[0.2237], init state:[ 5  6 17  0  0  0  0  0], end state:[ 0  6 17  0  0  0  0  0], runtime(seconds):[301.11]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999995, [128]) , maxSequence:(141, [150])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 151, score:[2774.40], loss:[4.48235], sequence:[142], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[47], eInit:[0.2215], init state:[ 2 12 51  0  0  0  0  0], end state:[ 4 12 51  1  1  0  1  0], runtime(seconds):[300.76]
INFO:Reinforcement.Functions:episode: 152, score:[2798.80], loss:[4.63454], sequence:[143], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[44], eInit:[0.2192], init state:[ 3 16 25  0  0  0  0  0], end state:[ 5 16 25  0  0  0  0  0], runtime(seconds):[300.51]
INFO:Reinforcement.Functions:episode: 153, score:[2784.00], loss:[3.66567], sequence:[144], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[56], eInit:[0.2170], init state:[ 6 21 45  1  0  0  0  0], end state:[ 1 21 45  1  0  0  0  0], runtime(seconds):[300.62]
INFO:Reinforcement.Functions:episode: 154, score:[2772.40], loss:[3.85891], sequence:[145], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[54], eInit:[0.2149], init state:[ 1  9 54  0  0  0  0  0], end state:[ 3  9 54  0  0  0  0  0], runtime(seconds):[301.07]
INFO:Reinforcement.Functions:episode: 155, score:[2719.60], loss:[3.94391], sequence:[146], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[54], eInit:[0.2127], init state:[ 4  4 51  0  0  0  0  0], end state:[ 6  4 51  0  0  0  0  0], runtime(seconds):[300.16]
INFO:Reinforcement.Functions:episode: 156, score:[2760.40], loss:[4.80977], sequence:[147], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[44], eInit:[0.2106], init state:[ 0 17 28  0  0  0  0  0], end state:[ 2 17 28  0  0  0  0  0], runtime(seconds):[301.55]
INFO:Reinforcement.Functions:episode: 157, score:[2770.80], loss:[4.28469], sequence:[148], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[49], eInit:[0.2085], init state:[ 2 16 27  0  0  0  0  0], end state:[ 4 16 27  0  0  0  0  0], runtime(seconds):[300.86]
INFO:Reinforcement.Functions:episode: 158, score:[2764.80], loss:[4.58651], sequence:[149], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[60], eInit:[0.2064], init state:[ 4 16 10  0  0  0  0  0], end state:[ 6 16 10  0  0  0  0  0], runtime(seconds):[300.75]
INFO:Reinforcement.Functions:episode: 159, score:[2725.20], loss:[5.29414], sequence:[150], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[49], eInit:[0.2043], init state:[ 5 22 42  1  0  0  1  0], end state:[ 0 22 42  1  0  0  0  0], runtime(seconds):[300.96]
INFO:Reinforcement.Functions:episode: 160, score:[2794.40], loss:[4.61900], sequence:[151], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[44], eInit:[0.2023], init state:[3 2 6 0 0 0 0 0], end state:[5 2 6 0 0 0 0 0], runtime(seconds):[301.09]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999995, [128]) , maxSequence:(151, [160])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 161, score:[2810.40], loss:[4.47004], sequence:[152], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[38], eInit:[0.2003], init state:[ 2 19 35  0  0  0  0  0], end state:[ 4 19 35  0  0  0  0  0], runtime(seconds):[300.66]
INFO:Reinforcement.Functions:episode: 162, score:[2801.20], loss:[4.71260], sequence:[153], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[51], eInit:[0.1983], init state:[ 0 11 32  0  0  0  0  0], end state:[ 2 11 32  0  0  0  0  0], runtime(seconds):[301.41]
INFO:Reinforcement.Functions:episode: 163, score:[2766.40], loss:[4.40644], sequence:[154], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[35], eInit:[0.1963], init state:[ 5  2 27  0  0  0  0  0], end state:[ 0  2 27  0  0  0  0  0], runtime(seconds):[300.17]
INFO:Reinforcement.Functions:episode: 164, score:[2811.60], loss:[4.13716], sequence:[155], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[47], eInit:[0.1943], init state:[ 1  1 31  0  0  0  0  0], end state:[ 3  1 31  1  1  0  0  1], runtime(seconds):[301.19]
INFO:Reinforcement.Functions:episode: 165, score:[2798.00], loss:[4.24086], sequence:[156], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[38], eInit:[0.1924], init state:[ 2 22 48  1  0  0  0  0], end state:[ 4 22 48  0  0  0  0  0], runtime(seconds):[300.47]
INFO:Reinforcement.Functions:episode: 166, score:[2813.60], loss:[3.47624], sequence:[157], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[42], eInit:[0.1905], init state:[ 3 13 31  0  0  0  0  0], end state:[ 5 13 31  0  0  0  0  0], runtime(seconds):[300.65]
INFO:Reinforcement.Functions:episode: 167, score:[2710.00], loss:[3.87975], sequence:[158], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[35], eInit:[0.1886], init state:[4 8 1 0 0 0 0 0], end state:[6 8 1 1 0 0 0 0], runtime(seconds):[300.22]
INFO:Reinforcement.Functions:episode: 168, score:[2808.00], loss:[4.23490], sequence:[159], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[45], eInit:[0.1867], init state:[ 0  3 39  0  0  0  0  0], end state:[ 2  3 39  0  0  0  0  0], runtime(seconds):[301.15]
INFO:Reinforcement.Functions:episode: 169, score:[2792.80], loss:[3.67057], sequence:[160], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[45], eInit:[0.1848], init state:[ 0  2 46  0  0  0  0  0], end state:[ 2  2 46  0  0  0  0  0], runtime(seconds):[300.34]
INFO:Reinforcement.Functions:episode: 170, score:[2804.80], loss:[3.79449], sequence:[161], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[27], eInit:[0.1830], init state:[5 6 7 0 0 0 0 0], end state:[0 6 7 0 0 0 0 0], runtime(seconds):[300.33]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999995, [128]) , maxSequence:(161, [170])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 171, score:[2810.40], loss:[4.28897], sequence:[162], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[45], eInit:[0.1811], init state:[ 1 16 21  0  0  0  0  0], end state:[ 3 16 21  0  0  0  0  0], runtime(seconds):[300.37]
INFO:Reinforcement.Functions:episode: 172, score:[2802.00], loss:[4.02260], sequence:[163], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[49], eInit:[0.1793], init state:[ 2  1 37  0  0  0  0  0], end state:[ 4  1 37  0  0  0  0  0], runtime(seconds):[300.84]
INFO:Reinforcement.Functions:episode: 173, score:[2812.00], loss:[3.66252], sequence:[164], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[47], eInit:[0.1775], init state:[ 3  4 55  0  0  0  0  0], end state:[ 5  4 55  0  0  0  0  0], runtime(seconds):[300.11]
INFO:Reinforcement.Functions:episode: 174, score:[2806.40], loss:[4.07043], sequence:[165], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[34], eInit:[0.1757], init state:[ 1 10 40  0  0  0  0  0], end state:[ 3 10 40  0  0  0  0  0], runtime(seconds):[301.03]
INFO:Reinforcement.Functions:episode: 175, score:[2789.60], loss:[3.76162], sequence:[166], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[40], eInit:[0.1740], init state:[ 1 19 34  0  0  0  0  0], end state:[ 3 19 34  0  0  0  0  0], runtime(seconds):[300.36]
INFO:Reinforcement.Functions:episode: 176, score:[2798.40], loss:[3.71430], sequence:[167], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[42], eInit:[0.1722], init state:[ 0 22 25  1  0  0  0  0], end state:[ 2 22 25  1  0  0  0  0], runtime(seconds):[301.02]
INFO:Reinforcement.Functions:episode: 177, score:[2803.20], loss:[3.54771], sequence:[168], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[43], eInit:[0.1705], init state:[ 3  2 59  0  0  0  0  0], end state:[ 5  2 59  0  0  0  0  0], runtime(seconds):[300.14]
INFO:Reinforcement.Functions:episode: 178, score:[2796.40], loss:[3.72872], sequence:[169], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[48], eInit:[0.1688], init state:[ 3  0 36  0  0  1  0  0], end state:[ 5  0 36  0  0  0  0  0], runtime(seconds):[300.62]
INFO:Reinforcement.Functions:episode: 179, score:[2804.00], loss:[3.68624], sequence:[170], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[45], eInit:[0.1671], init state:[ 3  1 10  0  0  0  0  0], end state:[ 5  1 10  0  0  0  0  0], runtime(seconds):[300.39]
INFO:Reinforcement.Functions:episode: 180, score:[2696.00], loss:[4.24242], sequence:[171], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[45], eInit:[0.1655], init state:[ 4 15 19  0  0  0  0  0], end state:[ 6 15 19  0  0  0  0  0], runtime(seconds):[300.12]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2821.5999999999995, [128]) , maxSequence:(171, [180])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 181, score:[2828.00], loss:[3.99178], sequence:[172], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[32], eInit:[0.1638], init state:[ 0 10 33  0  0  0  0  0], end state:[ 2 10 33  0  0  0  0  0], runtime(seconds):[300.40]
INFO:Reinforcement.Functions:episode: 182, score:[2722.80], loss:[3.91548], sequence:[173], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.08], random actions:[34], eInit:[0.1622], init state:[5 7 2 0 0 0 0 0], end state:[0 7 2 0 0 0 0 0], runtime(seconds):[300.20]
INFO:Reinforcement.Functions:episode: 183, score:[2802.00], loss:[3.48736], sequence:[174], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[34], eInit:[0.1605], init state:[0 1 9 0 0 1 0 0], end state:[2 1 9 0 0 1 0 0], runtime(seconds):[300.20]
INFO:Reinforcement.Functions:episode: 184, score:[2815.20], loss:[3.91424], sequence:[175], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[42], eInit:[0.1589], init state:[ 1  7 50  0  0  0  0  0], end state:[ 3  7 50  0  0  0  0  0], runtime(seconds):[300.50]
INFO:Reinforcement.Functions:episode: 185, score:[2802.00], loss:[3.34122], sequence:[176], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[51], eInit:[0.1574], init state:[0 4 9 0 0 0 0 0], end state:[2 4 9 0 0 0 0 0], runtime(seconds):[300.43]
INFO:Reinforcement.Functions:episode: 186, score:[2738.80], loss:[4.03275], sequence:[177], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[39], eInit:[0.1558], init state:[ 3 18 44  0  0  0  0  0], end state:[ 5 18 44  1  1  0  1  0], runtime(seconds):[301.23]
INFO:Reinforcement.Functions:episode: 187, score:[2790.40], loss:[3.90249], sequence:[178], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[37], eInit:[0.1542], init state:[ 2  4 34  0  0  0  0  0], end state:[ 4  4 34  0  0  0  0  0], runtime(seconds):[301.44]
INFO:Reinforcement.Functions:episode: 188, score:[2762.40], loss:[4.89708], sequence:[179], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[25], eInit:[0.1527], init state:[ 4 19 19  0  0  0  0  0], end state:[ 6 19 19  0  0  0  0  0], runtime(seconds):[301.82]
INFO:Reinforcement.Functions:episode: 189, score:[2809.60], loss:[3.55346], sequence:[180], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[33], eInit:[0.1512], init state:[ 2 20 49  1  1  0  1  0], end state:[ 4 20 49  0  0  0  0  0], runtime(seconds):[301.49]
INFO:Reinforcement.Functions:episode: 190, score:[2816.80], loss:[3.81927], sequence:[181], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[44], eInit:[0.1496], init state:[ 2  1 48  0  0  0  0  0], end state:[ 4  1 48  0  0  0  0  0], runtime(seconds):[302.37]
INFO:Reinforcement.Functions:maxScore:(2827.9999999999977, [181]) , maxSequence:(181, [190])
INFO:Reinforcement.Functions:Optimal models save history:[(181, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:episode: 191, score:[2717.20], loss:[3.93290], sequence:[182], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[35], eInit:[0.1481], init state:[ 5 23 27  1  0  0  0  0], end state:[ 0 23 27  1  1  0  1  0], runtime(seconds):[301.64]
INFO:Reinforcement.Functions:episode: 192, score:[2738.40], loss:[4.64139], sequence:[183], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[36], eInit:[0.1467], init state:[ 4  2 27  0  0  0  0  0], end state:[ 6  2 27  0  0  0  0  0], runtime(seconds):[302.33]
INFO:Reinforcement.Functions:episode: 193, score:[2794.80], loss:[4.36407], sequence:[184], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[37], eInit:[0.1452], init state:[ 3 18 52  0  0  0  0  0], end state:[ 5 18 52  1  1  0  1  0], runtime(seconds):[301.59]
INFO:Reinforcement.Functions:episode: 194, score:[2738.80], loss:[4.58495], sequence:[185], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[35], eInit:[0.1437], init state:[ 6  4 10  0  0  0  0  0], end state:[ 1  4 10  0  0  0  0  0], runtime(seconds):[302.92]
INFO:Reinforcement.Functions:episode: 195, score:[2766.40], loss:[4.33355], sequence:[186], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[43], eInit:[0.1423], init state:[ 6 17 14  0  0  0  0  0], end state:[ 1 17 14  0  0  0  0  0], runtime(seconds):[301.79]
INFO:Reinforcement.Functions:episode: 196, score:[2802.80], loss:[4.03271], sequence:[187], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[42], eInit:[0.1409], init state:[ 5 13 39  0  0  0  0  0], end state:[ 0 13 39  0  0  0  0  0], runtime(seconds):[302.17]
INFO:Reinforcement.Functions:episode: 197, score:[2800.00], loss:[4.13870], sequence:[188], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[35], eInit:[0.1395], init state:[ 3 21 29  1  1  0  1  0], end state:[ 5 21 29  1  0  0  1  1], runtime(seconds):[300.93]
INFO:Reinforcement.Functions:episode: 198, score:[2827.60], loss:[3.64312], sequence:[189], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[34], eInit:[0.1381], init state:[ 0  0 37  0  0  1  0  0], end state:[ 2  0 37  0  0  1  0  0], runtime(seconds):[303.23]
INFO:Reinforcement.Functions:episode: 199, score:[2763.60], loss:[3.92683], sequence:[190], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[48], eInit:[0.1367], init state:[ 4 23 13  0  0  0  0  0], end state:[ 6 23 13  1  0  0  0  0], runtime(seconds):[300.70]
INFO:Reinforcement.Functions:episode: 200, score:[2808.00], loss:[4.07795], sequence:[191], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[40], eInit:[0.1353], init state:[ 0 18 26  0  0  0  0  0], end state:[ 2 18 26  0  0  0  0  0], runtime(seconds):[302.35]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2827.9999999999977, [181]) , maxSequence:(191, [200])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 201, score:[2814.80], loss:[3.50398], sequence:[192], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[34], eInit:[0.1340], init state:[2 7 3 0 0 0 0 0], end state:[4 7 3 0 0 0 0 0], runtime(seconds):[301.72]
INFO:Reinforcement.Functions:episode: 202, score:[2824.40], loss:[3.61992], sequence:[193], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[43], eInit:[0.1326], init state:[ 1 22 32  1  0  0  0  0], end state:[ 3 22 32  1  0  0  0  0], runtime(seconds):[303.01]
INFO:Reinforcement.Functions:episode: 203, score:[2796.80], loss:[3.98956], sequence:[194], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[48], eInit:[0.1313], init state:[ 6  4 39  0  0  0  0  0], end state:[ 1  4 39  0  0  0  0  0], runtime(seconds):[301.95]
INFO:Reinforcement.Functions:episode: 204, score:[2801.60], loss:[3.99522], sequence:[195], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[34], eInit:[0.1300], init state:[ 5 17 18  0  0  0  0  0], end state:[ 0 17 18  0  0  0  0  0], runtime(seconds):[302.37]
INFO:Reinforcement.Functions:episode: 205, score:[2793.20], loss:[3.95631], sequence:[196], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.03], random actions:[28], eInit:[0.1287], init state:[ 4 12 37  1  1  0  0  0], end state:[ 6 12 37  0  0  0  0  0], runtime(seconds):[300.98]
INFO:Reinforcement.Functions:episode: 206, score:[2806.40], loss:[3.61050], sequence:[197], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[39], eInit:[0.1274], init state:[ 6 12 35  0  0  0  0  0], end state:[ 1 12 35  0  0  0  0  0], runtime(seconds):[302.36]
INFO:Reinforcement.Functions:episode: 207, score:[2800.80], loss:[3.72679], sequence:[198], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[43], eInit:[0.1261], init state:[ 0 10 58  0  0  0  0  0], end state:[ 2 10 58  0  0  0  0  0], runtime(seconds):[302.04]
INFO:Reinforcement.Functions:episode: 208, score:[2809.20], loss:[3.89997], sequence:[199], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[36], eInit:[0.1249], init state:[ 5  0 40  0  0  0  0  0], end state:[ 0  0 40  0  0  1  0  0], runtime(seconds):[302.39]
INFO:Reinforcement.Functions:episode: 209, score:[2810.40], loss:[3.79982], sequence:[200], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[44], eInit:[0.1236], init state:[ 0  8 15  1  0  0  0  0], end state:[ 2  8 15  1  0  0  0  0], runtime(seconds):[301.95]
INFO:Reinforcement.Functions:episode: 210, score:[2743.60], loss:[4.43968], sequence:[201], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[36], eInit:[0.1224], init state:[ 5  4 26  0  0  0  0  0], end state:[ 0  4 26  0  0  0  0  0], runtime(seconds):[302.60]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2827.9999999999977, [181]) , maxSequence:(201, [210])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 211, score:[2807.20], loss:[4.03362], sequence:[202], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[44], eInit:[0.1212], init state:[ 0 22  0  1  0  0  0  0], end state:[ 2 22  0  1  0  0  0  0], runtime(seconds):[301.64]
INFO:Reinforcement.Functions:episode: 212, score:[2815.60], loss:[4.24378], sequence:[203], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[39], eInit:[0.1200], init state:[ 6  9 13  0  0  0  0  0], end state:[ 1  9 13  0  0  0  0  0], runtime(seconds):[303.31]
INFO:Reinforcement.Functions:episode: 213, score:[2758.00], loss:[4.60471], sequence:[204], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[43], eInit:[0.1188], init state:[ 2 23 12  1  0  0  0  0], end state:[ 4 23 12  0  0  0  0  0], runtime(seconds):[300.96]
INFO:Reinforcement.Functions:episode: 214, score:[2812.40], loss:[4.08956], sequence:[205], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[46], eInit:[0.1176], init state:[ 0 17 49  0  0  0  0  0], end state:[ 2 17 49  0  0  0  0  0], runtime(seconds):[301.34]
INFO:Reinforcement.Functions:episode: 215, score:[2766.40], loss:[4.52330], sequence:[206], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[38], eInit:[0.1164], init state:[ 4  8 58  0  0  0  0  0], end state:[ 6  8 58  1  1  0  0  0], runtime(seconds):[299.69]
INFO:Reinforcement.Functions:episode: 216, score:[2792.80], loss:[4.11727], sequence:[207], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[36], eInit:[0.1152], init state:[ 0 16 57  0  0  0  0  0], end state:[ 2 16 57  0  0  0  0  0], runtime(seconds):[301.31]
INFO:Reinforcement.Functions:episode: 217, score:[2790.00], loss:[3.81751], sequence:[208], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[40], eInit:[0.1141], init state:[ 3 16 32  0  0  0  0  0], end state:[ 5 16 32  0  0  0  0  0], runtime(seconds):[299.67]
INFO:Reinforcement.Functions:episode: 218, score:[2788.40], loss:[4.56752], sequence:[209], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[45], eInit:[0.1129], init state:[ 0  9 59  0  0  0  0  0], end state:[ 2  9 59  0  0  0  0  0], runtime(seconds):[301.19]
INFO:Reinforcement.Functions:episode: 219, score:[2772.40], loss:[4.10442], sequence:[210], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[30], eInit:[0.1118], init state:[ 4 15 24  0  0  0  0  0], end state:[ 6 15 24  0  0  0  0  0], runtime(seconds):[299.49]
INFO:Reinforcement.Functions:episode: 220, score:[2788.00], loss:[4.22640], sequence:[211], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[32], eInit:[0.1107], init state:[ 4 13  6  1  1  0  1  0], end state:[ 6 13  6  0  0  0  0  0], runtime(seconds):[300.51]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2827.9999999999977, [181]) , maxSequence:(211, [220])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 221, score:[2784.40], loss:[3.95270], sequence:[212], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[43], eInit:[0.1096], init state:[ 5  1 14  0  0  0  0  0], end state:[ 0  1 14  0  0  0  0  0], runtime(seconds):[299.78]
INFO:Reinforcement.Functions:episode: 222, score:[2802.40], loss:[4.24253], sequence:[213], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[34], eInit:[0.1085], init state:[ 1 15 51  0  0  0  0  0], end state:[ 3 15 51  0  0  0  0  0], runtime(seconds):[301.20]
INFO:Reinforcement.Functions:episode: 223, score:[2778.80], loss:[3.91512], sequence:[214], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[37], eInit:[0.1074], init state:[4 3 4 0 0 0 0 0], end state:[6 3 4 0 0 0 0 0], runtime(seconds):[299.35]
INFO:Reinforcement.Functions:episode: 224, score:[2826.00], loss:[3.97610], sequence:[215], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[33], eInit:[0.1063], init state:[ 1  0 59  0  0  1  0  0], end state:[ 3  0 59  0  0  1  0  0], runtime(seconds):[301.26]
INFO:Reinforcement.Functions:episode: 225, score:[2764.00], loss:[4.89980], sequence:[216], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[33], eInit:[0.1053], init state:[ 4 11 50  1  1  0  0  0], end state:[ 6 11 50  0  0  0  0  0], runtime(seconds):[300.01]
INFO:Reinforcement.Functions:episode: 226, score:[2812.00], loss:[3.60621], sequence:[217], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[43], eInit:[0.1042], init state:[ 0 17 31  0  0  0  0  0], end state:[ 2 17 31  0  0  0  0  0], runtime(seconds):[301.14]
INFO:Reinforcement.Functions:episode: 227, score:[2780.40], loss:[3.98779], sequence:[218], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[48], eInit:[0.1032], init state:[ 6  5 11  0  0  0  0  0], end state:[ 1  5 11  0  0  0  0  0], runtime(seconds):[300.19]
INFO:Reinforcement.Functions:episode: 228, score:[2754.40], loss:[4.44249], sequence:[219], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[33], eInit:[0.1021], init state:[ 4  5 23  0  0  0  0  0], end state:[ 6  5 23  0  0  0  0  0], runtime(seconds):[300.67]
INFO:Reinforcement.Functions:episode: 229, score:[2769.60], loss:[4.29743], sequence:[220], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[38], eInit:[0.1011], init state:[ 6  8 45  1  1  0  0  0], end state:[ 1  8 45  1  1  0  0  0], runtime(seconds):[300.30]
INFO:Reinforcement.Functions:episode: 230, score:[2773.20], loss:[4.39149], sequence:[221], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[41], eInit:[0.1001], init state:[ 3  6 36  0  0  0  0  0], end state:[ 5  6 36  0  0  0  0  0], runtime(seconds):[300.95]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2827.9999999999977, [181]) , maxSequence:(221, [230])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 231, score:[2842.80], loss:[4.17521], sequence:[222], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[24], eInit:[0.0991], init state:[ 1  2 15  0  0  0  0  0], end state:[ 3  2 15  0  0  0  0  0], runtime(seconds):[300.18]
INFO:Reinforcement.Functions:episode: 232, score:[2780.00], loss:[3.69028], sequence:[223], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[36], eInit:[0.0981], init state:[ 5  3 15  0  0  0  0  0], end state:[ 0  3 15  0  0  0  0  0], runtime(seconds):[301.04]
INFO:Reinforcement.Functions:episode: 233, score:[2786.40], loss:[4.02050], sequence:[224], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[34], eInit:[0.0971], init state:[ 1 16 10  0  0  0  0  0], end state:[ 3 16 10  0  0  0  0  0], runtime(seconds):[300.19]
INFO:Reinforcement.Functions:episode: 234, score:[2799.20], loss:[3.70970], sequence:[225], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[44], eInit:[0.0962], init state:[ 0 10 12  0  0  0  0  0], end state:[ 2 10 12  0  0  0  0  0], runtime(seconds):[329.49]
INFO:Reinforcement.Functions:episode: 235, score:[2806.40], loss:[4.26275], sequence:[226], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[39], eInit:[0.0952], init state:[ 0 22 35  1  0  0  0  0], end state:[ 2 22 35  1  0  0  0  0], runtime(seconds):[431.63]
INFO:Reinforcement.Functions:episode: 236, score:[2796.80], loss:[4.27940], sequence:[227], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.04], random actions:[28], eInit:[0.0942], init state:[ 5  6 51  0  0  0  0  0], end state:[ 0  6 51  0  0  1  0  0], runtime(seconds):[432.12]
INFO:Reinforcement.Functions:episode: 237, score:[2765.60], loss:[4.41539], sequence:[228], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[27], eInit:[0.0933], init state:[ 0 16 12  0  0  0  0  0], end state:[ 2 16 12  0  0  0  0  0], runtime(seconds):[434.12]
INFO:Reinforcement.Functions:episode: 238, score:[2760.00], loss:[4.36902], sequence:[229], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[28], eInit:[0.0924], init state:[ 4 10 31  1  1  0  1  0], end state:[ 6 10 31  0  0  0  0  0], runtime(seconds):[432.73]
INFO:Reinforcement.Functions:episode: 239, score:[2763.20], loss:[4.34167], sequence:[230], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[38], eInit:[0.0914], init state:[ 3 12 17  0  0  0  0  0], end state:[ 5 12 17  0  0  0  0  0], runtime(seconds):[432.10]
INFO:Reinforcement.Functions:episode: 240, score:[2807.20], loss:[4.89554], sequence:[231], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[32], eInit:[0.0905], init state:[ 4 15 24  0  0  0  0  0], end state:[ 6 15 24  0  0  0  0  0], runtime(seconds):[433.47]
INFO:Reinforcement.Functions:maxScore:(2842.7999999999993, [231]) , maxSequence:(231, [240])
INFO:Reinforcement.Functions:Optimal models save history:[(231, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:episode: 241, score:[2791.60], loss:[3.98448], sequence:[232], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[41], eInit:[0.0896], init state:[ 2  5 54  0  0  0  0  0], end state:[ 4  5 54  0  0  0  0  0], runtime(seconds):[433.85]
INFO:Reinforcement.Functions:episode: 242, score:[2814.40], loss:[4.34038], sequence:[233], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0887], init state:[ 3 14 51  0  0  0  0  0], end state:[ 5 14 51  0  0  0  0  0], runtime(seconds):[433.14]
INFO:Reinforcement.Functions:episode: 243, score:[2808.00], loss:[4.06214], sequence:[234], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[41], eInit:[0.0878], init state:[ 1 20 57  1  1  0  1  0], end state:[ 3 20 57  0  1  1  0  1], runtime(seconds):[433.61]
INFO:Reinforcement.Functions:episode: 244, score:[2679.60], loss:[4.77449], sequence:[235], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.09], random actions:[40], eInit:[0.0870], init state:[ 5 16 43  0  0  0  0  0], end state:[ 0 16 43  1  0  0  0  0], runtime(seconds):[434.23]
INFO:Reinforcement.Functions:episode: 245, score:[2794.40], loss:[3.74322], sequence:[236], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[33], eInit:[0.0861], init state:[ 5  7 57  0  0  0  0  0], end state:[ 0  7 57  0  0  0  0  0], runtime(seconds):[434.42]
INFO:Reinforcement.Functions:episode: 246, score:[2780.00], loss:[3.94130], sequence:[237], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[42], eInit:[0.0852], init state:[ 4 15 42  0  0  0  0  0], end state:[ 6 15 42  0  0  0  0  0], runtime(seconds):[432.67]
INFO:Reinforcement.Functions:episode: 247, score:[2800.80], loss:[3.92897], sequence:[238], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[31], eInit:[0.0844], init state:[ 3  8 42  1  1  0  1  0], end state:[ 5  8 42  0  0  0  0  0], runtime(seconds):[433.82]
INFO:Reinforcement.Functions:episode: 248, score:[2788.80], loss:[4.09105], sequence:[239], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[33], eInit:[0.0835], init state:[ 6 17 53  0  0  0  0  0], end state:[ 1 17 53  0  0  0  0  0], runtime(seconds):[433.91]
INFO:Reinforcement.Functions:episode: 249, score:[2769.60], loss:[4.30034], sequence:[240], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[47], eInit:[0.0827], init state:[ 3 18 36  0  0  0  0  0], end state:[ 5 18 36  1  1  0  1  0], runtime(seconds):[433.03]
INFO:Reinforcement.Functions:episode: 250, score:[2808.80], loss:[3.88486], sequence:[241], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[35], eInit:[0.0819], init state:[ 1 16 11  0  0  0  0  0], end state:[ 3 16 11  0  0  0  0  0], runtime(seconds):[433.83]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2842.7999999999993, [231]) , maxSequence:(241, [250])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 251, score:[2685.20], loss:[4.95575], sequence:[242], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.08], random actions:[31], eInit:[0.0811], init state:[ 5  1 25  0  0  0  0  0], end state:[ 0  1 25  0  0  0  0  0], runtime(seconds):[434.34]
INFO:Reinforcement.Functions:episode: 252, score:[2789.20], loss:[4.57474], sequence:[243], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[37], eInit:[0.0802], init state:[ 0 22 24  1  0  0  0  0], end state:[ 2 22 24  1  0  0  0  0], runtime(seconds):[434.22]
INFO:Reinforcement.Functions:episode: 253, score:[2802.40], loss:[3.95560], sequence:[244], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[32], eInit:[0.0794], init state:[ 2  1 45  0  0  0  0  0], end state:[ 4  1 45  0  0  0  0  0], runtime(seconds):[432.60]
INFO:Reinforcement.Functions:episode: 254, score:[2804.40], loss:[4.52770], sequence:[245], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[28], eInit:[0.0787], init state:[ 6  3 22  0  0  0  0  0], end state:[ 1  3 22  0  0  0  0  0], runtime(seconds):[433.76]
INFO:Reinforcement.Functions:episode: 255, score:[2802.40], loss:[3.50500], sequence:[246], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[20], eInit:[0.0779], init state:[ 2 10 46  0  0  0  0  0], end state:[ 4 10 46  1  1  0  1  0], runtime(seconds):[433.51]
INFO:Reinforcement.Functions:episode: 256, score:[2816.00], loss:[3.92092], sequence:[247], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[29], eInit:[0.0771], init state:[ 5 19 38  1  0  0  1  0], end state:[ 0 19 38  0  0  0  0  0], runtime(seconds):[434.22]
INFO:Reinforcement.Functions:episode: 257, score:[2770.00], loss:[3.45792], sequence:[248], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[33], eInit:[0.0763], init state:[3 7 0 0 0 0 0 0], end state:[5 7 0 0 0 0 0 0], runtime(seconds):[432.32]
INFO:Reinforcement.Functions:episode: 258, score:[2831.20], loss:[3.46724], sequence:[249], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[32], eInit:[0.0756], init state:[ 1  2 43  0  0  0  0  0], end state:[ 3  2 43  0  0  0  0  0], runtime(seconds):[428.06]
INFO:Reinforcement.Functions:episode: 259, score:[2825.20], loss:[3.45074], sequence:[250], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[26], eInit:[0.0748], init state:[ 6  2 23  0  0  0  0  0], end state:[ 1  2 23  0  0  0  0  0], runtime(seconds):[433.62]
INFO:Reinforcement.Functions:episode: 260, score:[2810.00], loss:[4.03740], sequence:[251], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[35], eInit:[0.0740], init state:[ 5 14 31  0  0  0  0  0], end state:[ 0 14 31  0  0  0  0  0], runtime(seconds):[432.99]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2842.7999999999993, [231]) , maxSequence:(251, [260])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 261, score:[2767.20], loss:[3.65697], sequence:[252], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[32], eInit:[0.0733], init state:[ 3 23 36  1  0  0  1  0], end state:[ 5 23 36  1  0  0  0  0], runtime(seconds):[432.44]
INFO:Reinforcement.Functions:episode: 262, score:[2776.40], loss:[4.03872], sequence:[253], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[34], eInit:[0.0726], init state:[ 6  7 59  0  0  0  0  0], end state:[ 1  7 59  0  0  0  0  0], runtime(seconds):[434.59]
INFO:Reinforcement.Functions:episode: 263, score:[2794.80], loss:[3.73690], sequence:[254], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[33], eInit:[0.0718], init state:[ 0  3 26  0  0  0  0  0], end state:[ 2  3 26  0  0  0  0  0], runtime(seconds):[434.60]
INFO:Reinforcement.Functions:episode: 264, score:[2789.60], loss:[4.47161], sequence:[255], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[43], eInit:[0.0711], init state:[ 3 11 41  0  0  0  0  0], end state:[ 5 11 41  0  0  0  0  0], runtime(seconds):[431.10]
INFO:Reinforcement.Functions:episode: 265, score:[2801.60], loss:[3.81996], sequence:[256], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[36], eInit:[0.0704], init state:[ 2 17 51  0  0  0  0  0], end state:[ 4 17 51  0  0  0  0  0], runtime(seconds):[433.72]
INFO:Reinforcement.Functions:episode: 266, score:[2815.60], loss:[4.07438], sequence:[257], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[29], eInit:[0.0697], init state:[ 1 13 12  0  0  0  0  0], end state:[ 3 13 12  0  0  0  0  0], runtime(seconds):[432.02]
INFO:Reinforcement.Functions:episode: 267, score:[2780.40], loss:[3.35419], sequence:[258], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.05], random actions:[25], eInit:[0.0690], init state:[ 3 22 34  1  0  0  0  0], end state:[ 5 22 34  1  0  0  1  0], runtime(seconds):[431.54]
INFO:Reinforcement.Functions:episode: 268, score:[2815.20], loss:[3.81474], sequence:[259], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[30], eInit:[0.0683], init state:[ 1  9 54  0  0  0  0  0], end state:[ 3  9 54  1  1  0  0  0], runtime(seconds):[433.02]
INFO:Reinforcement.Functions:episode: 269, score:[2821.60], loss:[4.13580], sequence:[260], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[29], eInit:[0.0676], init state:[ 2  1 29  0  0  0  0  0], end state:[ 4  1 29  0  0  0  0  0], runtime(seconds):[434.71]
INFO:Reinforcement.Functions:episode: 270, score:[2825.20], loss:[3.55704], sequence:[261], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[32], eInit:[0.0670], init state:[ 0  8 26  1  0  0  0  0], end state:[ 2  8 26  1  0  0  0  0], runtime(seconds):[434.22]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2842.7999999999993, [231]) , maxSequence:(261, [270])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 271, score:[2811.60], loss:[3.36746], sequence:[262], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0663], init state:[ 0 22 46  1  0  0  0  0], end state:[ 2 22 46  1  0  0  0  0], runtime(seconds):[432.38]
INFO:Reinforcement.Functions:episode: 272, score:[2738.00], loss:[4.50600], sequence:[263], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[36], eInit:[0.0656], init state:[ 5 21  4  1  0  0  1  0], end state:[ 0 21  4  1  1  0  1  0], runtime(seconds):[433.28]
INFO:Reinforcement.Functions:episode: 273, score:[2798.00], loss:[3.57396], sequence:[264], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[26], eInit:[0.0650], init state:[ 4 14 44  0  0  0  0  0], end state:[ 6 14 44  0  0  0  0  0], runtime(seconds):[431.21]
INFO:Reinforcement.Functions:episode: 274, score:[2778.80], loss:[4.00999], sequence:[265], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[32], eInit:[0.0643], init state:[ 2 11 44  0  0  0  0  0], end state:[ 4 11 44  1  1  0  0  0], runtime(seconds):[432.89]
INFO:Reinforcement.Functions:episode: 275, score:[2817.60], loss:[3.85446], sequence:[266], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[27], eInit:[0.0637], init state:[ 2 23  7  1  0  0  0  0], end state:[ 4 23  7  0  0  0  0  0], runtime(seconds):[431.99]
INFO:Reinforcement.Functions:episode: 276, score:[2761.20], loss:[3.78060], sequence:[267], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[27], eInit:[0.0630], init state:[ 3 20 59  1  1  0  1  0], end state:[ 5 20 59  1  0  0  0  0], runtime(seconds):[431.94]
INFO:Reinforcement.Functions:episode: 277, score:[2758.00], loss:[4.69018], sequence:[268], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[29], eInit:[0.0624], init state:[ 6  8 38  1  1  0  1  0], end state:[ 1  8 38  1  1  0  1  0], runtime(seconds):[434.53]
INFO:Reinforcement.Functions:episode: 278, score:[2758.40], loss:[4.45561], sequence:[269], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[34], eInit:[0.0618], init state:[ 4 17 25  0  0  0  0  0], end state:[ 6 17 25  0  0  0  0  0], runtime(seconds):[431.78]
INFO:Reinforcement.Functions:episode: 279, score:[2728.40], loss:[4.31693], sequence:[270], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[38], eInit:[0.0612], init state:[ 3 13 37  0  0  0  0  0], end state:[ 5 13 37  0  0  0  0  0], runtime(seconds):[431.72]
INFO:Reinforcement.Functions:episode: 280, score:[2788.80], loss:[3.77848], sequence:[271], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[33], eInit:[0.0606], init state:[ 3  2 43  0  0  0  0  0], end state:[ 5  2 43  0  0  0  0  0], runtime(seconds):[433.54]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2842.7999999999993, [231]) , maxSequence:(271, [280])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 281, score:[2752.80], loss:[4.47352], sequence:[272], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[38], eInit:[0.0600], init state:[ 3 21  0  1  1  0  1  0], end state:[ 5 21  0  1  0  0  1  0], runtime(seconds):[431.26]
INFO:Reinforcement.Functions:episode: 282, score:[2814.80], loss:[4.38307], sequence:[273], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[30], eInit:[0.0594], init state:[ 1 20 49  1  1  0  1  0], end state:[ 3 20 49  1  1  0  1  0], runtime(seconds):[431.30]
INFO:Reinforcement.Functions:episode: 283, score:[2815.60], loss:[4.22130], sequence:[274], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[33], eInit:[0.0588], init state:[ 3 12 43  0  0  0  0  0], end state:[ 5 12 43  0  0  0  0  0], runtime(seconds):[431.85]
INFO:Reinforcement.Functions:episode: 284, score:[2802.00], loss:[4.41203], sequence:[275], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[33], eInit:[0.0582], init state:[ 2 18 53  0  0  0  0  0], end state:[ 4 18 53  0  0  0  0  0], runtime(seconds):[432.33]
INFO:Reinforcement.Functions:episode: 285, score:[2738.80], loss:[4.95209], sequence:[276], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[34], eInit:[0.0576], init state:[ 4 23 31  0  0  0  0  0], end state:[ 6 23 31  1  0  0  1  0], runtime(seconds):[432.66]
INFO:Reinforcement.Functions:episode: 286, score:[2800.40], loss:[4.64760], sequence:[277], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[30], eInit:[0.0570], init state:[ 6 23 33  1  0  0  1  0], end state:[ 1 23 33  1  0  0  1  0], runtime(seconds):[432.36]
INFO:Reinforcement.Functions:episode: 287, score:[2828.00], loss:[3.83952], sequence:[278], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[25], eInit:[0.0565], init state:[ 1  9 55  0  0  0  0  0], end state:[ 3  9 55  0  0  0  0  0], runtime(seconds):[432.85]
INFO:Reinforcement.Functions:episode: 288, score:[2825.20], loss:[3.39843], sequence:[279], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[31], eInit:[0.0559], init state:[ 2  8 57  1  1  0  0  0], end state:[ 4  8 57  0  0  0  0  0], runtime(seconds):[432.51]
INFO:Reinforcement.Functions:episode: 289, score:[2769.20], loss:[3.87196], sequence:[280], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[32], eInit:[0.0553], init state:[ 3  5 38  0  0  0  0  0], end state:[ 5  5 38  0  0  0  0  0], runtime(seconds):[431.45]
INFO:Reinforcement.Functions:episode: 290, score:[2834.00], loss:[3.75723], sequence:[281], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[30], eInit:[0.0548], init state:[ 3 13 26  0  0  0  0  0], end state:[ 5 13 26  0  0  0  0  0], runtime(seconds):[431.87]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2842.7999999999993, [231]) , maxSequence:(281, [290])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 291, score:[2786.00], loss:[4.16715], sequence:[282], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[33], eInit:[0.0542], init state:[0 0 5 1 0 0 0 0], end state:[2 0 5 1 0 0 0 0], runtime(seconds):[433.00]
INFO:Reinforcement.Functions:episode: 292, score:[2816.00], loss:[3.76363], sequence:[283], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[32], eInit:[0.0537], init state:[ 0 10 54  0  0  0  0  0], end state:[ 2 10 54  0  0  0  0  0], runtime(seconds):[426.64]
INFO:Reinforcement.Functions:episode: 293, score:[2802.40], loss:[4.40040], sequence:[284], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[37], eInit:[0.0531], init state:[ 1 21 45  1  0  0  0  0], end state:[ 3 21 45  1  0  0  0  0], runtime(seconds):[420.42]
INFO:Reinforcement.Functions:episode: 294, score:[2769.60], loss:[3.88312], sequence:[285], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[29], eInit:[0.0526], init state:[ 4 18 44  0  0  0  0  0], end state:[ 6 18 44  0  0  0  0  0], runtime(seconds):[415.65]
INFO:Reinforcement.Functions:episode: 295, score:[2798.80], loss:[4.09500], sequence:[286], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[18], eInit:[0.0521], init state:[ 4  2 30  0  0  0  0  0], end state:[ 6  2 30  0  0  0  0  0], runtime(seconds):[418.29]
INFO:Reinforcement.Functions:episode: 296, score:[2794.00], loss:[4.29178], sequence:[287], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[37], eInit:[0.0516], init state:[ 2 13 14  0  0  0  0  0], end state:[ 4 13 14  1  1  0  1  0], runtime(seconds):[432.25]
INFO:Reinforcement.Functions:episode: 297, score:[2758.80], loss:[3.75279], sequence:[288], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[37], eInit:[0.0511], init state:[ 4  1 39  0  0  0  0  0], end state:[ 6  1 39  0  0  0  0  0], runtime(seconds):[432.53]
INFO:Reinforcement.Functions:episode: 298, score:[2806.00], loss:[3.93580], sequence:[289], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.04], random actions:[23], eInit:[0.0505], init state:[ 6 12 50  0  0  0  0  0], end state:[ 1 12 50  0  0  0  0  0], runtime(seconds):[407.03]
INFO:Reinforcement.Functions:episode: 299, score:[2764.40], loss:[3.88093], sequence:[290], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[39], eInit:[0.0500], init state:[ 5  0 35  0  0  0  0  0], end state:[ 0  0 35  0  0  1  0  0], runtime(seconds):[431.31]
INFO:Reinforcement.Functions:episode: 300, score:[2772.80], loss:[4.33166], sequence:[291], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[18], eInit:[0.0495], init state:[ 5 15 14  0  0  0  0  0], end state:[ 0 15 14  0  0  0  0  0], runtime(seconds):[400.72]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2842.7999999999993, [231]) , maxSequence:(291, [300])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 301, score:[2764.40], loss:[3.82230], sequence:[292], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[23], eInit:[0.0490], init state:[6 0 3 1 0 0 0 0], end state:[1 0 3 1 0 0 0 0], runtime(seconds):[292.77]
INFO:Reinforcement.Functions:episode: 302, score:[2794.80], loss:[4.40509], sequence:[293], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[28], eInit:[0.0486], init state:[ 4  3 37  0  0  0  0  0], end state:[ 6  3 37  0  0  0  0  0], runtime(seconds):[290.41]
INFO:Reinforcement.Functions:episode: 303, score:[2744.00], loss:[4.58805], sequence:[294], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[27], eInit:[0.0481], init state:[ 5  1 36  0  0  0  0  0], end state:[ 0  1 36  0  0  0  0  0], runtime(seconds):[292.25]
INFO:Reinforcement.Functions:episode: 304, score:[2691.20], loss:[5.87969], sequence:[295], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.08], random actions:[34], eInit:[0.0476], init state:[ 4 17 49  0  0  0  0  0], end state:[ 6 17 49  0  0  0  0  0], runtime(seconds):[290.94]
INFO:Reinforcement.Functions:episode: 305, score:[2787.20], loss:[4.62182], sequence:[296], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[27], eInit:[0.0471], init state:[ 4  1 24  0  0  0  0  0], end state:[ 6  1 24  0  0  0  0  0], runtime(seconds):[336.28]
INFO:Reinforcement.Functions:episode: 306, score:[2798.00], loss:[4.54636], sequence:[297], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[36], eInit:[0.0466], init state:[ 2 16 46  0  0  0  0  0], end state:[ 4 16 46  0  0  0  0  0], runtime(seconds):[290.57]
INFO:Reinforcement.Functions:episode: 307, score:[2751.20], loss:[4.82508], sequence:[298], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[38], eInit:[0.0462], init state:[ 5 19 30  1  0  0  1  0], end state:[ 0 19 30  0  0  0  0  0], runtime(seconds):[291.16]
INFO:Reinforcement.Functions:episode: 308, score:[2813.60], loss:[4.10259], sequence:[299], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[31], eInit:[0.0457], init state:[2 5 3 0 0 0 0 0], end state:[4 5 3 0 0 0 0 0], runtime(seconds):[290.52]
INFO:Reinforcement.Functions:episode: 309, score:[2758.40], loss:[4.63325], sequence:[300], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[39], eInit:[0.0453], init state:[ 5  7 15  0  0  0  0  0], end state:[ 0  7 15  0  0  0  0  0], runtime(seconds):[292.01]
INFO:Reinforcement.Functions:episode: 310, score:[2847.20], loss:[3.45257], sequence:[301], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[24], eInit:[0.0448], init state:[1 2 7 0 0 0 0 0], end state:[3 2 7 0 0 0 0 0], runtime(seconds):[290.64]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(301, [310])
INFO:Reinforcement.Functions:Optimal models save history:[(310, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:episode: 311, score:[2791.20], loss:[3.48719], sequence:[302], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[40], eInit:[0.0444], init state:[ 5  1 28  0  0  0  0  0], end state:[ 0  1 28  0  0  0  0  0], runtime(seconds):[291.14]
INFO:Reinforcement.Functions:episode: 312, score:[2813.60], loss:[3.38643], sequence:[303], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[35], eInit:[0.0439], init state:[ 2  9 29  0  0  0  0  0], end state:[ 4  9 29  0  0  0  0  0], runtime(seconds):[413.12]
INFO:Reinforcement.Functions:episode: 313, score:[2823.60], loss:[3.11414], sequence:[304], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[37], eInit:[0.0435], init state:[ 2  5 28  0  0  0  0  0], end state:[ 4  5 28  0  0  0  0  0], runtime(seconds):[432.80]
INFO:Reinforcement.Functions:episode: 314, score:[2821.60], loss:[3.69299], sequence:[305], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0430], init state:[ 0 22  4  1  0  0  0  0], end state:[ 2 22  4  1  0  0  0  0], runtime(seconds):[432.64]
INFO:Reinforcement.Functions:episode: 315, score:[2776.80], loss:[3.10154], sequence:[306], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[37], eInit:[0.0426], init state:[ 1 17 37  0  0  0  0  0], end state:[ 3 17 37  0  0  0  0  0], runtime(seconds):[431.43]
INFO:Reinforcement.Functions:episode: 316, score:[2770.40], loss:[4.24752], sequence:[307], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[33], eInit:[0.0422], init state:[ 6  8 34  1  1  0  1  1], end state:[ 1  8 34  1  1  0  1  1], runtime(seconds):[432.79]
INFO:Reinforcement.Functions:episode: 317, score:[2803.20], loss:[3.66084], sequence:[308], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0418], init state:[ 5 10 28  0  0  0  0  0], end state:[ 0 10 28  0  0  0  0  0], runtime(seconds):[432.85]
INFO:Reinforcement.Functions:episode: 318, score:[2791.20], loss:[3.53800], sequence:[309], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.05], random actions:[27], eInit:[0.0413], init state:[ 3 16 11  0  0  0  0  0], end state:[ 5 16 11  0  0  0  0  0], runtime(seconds):[433.20]
INFO:Reinforcement.Functions:episode: 319, score:[2820.40], loss:[3.14541], sequence:[310], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[35], eInit:[0.0409], init state:[ 0  3 22  0  0  0  0  0], end state:[ 2  3 22  0  0  0  0  0], runtime(seconds):[434.03]
INFO:Reinforcement.Functions:episode: 320, score:[2790.00], loss:[4.14723], sequence:[311], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[26], eInit:[0.0405], init state:[ 6  6 11  0  0  0  0  0], end state:[ 1  6 11  0  0  0  0  0], runtime(seconds):[434.13]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(311, [320])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 321, score:[2799.20], loss:[3.74761], sequence:[312], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[31], eInit:[0.0401], init state:[ 5  4 47  0  0  0  0  0], end state:[ 0  4 47  0  0  0  0  0], runtime(seconds):[433.86]
INFO:Reinforcement.Functions:episode: 322, score:[2769.20], loss:[4.47020], sequence:[313], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[33], eInit:[0.0397], init state:[2 7 7 0 0 0 0 0], end state:[4 7 7 0 0 0 0 0], runtime(seconds):[433.23]
INFO:Reinforcement.Functions:episode: 323, score:[2758.00], loss:[4.30066], sequence:[314], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[34], eInit:[0.0393], init state:[ 6 17  7  0  0  0  0  0], end state:[ 1 17  7  0  0  0  0  0], runtime(seconds):[433.60]
INFO:Reinforcement.Functions:episode: 324, score:[2811.60], loss:[4.26890], sequence:[315], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[40], eInit:[0.0389], init state:[ 1  1 29  0  0  0  0  0], end state:[ 3  1 29  0  0  0  0  0], runtime(seconds):[434.66]
INFO:Reinforcement.Functions:episode: 325, score:[2826.00], loss:[3.70949], sequence:[316], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[29], eInit:[0.0385], init state:[ 0 18 40  0  0  0  0  0], end state:[ 2 18 40  0  0  0  0  0], runtime(seconds):[433.80]
INFO:Reinforcement.Functions:episode: 326, score:[2811.60], loss:[3.66956], sequence:[317], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[34], eInit:[0.0381], init state:[ 0 10  3  0  0  0  0  0], end state:[ 2 10  3  0  0  0  0  0], runtime(seconds):[432.03]
INFO:Reinforcement.Functions:episode: 327, score:[2784.40], loss:[3.51287], sequence:[318], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[27], eInit:[0.0378], init state:[ 3 13 33  0  0  0  0  0], end state:[ 5 13 33  0  0  0  0  0], runtime(seconds):[433.34]
INFO:Reinforcement.Functions:episode: 328, score:[2811.20], loss:[4.40707], sequence:[319], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[23], eInit:[0.0374], init state:[ 3 10 41  0  0  0  0  0], end state:[ 5 10 41  0  0  0  0  0], runtime(seconds):[431.78]
INFO:Reinforcement.Functions:episode: 329, score:[2802.80], loss:[3.92539], sequence:[320], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[36], eInit:[0.0370], init state:[ 0  3 56  0  0  0  0  0], end state:[ 2  3 56  0  0  0  0  0], runtime(seconds):[432.62]
INFO:Reinforcement.Functions:episode: 330, score:[2774.40], loss:[4.63162], sequence:[321], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[27], eInit:[0.0366], init state:[ 6 14 24  0  0  0  0  0], end state:[ 1 14 24  0  0  0  0  0], runtime(seconds):[431.39]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(321, [330])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 331, score:[2802.80], loss:[4.32829], sequence:[322], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[30], eInit:[0.0363], init state:[ 6  0 12  1  0  0  0  0], end state:[ 1  0 12  1  0  0  0  0], runtime(seconds):[434.65]
INFO:Reinforcement.Functions:episode: 332, score:[2694.00], loss:[4.44042], sequence:[323], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.09], random actions:[43], eInit:[0.0359], init state:[ 5 16 11  0  0  0  0  0], end state:[ 0 16 11  0  0  0  0  0], runtime(seconds):[433.42]
INFO:Reinforcement.Functions:episode: 333, score:[2804.00], loss:[5.40338], sequence:[324], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[25], eInit:[0.0356], init state:[ 3 19 35  0  0  0  0  0], end state:[ 5 19 35  1  0  0  1  0], runtime(seconds):[431.48]
INFO:Reinforcement.Functions:episode: 334, score:[2806.40], loss:[4.48093], sequence:[325], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[27], eInit:[0.0352], init state:[ 1 18  2  0  0  0  0  0], end state:[ 3 18  2  0  0  0  0  0], runtime(seconds):[433.38]
INFO:Reinforcement.Functions:episode: 335, score:[2833.60], loss:[4.04189], sequence:[326], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[23], eInit:[0.0348], init state:[ 2 17 55  0  0  0  0  0], end state:[ 4 17 55  0  0  0  0  0], runtime(seconds):[434.49]
INFO:Reinforcement.Functions:episode: 336, score:[2790.80], loss:[4.25824], sequence:[327], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[28], eInit:[0.0345], init state:[ 6 17 41  0  0  0  0  0], end state:[ 1 17 41  0  0  0  0  0], runtime(seconds):[435.20]
INFO:Reinforcement.Functions:episode: 337, score:[2834.80], loss:[3.58941], sequence:[328], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[34], eInit:[0.0342], init state:[ 0  4 36  0  0  0  0  0], end state:[ 2  4 36  0  0  0  0  0], runtime(seconds):[433.14]
INFO:Reinforcement.Functions:episode: 338, score:[2776.40], loss:[3.94169], sequence:[329], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[32], eInit:[0.0338], init state:[ 3  1 13  0  0  0  0  0], end state:[ 5  1 13  0  0  0  0  0], runtime(seconds):[433.61]
INFO:Reinforcement.Functions:episode: 339, score:[2824.00], loss:[3.57641], sequence:[330], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0335], init state:[ 0  0 56  0  0  1  0  0], end state:[ 2  0 56  0  0  1  0  0], runtime(seconds):[434.30]
INFO:Reinforcement.Functions:episode: 340, score:[2784.40], loss:[3.88709], sequence:[331], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[32], eInit:[0.0331], init state:[3 6 0 0 0 0 0 0], end state:[5 6 0 0 0 0 0 0], runtime(seconds):[433.03]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(331, [340])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 341, score:[2800.00], loss:[3.85922], sequence:[332], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[37], eInit:[0.0328], init state:[ 6  7 43  0  0  0  0  0], end state:[ 1  7 43  0  0  0  0  0], runtime(seconds):[433.58]
INFO:Reinforcement.Functions:episode: 342, score:[2783.20], loss:[3.88642], sequence:[333], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0325], init state:[ 1  7 58  0  0  0  0  0], end state:[ 3  7 58  0  0  0  0  0], runtime(seconds):[434.83]
INFO:Reinforcement.Functions:episode: 343, score:[2815.60], loss:[3.39254], sequence:[334], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0322], init state:[ 6 12  1  0  0  0  0  0], end state:[ 1 12  1  0  0  0  0  0], runtime(seconds):[435.26]
INFO:Reinforcement.Functions:episode: 344, score:[2838.40], loss:[2.76588], sequence:[335], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[28], eInit:[0.0318], init state:[ 2  5 51  0  0  0  0  0], end state:[ 4  5 51  0  0  0  0  0], runtime(seconds):[433.18]
INFO:Reinforcement.Functions:episode: 345, score:[2840.00], loss:[3.12800], sequence:[336], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[31], eInit:[0.0315], init state:[ 2  1 12  0  0  0  0  0], end state:[ 4  1 12  0  0  0  0  0], runtime(seconds):[434.14]
INFO:Reinforcement.Functions:episode: 346, score:[2834.00], loss:[3.82450], sequence:[337], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[33], eInit:[0.0312], init state:[ 6 16 33  0  0  0  0  0], end state:[ 1 16 33  0  0  0  0  0], runtime(seconds):[433.94]
INFO:Reinforcement.Functions:episode: 347, score:[2778.80], loss:[3.14343], sequence:[338], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[24], eInit:[0.0309], init state:[ 4 23 59  0  0  0  0  0], end state:[ 6 23 59  1  0  0  0  0], runtime(seconds):[433.33]
INFO:Reinforcement.Functions:episode: 348, score:[2843.20], loss:[2.69120], sequence:[339], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[27], eInit:[0.0306], init state:[ 6 23 45  1  0  0  0  0], end state:[ 1 23 45  1  0  0  0  0], runtime(seconds):[433.65]
INFO:Reinforcement.Functions:episode: 349, score:[2766.40], loss:[3.20103], sequence:[340], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[27], eInit:[0.0303], init state:[ 3 14 50  0  0  0  0  0], end state:[ 5 14 50  0  0  0  0  0], runtime(seconds):[433.80]
INFO:Reinforcement.Functions:episode: 350, score:[2821.60], loss:[2.68534], sequence:[341], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[37], eInit:[0.0300], init state:[ 0 14 47  0  0  0  0  0], end state:[ 2 14 47  0  0  0  0  0], runtime(seconds):[434.40]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(341, [350])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 351, score:[2776.80], loss:[2.96516], sequence:[342], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.05], random actions:[22], eInit:[0.0297], init state:[ 4 13  0  1  1  0  1  0], end state:[ 6 13  0  0  0  0  0  0], runtime(seconds):[431.35]
INFO:Reinforcement.Functions:episode: 352, score:[2784.00], loss:[3.50461], sequence:[343], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[31], eInit:[0.0294], init state:[ 3  5 16  0  0  0  0  0], end state:[ 5  5 16  0  0  0  0  0], runtime(seconds):[432.21]
INFO:Reinforcement.Functions:episode: 353, score:[2787.60], loss:[3.88135], sequence:[344], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[28], eInit:[0.0291], init state:[ 6 13 38  0  0  0  0  0], end state:[ 1 13 38  0  0  0  0  0], runtime(seconds):[432.85]
INFO:Reinforcement.Functions:episode: 354, score:[2840.00], loss:[2.68915], sequence:[345], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[27], eInit:[0.0288], init state:[ 0  0 49  0  0  1  0  0], end state:[ 2  0 49  0  0  1  0  0], runtime(seconds):[434.16]
INFO:Reinforcement.Functions:episode: 355, score:[2706.80], loss:[3.24518], sequence:[346], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.08], random actions:[26], eInit:[0.0285], init state:[ 4  4 57  0  0  0  0  0], end state:[ 6  4 57  0  0  0  0  0], runtime(seconds):[431.40]
INFO:Reinforcement.Functions:episode: 356, score:[2768.40], loss:[4.35565], sequence:[347], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[32], eInit:[0.0282], init state:[ 5 13 32  0  0  0  0  0], end state:[ 0 13 32  0  0  0  0  0], runtime(seconds):[433.77]
INFO:Reinforcement.Functions:episode: 357, score:[2802.40], loss:[3.79607], sequence:[348], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[35], eInit:[0.0279], init state:[ 3 11 35  0  0  0  0  0], end state:[ 5 11 35  0  0  0  0  0], runtime(seconds):[433.99]
INFO:Reinforcement.Functions:episode: 358, score:[2814.80], loss:[3.90975], sequence:[349], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[23], eInit:[0.0277], init state:[ 1  8 21  1  0  0  0  0], end state:[ 3  8 21  1  0  0  0  0], runtime(seconds):[434.61]
INFO:Reinforcement.Functions:episode: 359, score:[2780.40], loss:[3.99194], sequence:[350], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[33], eInit:[0.0274], init state:[ 5  6 47  0  0  0  0  0], end state:[ 0  6 47  0  0  0  0  0], runtime(seconds):[433.30]
INFO:Reinforcement.Functions:episode: 360, score:[2802.40], loss:[3.61230], sequence:[351], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[23], eInit:[0.0271], init state:[ 4  8 50  0  0  0  0  0], end state:[ 6  8 50  1  1  0  0  0], runtime(seconds):[433.88]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(351, [360])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 361, score:[2784.80], loss:[3.91457], sequence:[352], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[30], eInit:[0.0268], init state:[ 6  0 20  1  0  0  0  0], end state:[ 1  0 20  1  0  0  0  0], runtime(seconds):[434.85]
INFO:Reinforcement.Functions:episode: 362, score:[2816.40], loss:[3.93473], sequence:[353], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.03], random actions:[23], eInit:[0.0266], init state:[0 1 2 0 0 1 0 0], end state:[2 1 2 0 0 1 0 0], runtime(seconds):[433.48]
INFO:Reinforcement.Functions:episode: 363, score:[2811.60], loss:[3.76600], sequence:[354], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[38], eInit:[0.0263], init state:[ 1 18 52  0  0  0  0  0], end state:[ 3 18 52  0  0  0  0  0], runtime(seconds):[434.30]
INFO:Reinforcement.Functions:episode: 364, score:[2802.00], loss:[3.85173], sequence:[355], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.04], random actions:[22], eInit:[0.0260], init state:[ 5  6 48  0  0  0  0  0], end state:[ 0  6 48  0  0  0  0  0], runtime(seconds):[432.51]
INFO:Reinforcement.Functions:episode: 365, score:[2836.40], loss:[3.92683], sequence:[356], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[25], eInit:[0.0258], init state:[ 2  6 42  0  0  0  0  0], end state:[ 4  6 42  0  0  0  0  0], runtime(seconds):[435.31]
INFO:Reinforcement.Functions:episode: 366, score:[2766.40], loss:[4.00089], sequence:[357], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[39], eInit:[0.0255], init state:[ 1 16 44  0  0  0  0  0], end state:[ 3 16 44  0  0  0  0  0], runtime(seconds):[433.49]
INFO:Reinforcement.Functions:episode: 367, score:[2810.40], loss:[3.27277], sequence:[358], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.03], random actions:[27], eInit:[0.0253], init state:[0 2 8 0 0 0 0 0], end state:[2 2 8 0 0 0 0 0], runtime(seconds):[434.37]
INFO:Reinforcement.Functions:episode: 368, score:[2803.20], loss:[4.27205], sequence:[359], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[27], eInit:[0.0250], init state:[ 5  0 43  0  0  0  0  0], end state:[ 0  0 43  0  1  1  1  1], runtime(seconds):[433.88]
INFO:Reinforcement.Functions:episode: 369, score:[2836.00], loss:[3.82008], sequence:[360], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[23], eInit:[0.0248], init state:[1 7 7 0 0 0 0 0], end state:[3 7 7 0 0 0 0 0], runtime(seconds):[433.56]
INFO:Reinforcement.Functions:episode: 370, score:[2733.60], loss:[4.15396], sequence:[361], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[23], eInit:[0.0245], init state:[ 3 11 37  0  0  0  0  0], end state:[ 5 11 37  0  0  0  0  0], runtime(seconds):[433.60]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(361, [370])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 371, score:[2826.40], loss:[4.13801], sequence:[362], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[24], eInit:[0.0243], init state:[ 6 20 47  1  1  0  1  0], end state:[ 1 20 47  1  1  0  1  0], runtime(seconds):[434.11]
INFO:Reinforcement.Functions:episode: 372, score:[2816.00], loss:[3.65853], sequence:[363], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.03], random actions:[22], eInit:[0.0240], init state:[ 4 17 29  0  0  0  0  0], end state:[ 6 17 29  0  0  0  0  0], runtime(seconds):[434.04]
INFO:Reinforcement.Functions:episode: 373, score:[2765.20], loss:[3.74568], sequence:[364], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[35], eInit:[0.0238], init state:[ 2 18 21  0  0  0  0  0], end state:[ 4 18 21  0  0  0  0  0], runtime(seconds):[432.65]
INFO:Reinforcement.Functions:episode: 374, score:[2759.20], loss:[5.00043], sequence:[365], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[28], eInit:[0.0235], init state:[ 4  6 44  0  0  0  0  0], end state:[ 6  6 44  0  0  0  0  0], runtime(seconds):[431.97]
INFO:Reinforcement.Functions:episode: 375, score:[2802.80], loss:[4.35894], sequence:[366], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[31], eInit:[0.0233], init state:[ 5 18 35  1  1  0  1  0], end state:[ 0 18 35  0  0  0  0  0], runtime(seconds):[432.75]
INFO:Reinforcement.Functions:episode: 376, score:[2813.60], loss:[4.55557], sequence:[367], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[21], eInit:[0.0231], init state:[ 4 17 21  0  0  0  0  0], end state:[ 6 17 21  0  0  0  0  0], runtime(seconds):[431.65]
INFO:Reinforcement.Functions:episode: 377, score:[2783.60], loss:[3.98105], sequence:[368], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[30], eInit:[0.0228], init state:[ 3  2 28  0  0  0  0  0], end state:[ 5  2 28  0  0  0  0  0], runtime(seconds):[431.66]
INFO:Reinforcement.Functions:episode: 378, score:[2770.00], loss:[4.84125], sequence:[369], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[28], eInit:[0.0226], init state:[ 3 15 13  0  0  0  0  0], end state:[ 5 15 13  0  0  0  0  0], runtime(seconds):[433.73]
INFO:Reinforcement.Functions:episode: 379, score:[2788.80], loss:[4.05274], sequence:[370], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[30], eInit:[0.0224], init state:[4 2 2 0 0 0 0 0], end state:[6 2 2 0 0 0 0 0], runtime(seconds):[432.20]
INFO:Reinforcement.Functions:episode: 380, score:[2799.20], loss:[3.73850], sequence:[371], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0222], init state:[ 5 13 52  0  0  0  0  0], end state:[ 0 13 52  0  0  0  0  0], runtime(seconds):[432.48]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(371, [380])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 381, score:[2778.40], loss:[5.21566], sequence:[372], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[42], eInit:[0.0219], init state:[ 2 20 59  1  1  0  1  0], end state:[ 4 20 59  0  0  0  0  0], runtime(seconds):[433.34]
INFO:Reinforcement.Functions:episode: 382, score:[2796.80], loss:[5.34291], sequence:[373], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[38], eInit:[0.0217], init state:[ 4 10 32  1  1  0  1  0], end state:[ 6 10 32  0  0  0  0  0], runtime(seconds):[431.72]
INFO:Reinforcement.Functions:episode: 383, score:[2780.40], loss:[4.33904], sequence:[374], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[24], eInit:[0.0215], init state:[ 3  4 41  0  0  0  0  0], end state:[ 5  4 41  0  0  0  0  0], runtime(seconds):[435.03]
INFO:Reinforcement.Functions:episode: 384, score:[2746.00], loss:[3.86555], sequence:[375], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[32], eInit:[0.0213], init state:[ 3  7 32  0  0  0  0  0], end state:[ 5  7 32  0  0  0  0  0], runtime(seconds):[432.65]
INFO:Reinforcement.Functions:episode: 385, score:[2832.80], loss:[3.96235], sequence:[376], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.02], random actions:[22], eInit:[0.0211], init state:[ 6 20 11  0  0  0  0  0], end state:[ 1 20 11  1  0  0  1  0], runtime(seconds):[432.94]
INFO:Reinforcement.Functions:episode: 386, score:[2825.20], loss:[3.44275], sequence:[377], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0209], init state:[ 2 18  7  0  0  0  0  0], end state:[ 4 18  7  0  0  0  0  0], runtime(seconds):[434.58]
INFO:Reinforcement.Functions:episode: 387, score:[2778.80], loss:[3.45983], sequence:[378], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[35], eInit:[0.0207], init state:[ 4 20 37  0  0  0  0  0], end state:[ 6 20 37  1  1  0  0  0], runtime(seconds):[432.70]
INFO:Reinforcement.Functions:episode: 388, score:[2809.20], loss:[3.59966], sequence:[379], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[37], eInit:[0.0205], init state:[ 1 14 40  0  0  0  0  0], end state:[ 3 14 40  0  0  0  0  0], runtime(seconds):[433.83]
INFO:Reinforcement.Functions:episode: 389, score:[2832.00], loss:[3.25422], sequence:[380], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[23], eInit:[0.0203], init state:[ 1  4 51  0  0  0  0  0], end state:[ 3  4 51  0  0  0  0  0], runtime(seconds):[434.76]
INFO:Reinforcement.Functions:episode: 390, score:[2830.40], loss:[3.00217], sequence:[381], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[28], eInit:[0.0200], init state:[ 1 23 34  1  0  0  1  0], end state:[ 3 23 34  1  0  0  0  0], runtime(seconds):[433.71]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(381, [390])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 391, score:[2826.80], loss:[3.54066], sequence:[382], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[31], eInit:[0.0198], init state:[ 0 21 59  1  0  0  0  0], end state:[ 2 21 59  1  0  0  0  0], runtime(seconds):[433.49]
INFO:Reinforcement.Functions:episode: 392, score:[2817.60], loss:[3.05776], sequence:[383], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[24], eInit:[0.0196], init state:[ 3 18 51  0  0  0  0  0], end state:[ 5 18 51  1  1  0  1  0], runtime(seconds):[432.32]
INFO:Reinforcement.Functions:episode: 393, score:[2781.60], loss:[3.50476], sequence:[384], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[27], eInit:[0.0195], init state:[ 2 12 46  0  0  0  0  0], end state:[ 4 12 46  1  1  0  1  0], runtime(seconds):[432.90]
INFO:Reinforcement.Functions:episode: 394, score:[2816.00], loss:[3.20497], sequence:[385], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[35], eInit:[0.0193], init state:[ 1  9 49  0  0  0  0  0], end state:[ 3  9 49  0  0  0  0  0], runtime(seconds):[433.53]
INFO:Reinforcement.Functions:episode: 395, score:[2805.20], loss:[3.24881], sequence:[386], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[20], eInit:[0.0191], init state:[ 3 21  6  1  1  0  1  1], end state:[ 5 21  6  1  0  0  1  0], runtime(seconds):[433.63]
INFO:Reinforcement.Functions:episode: 396, score:[2776.40], loss:[3.37089], sequence:[387], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[23], eInit:[0.0189], init state:[ 1 18 49  0  0  0  0  0], end state:[ 3 18 49  0  0  0  0  0], runtime(seconds):[434.48]
INFO:Reinforcement.Functions:episode: 397, score:[2777.20], loss:[3.93254], sequence:[388], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[26], eInit:[0.0187], init state:[ 5 19 58  1  0  0  1  0], end state:[ 0 19 58  0  0  0  0  0], runtime(seconds):[434.64]
INFO:Reinforcement.Functions:episode: 398, score:[2810.80], loss:[2.95477], sequence:[389], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[34], eInit:[0.0185], init state:[ 6 10 39  0  0  0  0  0], end state:[ 1 10 39  0  0  0  0  0], runtime(seconds):[432.82]
INFO:Reinforcement.Functions:episode: 399, score:[2809.20], loss:[3.55549], sequence:[390], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[27], eInit:[0.0183], init state:[ 2 18 46  0  0  0  0  0], end state:[ 4 18 46  0  0  0  0  0], runtime(seconds):[432.74]
INFO:Reinforcement.Functions:episode: 400, score:[2822.00], loss:[3.16419], sequence:[391], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[26], eInit:[0.0181], init state:[ 3 11 32  0  0  0  0  0], end state:[ 5 11 32  0  0  0  0  0], runtime(seconds):[431.83]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(391, [400])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 401, score:[2829.20], loss:[3.14654], sequence:[392], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[29], eInit:[0.0180], init state:[ 0  1 46  0  0  0  0  0], end state:[ 2  1 46  0  0  0  0  0], runtime(seconds):[434.55]
INFO:Reinforcement.Functions:episode: 402, score:[2823.60], loss:[2.50681], sequence:[393], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[23], eInit:[0.0178], init state:[ 2 10 47  0  0  0  0  0], end state:[ 4 10 47  1  1  0  1  0], runtime(seconds):[434.16]
INFO:Reinforcement.Functions:episode: 403, score:[2809.60], loss:[2.95918], sequence:[394], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[40], eInit:[0.0176], init state:[ 1 17 14  0  0  0  0  0], end state:[ 3 17 14  0  0  0  0  0], runtime(seconds):[434.78]
INFO:Reinforcement.Functions:episode: 404, score:[2807.20], loss:[3.40207], sequence:[395], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[31], eInit:[0.0174], init state:[ 1  5 28  0  0  0  0  0], end state:[ 3  5 28  0  0  0  0  0], runtime(seconds):[432.78]
INFO:Reinforcement.Functions:episode: 405, score:[2731.60], loss:[3.56991], sequence:[396], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.08], random actions:[28], eInit:[0.0172], init state:[ 3  0 48  0  0  1  0  0], end state:[ 5  0 48  0  0  0  0  0], runtime(seconds):[432.33]
INFO:Reinforcement.Functions:episode: 406, score:[2706.80], loss:[4.22780], sequence:[397], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.10], random actions:[29], eInit:[0.0171], init state:[5 3 0 0 0 0 0 0], end state:[0 3 0 0 0 0 0 0], runtime(seconds):[431.94]
INFO:Reinforcement.Functions:episode: 407, score:[2799.20], loss:[3.62568], sequence:[398], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[28], eInit:[0.0169], init state:[ 6 18  9  0  0  0  0  0], end state:[ 1 18  9  0  0  0  0  0], runtime(seconds):[433.05]
INFO:Reinforcement.Functions:episode: 408, score:[2820.80], loss:[3.48316], sequence:[399], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[24], eInit:[0.0167], init state:[ 6  8 28  1  0  0  0  0], end state:[ 1  8 28  1  0  0  0  0], runtime(seconds):[431.82]
INFO:Reinforcement.Functions:episode: 409, score:[2794.40], loss:[3.59811], sequence:[400], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[22], eInit:[0.0166], init state:[ 4 18 54  0  0  0  0  0], end state:[ 6 18 54  0  0  0  0  0], runtime(seconds):[430.19]
INFO:Reinforcement.Functions:episode: 410, score:[2803.20], loss:[4.19277], sequence:[401], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[34], eInit:[0.0164], init state:[ 1 14 52  0  0  0  0  0], end state:[ 3 14 52  0  0  0  0  0], runtime(seconds):[432.85]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(401, [410])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 411, score:[2783.60], loss:[3.65913], sequence:[402], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[25], eInit:[0.0162], init state:[ 3  7 18  0  0  0  0  0], end state:[ 5  7 18  0  0  0  0  0], runtime(seconds):[432.82]
INFO:Reinforcement.Functions:episode: 412, score:[2770.40], loss:[3.91470], sequence:[403], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[31], eInit:[0.0161], init state:[ 5 10 23  0  0  0  0  0], end state:[ 0 10 23  0  0  0  0  0], runtime(seconds):[434.39]
INFO:Reinforcement.Functions:episode: 413, score:[2695.20], loss:[4.71200], sequence:[404], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.08], random actions:[35], eInit:[0.0159], init state:[ 4 23 13  0  0  0  0  0], end state:[ 6 23 13  1  0  0  0  0], runtime(seconds):[433.23]
INFO:Reinforcement.Functions:episode: 414, score:[2828.00], loss:[4.25099], sequence:[405], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[23], eInit:[0.0158], init state:[ 1  8 34  1  1  0  1  1], end state:[ 3  8 34  0  0  0  1  1], runtime(seconds):[433.18]
INFO:Reinforcement.Functions:episode: 415, score:[2803.20], loss:[3.62134], sequence:[406], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[26], eInit:[0.0156], init state:[ 4 21 40  0  0  0  0  0], end state:[ 6 21 40  1  0  0  0  0], runtime(seconds):[433.34]
INFO:Reinforcement.Functions:episode: 416, score:[2831.60], loss:[3.69553], sequence:[407], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[29], eInit:[0.0154], init state:[ 2 10 47  0  0  0  0  0], end state:[ 4 10 47  1  1  0  1  0], runtime(seconds):[433.04]
INFO:Reinforcement.Functions:episode: 417, score:[2783.20], loss:[3.16674], sequence:[408], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[31], eInit:[0.0153], init state:[ 3  0 25  1  0  0  0  0], end state:[ 5  0 25  0  0  0  0  0], runtime(seconds):[434.07]
INFO:Reinforcement.Functions:episode: 418, score:[2794.00], loss:[4.75288], sequence:[409], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[33], eInit:[0.0151], init state:[3 7 4 0 0 0 0 0], end state:[5 7 4 0 0 0 0 0], runtime(seconds):[433.42]
INFO:Reinforcement.Functions:episode: 419, score:[2792.00], loss:[4.35469], sequence:[410], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[33], eInit:[0.0150], init state:[ 2  9 47  0  0  0  0  0], end state:[ 4  9 47  1  0  0  0  0], runtime(seconds):[434.04]
INFO:Reinforcement.Functions:episode: 420, score:[2788.00], loss:[3.57190], sequence:[411], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[32], eInit:[0.0148], init state:[ 3 18 23  0  0  0  0  0], end state:[ 5 18 23  1  1  0  1  0], runtime(seconds):[433.01]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(411, [420])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 421, score:[2816.00], loss:[4.09193], sequence:[412], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[34], eInit:[0.0147], init state:[ 2  8 30  1  1  0  1  1], end state:[ 4  8 30  0  0  0  0  0], runtime(seconds):[433.19]
INFO:Reinforcement.Functions:episode: 422, score:[2828.40], loss:[2.69533], sequence:[413], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[33], eInit:[0.0145], init state:[ 2  6 12  0  0  0  0  0], end state:[ 4  6 12  0  0  0  0  0], runtime(seconds):[433.44]
INFO:Reinforcement.Functions:episode: 423, score:[2821.60], loss:[3.17712], sequence:[414], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[42], eInit:[0.0144], init state:[ 1  2 32  0  0  0  0  0], end state:[ 3  2 32  0  0  0  0  0], runtime(seconds):[433.02]
INFO:Reinforcement.Functions:episode: 424, score:[2774.40], loss:[3.37605], sequence:[415], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[35], eInit:[0.0142], init state:[4 2 9 0 0 0 0 0], end state:[6 2 9 0 0 0 0 0], runtime(seconds):[432.79]
INFO:Reinforcement.Functions:episode: 425, score:[2811.20], loss:[3.53323], sequence:[416], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[21], eInit:[0.0141], init state:[ 1 13 13  0  0  0  0  0], end state:[ 3 13 13  0  0  0  0  0], runtime(seconds):[433.94]
INFO:Reinforcement.Functions:episode: 426, score:[2782.40], loss:[3.84353], sequence:[417], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[26], eInit:[0.0140], init state:[ 4 17 41  0  0  0  0  0], end state:[ 6 17 41  0  0  0  0  0], runtime(seconds):[433.62]
INFO:Reinforcement.Functions:episode: 427, score:[2777.60], loss:[4.20218], sequence:[418], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[35], eInit:[0.0138], init state:[ 6  9 27  0  0  0  0  0], end state:[ 1  9 27  0  0  0  0  0], runtime(seconds):[435.08]
INFO:Reinforcement.Functions:episode: 428, score:[2777.20], loss:[4.09016], sequence:[419], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[33], eInit:[0.0137], init state:[ 4  9 12  0  0  0  0  0], end state:[ 6  9 12  0  0  0  0  0], runtime(seconds):[429.17]
INFO:Reinforcement.Functions:episode: 429, score:[2779.20], loss:[4.09669], sequence:[420], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[34], eInit:[0.0135], init state:[ 5 10 23  0  0  0  0  0], end state:[ 0 10 23  0  0  0  0  0], runtime(seconds):[429.22]
INFO:Reinforcement.Functions:episode: 430, score:[2796.80], loss:[3.66499], sequence:[421], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.04], random actions:[25], eInit:[0.0134], init state:[ 5 21 20  1  0  0  1  1], end state:[ 0 21 20  1  1  0  1  0], runtime(seconds):[430.76]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(421, [430])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 431, score:[2746.80], loss:[3.61766], sequence:[422], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[38], eInit:[0.0133], init state:[ 4  1 43  0  0  0  0  0], end state:[ 6  1 43  0  0  0  0  0], runtime(seconds):[429.07]
INFO:Reinforcement.Functions:episode: 432, score:[2845.20], loss:[3.79840], sequence:[423], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[21], eInit:[0.0131], init state:[ 1 10  8  0  0  0  0  0], end state:[ 3 10  8  0  0  0  0  0], runtime(seconds):[430.29]
INFO:Reinforcement.Functions:episode: 433, score:[2842.80], loss:[3.15191], sequence:[424], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[25], eInit:[0.0130], init state:[ 6 21 52  1  0  0  0  0], end state:[ 1 21 52  1  0  0  0  0], runtime(seconds):[429.93]
INFO:Reinforcement.Functions:episode: 434, score:[2811.60], loss:[3.28538], sequence:[425], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0129], init state:[ 2 18 43  0  0  0  0  0], end state:[ 4 18 43  0  0  0  0  0], runtime(seconds):[429.15]
INFO:Reinforcement.Functions:episode: 435, score:[2807.60], loss:[3.42323], sequence:[426], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[30], eInit:[0.0128], init state:[ 6 18  9  0  0  0  0  0], end state:[ 1 18  9  0  0  0  0  0], runtime(seconds):[430.32]
INFO:Reinforcement.Functions:episode: 436, score:[2814.80], loss:[3.41874], sequence:[427], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[25], eInit:[0.0126], init state:[ 3  9 25  0  0  0  0  0], end state:[ 5  9 25  0  0  0  0  0], runtime(seconds):[430.15]
INFO:Reinforcement.Functions:episode: 437, score:[2736.40], loss:[3.58491], sequence:[428], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[30], eInit:[0.0125], init state:[ 3 22 20  1  0  0  0  0], end state:[ 5 22 20  1  0  0  1  0], runtime(seconds):[427.46]
INFO:Reinforcement.Functions:episode: 438, score:[2810.00], loss:[3.50253], sequence:[429], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.03], random actions:[26], eInit:[0.0124], init state:[ 6  2 42  0  0  0  0  0], end state:[ 1  2 42  0  0  0  0  0], runtime(seconds):[428.96]
INFO:Reinforcement.Functions:episode: 439, score:[2806.40], loss:[3.57267], sequence:[430], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0123], init state:[ 3 16  3  0  0  0  0  0], end state:[ 5 16  3  0  0  0  0  0], runtime(seconds):[435.70]
INFO:Reinforcement.Functions:episode: 440, score:[2778.00], loss:[3.99248], sequence:[431], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[25], eInit:[0.0121], init state:[ 4  1 36  0  0  0  0  0], end state:[ 6  1 36  0  0  0  0  0], runtime(seconds):[432.84]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(431, [440])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 441, score:[2799.20], loss:[3.81613], sequence:[432], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[31], eInit:[0.0120], init state:[ 3 18 35  0  0  0  0  0], end state:[ 5 18 35  1  1  0  1  0], runtime(seconds):[429.96]
INFO:Reinforcement.Functions:episode: 442, score:[2830.80], loss:[3.88469], sequence:[433], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[24], eInit:[0.0119], init state:[ 5  3 42  0  0  0  0  0], end state:[ 0  3 42  0  0  0  0  0], runtime(seconds):[431.52]
INFO:Reinforcement.Functions:episode: 443, score:[2798.00], loss:[3.29010], sequence:[434], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0118], init state:[ 1 21 41  1  0  0  0  0], end state:[ 3 21 41  1  0  0  0  0], runtime(seconds):[433.40]
INFO:Reinforcement.Functions:episode: 444, score:[2781.20], loss:[3.70138], sequence:[435], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[36], eInit:[0.0117], init state:[ 2  2 23  0  0  0  0  0], end state:[ 4  2 23  0  0  0  0  0], runtime(seconds):[433.21]
INFO:Reinforcement.Functions:episode: 445, score:[2766.40], loss:[4.84696], sequence:[436], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[28], eInit:[0.0115], init state:[ 6  8 59  1  1  0  0  0], end state:[ 1  8 59  1  0  0  0  0], runtime(seconds):[433.67]
INFO:Reinforcement.Functions:episode: 446, score:[2819.20], loss:[3.90544], sequence:[437], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[28], eInit:[0.0114], init state:[0 8 1 1 0 0 0 0], end state:[2 8 1 1 0 0 0 0], runtime(seconds):[431.79]
INFO:Reinforcement.Functions:episode: 447, score:[2811.60], loss:[4.10357], sequence:[438], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[30], eInit:[0.0113], init state:[ 2  3 13  0  0  0  0  0], end state:[ 4  3 13  0  0  0  0  0], runtime(seconds):[433.21]
INFO:Reinforcement.Functions:episode: 448, score:[2816.40], loss:[4.16986], sequence:[439], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[28], eInit:[0.0112], init state:[ 4  0 11  1  0  0  0  0], end state:[ 6  0 11  1  0  0  0  0], runtime(seconds):[431.51]
INFO:Reinforcement.Functions:episode: 449, score:[2810.00], loss:[3.30259], sequence:[440], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[27], eInit:[0.0111], init state:[ 4 15 22  0  0  0  0  0], end state:[ 6 15 22  0  0  0  0  0], runtime(seconds):[431.93]
INFO:Reinforcement.Functions:episode: 450, score:[2837.60], loss:[3.15926], sequence:[441], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[24], eInit:[0.0110], init state:[ 0 23 24  1  0  0  1  0], end state:[ 2 23 24  1  0  0  1  0], runtime(seconds):[433.97]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(441, [450])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 451, score:[2828.00], loss:[3.20911], sequence:[442], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[33], eInit:[0.0109], init state:[ 3 10 25  0  0  0  0  0], end state:[ 5 10 25  0  0  0  0  0], runtime(seconds):[432.20]
INFO:Reinforcement.Functions:episode: 452, score:[2720.00], loss:[3.43514], sequence:[443], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[33], eInit:[0.0108], init state:[ 4 11 43  1  1  0  0  0], end state:[ 6 11 43  0  0  0  0  0], runtime(seconds):[431.32]
INFO:Reinforcement.Functions:episode: 453, score:[2700.40], loss:[4.25889], sequence:[444], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[35], eInit:[0.0106], init state:[ 3  0 20  1  0  0  0  0], end state:[ 5  0 20  0  0  0  0  0], runtime(seconds):[429.60]
INFO:Reinforcement.Functions:episode: 454, score:[2803.60], loss:[4.71500], sequence:[445], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[32], eInit:[0.0105], init state:[ 3  8 35  1  1  0  1  0], end state:[ 5  8 35  0  0  0  0  0], runtime(seconds):[431.82]
INFO:Reinforcement.Functions:episode: 455, score:[2832.00], loss:[3.36848], sequence:[446], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.02], random actions:[24], eInit:[0.0104], init state:[ 4  5 11  0  0  0  0  0], end state:[ 6  5 11  0  0  0  0  0], runtime(seconds):[430.30]
INFO:Reinforcement.Functions:episode: 456, score:[2812.80], loss:[3.78241], sequence:[447], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.03], random actions:[28], eInit:[0.0103], init state:[ 3 12 50  0  0  0  0  0], end state:[ 5 12 50  0  0  0  0  0], runtime(seconds):[431.52]
INFO:Reinforcement.Functions:episode: 457, score:[2817.20], loss:[3.18983], sequence:[448], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[38], eInit:[0.0102], init state:[ 3  5 47  0  0  0  0  0], end state:[ 5  5 47  0  0  0  0  0], runtime(seconds):[431.11]
INFO:Reinforcement.Functions:episode: 458, score:[2787.20], loss:[3.23555], sequence:[449], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[33], eInit:[0.0101], init state:[ 6  1 10  0  0  0  0  0], end state:[ 1  1 10  0  0  0  0  0], runtime(seconds):[433.07]
INFO:Reinforcement.Functions:episode: 459, score:[2796.00], loss:[3.13400], sequence:[450], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[45], eInit:[0.0100], init state:[ 2  2 39  0  0  0  0  0], end state:[ 4  2 39  0  0  0  0  0], runtime(seconds):[430.34]
INFO:Reinforcement.Functions:episode: 460, score:[2805.60], loss:[3.44521], sequence:[451], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[30], eInit:[0.0100], init state:[0 7 6 0 0 0 0 0], end state:[2 7 6 0 0 0 0 0], runtime(seconds):[431.71]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(451, [460])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 461, score:[2816.40], loss:[3.02301], sequence:[452], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[40], eInit:[0.0100], init state:[ 2 21 49  1  0  0  0  0], end state:[ 4 21 49  0  0  0  0  0], runtime(seconds):[430.91]
INFO:Reinforcement.Functions:episode: 462, score:[2806.80], loss:[3.04570], sequence:[453], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[34], eInit:[0.0100], init state:[2 7 7 0 0 0 0 0], end state:[4 7 7 0 0 0 0 0], runtime(seconds):[432.53]
INFO:Reinforcement.Functions:episode: 463, score:[2820.00], loss:[2.94151], sequence:[454], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[29], eInit:[0.0100], init state:[ 6 11 43  0  0  0  0  0], end state:[ 1 11 43  0  0  0  0  0], runtime(seconds):[431.52]
INFO:Reinforcement.Functions:episode: 464, score:[2834.40], loss:[2.59575], sequence:[455], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.02], random actions:[21], eInit:[0.0100], init state:[ 2 11 51  0  0  0  0  0], end state:[ 4 11 51  1  1  0  0  1], runtime(seconds):[432.47]
INFO:Reinforcement.Functions:episode: 465, score:[2740.80], loss:[2.97051], sequence:[456], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[27], eInit:[0.0100], init state:[ 5  9 19  0  0  0  0  0], end state:[ 0  9 19  0  0  0  0  0], runtime(seconds):[431.95]
INFO:Reinforcement.Functions:episode: 466, score:[2767.60], loss:[4.05491], sequence:[457], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[29], eInit:[0.0100], init state:[ 6  2 47  0  0  0  0  0], end state:[ 1  2 47  0  0  0  0  0], runtime(seconds):[432.66]
INFO:Reinforcement.Functions:episode: 467, score:[2833.20], loss:[3.33252], sequence:[458], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[28], eInit:[0.0100], init state:[2 3 1 0 0 0 0 0], end state:[4 3 1 0 0 0 0 0], runtime(seconds):[430.00]
INFO:Reinforcement.Functions:episode: 468, score:[2794.40], loss:[3.10530], sequence:[459], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[32], eInit:[0.0100], init state:[ 1  2 45  0  0  0  0  0], end state:[ 3  2 45  0  0  0  0  0], runtime(seconds):[433.07]
INFO:Reinforcement.Functions:episode: 469, score:[2842.00], loss:[3.33997], sequence:[460], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[25], eInit:[0.0100], init state:[ 6 18 17  0  0  0  0  0], end state:[ 1 18 17  0  0  0  0  0], runtime(seconds):[432.23]
INFO:Reinforcement.Functions:episode: 470, score:[2846.00], loss:[2.72836], sequence:[461], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[27], eInit:[0.0100], init state:[ 0  0 10  1  0  0  0  0], end state:[ 2  0 10  1  0  0  0  0], runtime(seconds):[431.31]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(461, [470])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 471, score:[2827.60], loss:[2.59689], sequence:[462], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[27], eInit:[0.0100], init state:[ 1  0 29  1  0  0  0  0], end state:[ 3  0 29  1  0  0  0  0], runtime(seconds):[432.31]
INFO:Reinforcement.Functions:episode: 472, score:[2788.40], loss:[2.99128], sequence:[463], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0100], init state:[ 3 16 37  0  0  0  0  0], end state:[ 5 16 37  0  0  0  0  0], runtime(seconds):[432.61]
INFO:Reinforcement.Functions:episode: 473, score:[2838.40], loss:[2.89229], sequence:[464], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[23], eInit:[0.0100], init state:[ 0  6 45  0  0  0  0  0], end state:[ 2  6 45  0  0  0  0  0], runtime(seconds):[433.27]
INFO:Reinforcement.Functions:episode: 474, score:[2796.80], loss:[2.74615], sequence:[465], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0100], init state:[ 6  3 52  0  0  0  0  0], end state:[ 1  3 52  0  0  0  0  0], runtime(seconds):[433.04]
INFO:Reinforcement.Functions:episode: 475, score:[2824.00], loss:[2.40565], sequence:[466], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[28], eInit:[0.0100], init state:[ 6  8 42  1  1  0  1  0], end state:[ 1  8 42  1  1  0  1  0], runtime(seconds):[433.01]
INFO:Reinforcement.Functions:episode: 476, score:[2831.20], loss:[2.70048], sequence:[467], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[29], eInit:[0.0100], init state:[ 1  1 34  0  0  0  0  0], end state:[ 3  1 34  0  0  0  0  0], runtime(seconds):[430.90]
INFO:Reinforcement.Functions:episode: 477, score:[2767.60], loss:[2.87259], sequence:[468], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[30], eInit:[0.0100], init state:[ 3  3 39  0  0  0  0  0], end state:[ 5  3 39  0  0  0  0  0], runtime(seconds):[430.14]
INFO:Reinforcement.Functions:episode: 478, score:[2782.40], loss:[2.80829], sequence:[469], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[33], eInit:[0.0100], init state:[ 2 14 30  0  0  0  0  0], end state:[ 4 14 30  0  0  0  0  0], runtime(seconds):[429.94]
INFO:Reinforcement.Functions:episode: 479, score:[2776.80], loss:[3.67696], sequence:[470], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[30], eInit:[0.0100], init state:[ 5  0 35  0  0  0  0  0], end state:[ 0  0 35  0  0  1  0  0], runtime(seconds):[432.20]
INFO:Reinforcement.Functions:episode: 480, score:[2747.60], loss:[3.79741], sequence:[471], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[24], eInit:[0.0100], init state:[ 4 12  4  1  1  0  0  0], end state:[ 6 12  4  0  0  0  0  0], runtime(seconds):[431.69]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(471, [480])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 481, score:[2808.00], loss:[3.64754], sequence:[472], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.03], random actions:[26], eInit:[0.0100], init state:[ 1 21 27  1  1  0  1  0], end state:[ 3 21 27  1  1  0  1  0], runtime(seconds):[432.34]
INFO:Reinforcement.Functions:episode: 482, score:[2772.00], loss:[3.75861], sequence:[473], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[25], eInit:[0.0100], init state:[ 4 22 19  0  0  0  0  0], end state:[ 6 22 19  1  0  0  0  0], runtime(seconds):[430.71]
INFO:Reinforcement.Functions:episode: 483, score:[2810.80], loss:[2.94568], sequence:[474], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[26], eInit:[0.0100], init state:[ 2  6 36  0  0  0  0  0], end state:[ 4  6 36  0  0  0  0  0], runtime(seconds):[432.80]
INFO:Reinforcement.Functions:episode: 484, score:[2790.40], loss:[3.04713], sequence:[475], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[29], eInit:[0.0100], init state:[ 4 13  1  1  1  0  1  0], end state:[ 6 13  1  0  0  0  0  0], runtime(seconds):[430.41]
INFO:Reinforcement.Functions:episode: 485, score:[2823.60], loss:[3.57313], sequence:[476], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.02], random actions:[25], eInit:[0.0100], init state:[ 0 12 58  0  0  0  0  0], end state:[ 2 12 58  0  0  0  0  0], runtime(seconds):[430.84]
INFO:Reinforcement.Functions:episode: 486, score:[2759.60], loss:[4.66674], sequence:[477], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[30], eInit:[0.0100], init state:[6 8 8 1 0 0 0 0], end state:[1 8 8 1 0 0 0 0], runtime(seconds):[431.38]
INFO:Reinforcement.Functions:episode: 487, score:[2760.00], loss:[4.27224], sequence:[478], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[38], eInit:[0.0100], init state:[ 0 16 19  0  0  0  0  0], end state:[ 2 16 19  0  0  0  0  0], runtime(seconds):[370.68]
INFO:Reinforcement.Functions:episode: 488, score:[2767.20], loss:[3.98681], sequence:[479], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[36], eInit:[0.0100], init state:[ 2 19 25  0  0  0  0  0], end state:[ 4 19 25  0  0  0  0  0], runtime(seconds):[361.46]
INFO:Reinforcement.Functions:episode: 489, score:[2756.80], loss:[4.75950], sequence:[480], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[21], eInit:[0.0100], init state:[ 2 22 50  1  0  0  0  0], end state:[ 4 22 50  0  0  0  0  0], runtime(seconds):[289.93]
INFO:Reinforcement.Functions:episode: 490, score:[2842.80], loss:[4.07379], sequence:[481], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[19], eInit:[0.0100], init state:[ 6 16 50  0  0  0  0  0], end state:[ 1 16 50  0  0  0  0  0], runtime(seconds):[290.76]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(481, [490])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 491, score:[2834.00], loss:[3.03792], sequence:[482], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.02], random actions:[26], eInit:[0.0100], init state:[ 1  2 13  0  0  0  0  0], end state:[ 3  2 13  0  0  0  0  0], runtime(seconds):[289.93]
INFO:Reinforcement.Functions:episode: 492, score:[2780.40], loss:[3.66775], sequence:[483], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[36], eInit:[0.0100], init state:[5 9 4 0 0 0 0 0], end state:[0 9 4 0 0 0 0 0], runtime(seconds):[289.72]
INFO:Reinforcement.Functions:episode: 493, score:[2818.40], loss:[3.18862], sequence:[484], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[20], eInit:[0.0100], init state:[6 2 0 0 0 0 0 0], end state:[1 2 0 0 0 0 0 0], runtime(seconds):[356.67]
INFO:Reinforcement.Functions:episode: 494, score:[2763.60], loss:[4.35487], sequence:[485], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[29], eInit:[0.0100], init state:[ 3 15  8  0  0  0  0  0], end state:[ 5 15  8  0  0  0  0  0], runtime(seconds):[300.77]
INFO:Reinforcement.Functions:episode: 495, score:[2833.60], loss:[4.51438], sequence:[486], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[23], eInit:[0.0100], init state:[ 1 14 10  0  0  0  0  0], end state:[ 3 14 10  0  0  0  0  0], runtime(seconds):[290.76]
INFO:Reinforcement.Functions:episode: 496, score:[2798.40], loss:[3.12076], sequence:[487], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[25], eInit:[0.0100], init state:[ 4  7 50  0  0  0  0  0], end state:[ 6  7 50  0  0  0  0  0], runtime(seconds):[315.16]
INFO:Reinforcement.Functions:episode: 497, score:[2812.00], loss:[3.45972], sequence:[488], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[26], eInit:[0.0100], init state:[5 8 5 0 0 0 0 0], end state:[0 8 5 1 0 0 0 0], runtime(seconds):[366.94]
INFO:Reinforcement.Functions:episode: 498, score:[2830.80], loss:[3.72699], sequence:[489], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[23], eInit:[0.0100], init state:[ 0  7 57  0  0  0  0  0], end state:[ 2  7 57  0  0  0  0  0], runtime(seconds):[290.66]
INFO:Reinforcement.Functions:episode: 499, score:[2839.20], loss:[3.39368], sequence:[490], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[24], eInit:[0.0100], init state:[ 6 20 52  1  1  0  1  0], end state:[ 1 20 52  1  1  0  1  0], runtime(seconds):[291.09]
INFO:Reinforcement.Functions:episode: 500, score:[2775.20], loss:[3.16598], sequence:[491], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.07], random actions:[24], eInit:[0.0100], init state:[ 5 23  5  1  0  0  1  0], end state:[ 0 23  5  1  0  0  0  0], runtime(seconds):[290.02]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310]) , maxSequence:(491, [500])
INFO:Reinforcement.Functions:Optimal models save history:[]
INFO:Reinforcement.Functions:episode: 501, score:[2784.00], loss:[3.12482], sequence:[492], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.05], random actions:[30], eInit:[0.0100], init state:[ 5  7 34  0  0  0  0  0], end state:[ 0  7 34  0  0  0  0  0], runtime(seconds):[290.58]
INFO:Reinforcement.Functions:episode: 502, score:[2792.40], loss:[3.22973], sequence:[493], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[42], eInit:[0.0100], init state:[ 2 16 26  0  0  0  0  0], end state:[ 4 16 26  0  0  0  0  0], runtime(seconds):[303.23]
INFO:Reinforcement.Functions:episode: 503, score:[2819.20], loss:[3.35542], sequence:[494], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.0100], init state:[ 0 13  8  0  0  0  0  0], end state:[ 2 13  8  0  0  0  0  0], runtime(seconds):[290.36]
INFO:Reinforcement.Functions:episode: 504, score:[2838.00], loss:[3.46870], sequence:[495], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[30], eInit:[0.0100], init state:[ 0 12 14  0  0  0  0  0], end state:[ 2 12 14  0  0  0  0  0], runtime(seconds):[290.40]
INFO:Reinforcement.Functions:episode: 505, score:[2824.80], loss:[3.53262], sequence:[496], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[33], eInit:[0.0100], init state:[ 1 11  1  0  0  0  0  0], end state:[ 3 11  1  0  0  0  0  0], runtime(seconds):[291.00]
INFO:Reinforcement.Functions:episode: 506, score:[2784.00], loss:[3.64241], sequence:[497], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[29], eInit:[0.0100], init state:[6 1 8 0 0 1 0 0], end state:[1 1 8 0 0 1 0 0], runtime(seconds):[290.68]
INFO:Reinforcement.Functions:episode: 507, score:[2847.20], loss:[3.19218], sequence:[498], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[21], eInit:[0.0100], init state:[ 1  1 28  0  0  0  0  0], end state:[ 3  1 28  0  0  0  0  0], runtime(seconds):[290.80]
INFO:Reinforcement.Functions:episode: 508, score:[2840.40], loss:[2.69694], sequence:[499], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[29], eInit:[0.0100], init state:[1 3 3 0 0 0 0 0], end state:[3 3 3 0 0 0 0 0], runtime(seconds):[290.28]
INFO:Reinforcement.Functions:episode: 509, score:[2832.00], loss:[2.24737], sequence:[500], isInPoolRatio:[1.00], optActionSelectedRatio:[0.98], optActionInPoolButNotSelected:[0.01], random actions:[31], eInit:[0.0100], init state:[ 0  9 20  0  0  0  0  0], end state:[ 2  9 20  0  0  0  0  0], runtime(seconds):[363.57]
INFO:Reinforcement.Functions:maxScore:(2847.1999999999985, [310, 507]) , maxSequence:(500, [509])
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-8-4-H-18-32-12/Critic-target-model-2.h5]

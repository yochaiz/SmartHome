INFO:Reinforcement.Functions:results:[{'loss': [], 'actionDim': 'actionDim-5', 'score': [], 'baseFolder': '/home/yochaiz/SmartHome/Reinforcement/DDPG', 'folderName': 'D-10-4-H-14-19-40', 'fullPath': '/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40'}]
INFO:Reinforcement.Functions:settings:[{'gameMinutesLength': 2880, 'learningRate': 0.001, 'trainSetSize': 64, 'nGamesPerSave': 10, 'minGameScore': 1224, 'dequeSize': 50000, 'nEpochs': 1, 'TAU': 0.001, 'minGameScoreRatio': 0.85, 'gamma': 0.95, 'batchSize': 64, 'nModelBackups': 3, 'minGameSequence': 500}]
INFO:Reinforcement.Functions:Actor:[{'epsilon_min': 0.01, 'epsilon_decay': 0.99, 'curBackupIdx': 0, 'epsilon': 1.0, 'actionDim': 5, 'nActions': 32, 'nBackups': 3, 'TAU': 0.001, 'k': 32}]
INFO:Reinforcement.Functions:Critic:[{'actionDim': 5, 'nBackups': 3, 'curBackupIdx': 0, 'TAU': 0.001}]
INFO:Reinforcement.Functions:policy:[{'stateDim': (1, 8), 'numOfDevices': 5, 'fname': '/home/yochaiz/SmartHome/Reinforcement/Policies/Week/policy2.json', 'rewardScaleFactor': 0.5, 'seqLen': 1}]
INFO:Reinforcement.Functions:args:[{'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json', 'sequential': True, 'rewardScale': 0.5, 'random': False, 'gpuNum': 0, 'gpuFrac': 0.3, 'desc': '"deep model **sequential** with rewardScaleFactor = 0.5"', 'k': 32}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:===== DESCRIPTIONS =====
INFO:Reinforcement.Functions:[General]: "deep model **sequential** with rewardScaleFactor = 0.5"
INFO:Reinforcement.Functions:[Actor]: Try deeper architecture
INFO:Reinforcement.Functions:[Actor]: Fixed bug where future reward (step 13) used continuous action instead of discrete action
INFO:Reinforcement.Functions:[Actor]: No more threading during replays
INFO:Reinforcement.Functions:[Critic]: Try deeper architecture
INFO:Reinforcement.Functions:===== ============ =====
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 8)              0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 256)            2304      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)              (None, 1, 256)            65792     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)              (None, 1, 5)              1285      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 5)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 266,757
INFO:Reinforcement.Functions:Trainable params: 266,757
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 8)         0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 256)       2304        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 5)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_8 (Dense)                 (None, 1, 256)       65792       dense_7[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_9 (Dense)                 (None, 256)          1536        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_8[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_9[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_10 (Dense)                (None, 1, 256)       65792       activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_11 (Dense)                (None, 1, 256)       65792       dense_10[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_12 (Dense)                (None, 1, 256)       65792       dense_11[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_13 (Dense)                (None, 1, 1)         257         dense_12[0][0]                   
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_13[0][0]                   
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 267,265
INFO:Reinforcement.Functions:Trainable params: 267,265
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[861.00], loss:[15.11735], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.25], optActionInPoolButNotSelected:[0.74], random actions:[106], eInit:[1.0000], init state:[ 5 16 58  0  0  0  0  0], end state:[ 0 16 58  1  0  0  0  0], runtime(seconds):[424.57]
INFO:Reinforcement.Functions:episode: 2, score:[1036.80], loss:[9.23550], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.49], optActionInPoolButNotSelected:[0.50], random actions:[102], eInit:[0.9900], init state:[6 5 5 0 0 0 0 0], end state:[1 5 5 0 0 0 0 0], runtime(seconds):[426.54]
INFO:Reinforcement.Functions:episode: 3, score:[1076.60], loss:[9.11380], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.53], optActionInPoolButNotSelected:[0.45], random actions:[125], eInit:[0.9801], init state:[ 6 17 12  0  0  0  0  0], end state:[ 1 17 12  0  0  0  0  0], runtime(seconds):[426.58]
INFO:Reinforcement.Functions:episode: 4, score:[1219.80], loss:[9.57972], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.75], optActionInPoolButNotSelected:[0.22], random actions:[101], eInit:[0.9703], init state:[ 0  5 19  0  0  0  0  0], end state:[ 2  5 19  0  0  0  0  0], runtime(seconds):[426.57]
INFO:Reinforcement.Functions:episode: 5, score:[1235.60], loss:[7.89983], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.20], random actions:[119], eInit:[0.9606], init state:[ 0 17 26  0  0  0  0  0], end state:[ 2 17 26  0  0  0  0  0], runtime(seconds):[426.04]
INFO:Reinforcement.Functions:episode: 6, score:[1266.40], loss:[6.89596], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.82], optActionInPoolButNotSelected:[0.15], random actions:[108], eInit:[0.9510], init state:[ 1  5 33  0  0  0  0  0], end state:[ 3  5 33  0  0  0  0  0], runtime(seconds):[426.72]
INFO:Reinforcement.Functions:episode: 7, score:[1290.60], loss:[6.79564], sequence:[3], isInPoolRatio:[1.00], optActionSelectedRatio:[0.86], optActionInPoolButNotSelected:[0.11], random actions:[110], eInit:[0.9415], init state:[ 1 17 40  0  0  0  0  0], end state:[ 3 17 40  0  0  0  0  0], runtime(seconds):[426.38]
INFO:Reinforcement.Functions:episode: 8, score:[1265.60], loss:[5.94843], sequence:[4], isInPoolRatio:[1.00], optActionSelectedRatio:[0.83], optActionInPoolButNotSelected:[0.13], random actions:[121], eInit:[0.9321], init state:[ 2  5 47  0  0  0  0  0], end state:[ 4  5 47  0  0  0  0  0], runtime(seconds):[426.19]
INFO:Reinforcement.Functions:episode: 9, score:[1188.80], loss:[6.31758], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.21], random actions:[120], eInit:[0.9227], init state:[ 2 17 54  0  0  0  0  0], end state:[ 4 17 54  0  0  0  0  0], runtime(seconds):[425.42]
INFO:Reinforcement.Functions:episode: 10, score:[1165.40], loss:[6.15703], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.72], optActionInPoolButNotSelected:[0.24], random actions:[123], eInit:[0.9135], init state:[3 6 1 0 0 0 0 0], end state:[5 6 1 0 0 0 0 0], runtime(seconds):[425.40]
INFO:Reinforcement.Functions:Optimal models save history:[(1, [('Actor', 1), ('Critic', 1)]), (2, [('Actor', 2), ('Critic', 2)]), (3, [('Actor', 0), ('Critic', 0)]), (4, [('Actor', 1), ('Critic', 1)]), (5, [('Actor', 2), ('Critic', 2)]), (6, [('Actor', 0), ('Critic', 0)]), (7, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(1290.5999999999956, [7]) , maxSequence:(4, [8])
INFO:Reinforcement.Functions:episode: 11, score:[1201.00], loss:[6.10093], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.21], random actions:[95], eInit:[0.9044], init state:[ 3 18  8  0  0  0  0  0], end state:[ 5 18  8  0  0  0  0  0], runtime(seconds):[425.29]
INFO:Reinforcement.Functions:episode: 12, score:[1144.20], loss:[6.13436], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.67], optActionInPoolButNotSelected:[0.31], random actions:[94], eInit:[0.8953], init state:[ 4  6 15  0  0  0  0  0], end state:[ 6  6 15  0  0  0  0  0], runtime(seconds):[425.03]
INFO:Reinforcement.Functions:episode: 13, score:[1201.80], loss:[5.63885], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.72], optActionInPoolButNotSelected:[0.25], random actions:[122], eInit:[0.8864], init state:[ 4 18 22  0  0  0  0  0], end state:[ 6 18 22  0  0  0  0  0], runtime(seconds):[425.60]
INFO:Reinforcement.Functions:episode: 14, score:[1235.40], loss:[5.27541], sequence:[1], isInPoolRatio:[1.00], optActionSelectedRatio:[0.78], optActionInPoolButNotSelected:[0.19], random actions:[106], eInit:[0.8775], init state:[ 5  6 29  0  0  0  0  0], end state:[ 0  6 29  0  0  0  0  0], runtime(seconds):[429.73]
INFO:Reinforcement.Functions:episode: 15, score:[1273.40], loss:[5.23939], sequence:[2], isInPoolRatio:[1.00], optActionSelectedRatio:[0.83], optActionInPoolButNotSelected:[0.13], random actions:[120], eInit:[0.8687], init state:[ 5 18 36  1  1  0  1  0], end state:[ 0 18 36  0  0  0  0  0], runtime(seconds):[432.76]
INFO:Reinforcement.Functions:episode: 16, score:[1325.60], loss:[4.96215], sequence:[3], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[98], eInit:[0.8601], init state:[ 6  6 43  0  0  0  0  0], end state:[ 1  6 43  0  0  0  1  0], runtime(seconds):[431.07]
INFO:Reinforcement.Functions:episode: 17, score:[1332.40], loss:[4.63974], sequence:[4], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[111], eInit:[0.8515], init state:[ 6 18 50  0  0  0  0  0], end state:[ 1 18 50  0  0  0  0  0], runtime(seconds):[431.75]
INFO:Reinforcement.Functions:episode: 18, score:[1328.40], loss:[4.54169], sequence:[5], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.06], random actions:[98], eInit:[0.8429], init state:[ 0  6 57  0  0  0  0  0], end state:[ 2  6 57  0  0  0  0  0], runtime(seconds):[429.63]
INFO:Reinforcement.Functions:episode: 19, score:[1342.80], loss:[4.18395], sequence:[6], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[99], eInit:[0.8345], init state:[ 0 19  4  0  0  0  0  0], end state:[ 2 19  4  0  0  0  0  0], runtime(seconds):[426.32]
INFO:Reinforcement.Functions:episode: 20, score:[1336.60], loss:[4.70775], sequence:[7], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[99], eInit:[0.8262], init state:[ 1  7 11  0  0  0  0  0], end state:[ 3  7 11  0  0  0  0  0], runtime(seconds):[427.71]
INFO:Reinforcement.Functions:Optimal models save history:[(16, [('Actor', 2), ('Critic', 2)]), (17, [('Actor', 0), ('Critic', 0)]), (19, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(1342.7999999999975, [19]) , maxSequence:(7, [20])
INFO:Reinforcement.Functions:episode: 21, score:[1333.60], loss:[4.36663], sequence:[8], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.06], random actions:[101], eInit:[0.8179], init state:[ 1 19 18  0  0  0  0  0], end state:[ 3 19 18  0  0  0  0  0], runtime(seconds):[427.25]
INFO:Reinforcement.Functions:episode: 22, score:[1335.80], loss:[3.71814], sequence:[9], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[108], eInit:[0.8097], init state:[ 2  7 25  0  0  0  0  0], end state:[ 4  7 25  0  0  0  0  0], runtime(seconds):[428.53]
INFO:Reinforcement.Functions:episode: 23, score:[1262.00], loss:[4.04823], sequence:[10], isInPoolRatio:[1.00], optActionSelectedRatio:[0.83], optActionInPoolButNotSelected:[0.14], random actions:[102], eInit:[0.8016], init state:[ 2 19 32  0  0  0  0  0], end state:[ 4 19 32  0  0  0  0  0], runtime(seconds):[428.10]
INFO:Reinforcement.Functions:episode: 24, score:[1265.20], loss:[4.33725], sequence:[11], isInPoolRatio:[1.00], optActionSelectedRatio:[0.80], optActionInPoolButNotSelected:[0.17], random actions:[98], eInit:[0.7936], init state:[ 3  7 39  0  0  0  0  0], end state:[ 5  7 39  0  0  0  0  0], runtime(seconds):[428.31]
INFO:Reinforcement.Functions:episode: 25, score:[1278.40], loss:[4.20146], sequence:[12], isInPoolRatio:[1.00], optActionSelectedRatio:[0.82], optActionInPoolButNotSelected:[0.15], random actions:[106], eInit:[0.7857], init state:[ 3 19 46  0  0  0  0  0], end state:[ 5 19 46  1  1  0  1  0], runtime(seconds):[427.78]
INFO:Reinforcement.Functions:episode: 26, score:[1265.60], loss:[4.21693], sequence:[13], isInPoolRatio:[1.00], optActionSelectedRatio:[0.82], optActionInPoolButNotSelected:[0.16], random actions:[92], eInit:[0.7778], init state:[ 4  7 53  0  0  0  0  0], end state:[ 6  7 53  0  0  0  0  0], runtime(seconds):[426.59]
INFO:Reinforcement.Functions:episode: 27, score:[1325.60], loss:[4.21207], sequence:[14], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.09], random actions:[91], eInit:[0.7700], init state:[ 4 20  0  0  0  0  0  0], end state:[ 6 20  0  0  0  0  0  0], runtime(seconds):[427.38]
INFO:Reinforcement.Functions:episode: 28, score:[1293.60], loss:[3.85682], sequence:[15], isInPoolRatio:[1.00], optActionSelectedRatio:[0.83], optActionInPoolButNotSelected:[0.14], random actions:[108], eInit:[0.7623], init state:[5 8 7 0 0 0 0 0], end state:[0 8 7 1 0 0 0 0], runtime(seconds):[427.24]
INFO:Reinforcement.Functions:episode: 29, score:[1317.00], loss:[3.64178], sequence:[16], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[101], eInit:[0.7547], init state:[ 5 20 14  1  0  0  0  0], end state:[ 0 20 14  0  0  0  0  0], runtime(seconds):[427.45]
INFO:Reinforcement.Functions:episode: 30, score:[1345.00], loss:[3.34373], sequence:[17], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[94], eInit:[0.7472], init state:[ 6  8 21  1  0  0  0  0], end state:[ 1  8 21  1  0  0  0  0], runtime(seconds):[426.74]
INFO:Reinforcement.Functions:Optimal models save history:[(30, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(1344.9999999999982, [30]) , maxSequence:(17, [30])
INFO:Reinforcement.Functions:episode: 31, score:[1344.60], loss:[3.59997], sequence:[18], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[102], eInit:[0.7397], init state:[ 6 20 28  0  0  0  0  0], end state:[ 1 20 28  0  0  0  0  0], runtime(seconds):[427.97]
INFO:Reinforcement.Functions:episode: 32, score:[1355.60], loss:[3.27389], sequence:[19], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[94], eInit:[0.7323], init state:[ 0  8 35  1  1  0  1  0], end state:[ 2  8 35  1  1  0  1  0], runtime(seconds):[429.29]
INFO:Reinforcement.Functions:episode: 33, score:[1341.80], loss:[3.22064], sequence:[20], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[94], eInit:[0.7250], init state:[ 0 20 42  1  1  0  0  0], end state:[ 2 20 42  1  1  0  0  0], runtime(seconds):[427.50]
INFO:Reinforcement.Functions:episode: 34, score:[1369.20], loss:[3.19073], sequence:[21], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[80], eInit:[0.7177], init state:[ 1  8 49  1  1  0  0  0], end state:[ 3  8 49  1  1  0  0  0], runtime(seconds):[428.30]
INFO:Reinforcement.Functions:episode: 35, score:[1363.80], loss:[3.13071], sequence:[22], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[93], eInit:[0.7106], init state:[ 1 20 56  1  1  0  1  0], end state:[ 3 20 56  1  1  0  1  0], runtime(seconds):[428.27]
INFO:Reinforcement.Functions:episode: 36, score:[1331.40], loss:[2.81950], sequence:[23], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.06], random actions:[102], eInit:[0.7034], init state:[2 9 3 0 0 0 0 0], end state:[4 9 3 0 0 0 0 0], runtime(seconds):[427.98]
INFO:Reinforcement.Functions:episode: 37, score:[1308.40], loss:[2.85468], sequence:[24], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[102], eInit:[0.6964], init state:[ 2 21 10  1  1  0  1  0], end state:[ 4 21 10  0  0  0  0  0], runtime(seconds):[427.64]
INFO:Reinforcement.Functions:episode: 38, score:[1325.20], loss:[3.13601], sequence:[25], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[85], eInit:[0.6894], init state:[ 3  9 17  0  0  0  0  0], end state:[ 5  9 17  0  0  0  0  0], runtime(seconds):[427.85]
INFO:Reinforcement.Functions:episode: 39, score:[1324.00], loss:[2.87232], sequence:[26], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[94], eInit:[0.6826], init state:[ 3 21 24  1  1  0  1  0], end state:[ 5 21 24  1  0  0  1  1], runtime(seconds):[427.24]
INFO:Reinforcement.Functions:episode: 40, score:[1299.60], loss:[3.12572], sequence:[27], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.12], random actions:[86], eInit:[0.6757], init state:[ 4  9 31  1  0  0  0  0], end state:[ 6  9 31  0  0  0  0  0], runtime(seconds):[426.95]
INFO:Reinforcement.Functions:Optimal models save history:[(32, [('Actor', 0), ('Critic', 0)]), (34, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(1369.1999999999982, [34]) , maxSequence:(27, [40])
INFO:Reinforcement.Functions:episode: 41, score:[1310.20], loss:[3.21208], sequence:[28], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.10], random actions:[86], eInit:[0.6690], init state:[ 4 21 38  0  0  0  0  0], end state:[ 6 21 38  1  0  0  0  0], runtime(seconds):[427.15]
INFO:Reinforcement.Functions:episode: 42, score:[1328.60], loss:[2.83959], sequence:[29], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.08], random actions:[95], eInit:[0.6623], init state:[ 5  9 45  0  0  0  0  0], end state:[ 0  9 45  0  0  0  0  0], runtime(seconds):[427.70]
INFO:Reinforcement.Functions:episode: 43, score:[1355.00], loss:[2.76361], sequence:[30], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[88], eInit:[0.6557], init state:[ 5 21 52  1  0  0  1  0], end state:[ 0 21 52  1  0  0  0  0], runtime(seconds):[427.94]
INFO:Reinforcement.Functions:episode: 44, score:[1359.40], loss:[2.32518], sequence:[31], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[84], eInit:[0.6491], init state:[ 6  9 59  0  0  0  0  0], end state:[ 1  9 59  0  0  0  0  0], runtime(seconds):[428.56]
INFO:Reinforcement.Functions:episode: 45, score:[1353.60], loss:[2.73058], sequence:[32], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[92], eInit:[0.6426], init state:[ 6 22  6  1  0  0  0  0], end state:[ 1 22  6  1  0  0  0  0], runtime(seconds):[429.04]
INFO:Reinforcement.Functions:episode: 46, score:[1370.80], loss:[2.42774], sequence:[33], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[97], eInit:[0.6362], init state:[ 0 10 13  0  0  0  0  0], end state:[ 2 10 13  0  0  0  0  0], runtime(seconds):[429.61]
INFO:Reinforcement.Functions:episode: 47, score:[1367.40], loss:[2.38535], sequence:[34], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[86], eInit:[0.6298], init state:[ 0 22 20  1  0  0  0  0], end state:[ 2 22 20  1  0  0  0  0], runtime(seconds):[427.89]
INFO:Reinforcement.Functions:episode: 48, score:[1361.60], loss:[2.43093], sequence:[35], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[77], eInit:[0.6235], init state:[ 1 10 27  0  0  0  0  0], end state:[ 3 10 27  0  0  0  0  0], runtime(seconds):[430.52]
INFO:Reinforcement.Functions:episode: 49, score:[1353.40], loss:[3.23584], sequence:[36], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[77], eInit:[0.6173], init state:[ 1 22 34  1  0  0  0  0], end state:[ 3 22 34  1  0  0  0  0], runtime(seconds):[427.50]
INFO:Reinforcement.Functions:episode: 50, score:[1344.80], loss:[2.84809], sequence:[37], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[80], eInit:[0.6111], init state:[ 2 10 41  0  0  0  0  0], end state:[ 4 10 41  1  1  0  1  0], runtime(seconds):[425.54]
INFO:Reinforcement.Functions:Optimal models save history:[(46, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(1370.7999999999984, [46]) , maxSequence:(37, [50])
INFO:Reinforcement.Functions:episode: 51, score:[1359.20], loss:[2.43350], sequence:[38], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[80], eInit:[0.6050], init state:[ 2 22 48  1  0  0  0  0], end state:[ 4 22 48  0  0  0  0  0], runtime(seconds):[425.47]
INFO:Reinforcement.Functions:episode: 52, score:[1366.80], loss:[2.49379], sequence:[39], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[94], eInit:[0.5990], init state:[ 3 10 55  0  0  0  0  0], end state:[ 5 10 55  0  0  0  0  0], runtime(seconds):[425.23]
INFO:Reinforcement.Functions:episode: 53, score:[1330.00], loss:[2.53008], sequence:[40], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.09], random actions:[78], eInit:[0.5930], init state:[ 3 23  2  1  0  0  0  0], end state:[ 5 23  2  1  0  0  1  0], runtime(seconds):[425.46]
INFO:Reinforcement.Functions:episode: 54, score:[1334.60], loss:[2.48039], sequence:[41], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.07], random actions:[102], eInit:[0.5870], init state:[ 4 11  9  1  1  0  0  0], end state:[ 6 11  9  0  0  0  0  0], runtime(seconds):[425.31]
INFO:Reinforcement.Functions:episode: 55, score:[1353.60], loss:[2.72695], sequence:[42], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[86], eInit:[0.5812], init state:[ 4 23 16  0  0  0  0  0], end state:[ 6 23 16  1  0  0  1  0], runtime(seconds):[427.60]
INFO:Reinforcement.Functions:episode: 56, score:[1321.40], loss:[2.14836], sequence:[43], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.09], random actions:[93], eInit:[0.5754], init state:[ 5 11 23  0  0  0  0  0], end state:[ 0 11 23  0  0  0  0  0], runtime(seconds):[426.31]
INFO:Reinforcement.Functions:episode: 57, score:[1334.00], loss:[2.37342], sequence:[44], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.06], random actions:[98], eInit:[0.5696], init state:[ 5 23 30  1  0  0  0  0], end state:[ 0 23 30  1  0  0  1  0], runtime(seconds):[426.22]
INFO:Reinforcement.Functions:episode: 58, score:[1363.40], loss:[2.65775], sequence:[45], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[66], eInit:[0.5639], init state:[ 6 11 37  0  0  0  0  0], end state:[ 1 11 37  0  0  0  0  0], runtime(seconds):[426.61]
INFO:Reinforcement.Functions:episode: 59, score:[1374.80], loss:[1.92786], sequence:[46], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[84], eInit:[0.5583], init state:[ 6 23 44  1  0  0  1  0], end state:[ 1 23 44  1  0  0  1  0], runtime(seconds):[426.22]
INFO:Reinforcement.Functions:episode: 60, score:[1374.20], loss:[1.90499], sequence:[47], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[84], eInit:[0.5527], init state:[ 0 11 51  0  0  0  0  0], end state:[ 2 11 51  0  0  0  0  0], runtime(seconds):[425.88]
INFO:Reinforcement.Functions:Optimal models save history:[(59, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(1374.7999999999988, [59]) , maxSequence:(47, [60])
INFO:Reinforcement.Functions:episode: 61, score:[1374.00], loss:[1.85217], sequence:[48], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[62], eInit:[0.5472], init state:[ 0 23 58  1  0  0  0  0], end state:[ 2 23 58  1  0  0  0  0], runtime(seconds):[425.74]
INFO:Reinforcement.Functions:episode: 62, score:[1380.20], loss:[2.15980], sequence:[49], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[77], eInit:[0.5417], init state:[ 1 12  5  0  0  0  0  0], end state:[ 3 12  5  0  0  0  0  0], runtime(seconds):[426.23]
INFO:Reinforcement.Functions:episode: 63, score:[1381.60], loss:[2.07783], sequence:[50], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[89], eInit:[0.5363], init state:[ 2  0 12  1  0  0  0  0], end state:[ 4  0 12  1  0  0  0  0], runtime(seconds):[425.92]
INFO:Reinforcement.Functions:episode: 64, score:[1348.40], loss:[1.97332], sequence:[51], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[76], eInit:[0.5309], init state:[ 2 12 19  0  0  0  0  0], end state:[ 4 12 19  1  1  0  0  0], runtime(seconds):[427.28]
INFO:Reinforcement.Functions:episode: 65, score:[1359.40], loss:[2.16503], sequence:[52], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[61], eInit:[0.5256], init state:[ 3  0 26  1  0  0  0  0], end state:[ 5  0 26  0  0  0  0  0], runtime(seconds):[427.16]
INFO:Reinforcement.Functions:episode: 66, score:[1336.60], loss:[2.03948], sequence:[53], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.06], random actions:[100], eInit:[0.5203], init state:[ 3 12 33  0  0  0  0  0], end state:[ 5 12 33  0  0  0  0  0], runtime(seconds):[426.66]
INFO:Reinforcement.Functions:episode: 67, score:[1356.80], loss:[1.93623], sequence:[54], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[69], eInit:[0.5151], init state:[ 4  0 40  1  0  1  0  0], end state:[ 6  0 40  0  0  1  0  0], runtime(seconds):[426.44]
INFO:Reinforcement.Functions:episode: 68, score:[1360.00], loss:[1.92923], sequence:[55], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[91], eInit:[0.5100], init state:[ 4 12 47  1  1  0  1  0], end state:[ 6 12 47  0  0  0  0  0], runtime(seconds):[425.99]
INFO:Reinforcement.Functions:episode: 69, score:[1356.60], loss:[1.91539], sequence:[56], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[81], eInit:[0.5049], init state:[ 5  0 54  0  0  0  0  0], end state:[ 0  0 54  0  0  1  0  0], runtime(seconds):[426.93]
INFO:Reinforcement.Functions:episode: 70, score:[1311.40], loss:[2.15434], sequence:[57], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.10], random actions:[84], eInit:[0.4998], init state:[ 5 13  1  0  0  0  0  0], end state:[ 0 13  1  0  0  0  0  0], runtime(seconds):[427.05]
INFO:Reinforcement.Functions:Optimal models save history:[(62, [('Actor', 1), ('Critic', 1)]), (63, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(1381.5999999999985, [63]) , maxSequence:(57, [70])
INFO:Reinforcement.Functions:episode: 71, score:[1377.40], loss:[1.88277], sequence:[58], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[65], eInit:[0.4948], init state:[6 1 8 0 0 1 0 0], end state:[1 1 8 0 0 1 0 0], runtime(seconds):[426.05]
INFO:Reinforcement.Functions:episode: 72, score:[1385.60], loss:[1.60070], sequence:[59], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[74], eInit:[0.4899], init state:[ 6 13 15  0  0  0  0  0], end state:[ 1 13 15  0  0  0  0  0], runtime(seconds):[426.04]
INFO:Reinforcement.Functions:episode: 73, score:[1374.20], loss:[1.76087], sequence:[60], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.03], random actions:[77], eInit:[0.4850], init state:[ 0  1 22  0  0  0  0  0], end state:[ 2  1 22  0  0  0  0  0], runtime(seconds):[426.63]
INFO:Reinforcement.Functions:episode: 74, score:[1353.80], loss:[1.65773], sequence:[61], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.04], random actions:[95], eInit:[0.4801], init state:[ 0 13 29  0  0  0  0  0], end state:[ 2 13 29  0  0  0  0  0], runtime(seconds):[426.48]
INFO:Reinforcement.Functions:episode: 75, score:[1392.40], loss:[1.70327], sequence:[62], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[59], eInit:[0.4753], init state:[ 1  1 36  0  0  0  0  0], end state:[ 3  1 36  0  0  0  0  0], runtime(seconds):[426.64]
INFO:Reinforcement.Functions:episode: 76, score:[1383.60], loss:[1.60613], sequence:[63], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[68], eInit:[0.4706], init state:[ 1 13 43  0  0  0  0  0], end state:[ 3 13 43  0  0  0  0  0], runtime(seconds):[426.48]
INFO:Reinforcement.Functions:episode: 77, score:[1390.60], loss:[1.53243], sequence:[64], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[60], eInit:[0.4659], init state:[ 2  1 50  0  0  0  0  0], end state:[ 4  1 50  0  0  0  0  0], runtime(seconds):[426.70]
INFO:Reinforcement.Functions:episode: 78, score:[1353.20], loss:[1.58460], sequence:[65], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.05], random actions:[75], eInit:[0.4612], init state:[ 2 13 57  0  0  0  0  0], end state:[ 4 13 57  0  0  0  0  0], runtime(seconds):[425.82]
INFO:Reinforcement.Functions:episode: 79, score:[1349.80], loss:[1.83228], sequence:[66], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[60], eInit:[0.4566], init state:[3 2 4 0 0 0 0 0], end state:[5 2 4 0 0 0 0 0], runtime(seconds):[426.31]
INFO:Reinforcement.Functions:episode: 80, score:[1366.20], loss:[1.66753], sequence:[67], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[70], eInit:[0.4520], init state:[ 3 14 11  0  0  0  0  0], end state:[ 5 14 11  0  0  0  0  0], runtime(seconds):[426.19]
INFO:Reinforcement.Functions:Optimal models save history:[(72, [('Actor', 0), ('Critic', 0)]), (75, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(1392.3999999999987, [75]) , maxSequence:(67, [80])
INFO:Reinforcement.Functions:episode: 81, score:[1348.80], loss:[1.62755], sequence:[68], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[75], eInit:[0.4475], init state:[ 4  2 18  0  0  0  0  0], end state:[ 6  2 18  0  0  0  0  0], runtime(seconds):[425.57]
INFO:Reinforcement.Functions:episode: 82, score:[1388.40], loss:[1.46421], sequence:[69], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[69], eInit:[0.4430], init state:[ 4 14 25  0  0  0  0  0], end state:[ 6 14 25  0  0  0  0  0], runtime(seconds):[425.76]
INFO:Reinforcement.Functions:episode: 83, score:[1357.80], loss:[1.68417], sequence:[70], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[57], eInit:[0.4386], init state:[ 5  2 32  0  0  0  0  0], end state:[ 0  2 32  0  0  0  0  0], runtime(seconds):[427.21]
INFO:Reinforcement.Functions:episode: 84, score:[1345.00], loss:[1.75650], sequence:[71], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[67], eInit:[0.4342], init state:[ 5 14 39  0  0  0  0  0], end state:[ 0 14 39  0  0  0  0  0], runtime(seconds):[427.81]
INFO:Reinforcement.Functions:episode: 85, score:[1371.80], loss:[1.45478], sequence:[72], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[80], eInit:[0.4299], init state:[ 6  2 46  0  0  0  0  0], end state:[ 1  2 46  0  0  0  0  0], runtime(seconds):[427.19]
INFO:Reinforcement.Functions:episode: 86, score:[1378.80], loss:[1.98443], sequence:[73], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[69], eInit:[0.4256], init state:[ 6 14 53  0  0  0  0  0], end state:[ 1 14 53  0  0  0  0  0], runtime(seconds):[428.75]
INFO:Reinforcement.Functions:episode: 87, score:[1398.20], loss:[1.53508], sequence:[74], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[50], eInit:[0.4213], init state:[0 3 0 0 0 0 0 0], end state:[2 3 0 0 0 0 0 0], runtime(seconds):[428.12]
INFO:Reinforcement.Functions:episode: 88, score:[1387.60], loss:[1.37548], sequence:[75], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[61], eInit:[0.4171], init state:[ 0 15  7  0  0  0  0  0], end state:[ 2 15  7  0  0  0  0  0], runtime(seconds):[426.83]
INFO:Reinforcement.Functions:episode: 89, score:[1382.80], loss:[1.27739], sequence:[76], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[83], eInit:[0.4129], init state:[ 1  3 14  0  0  0  0  0], end state:[ 3  3 14  0  0  0  0  0], runtime(seconds):[426.49]
INFO:Reinforcement.Functions:episode: 90, score:[1392.60], loss:[1.68317], sequence:[77], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[67], eInit:[0.4088], init state:[ 1 15 21  0  0  0  0  0], end state:[ 3 15 21  0  0  0  0  0], runtime(seconds):[426.39]
INFO:Reinforcement.Functions:Optimal models save history:[(87, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(1398.1999999999978, [87]) , maxSequence:(77, [90])
INFO:Reinforcement.Functions:episode: 91, score:[1388.20], loss:[1.37175], sequence:[78], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[64], eInit:[0.4047], init state:[ 2  3 28  0  0  0  0  0], end state:[ 4  3 28  0  0  0  0  0], runtime(seconds):[426.56]
INFO:Reinforcement.Functions:episode: 92, score:[1336.60], loss:[1.57423], sequence:[79], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[56], eInit:[0.4007], init state:[ 2 15 35  0  0  0  0  0], end state:[ 4 15 35  0  0  0  0  0], runtime(seconds):[425.34]
INFO:Reinforcement.Functions:episode: 93, score:[1366.60], loss:[1.77369], sequence:[80], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[74], eInit:[0.3967], init state:[ 3  3 42  0  0  0  0  0], end state:[ 5  3 42  0  0  0  0  0], runtime(seconds):[427.26]
INFO:Reinforcement.Functions:episode: 94, score:[1353.00], loss:[1.72880], sequence:[81], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[60], eInit:[0.3927], init state:[ 3 15 49  0  0  0  0  0], end state:[ 5 15 49  0  0  0  0  0], runtime(seconds):[426.98]
INFO:Reinforcement.Functions:episode: 95, score:[1347.20], loss:[1.49116], sequence:[82], isInPoolRatio:[1.00], optActionSelectedRatio:[0.89], optActionInPoolButNotSelected:[0.09], random actions:[57], eInit:[0.3888], init state:[ 4  3 56  0  0  0  0  0], end state:[ 6  3 56  0  0  0  0  0], runtime(seconds):[426.51]
INFO:Reinforcement.Functions:episode: 96, score:[1335.60], loss:[1.66143], sequence:[83], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.08], random actions:[50], eInit:[0.3849], init state:[ 4 16  3  0  0  0  0  0], end state:[ 6 16  3  0  0  0  0  0], runtime(seconds):[425.88]
INFO:Reinforcement.Functions:episode: 97, score:[1356.60], loss:[1.67235], sequence:[84], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[72], eInit:[0.3810], init state:[ 5  4 10  0  0  0  0  0], end state:[ 0  4 10  0  0  0  0  0], runtime(seconds):[427.21]
INFO:Reinforcement.Functions:episode: 98, score:[1345.20], loss:[1.85846], sequence:[85], isInPoolRatio:[1.00], optActionSelectedRatio:[0.90], optActionInPoolButNotSelected:[0.08], random actions:[63], eInit:[0.3772], init state:[ 5 16 17  0  0  0  0  0], end state:[ 0 16 17  0  0  0  0  0], runtime(seconds):[427.19]
INFO:Reinforcement.Functions:episode: 99, score:[1377.80], loss:[1.78464], sequence:[86], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[57], eInit:[0.3735], init state:[ 6  4 24  0  0  0  0  0], end state:[ 1  4 24  0  0  0  0  0], runtime(seconds):[425.41]
INFO:Reinforcement.Functions:episode: 100, score:[1371.20], loss:[1.71071], sequence:[87], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[70], eInit:[0.3697], init state:[ 6 16 31  0  0  0  0  0], end state:[ 1 16 31  0  0  0  0  0], runtime(seconds):[426.76]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(1398.1999999999978, [87]) , maxSequence:(87, [100])
INFO:Reinforcement.Functions:episode: 101, score:[1385.80], loss:[1.37308], sequence:[88], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.02], random actions:[71], eInit:[0.3660], init state:[ 0  4 38  0  0  0  0  0], end state:[ 2  4 38  0  0  0  0  0], runtime(seconds):[426.32]
INFO:Reinforcement.Functions:episode: 102, score:[1388.60], loss:[1.72604], sequence:[89], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[64], eInit:[0.3624], init state:[ 0 16 45  0  0  0  0  0], end state:[ 2 16 45  0  0  0  0  0], runtime(seconds):[425.44]
INFO:Reinforcement.Functions:episode: 103, score:[1393.00], loss:[1.20936], sequence:[90], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[64], eInit:[0.3587], init state:[ 1  4 52  0  0  0  0  0], end state:[ 3  4 52  0  0  0  0  0], runtime(seconds):[426.75]
INFO:Reinforcement.Functions:episode: 104, score:[1396.20], loss:[1.21177], sequence:[91], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[47], eInit:[0.3552], init state:[ 1 16 59  0  0  0  0  0], end state:[ 3 16 59  1  1  1  0  1], runtime(seconds):[426.89]
INFO:Reinforcement.Functions:episode: 105, score:[1367.40], loss:[1.50390], sequence:[92], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[57], eInit:[0.3516], init state:[2 5 6 0 0 0 0 0], end state:[4 5 6 0 0 0 0 0], runtime(seconds):[426.98]
INFO:Reinforcement.Functions:episode: 106, score:[1348.60], loss:[2.01232], sequence:[93], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[57], eInit:[0.3481], init state:[ 2 17 13  0  0  0  0  0], end state:[ 4 17 13  0  0  0  0  0], runtime(seconds):[426.64]
INFO:Reinforcement.Functions:episode: 107, score:[1349.80], loss:[1.60243], sequence:[94], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[69], eInit:[0.3446], init state:[ 3  5 20  0  0  0  0  0], end state:[ 5  5 20  0  0  0  0  0], runtime(seconds):[427.08]
INFO:Reinforcement.Functions:episode: 108, score:[1355.20], loss:[1.54788], sequence:[95], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[66], eInit:[0.3412], init state:[ 3 17 27  0  0  0  0  0], end state:[ 5 17 27  0  0  0  0  0], runtime(seconds):[427.14]
INFO:Reinforcement.Functions:episode: 109, score:[1386.40], loss:[1.65459], sequence:[96], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[60], eInit:[0.3378], init state:[ 4  5 34  0  0  0  0  0], end state:[ 6  5 34  0  0  0  0  0], runtime(seconds):[425.21]
INFO:Reinforcement.Functions:episode: 110, score:[1383.00], loss:[1.44693], sequence:[97], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[50], eInit:[0.3344], init state:[ 4 17 41  0  0  0  0  0], end state:[ 6 17 41  0  0  0  0  0], runtime(seconds):[426.24]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(1398.1999999999978, [87]) , maxSequence:(97, [110])
INFO:Reinforcement.Functions:episode: 111, score:[1387.60], loss:[1.54993], sequence:[98], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[56], eInit:[0.3310], init state:[ 5  5 48  0  0  0  0  0], end state:[ 0  5 48  0  0  0  0  0], runtime(seconds):[425.86]
INFO:Reinforcement.Functions:episode: 112, score:[1359.60], loss:[1.68510], sequence:[99], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.07], random actions:[60], eInit:[0.3277], init state:[ 5 17 55  0  0  0  0  0], end state:[ 0 17 55  0  0  0  0  0], runtime(seconds):[426.18]
INFO:Reinforcement.Functions:episode: 113, score:[1375.80], loss:[1.80315], sequence:[100], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[54], eInit:[0.3244], init state:[6 6 2 0 0 0 0 0], end state:[1 6 2 0 0 0 0 0], runtime(seconds):[426.09]
INFO:Reinforcement.Functions:episode: 114, score:[1371.60], loss:[1.63528], sequence:[101], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[59], eInit:[0.3212], init state:[ 6 18  9  0  0  0  0  0], end state:[ 1 18  9  0  0  0  0  0], runtime(seconds):[427.18]
INFO:Reinforcement.Functions:episode: 115, score:[1388.80], loss:[1.56581], sequence:[102], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[54], eInit:[0.3180], init state:[ 0  6 16  0  0  0  0  0], end state:[ 2  6 16  0  0  0  0  0], runtime(seconds):[427.39]
INFO:Reinforcement.Functions:episode: 116, score:[1384.00], loss:[1.48662], sequence:[103], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[56], eInit:[0.3148], init state:[ 0 18 23  0  0  0  0  0], end state:[ 2 18 23  0  0  0  0  0], runtime(seconds):[426.56]
INFO:Reinforcement.Functions:episode: 117, score:[1398.20], loss:[1.33699], sequence:[104], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[58], eInit:[0.3117], init state:[ 1  6 30  0  0  0  0  0], end state:[ 3  6 30  0  0  0  0  0], runtime(seconds):[426.54]
INFO:Reinforcement.Functions:episode: 118, score:[1381.00], loss:[1.25786], sequence:[105], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[52], eInit:[0.3085], init state:[ 1 18 37  0  0  0  0  0], end state:[ 3 18 37  0  0  0  0  0], runtime(seconds):[427.10]
INFO:Reinforcement.Functions:episode: 119, score:[1386.00], loss:[1.39650], sequence:[106], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[51], eInit:[0.3055], init state:[ 2  6 44  0  0  0  0  0], end state:[ 4  6 44  0  0  0  0  0], runtime(seconds):[426.60]
INFO:Reinforcement.Functions:episode: 120, score:[1377.00], loss:[1.39530], sequence:[107], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[61], eInit:[0.3024], init state:[ 2 18 51  0  0  0  0  0], end state:[ 4 18 51  0  0  0  0  0], runtime(seconds):[425.40]
INFO:Reinforcement.Functions:Optimal models save history:[(117, [('Actor', 2), ('Critic', 2)])]
INFO:Reinforcement.Functions:maxScore:(1398.1999999999987, [117]) , maxSequence:(107, [120])
INFO:Reinforcement.Functions:episode: 121, score:[1387.20], loss:[1.48194], sequence:[108], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[52], eInit:[0.2994], init state:[ 3  6 58  0  0  0  0  0], end state:[ 5  6 58  0  0  0  0  0], runtime(seconds):[426.65]
INFO:Reinforcement.Functions:episode: 122, score:[1371.60], loss:[1.48046], sequence:[109], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[59], eInit:[0.2964], init state:[ 3 19  5  0  0  0  0  0], end state:[ 5 19  5  1  1  0  1  0], runtime(seconds):[426.35]
INFO:Reinforcement.Functions:episode: 123, score:[1308.00], loss:[1.80810], sequence:[110], isInPoolRatio:[1.00], optActionSelectedRatio:[0.88], optActionInPoolButNotSelected:[0.10], random actions:[59], eInit:[0.2934], init state:[ 4  7 12  0  0  0  0  0], end state:[ 6  7 12  0  0  0  0  0], runtime(seconds):[426.11]
INFO:Reinforcement.Functions:episode: 124, score:[1371.80], loss:[1.64564], sequence:[111], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[52], eInit:[0.2905], init state:[ 4 19 19  0  0  0  0  0], end state:[ 6 19 19  0  0  0  0  0], runtime(seconds):[427.11]
INFO:Reinforcement.Functions:episode: 125, score:[1356.00], loss:[1.38302], sequence:[112], isInPoolRatio:[1.00], optActionSelectedRatio:[0.92], optActionInPoolButNotSelected:[0.06], random actions:[62], eInit:[0.2876], init state:[ 5  7 26  0  0  0  0  0], end state:[ 0  7 26  0  0  0  0  0], runtime(seconds):[427.30]
INFO:Reinforcement.Functions:episode: 126, score:[1360.20], loss:[1.50858], sequence:[113], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[60], eInit:[0.2847], init state:[ 5 19 33  1  0  0  1  0], end state:[ 0 19 33  0  0  0  0  0], runtime(seconds):[426.83]
INFO:Reinforcement.Functions:episode: 127, score:[1373.20], loss:[1.61224], sequence:[114], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[46], eInit:[0.2819], init state:[ 6  7 40  0  0  0  0  0], end state:[ 1  7 40  1  1  0  1  0], runtime(seconds):[425.66]
INFO:Reinforcement.Functions:episode: 128, score:[1375.20], loss:[1.64679], sequence:[115], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[44], eInit:[0.2790], init state:[ 6 19 47  0  0  0  0  0], end state:[ 1 19 47  0  0  0  0  0], runtime(seconds):[426.79]
INFO:Reinforcement.Functions:episode: 129, score:[1381.60], loss:[1.41453], sequence:[116], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[55], eInit:[0.2763], init state:[ 0  7 54  0  0  0  0  0], end state:[ 2  7 54  0  0  0  0  0], runtime(seconds):[426.43]
INFO:Reinforcement.Functions:episode: 130, score:[1389.80], loss:[1.44379], sequence:[117], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[57], eInit:[0.2735], init state:[ 0 20  1  0  0  0  0  0], end state:[ 2 20  1  0  0  0  0  0], runtime(seconds):[425.04]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(1398.1999999999987, [117]) , maxSequence:(117, [130])
INFO:Reinforcement.Functions:episode: 131, score:[1396.60], loss:[1.64229], sequence:[118], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[50], eInit:[0.2708], init state:[1 8 8 1 0 0 0 0], end state:[3 8 8 1 0 0 0 0], runtime(seconds):[426.86]
INFO:Reinforcement.Functions:episode: 132, score:[1400.80], loss:[1.23765], sequence:[119], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[52], eInit:[0.2680], init state:[ 1 20 15  0  0  0  0  0], end state:[ 3 20 15  0  0  0  0  0], runtime(seconds):[426.90]
INFO:Reinforcement.Functions:episode: 133, score:[1399.20], loss:[1.41314], sequence:[120], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[52], eInit:[0.2654], init state:[ 2  8 22  1  0  0  0  0], end state:[ 4  8 22  0  0  0  0  0], runtime(seconds):[426.85]
INFO:Reinforcement.Functions:episode: 134, score:[1371.60], loss:[1.39157], sequence:[121], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[51], eInit:[0.2627], init state:[ 2 20 29  0  0  0  0  0], end state:[ 4 20 29  0  0  0  0  0], runtime(seconds):[425.46]
INFO:Reinforcement.Functions:episode: 135, score:[1385.60], loss:[1.26773], sequence:[122], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[58], eInit:[0.2601], init state:[ 3  8 36  1  1  0  1  0], end state:[ 5  8 36  0  0  0  0  0], runtime(seconds):[426.55]
INFO:Reinforcement.Functions:episode: 136, score:[1362.40], loss:[1.53514], sequence:[123], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[48], eInit:[0.2575], init state:[ 3 20 43  1  1  0  0  0], end state:[ 5 20 43  1  0  0  0  0], runtime(seconds):[426.47]
INFO:Reinforcement.Functions:episode: 137, score:[1336.20], loss:[1.73034], sequence:[124], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[64], eInit:[0.2549], init state:[ 4  8 50  0  0  0  0  0], end state:[ 6  8 50  1  1  0  0  0], runtime(seconds):[424.65]
INFO:Reinforcement.Functions:episode: 138, score:[1356.00], loss:[1.61738], sequence:[125], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[57], eInit:[0.2524], init state:[ 4 20 57  0  0  0  0  0], end state:[ 6 20 57  1  1  0  1  0], runtime(seconds):[425.99]
INFO:Reinforcement.Functions:episode: 139, score:[1381.40], loss:[1.48380], sequence:[126], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[40], eInit:[0.2498], init state:[5 9 4 0 0 0 0 0], end state:[0 9 4 0 0 0 0 0], runtime(seconds):[425.72]
INFO:Reinforcement.Functions:episode: 140, score:[1377.00], loss:[1.47998], sequence:[127], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[59], eInit:[0.2473], init state:[ 5 21 11  1  0  0  1  0], end state:[ 0 21 11  1  1  0  1  0], runtime(seconds):[425.63]
INFO:Reinforcement.Functions:Optimal models save history:[(132, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(1400.7999999999988, [132]) , maxSequence:(127, [140])
INFO:Reinforcement.Functions:episode: 141, score:[1388.00], loss:[1.40392], sequence:[128], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[58], eInit:[0.2449], init state:[ 6  9 18  0  0  0  0  0], end state:[ 1  9 18  0  0  0  0  0], runtime(seconds):[426.38]
INFO:Reinforcement.Functions:episode: 142, score:[1394.00], loss:[1.43069], sequence:[129], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[44], eInit:[0.2424], init state:[ 6 21 25  1  1  0  1  0], end state:[ 1 21 25  1  1  0  1  0], runtime(seconds):[427.34]
INFO:Reinforcement.Functions:episode: 143, score:[1402.00], loss:[1.29506], sequence:[130], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[57], eInit:[0.2400], init state:[ 0  9 32  0  0  0  0  0], end state:[ 2  9 32  0  0  0  0  0], runtime(seconds):[426.68]
INFO:Reinforcement.Functions:episode: 144, score:[1406.00], loss:[1.35414], sequence:[131], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[47], eInit:[0.2376], init state:[ 0 21 39  1  0  0  0  0], end state:[ 2 21 39  1  0  0  0  0], runtime(seconds):[425.11]
INFO:Reinforcement.Functions:episode: 145, score:[1393.20], loss:[1.32080], sequence:[132], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[44], eInit:[0.2352], init state:[ 1  9 46  0  0  0  0  0], end state:[ 3  9 46  0  0  0  0  0], runtime(seconds):[426.69]
INFO:Reinforcement.Functions:episode: 146, score:[1391.20], loss:[1.14820], sequence:[133], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[41], eInit:[0.2329], init state:[ 1 21 53  1  0  0  0  0], end state:[ 3 21 53  1  1  0  1  0], runtime(seconds):[427.34]
INFO:Reinforcement.Functions:episode: 147, score:[1402.40], loss:[1.32164], sequence:[134], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[39], eInit:[0.2305], init state:[ 2 10  0  0  0  0  0  0], end state:[ 4 10  0  1  0  0  0  0], runtime(seconds):[425.41]
INFO:Reinforcement.Functions:episode: 148, score:[1384.20], loss:[1.43295], sequence:[135], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[52], eInit:[0.2282], init state:[ 2 22  7  1  0  0  0  0], end state:[ 4 22  7  0  0  0  0  0], runtime(seconds):[426.07]
INFO:Reinforcement.Functions:episode: 149, score:[1394.00], loss:[1.53345], sequence:[136], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[46], eInit:[0.2259], init state:[ 3 10 14  0  0  0  0  0], end state:[ 5 10 14  0  0  0  0  0], runtime(seconds):[426.01]
INFO:Reinforcement.Functions:episode: 150, score:[1377.20], loss:[1.30515], sequence:[137], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[46], eInit:[0.2237], init state:[ 3 22 21  1  0  0  0  0], end state:[ 5 22 21  1  0  0  1  0], runtime(seconds):[425.64]
INFO:Reinforcement.Functions:Optimal models save history:[(143, [('Actor', 2), ('Critic', 2)]), (144, [('Actor', 0), ('Critic', 0)])]
INFO:Reinforcement.Functions:maxScore:(1405.9999999999989, [144]) , maxSequence:(137, [150])
INFO:Reinforcement.Functions:episode: 151, score:[1371.40], loss:[1.57066], sequence:[138], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[48], eInit:[0.2215], init state:[ 4 10 28  1  1  0  1  0], end state:[ 6 10 28  0  0  0  0  0], runtime(seconds):[425.68]
INFO:Reinforcement.Functions:episode: 152, score:[1347.80], loss:[1.54676], sequence:[139], isInPoolRatio:[1.00], optActionSelectedRatio:[0.91], optActionInPoolButNotSelected:[0.07], random actions:[57], eInit:[0.2192], init state:[ 4 22 35  0  0  0  0  0], end state:[ 6 22 35  1  0  0  0  0], runtime(seconds):[426.29]
INFO:Reinforcement.Functions:episode: 153, score:[1367.40], loss:[1.40627], sequence:[140], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[44], eInit:[0.2170], init state:[ 5 10 42  0  0  0  0  0], end state:[ 0 10 42  0  0  0  0  0], runtime(seconds):[426.70]
INFO:Reinforcement.Functions:episode: 154, score:[1394.60], loss:[1.46127], sequence:[141], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[48], eInit:[0.2149], init state:[ 5 22 49  1  0  0  1  0], end state:[ 0 22 49  1  0  0  0  0], runtime(seconds):[426.61]
INFO:Reinforcement.Functions:episode: 155, score:[1373.40], loss:[1.42026], sequence:[142], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.05], random actions:[47], eInit:[0.2127], init state:[ 6 10 56  0  0  0  0  0], end state:[ 1 10 56  0  0  0  0  0], runtime(seconds):[426.99]
INFO:Reinforcement.Functions:episode: 156, score:[1405.40], loss:[1.31506], sequence:[143], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[43], eInit:[0.2106], init state:[ 6 23  3  1  0  0  0  0], end state:[ 1 23  3  1  0  0  0  0], runtime(seconds):[427.14]
INFO:Reinforcement.Functions:episode: 157, score:[1378.20], loss:[1.39883], sequence:[144], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[43], eInit:[0.2085], init state:[ 0 11 10  0  0  0  0  0], end state:[ 2 11 10  0  0  0  0  0], runtime(seconds):[425.70]
INFO:Reinforcement.Functions:episode: 158, score:[1406.60], loss:[1.24774], sequence:[145], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[38], eInit:[0.2064], init state:[ 0 23 17  1  0  0  1  0], end state:[ 2 23 17  1  0  0  1  0], runtime(seconds):[425.20]
INFO:Reinforcement.Functions:episode: 159, score:[1357.20], loss:[1.23027], sequence:[146], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.05], random actions:[44], eInit:[0.2043], init state:[ 1 11 24  0  0  0  0  0], end state:[ 3 11 24  0  0  0  0  0], runtime(seconds):[426.19]
INFO:Reinforcement.Functions:episode: 160, score:[1395.20], loss:[1.26207], sequence:[147], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[46], eInit:[0.2023], init state:[ 1 23 31  1  0  0  1  0], end state:[ 3 23 31  1  0  0  1  0], runtime(seconds):[428.01]
INFO:Reinforcement.Functions:Optimal models save history:[(158, [('Actor', 1), ('Critic', 1)])]
INFO:Reinforcement.Functions:maxScore:(1406.5999999999983, [158]) , maxSequence:(147, [160])
INFO:Reinforcement.Functions:episode: 161, score:[1396.00], loss:[1.07561], sequence:[148], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[38], eInit:[0.2003], init state:[ 2 11 38  0  0  0  0  0], end state:[ 4 11 38  1  1  0  0  0], runtime(seconds):[425.30]
INFO:Reinforcement.Functions:episode: 162, score:[1405.60], loss:[1.01052], sequence:[149], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[31], eInit:[0.1983], init state:[ 2 23 45  1  0  0  0  0], end state:[ 4 23 45  0  0  0  0  0], runtime(seconds):[427.19]
INFO:Reinforcement.Functions:episode: 163, score:[1402.60], loss:[1.13250], sequence:[150], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[43], eInit:[0.1963], init state:[ 3 11 52  0  0  0  0  0], end state:[ 5 11 52  0  0  0  0  0], runtime(seconds):[428.11]
INFO:Reinforcement.Functions:episode: 164, score:[1393.40], loss:[1.10034], sequence:[151], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[40], eInit:[0.1943], init state:[ 3 23 59  1  0  0  0  0], end state:[ 5 23 59  1  0  0  0  0], runtime(seconds):[430.77]
INFO:Reinforcement.Functions:episode: 165, score:[1378.00], loss:[1.36664], sequence:[152], isInPoolRatio:[1.00], optActionSelectedRatio:[0.93], optActionInPoolButNotSelected:[0.06], random actions:[40], eInit:[0.1924], init state:[ 4 12  6  1  1  0  0  0], end state:[ 6 12  6  0  0  0  0  0], runtime(seconds):[425.30]
INFO:Reinforcement.Functions:episode: 166, score:[1393.20], loss:[1.57156], sequence:[153], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.04], random actions:[32], eInit:[0.1905], init state:[ 5  0 13  0  0  0  0  0], end state:[ 0  0 13  1  0  0  0  0], runtime(seconds):[444.70]
INFO:Reinforcement.Functions:episode: 167, score:[1380.60], loss:[1.29826], sequence:[154], isInPoolRatio:[1.00], optActionSelectedRatio:[0.94], optActionInPoolButNotSelected:[0.04], random actions:[52], eInit:[0.1886], init state:[ 5 12 20  0  0  0  0  0], end state:[ 0 12 20  0  0  0  0  0], runtime(seconds):[443.83]
INFO:Reinforcement.Functions:episode: 168, score:[1396.00], loss:[1.22670], sequence:[155], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.03], random actions:[49], eInit:[0.1867], init state:[ 6  0 27  1  0  0  0  0], end state:[ 1  0 27  1  0  0  0  0], runtime(seconds):[426.73]
INFO:Reinforcement.Functions:episode: 169, score:[1398.60], loss:[1.15982], sequence:[156], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[52], eInit:[0.1848], init state:[ 6 12 34  0  0  0  0  0], end state:[ 1 12 34  0  0  0  0  0], runtime(seconds):[430.85]
INFO:Reinforcement.Functions:episode: 170, score:[1403.60], loss:[1.25997], sequence:[157], isInPoolRatio:[1.00], optActionSelectedRatio:[0.96], optActionInPoolButNotSelected:[0.02], random actions:[43], eInit:[0.1830], init state:[ 0  0 41  0  0  1  0  0], end state:[ 2  0 41  0  0  1  0  0], runtime(seconds):[430.92]
INFO:Reinforcement.Functions:Saving [Actor] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [/home/yochaiz/SmartHome/Reinforcement/DDPG/results/actionDim-5/D-10-4-H-14-19-40/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(1406.5999999999983, [158]) , maxSequence:(157, [170])
INFO:Reinforcement.Functions:episode: 171, score:[1413.60], loss:[0.87278], sequence:[158], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.01], random actions:[34], eInit:[0.1811], init state:[ 0 12 48  0  0  0  0  0], end state:[ 2 12 48  0  0  0  0  0], runtime(seconds):[430.84]
INFO:Reinforcement.Functions:episode: 172, score:[1412.20], loss:[1.21645], sequence:[159], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[34], eInit:[0.1793], init state:[ 1  0 55  0  0  1  0  0], end state:[ 3  0 55  0  0  1  0  0], runtime(seconds):[429.07]
INFO:Reinforcement.Functions:episode: 173, score:[1385.40], loss:[1.11114], sequence:[160], isInPoolRatio:[1.00], optActionSelectedRatio:[0.95], optActionInPoolButNotSelected:[0.03], random actions:[46], eInit:[0.1775], init state:[ 1 13  2  0  0  0  0  0], end state:[ 3 13  2  0  0  0  0  0], runtime(seconds):[426.61]
INFO:Reinforcement.Functions:episode: 174, score:[1403.20], loss:[1.22188], sequence:[161], isInPoolRatio:[1.00], optActionSelectedRatio:[0.97], optActionInPoolButNotSelected:[0.02], random actions:[41], eInit:[0.1757], init state:[2 1 9 0 0 1 0 0], end state:[4 1 9 0 0 1 0 0], runtime(seconds):[426.46]

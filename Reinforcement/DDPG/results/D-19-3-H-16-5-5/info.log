Description: expected future reward is calculated with DISCRETE action, as in step 13 in paper algorithm
INFO:Reinforcement.Functions:settings:[{'minGameScore': 2736, u'TAU': 0.001, u'minGameScoreRatio': 0.95, u'batchSize': 256, u'nGamesPerSave': 50, u'nEpochs': 1, u'minGameSequence': 500, u'nModelBackups': 3, u'gameMinutesLength': 2880, u'dequeSize': 50000, u'learningRate': 0.001, u'gamma': 0.95, u'trainSetSize': 256}]
INFO:Reinforcement.Functions:args:[{'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json', 'random': True, 'sequential': False, 'gpuNum': 1, 'gpuFrac': 0.3, 'desc': None}]
INFO:Reinforcement.Functions:results:[{'loss': [], 'score': []}]
INFO:Reinforcement.Functions:Actor:[{'epsilon_decay': 0.99, 'epsilon': 1.0, 'curBackupIdx': 0, 'epsilon_min': 0.01, 'TAU': 0.001, 'nBackups': 3, 'k': 32, 'actionDim': 5}]
INFO:Reinforcement.Functions:Critic:[{'TAU': 0.001, 'nBackups': 3, 'curBackupIdx': 0, 'actionDim': 5}]
INFO:Reinforcement.Functions:policy:[{'numOfDevices': 5, 'stateDim': (1, 8), 'seqLen': 1, 'policyJSON': {u'10': [{u'days': u'weekdays', u'times': [[u'21:00', u'23:29']]}, {u'days': [5], u'times': [[u'21:00', u'23:29']]}], u'6': [{u'days': u'weekdays', u'times': [[u'20:40', u'23:59'], [u'00:00', u'00:14']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'weekdays': [0, 1, 2, 3, 6], u'Devices': [u'Room light1', u'Room light2', u'Room light3 (backdoor)', u'Kitchen light', u'Toilets light'], u'days': [u'Monday', u'Tuesday', u'Wednesday', u'Thursday', u'Friday', u'Saturday', u'Sunday'], u'1': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:59'], [u'20:30', u'21:29']]}, {u'days': [4], u'times': [[u'10:00', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'0': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:29'], [u'08:00', u'08:59'], [u'20:30', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:59'], [u'09:30', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'23:59']]}], u'3': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:44'], [u'20:45', u'21:29'], [u'23:15', u'23:44']]}, {u'days': [4], u'times': [[u'10:00', u'10:59'], [u'12:45', u'13:14']]}, {u'days': [5], u'times': [[u'18:00', u'19:59'], [u'21:00', u'23:14']]}], u'2': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:30', u'01:09']]}, {u'days': [4], u'times': [[u'00:30', u'01:09']]}], u'5': [{u'days': u'weekdays', u'times': [[u'08:35', u'08:42'], [u'21:09', u'21:11'], [u'00:05', u'00:24']]}, {u'days': [4], u'times': [[u'10:18', u'10:29'], [u'00:05', u'00:24']]}, {u'days': [5], u'times': [[u'19:09', u'19:09'], [u'21:34', u'21:34']]}], u'4': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:34'], [u'21:05', u'21:08']]}, {u'days': [4], u'times': [[u'10:10', u'10:17']]}, {u'days': [5], u'times': [[u'19:05', u'19:08'], [u'21:20', u'21:33']]}], u'7': [{u'days': u'weekdays', u'times': [[u'20:40', u'23:59'], [u'00:00', u'00:14']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'Time format': u'%H:%M', u'9': [{u'days': u'weekdays', u'times': [[u'09:00', u'09:00'], [u'20:30', u'20:30']]}, {u'days': [4], u'times': [[u'13:29', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:00']]}], u'8': [{u'days': u'weekdays', u'times': [[u'20:31', u'20:54']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'weekend': [4, 5]}}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-19-3-H-16-5-5/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-19-3-H-16-5-5/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-19-3-H-16-5-5/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-19-3-H-16-5-5/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 8)              0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 2048)           18432     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 2048)           4196352   
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 5)              10245     
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 5)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 4,225,029
INFO:Reinforcement.Functions:Trainable params: 4,225,029
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 8)         0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)                 (None, 1, 2048)      18432       input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 5)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)                 (None, 1, 2048)      4196352     dense_4[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)                 (None, 2048)         12288       input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 2048)      0           dense_5[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_6[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 2048)      0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 1)         2049        activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_7[0][0]                    
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 4,229,121
INFO:Reinforcement.Functions:Trainable params: 4,229,121
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[2278.40], loss:[82.98629], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.68], optActionInPoolButNotSelected:[0.29], random actions:[119], eInit:[1.0000], init state:[ 1  7 20  0  0  0  0  0], end state:[ 3  7 20  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 2, score:[2292.40], loss:[33.25442], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.70], optActionInPoolButNotSelected:[0.27], random actions:[120], eInit:[0.9900], init state:[ 0 17 42  0  0  0  0  0], end state:[ 2 17 42  0  0  0  0  1]
INFO:Reinforcement.Functions:episode: 3, score:[2425.20], loss:[14.13316], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.75], optActionInPoolButNotSelected:[0.22], random actions:[122], eInit:[0.9801], init state:[ 1 14 16  0  0  0  0  0], end state:[ 3 14 16  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 4, score:[2248.40], loss:[12.98130], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.69], optActionInPoolButNotSelected:[0.28], random actions:[141], eInit:[0.9703], init state:[ 2 22 36  1  0  0  0  0], end state:[ 4 22 36  1  0  0  0  0]
INFO:Reinforcement.Functions:episode: 5, score:[2482.80], loss:[14.73789], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.79], optActionInPoolButNotSelected:[0.18], random actions:[131], eInit:[0.9606], init state:[ 0 18 40  0  0  0  0  0], end state:[ 2 18 40  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 6, score:[2379.60], loss:[11.53204], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.70], optActionInPoolButNotSelected:[0.28], random actions:[120], eInit:[0.9510], init state:[ 3 11 40  0  0  0  0  0], end state:[ 5 11 40  0  1  0  0  0]
INFO:Reinforcement.Functions:episode: 7, score:[2126.80], loss:[11.32200], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.59], optActionInPoolButNotSelected:[0.38], random actions:[128], eInit:[0.9415], init state:[ 4  2 10  0  0  0  0  0], end state:[ 6  2 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 8, score:[2180.00], loss:[15.87572], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.63], optActionInPoolButNotSelected:[0.34], random actions:[140], eInit:[0.9321], init state:[ 5 14  4  0  0  0  0  0], end state:[ 0 14  4  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 9, score:[2527.60], loss:[10.59841], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.82], optActionInPoolButNotSelected:[0.14], random actions:[115], eInit:[0.9227], init state:[ 1 10 10  0  0  0  0  0], end state:[ 3 10 10  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 10, score:[2329.20], loss:[10.41741], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.71], optActionInPoolButNotSelected:[0.26], random actions:[105], eInit:[0.9135], init state:[ 4  3 22  0  0  0  0  0], end state:[ 6  3 22  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 11, score:[2453.20], loss:[10.92707], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.21], random actions:[115], eInit:[0.9044], init state:[ 6  7 32  0  0  0  0  0], end state:[ 1  7 32  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 12, score:[2591.60], loss:[9.18484], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.85], optActionInPoolButNotSelected:[0.12], random actions:[110], eInit:[0.8953], init state:[ 1  3 48  0  0  0  0  0], end state:[ 3  3 48  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 13, score:[2631.60], loss:[8.56470], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.87], optActionInPoolButNotSelected:[0.09], random actions:[109], eInit:[0.8864], init state:[ 0  6 31  0  0  0  0  0], end state:[ 2  6 31  0  0  0  0  0]
INFO:Reinforcement.Functions:episode: 14, score:[2423.60], loss:[8.84511], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.76], optActionInPoolButNotSelected:[0.21], random actions:[125], eInit:[0.8775], init state:[ 4 23  3  0  0  0  0  0], end state:[ 6 23  3  1  0  0  1  0]
INFO:Reinforcement.Functions:episode: 15, score:[2531.20], loss:[8.34629], sequence:[0], isInPoolRatio:[1.00], optActionSelectedRatio:[0.81], optActionInPoolButNotSelected:[0.16], random actions:[125], eInit:[0.8687], init state:[ 3  4 44  0  0  0  0  0], end state:[ 5  4 44  0  0  0  0  0]

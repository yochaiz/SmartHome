INFO:Reinforcement.Functions:settings:[{'minGameScore': 2736, u'TAU': 0.001, u'minGameScoreRatio': 0.95, u'batchSize': 256, u'nGamesPerSave': 10, u'nEpochs': 1, u'minGameSequence': 500, u'nModelBackups': 3, u'gameMinutesLength': 2880, u'dequeSize': 50000, u'learningRate': 0.001, u'gamma': 0.95, u'trainSetSize': 128}]
INFO:Reinforcement.Functions:args:[{'random': True, 'gpuFrac': 0.3, 'sequential': False, 'gpuNum': 0, 'settings': '/home/yochaiz/SmartHome/Reinforcement/settings.json'}]
INFO:Reinforcement.Functions:results:[{'loss': [], 'score': []}]
INFO:Reinforcement.Functions:Actor:[{'epsilon_decay': 0.99, 'epsilon': 1.0, 'curBackupIdx': 0, 'epsilon_min': 0.01, 'TAU': 0.001, 'nBackups': 3, 'k': 8, 'actionDim': 3}]
INFO:Reinforcement.Functions:Critic:[{'TAU': 0.001, 'nBackups': 3, 'curBackupIdx': 0, 'actionDim': 3}]
INFO:Reinforcement.Functions:policy:[{'numOfDevices': 3, 'stateDim': (1, 6), 'seqLen': 1, 'policyJSON': {u'10': [{u'days': u'weekdays', u'times': [[u'21:00', u'23:29']]}, {u'days': [5], u'times': [[u'21:00', u'23:29']]}], u'6': [{u'days': u'weekdays', u'times': [[u'20:40', u'23:59'], [u'00:00', u'00:14']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'weekdays': [0, 1, 2, 3, 6], u'Devices': [u'Room light1', u'Room light2', u'Room light3 (backdoor)'], u'days': [u'Monday', u'Tuesday', u'Wednesday', u'Thursday', u'Friday', u'Saturday', u'Sunday'], u'1': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'08:30', u'08:59'], [u'20:30', u'21:29']]}, {u'days': [4], u'times': [[u'10:00', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'0': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:00', u'00:29'], [u'08:00', u'08:59'], [u'20:30', u'23:59']]}, {u'days': [4], u'times': [[u'00:00', u'00:59'], [u'09:30', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'23:59']]}], u'3': [{u'days': u'weekdays', u'times': [[u'08:30', u'08:44'], [u'20:45', u'21:29'], [u'23:15', u'23:44']]}, {u'days': [4], u'times': [[u'10:00', u'10:59'], [u'12:45', u'13:14']]}, {u'days': [5], u'times': [[u'18:00', u'19:59'], [u'21:00', u'23:14']]}], u'2': [{u'days': [0, 1, 2, 3, 6], u'times': [[u'00:30', u'01:09']]}, {u'days': [4], u'times': [[u'00:30', u'01:09']]}], u'5': [{u'days': u'weekdays', u'times': [[u'08:35', u'08:42'], [u'21:09', u'21:11'], [u'00:05', u'00:24']]}, {u'days': [4], u'times': [[u'10:18', u'10:29'], [u'00:05', u'00:24']]}, {u'days': [5], u'times': [[u'19:09', u'19:09'], [u'21:34', u'21:34']]}], u'4': [{u'days': u'weekdays', u'times': [[u'08:30', u'08:34'], [u'21:05', u'21:08']]}, {u'days': [4], u'times': [[u'10:10', u'10:17']]}, {u'days': [5], u'times': [[u'19:05', u'19:08'], [u'21:20', u'21:33']]}], u'7': [{u'days': u'weekdays', u'times': [[u'20:40', u'23:59'], [u'00:00', u'00:14']]}, {u'days': [4], u'times': [[u'00:00', u'00:14']]}, {u'days': [5], u'times': [[u'21:00', u'23:59']]}], u'Time format': u'%H:%M', u'9': [{u'days': u'weekdays', u'times': [[u'09:00', u'09:00'], [u'20:30', u'20:30']]}, {u'days': [4], u'times': [[u'13:29', u'13:29']]}, {u'days': [5], u'times': [[u'18:00', u'18:00']]}], u'8': [{u'days': u'weekdays', u'times': [[u'20:31', u'20:54']]}, {u'days': [5], u'times': [[u'18:00', u'18:59']]}], u'weekend': [4, 5]}}]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:[Actor] model architecture:
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                 Output Shape              Param #   
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:input_1 (InputLayer)         (None, 1, 6)              0         
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_1 (Dense)              (None, 1, 512)            3584      
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_2 (Dense)              (None, 1, 256)            131328    
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:dense_3 (Dense)              (None, 1, 3)              771       
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:reshape_1 (Reshape)          (None, 3)                 0         
INFO:Reinforcement.Functions:=================================================================
INFO:Reinforcement.Functions:Total params: 135,683
INFO:Reinforcement.Functions:Trainable params: 135,683
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:_________________________________________________________________
INFO:Reinforcement.Functions:[Critic] model architecture:
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:Layer (type)                    Output Shape         Param #     Connected to                     
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:input_2 (InputLayer)            (None, 1, 6)         0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_4 (Dense)                 (None, 1, 512)       3584        input_2[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:input_3 (InputLayer)            (None, 3)            0                                            
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_5 (Dense)                 (None, 1, 256)       131328      dense_4[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_6 (Dense)                 (None, 256)          1024        input_3[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:add_1 (Add)                     (None, 1, 256)       0           dense_5[0][0]                    
INFO:Reinforcement.Functions:                                                                 dense_6[0][0]                    
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:activation_1 (Activation)       (None, 1, 256)       0           add_1[0][0]                      
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:dense_7 (Dense)                 (None, 1, 1)         257         activation_1[0][0]               
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:reshape_2 (Reshape)             (None, 1)            0           dense_7[0][0]                    
INFO:Reinforcement.Functions:==================================================================================================
INFO:Reinforcement.Functions:Total params: 136,193
INFO:Reinforcement.Functions:Trainable params: 136,193
INFO:Reinforcement.Functions:Non-trainable params: 0
INFO:Reinforcement.Functions:__________________________________________________________________________________________________
INFO:Reinforcement.Functions:episode: 1, score:[1979.33], loss:[98.12670], sequence:[0], random actions:[132], eInit:[1.0000], init state:[ 6 14 45  0  0  0], end state:[ 1 14 45  0  0  0]
INFO:Reinforcement.Functions:episode: 2, score:[2297.33], loss:[67.66890], sequence:[0], random actions:[119], eInit:[0.9900], init state:[ 0 13 58  0  0  0], end state:[ 2 13 58  0  0  0]
INFO:Reinforcement.Functions:episode: 3, score:[2121.33], loss:[49.18171], sequence:[0], random actions:[123], eInit:[0.9801], init state:[ 3  1 24  0  0  0], end state:[ 5  1 24  0  0  0]
INFO:Reinforcement.Functions:episode: 4, score:[2140.67], loss:[34.82025], sequence:[0], random actions:[124], eInit:[0.9703], init state:[ 4  6 33  0  0  0], end state:[ 6  6 33  0  0  0]
INFO:Reinforcement.Functions:episode: 5, score:[2478.00], loss:[30.45747], sequence:[0], random actions:[113], eInit:[0.9606], init state:[ 3 17 24  0  0  0], end state:[ 5 17 24  0  0  0]
INFO:Reinforcement.Functions:episode: 6, score:[2324.00], loss:[26.66444], sequence:[0], random actions:[122], eInit:[0.9510], init state:[ 1 17 19  0  0  0], end state:[ 3 17 19  0  0  0]
INFO:Reinforcement.Functions:episode: 7, score:[2472.67], loss:[25.91288], sequence:[0], random actions:[123], eInit:[0.9415], init state:[ 0 16 16  0  0  0], end state:[ 2 16 16  0  0  0]
INFO:Reinforcement.Functions:episode: 8, score:[2471.33], loss:[23.11024], sequence:[0], random actions:[105], eInit:[0.9321], init state:[ 4 15 32  0  0  0], end state:[ 6 15 32  0  0  0]
INFO:Reinforcement.Functions:episode: 9, score:[2277.33], loss:[22.76743], sequence:[0], random actions:[112], eInit:[0.9227], init state:[5 9 6 0 0 0], end state:[0 9 6 0 0 0]
INFO:Reinforcement.Functions:episode: 10, score:[2562.67], loss:[19.84511], sequence:[0], random actions:[113], eInit:[0.9135], init state:[ 0  2 51  0  0  0], end state:[ 2  2 51  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2562.666666666674, [10]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
INFO:Reinforcement.Functions:episode: 11, score:[2436.67], loss:[17.44356], sequence:[0], random actions:[112], eInit:[0.9044], init state:[ 4  1 51  0  0  0], end state:[ 6  1 51  0  0  0]
INFO:Reinforcement.Functions:episode: 12, score:[2520.00], loss:[17.92245], sequence:[0], random actions:[108], eInit:[0.8953], init state:[ 3 21 28  1  1  0], end state:[ 5 21 28  0  0  0]
INFO:Reinforcement.Functions:episode: 13, score:[2601.33], loss:[16.42697], sequence:[0], random actions:[111], eInit:[0.8864], init state:[ 3 14 41  0  0  0], end state:[ 5 14 41  0  0  0]
INFO:Reinforcement.Functions:episode: 14, score:[2590.00], loss:[15.45713], sequence:[0], random actions:[98], eInit:[0.8775], init state:[3 2 5 0 0 0], end state:[5 2 5 0 0 0]
INFO:Reinforcement.Functions:episode: 15, score:[2642.67], loss:[14.63833], sequence:[0], random actions:[111], eInit:[0.8687], init state:[ 1 14 35  0  0  0], end state:[ 3 14 35  0  0  0]
INFO:Reinforcement.Functions:episode: 16, score:[2657.33], loss:[15.30602], sequence:[0], random actions:[111], eInit:[0.8601], init state:[ 3  4 39  0  0  0], end state:[ 5  4 39  0  0  0]
INFO:Reinforcement.Functions:episode: 17, score:[2444.00], loss:[14.45134], sequence:[0], random actions:[112], eInit:[0.8515], init state:[ 5  5 23  0  0  0], end state:[ 0  5 23  0  0  0]
INFO:Reinforcement.Functions:episode: 18, score:[2593.33], loss:[16.02322], sequence:[0], random actions:[121], eInit:[0.8429], init state:[ 1 23 56  1  0  0], end state:[ 3 23 56  1  0  0]
INFO:Reinforcement.Functions:episode: 19, score:[2546.67], loss:[15.31530], sequence:[0], random actions:[106], eInit:[0.8345], init state:[ 5  1 46  0  0  0], end state:[ 0  1 46  0  0  0]
INFO:Reinforcement.Functions:episode: 20, score:[2722.00], loss:[14.35373], sequence:[0], random actions:[90], eInit:[0.8262], init state:[ 2 22 30  1  0  0], end state:[ 4 22 30  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2721.999999999998, [20]) , maxSequence:(0, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])
INFO:Reinforcement.Functions:episode: 21, score:[2688.67], loss:[13.54171], sequence:[0], random actions:[115], eInit:[0.8179], init state:[ 1 12 36  0  0  0], end state:[ 3 12 36  0  0  0]
INFO:Reinforcement.Functions:episode: 22, score:[2654.00], loss:[13.55778], sequence:[0], random actions:[112], eInit:[0.8097], init state:[ 3 19 19  0  0  0], end state:[ 5 19 19  1  0  0]
INFO:Reinforcement.Functions:episode: 23, score:[2521.33], loss:[12.78577], sequence:[0], random actions:[113], eInit:[0.8016], init state:[ 5  9 14  0  0  0], end state:[ 0  9 14  0  0  0]
INFO:Reinforcement.Functions:episode: 24, score:[2531.33], loss:[12.91372], sequence:[0], random actions:[95], eInit:[0.7936], init state:[ 5 22 42  1  0  0], end state:[ 0 22 42  1  0  0]
INFO:Reinforcement.Functions:episode: 25, score:[2674.00], loss:[12.43354], sequence:[0], random actions:[119], eInit:[0.7857], init state:[ 2 15 15  0  0  0], end state:[ 4 15 15  0  0  0]
INFO:Reinforcement.Functions:episode: 26, score:[2711.33], loss:[11.84425], sequence:[0], random actions:[92], eInit:[0.7778], init state:[ 2 13 16  0  0  0], end state:[ 4 13 16  1  1  0]
INFO:Reinforcement.Functions:episode: 27, score:[2720.00], loss:[11.92339], sequence:[0], random actions:[98], eInit:[0.7700], init state:[ 2  6 30  0  0  0], end state:[ 4  6 30  0  0  0]
INFO:Reinforcement.Functions:episode: 28, score:[2624.67], loss:[11.58466], sequence:[0], random actions:[118], eInit:[0.7623], init state:[ 5 22  4  1  0  0], end state:[ 0 22  4  1  0  0]
INFO:Reinforcement.Functions:episode: 29, score:[2680.00], loss:[11.24013], sequence:[0], random actions:[94], eInit:[0.7547], init state:[ 0 16 46  0  0  0], end state:[ 2 16 46  0  0  0]
INFO:Reinforcement.Functions:episode: 30, score:[2748.00], loss:[10.15454], sequence:[1], random actions:[97], eInit:[0.7472], init state:[ 2 10 46  0  0  0], end state:[ 4 10 46  1  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2748.0000000000027, [30]) , maxSequence:(1, [30])
INFO:Reinforcement.Functions:episode: 31, score:[2555.33], loss:[12.31485], sequence:[0], random actions:[104], eInit:[0.7397], init state:[ 6  6 10  0  0  0], end state:[ 1  6 10  0  0  0]
INFO:Reinforcement.Functions:episode: 32, score:[2682.67], loss:[11.55257], sequence:[0], random actions:[89], eInit:[0.7323], init state:[ 3 21 36  1  0  0], end state:[ 5 21 36  1  0  0]
INFO:Reinforcement.Functions:episode: 33, score:[2666.67], loss:[11.37178], sequence:[0], random actions:[99], eInit:[0.7250], init state:[ 6 13  9  0  0  0], end state:[ 1 13  9  0  0  0]
INFO:Reinforcement.Functions:episode: 34, score:[2750.00], loss:[11.02624], sequence:[1], random actions:[99], eInit:[0.7177], init state:[ 3 12 44  0  0  0], end state:[ 5 12 44  0  0  0]
INFO:Reinforcement.Functions:episode: 35, score:[2780.00], loss:[10.12884], sequence:[2], random actions:[79], eInit:[0.7106], init state:[ 3 17 41  0  0  0], end state:[ 5 17 41  0  0  0]
INFO:Reinforcement.Functions:episode: 36, score:[2700.67], loss:[9.65008], sequence:[0], random actions:[89], eInit:[0.7034], init state:[ 4 15 44  0  0  0], end state:[ 6 15 44  0  0  0]
INFO:Reinforcement.Functions:episode: 37, score:[2705.33], loss:[10.01761], sequence:[0], random actions:[91], eInit:[0.6964], init state:[2 0 3 1 0 0], end state:[4 0 3 1 0 0]
INFO:Reinforcement.Functions:episode: 38, score:[2704.00], loss:[9.58966], sequence:[0], random actions:[98], eInit:[0.6894], init state:[ 5 20 55  1  0  0], end state:[ 0 20 55  1  1  0]
INFO:Reinforcement.Functions:episode: 39, score:[2757.33], loss:[8.99273], sequence:[1], random actions:[96], eInit:[0.6826], init state:[ 1  4 20  0  0  0], end state:[ 3  4 20  0  0  0]
INFO:Reinforcement.Functions:episode: 40, score:[2622.00], loss:[8.94892], sequence:[0], random actions:[92], eInit:[0.6757], init state:[6 2 2 0 0 0], end state:[1 2 2 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2780.0, [35]) , maxSequence:(2, [35])
INFO:Reinforcement.Functions:episode: 41, score:[2756.67], loss:[8.18556], sequence:[1], random actions:[92], eInit:[0.6690], init state:[2 2 3 0 0 0], end state:[4 2 3 0 0 0]
INFO:Reinforcement.Functions:episode: 42, score:[2687.33], loss:[8.14003], sequence:[0], random actions:[99], eInit:[0.6623], init state:[ 5  7 14  0  0  0], end state:[ 0  7 14  0  0  0]
INFO:Reinforcement.Functions:episode: 43, score:[2755.33], loss:[7.90376], sequence:[1], random actions:[94], eInit:[0.6557], init state:[ 0 13 49  0  0  0], end state:[ 2 13 49  0  0  0]
INFO:Reinforcement.Functions:episode: 44, score:[2722.67], loss:[8.15144], sequence:[0], random actions:[91], eInit:[0.6491], init state:[ 2 20 21  0  0  0], end state:[ 4 20 21  0  0  0]
INFO:Reinforcement.Functions:episode: 45, score:[2761.33], loss:[7.74986], sequence:[1], random actions:[87], eInit:[0.6426], init state:[2 7 5 0 0 0], end state:[4 7 5 0 0 0]
INFO:Reinforcement.Functions:episode: 46, score:[2772.00], loss:[7.08205], sequence:[2], random actions:[103], eInit:[0.6362], init state:[ 1 15  5  0  0  0], end state:[ 3 15  5  0  0  0]
INFO:Reinforcement.Functions:episode: 47, score:[2800.00], loss:[7.05840], sequence:[3], random actions:[76], eInit:[0.6298], init state:[ 0  9 51  0  0  0], end state:[ 2  9 51  0  0  0]
INFO:Reinforcement.Functions:episode: 48, score:[2720.67], loss:[7.26388], sequence:[0], random actions:[87], eInit:[0.6235], init state:[3 7 3 0 0 0], end state:[5 7 3 0 0 0]
INFO:Reinforcement.Functions:episode: 49, score:[2721.33], loss:[7.08130], sequence:[0], random actions:[66], eInit:[0.6173], init state:[ 5  7 19  0  0  0], end state:[ 0  7 19  0  0  0]
INFO:Reinforcement.Functions:episode: 50, score:[2716.00], loss:[7.65642], sequence:[0], random actions:[79], eInit:[0.6111], init state:[ 5 19 33  1  0  0], end state:[ 0 19 33  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2800.0000000000005, [47]) , maxSequence:(3, [47])
INFO:Reinforcement.Functions:episode: 51, score:[2780.67], loss:[6.95554], sequence:[1], random actions:[84], eInit:[0.6050], init state:[ 2  8 41  1  1  0], end state:[ 4  8 41  0  0  0]
INFO:Reinforcement.Functions:episode: 52, score:[2766.67], loss:[6.37306], sequence:[2], random actions:[86], eInit:[0.5990], init state:[ 0 10 57  0  0  0], end state:[ 2 10 57  0  0  0]
INFO:Reinforcement.Functions:episode: 53, score:[2737.33], loss:[6.79122], sequence:[3], random actions:[79], eInit:[0.5930], init state:[ 3 20 56  1  1  0], end state:[ 5 20 56  1  0  0]
INFO:Reinforcement.Functions:episode: 54, score:[2759.33], loss:[6.89292], sequence:[4], random actions:[100], eInit:[0.5870], init state:[ 3  7 35  0  0  0], end state:[ 5  7 35  0  0  0]
INFO:Reinforcement.Functions:episode: 55, score:[2682.67], loss:[6.91861], sequence:[0], random actions:[87], eInit:[0.5812], init state:[ 4 21  9  0  0  0], end state:[ 6 21  9  1  1  0]
INFO:Reinforcement.Functions:episode: 56, score:[2797.33], loss:[6.17314], sequence:[1], random actions:[72], eInit:[0.5754], init state:[ 6  9 41  0  0  0], end state:[ 1  9 41  0  0  0]
INFO:Reinforcement.Functions:episode: 57, score:[2754.67], loss:[6.21228], sequence:[2], random actions:[92], eInit:[0.5696], init state:[ 6  4 12  0  0  0], end state:[ 1  4 12  0  0  0]
INFO:Reinforcement.Functions:episode: 58, score:[2758.00], loss:[6.28473], sequence:[3], random actions:[85], eInit:[0.5639], init state:[ 3 23 59  1  0  0], end state:[ 5 23 59  1  0  0]
INFO:Reinforcement.Functions:episode: 59, score:[2746.00], loss:[6.29261], sequence:[4], random actions:[70], eInit:[0.5583], init state:[ 0 23 23  1  0  0], end state:[ 2 23 23  1  0  0]
INFO:Reinforcement.Functions:episode: 60, score:[2714.67], loss:[6.20116], sequence:[0], random actions:[88], eInit:[0.5527], init state:[ 3 23 17  1  0  0], end state:[ 5 23 17  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2800.0000000000005, [47]) , maxSequence:(4, [54, 59])
INFO:Reinforcement.Functions:episode: 61, score:[2690.67], loss:[6.85969], sequence:[0], random actions:[73], eInit:[0.5472], init state:[ 3 18 23  0  0  0], end state:[ 5 18 23  1  1  0]
INFO:Reinforcement.Functions:episode: 62, score:[2742.67], loss:[6.90597], sequence:[1], random actions:[66], eInit:[0.5417], init state:[ 5 17 42  0  0  0], end state:[ 0 17 42  0  0  0]
INFO:Reinforcement.Functions:episode: 63, score:[2745.33], loss:[6.80471], sequence:[2], random actions:[82], eInit:[0.5363], init state:[ 3 18 34  0  0  0], end state:[ 5 18 34  0  1  0]
INFO:Reinforcement.Functions:episode: 64, score:[2759.33], loss:[6.61873], sequence:[3], random actions:[89], eInit:[0.5309], init state:[ 2  4 51  0  0  0], end state:[ 4  4 51  0  0  0]
INFO:Reinforcement.Functions:episode: 65, score:[2769.33], loss:[6.42093], sequence:[4], random actions:[59], eInit:[0.5256], init state:[ 6  1 42  0  0  0], end state:[ 1  1 42  0  0  0]
INFO:Reinforcement.Functions:episode: 66, score:[2742.00], loss:[6.29456], sequence:[5], random actions:[73], eInit:[0.5203], init state:[ 5 22  8  1  0  0], end state:[ 0 22  8  1  0  0]
INFO:Reinforcement.Functions:episode: 67, score:[2786.00], loss:[5.73344], sequence:[6], random actions:[79], eInit:[0.5151], init state:[ 3  1 55  0  0  0], end state:[ 5  1 55  0  0  0]
INFO:Reinforcement.Functions:episode: 68, score:[2765.33], loss:[6.09301], sequence:[7], random actions:[74], eInit:[0.5100], init state:[ 3 20 39  1  1  0], end state:[ 5 20 39  1  0  0]
INFO:Reinforcement.Functions:episode: 69, score:[2770.67], loss:[5.70798], sequence:[8], random actions:[82], eInit:[0.5049], init state:[ 3  6 18  0  0  0], end state:[ 5  6 18  0  0  0]
INFO:Reinforcement.Functions:episode: 70, score:[2750.67], loss:[6.01022], sequence:[9], random actions:[76], eInit:[0.4998], init state:[ 4 13  4  1  1  0], end state:[ 6 13  4  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2800.0000000000005, [47]) , maxSequence:(9, [70])
INFO:Reinforcement.Functions:episode: 71, score:[2784.00], loss:[5.78572], sequence:[10], random actions:[72], eInit:[0.4948], init state:[ 4  3 32  0  0  0], end state:[ 6  3 32  0  0  0]
INFO:Reinforcement.Functions:episode: 72, score:[2744.00], loss:[5.94747], sequence:[11], random actions:[72], eInit:[0.4899], init state:[ 4 18  2  0  0  0], end state:[ 6 18  2  0  0  0]
INFO:Reinforcement.Functions:episode: 73, score:[2777.33], loss:[5.57825], sequence:[12], random actions:[74], eInit:[0.4850], init state:[ 3  3 51  0  0  0], end state:[ 5  3 51  0  0  0]
INFO:Reinforcement.Functions:episode: 74, score:[2764.67], loss:[5.70302], sequence:[13], random actions:[69], eInit:[0.4801], init state:[ 4 21 27  0  0  0], end state:[ 6 21 27  1  1  0]
INFO:Reinforcement.Functions:episode: 75, score:[2736.00], loss:[5.32280], sequence:[0], random actions:[78], eInit:[0.4753], init state:[ 6  3 59  0  0  0], end state:[ 1  3 59  0  0  0]
INFO:Reinforcement.Functions:episode: 76, score:[2764.00], loss:[5.32640], sequence:[1], random actions:[74], eInit:[0.4706], init state:[ 4 22 58  0  0  0], end state:[ 6 22 58  1  0  0]
INFO:Reinforcement.Functions:episode: 77, score:[2782.00], loss:[5.25327], sequence:[2], random actions:[82], eInit:[0.4659], init state:[ 5  7 50  0  0  0], end state:[ 0  7 50  0  0  0]
INFO:Reinforcement.Functions:episode: 78, score:[2784.67], loss:[5.33793], sequence:[3], random actions:[74], eInit:[0.4612], init state:[ 6 12 54  0  0  0], end state:[ 1 12 54  0  0  0]
INFO:Reinforcement.Functions:episode: 79, score:[2798.67], loss:[5.27014], sequence:[4], random actions:[71], eInit:[0.4566], init state:[ 4  2 49  0  0  0], end state:[ 6  2 49  0  0  0]
INFO:Reinforcement.Functions:episode: 80, score:[2750.67], loss:[5.10724], sequence:[5], random actions:[72], eInit:[0.4520], init state:[ 6 14 51  0  0  0], end state:[ 1 14 51  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2800.0000000000005, [47]) , maxSequence:(13, [74])
INFO:Reinforcement.Functions:episode: 81, score:[2784.00], loss:[5.10095], sequence:[6], random actions:[62], eInit:[0.4475], init state:[ 3 22 29  1  0  0], end state:[ 5 22 29  1  0  0]
INFO:Reinforcement.Functions:episode: 82, score:[2793.33], loss:[4.87010], sequence:[7], random actions:[64], eInit:[0.4430], init state:[ 3 23  1  1  0  0], end state:[ 5 23  1  1  0  0]
INFO:Reinforcement.Functions:episode: 83, score:[2781.33], loss:[4.77011], sequence:[8], random actions:[67], eInit:[0.4386], init state:[ 1 15 45  0  0  0], end state:[ 3 15 45  0  0  0]
INFO:Reinforcement.Functions:episode: 84, score:[2742.00], loss:[4.68665], sequence:[9], random actions:[72], eInit:[0.4342], init state:[ 6 23 16  1  0  0], end state:[ 1 23 16  1  0  0]
INFO:Reinforcement.Functions:episode: 85, score:[2800.67], loss:[4.70554], sequence:[10], random actions:[71], eInit:[0.4299], init state:[ 3 22 46  1  0  0], end state:[ 5 22 46  1  0  0]
INFO:Reinforcement.Functions:episode: 86, score:[2768.67], loss:[4.30037], sequence:[11], random actions:[69], eInit:[0.4256], init state:[ 5  2 22  0  0  0], end state:[ 0  2 22  0  0  0]
INFO:Reinforcement.Functions:episode: 87, score:[2764.00], loss:[4.35318], sequence:[12], random actions:[68], eInit:[0.4213], init state:[ 4 12 40  1  1  0], end state:[ 6 12 40  0  0  0]
INFO:Reinforcement.Functions:episode: 88, score:[2738.00], loss:[4.48958], sequence:[13], random actions:[70], eInit:[0.4171], init state:[ 5  4 52  0  0  0], end state:[ 0  4 52  0  0  0]
INFO:Reinforcement.Functions:episode: 89, score:[2806.67], loss:[3.92971], sequence:[14], random actions:[58], eInit:[0.4129], init state:[ 4 19 42  0  0  0], end state:[ 6 19 42  0  0  0]
INFO:Reinforcement.Functions:episode: 90, score:[2786.00], loss:[4.13326], sequence:[15], random actions:[60], eInit:[0.4088], init state:[ 3 20 40  1  1  0], end state:[ 5 20 40  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2806.6666666666642, [89]) , maxSequence:(15, [90])
INFO:Reinforcement.Functions:episode: 91, score:[2754.00], loss:[4.05238], sequence:[16], random actions:[53], eInit:[0.4047], init state:[ 6  1 35  0  0  0], end state:[ 1  1 35  0  0  0]
INFO:Reinforcement.Functions:episode: 92, score:[2746.67], loss:[4.22735], sequence:[17], random actions:[74], eInit:[0.4007], init state:[ 4 12 43  1  1  0], end state:[ 6 12 43  0  0  0]
INFO:Reinforcement.Functions:episode: 93, score:[2779.33], loss:[4.03251], sequence:[18], random actions:[59], eInit:[0.3967], init state:[ 2 14 45  0  0  0], end state:[ 4 14 45  0  0  0]
INFO:Reinforcement.Functions:episode: 94, score:[2788.67], loss:[4.09385], sequence:[19], random actions:[51], eInit:[0.3927], init state:[ 1 13 30  0  0  0], end state:[ 3 13 30  0  0  0]
INFO:Reinforcement.Functions:episode: 95, score:[2788.67], loss:[4.79782], sequence:[20], random actions:[68], eInit:[0.3888], init state:[ 3  8 55  1  1  0], end state:[ 5  8 55  0  0  0]
INFO:Reinforcement.Functions:episode: 96, score:[2756.00], loss:[4.24482], sequence:[21], random actions:[59], eInit:[0.3849], init state:[ 5 12 14  0  0  0], end state:[ 0 12 14  0  0  0]
INFO:Reinforcement.Functions:episode: 97, score:[2788.00], loss:[4.32870], sequence:[22], random actions:[57], eInit:[0.3810], init state:[ 0 17  1  0  0  0], end state:[ 2 17  1  0  0  0]
INFO:Reinforcement.Functions:episode: 98, score:[2786.00], loss:[4.14956], sequence:[23], random actions:[69], eInit:[0.3772], init state:[4 4 0 0 0 0], end state:[6 4 0 0 0 0]
INFO:Reinforcement.Functions:episode: 99, score:[2807.33], loss:[4.04617], sequence:[24], random actions:[55], eInit:[0.3735], init state:[ 1 15 37  0  0  0], end state:[ 3 15 37  0  0  0]
INFO:Reinforcement.Functions:episode: 100, score:[2802.67], loss:[4.30706], sequence:[25], random actions:[55], eInit:[0.3697], init state:[ 3  5 19  0  0  0], end state:[ 5  5 19  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2807.333333333334, [99]) , maxSequence:(25, [100])
INFO:Reinforcement.Functions:episode: 101, score:[2802.00], loss:[3.98580], sequence:[26], random actions:[63], eInit:[0.3660], init state:[ 0 23 46  1  0  0], end state:[ 2 23 46  1  0  0]
INFO:Reinforcement.Functions:episode: 102, score:[2809.33], loss:[4.33791], sequence:[27], random actions:[55], eInit:[0.3624], init state:[ 0 22 58  1  0  0], end state:[ 2 22 58  1  0  0]
INFO:Reinforcement.Functions:episode: 103, score:[2816.67], loss:[4.15398], sequence:[28], random actions:[57], eInit:[0.3587], init state:[ 0  0 31  0  0  1], end state:[ 2  0 31  0  0  1]
INFO:Reinforcement.Functions:episode: 104, score:[2817.33], loss:[4.14874], sequence:[29], random actions:[59], eInit:[0.3552], init state:[ 0 21 54  1  0  0], end state:[ 2 21 54  1  0  0]
INFO:Reinforcement.Functions:episode: 105, score:[2774.67], loss:[3.92923], sequence:[30], random actions:[62], eInit:[0.3516], init state:[ 2 10 36  0  0  0], end state:[ 4 10 36  1  1  0]
INFO:Reinforcement.Functions:episode: 106, score:[2789.33], loss:[4.06659], sequence:[31], random actions:[51], eInit:[0.3481], init state:[ 6 18 16  0  0  0], end state:[ 1 18 16  0  0  0]
INFO:Reinforcement.Functions:episode: 107, score:[2762.00], loss:[4.26454], sequence:[32], random actions:[66], eInit:[0.3446], init state:[ 6  5 24  0  0  0], end state:[ 1  5 24  0  0  0]
INFO:Reinforcement.Functions:episode: 108, score:[2797.33], loss:[3.96740], sequence:[33], random actions:[65], eInit:[0.3412], init state:[ 3 16 45  0  0  0], end state:[ 5 16 45  0  0  0]
INFO:Reinforcement.Functions:episode: 109, score:[2824.00], loss:[3.66028], sequence:[34], random actions:[46], eInit:[0.3378], init state:[0 1 0 0 0 1], end state:[2 1 0 0 0 1]
INFO:Reinforcement.Functions:episode: 110, score:[2806.67], loss:[3.43767], sequence:[35], random actions:[57], eInit:[0.3344], init state:[ 1 21 56  1  0  0], end state:[ 3 21 56  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2824.0, [109]) , maxSequence:(35, [110])
INFO:Reinforcement.Functions:episode: 111, score:[2816.67], loss:[3.29952], sequence:[36], random actions:[50], eInit:[0.3310], init state:[ 2 13 57  0  0  0], end state:[ 4 13 57  0  0  0]
INFO:Reinforcement.Functions:episode: 112, score:[2754.67], loss:[3.92147], sequence:[37], random actions:[61], eInit:[0.3277], init state:[ 6 19 18  0  0  0], end state:[ 1 19 18  0  0  0]
INFO:Reinforcement.Functions:episode: 113, score:[2808.67], loss:[3.32846], sequence:[38], random actions:[48], eInit:[0.3244], init state:[ 5  9 19  0  0  0], end state:[ 0  9 19  0  0  0]
INFO:Reinforcement.Functions:episode: 114, score:[2826.00], loss:[3.10483], sequence:[39], random actions:[50], eInit:[0.3212], init state:[ 0 12 13  0  0  0], end state:[ 2 12 13  0  0  0]
INFO:Reinforcement.Functions:episode: 115, score:[2740.67], loss:[3.38271], sequence:[40], random actions:[65], eInit:[0.3180], init state:[ 4  8 18  0  0  0], end state:[ 6  8 18  1  0  0]
INFO:Reinforcement.Functions:episode: 116, score:[2780.00], loss:[3.43538], sequence:[41], random actions:[54], eInit:[0.3148], init state:[ 6 17 19  0  0  0], end state:[ 1 17 19  0  0  0]
INFO:Reinforcement.Functions:episode: 117, score:[2780.67], loss:[3.23907], sequence:[42], random actions:[48], eInit:[0.3117], init state:[ 4  2 52  0  0  0], end state:[ 6  2 52  0  0  0]
INFO:Reinforcement.Functions:episode: 118, score:[2783.33], loss:[3.32095], sequence:[43], random actions:[70], eInit:[0.3085], init state:[ 1  4 12  0  0  0], end state:[ 3  4 12  0  0  0]
INFO:Reinforcement.Functions:episode: 119, score:[2822.67], loss:[3.23157], sequence:[44], random actions:[39], eInit:[0.3055], init state:[ 1  7 21  0  0  0], end state:[ 3  7 21  0  0  0]
INFO:Reinforcement.Functions:episode: 120, score:[2721.33], loss:[3.24853], sequence:[0], random actions:[41], eInit:[0.3024], init state:[5 5 2 0 0 0], end state:[0 5 2 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2826.0, [114]) , maxSequence:(44, [119])
INFO:Reinforcement.Functions:episode: 121, score:[2748.67], loss:[3.14623], sequence:[1], random actions:[60], eInit:[0.2994], init state:[ 4  5 12  0  0  0], end state:[ 6  5 12  0  0  0]
INFO:Reinforcement.Functions:episode: 122, score:[2752.67], loss:[3.56209], sequence:[2], random actions:[74], eInit:[0.2964], init state:[ 3  9 11  0  0  0], end state:[ 5  9 11  0  0  0]
INFO:Reinforcement.Functions:episode: 123, score:[2818.67], loss:[3.07780], sequence:[3], random actions:[51], eInit:[0.2934], init state:[ 6 12 52  0  0  0], end state:[ 1 12 52  0  0  0]
INFO:Reinforcement.Functions:episode: 124, score:[2814.00], loss:[2.94901], sequence:[4], random actions:[56], eInit:[0.2905], init state:[ 6  2 51  0  0  0], end state:[ 1  2 51  0  0  0]
INFO:Reinforcement.Functions:episode: 125, score:[2826.67], loss:[2.96768], sequence:[5], random actions:[48], eInit:[0.2876], init state:[ 6 21 59  1  0  0], end state:[ 1 21 59  1  0  0]
INFO:Reinforcement.Functions:episode: 126, score:[2786.00], loss:[2.88045], sequence:[6], random actions:[60], eInit:[0.2847], init state:[ 1 10 13  0  0  0], end state:[ 3 10 13  0  0  0]
INFO:Reinforcement.Functions:episode: 127, score:[2803.33], loss:[2.95692], sequence:[7], random actions:[44], eInit:[0.2819], init state:[ 5  8 30  0  0  0], end state:[ 0  8 30  1  1  0]
INFO:Reinforcement.Functions:episode: 128, score:[2807.33], loss:[2.82819], sequence:[8], random actions:[54], eInit:[0.2790], init state:[ 0 22 47  1  0  0], end state:[ 2 22 47  1  0  0]
INFO:Reinforcement.Functions:episode: 129, score:[2789.33], loss:[2.68444], sequence:[9], random actions:[58], eInit:[0.2763], init state:[6 9 3 0 0 0], end state:[1 9 3 0 0 0]
INFO:Reinforcement.Functions:episode: 130, score:[2766.67], loss:[2.65904], sequence:[10], random actions:[57], eInit:[0.2735], init state:[ 2 13 40  0  0  0], end state:[ 4 13 40  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2826.666666666667, [125]) , maxSequence:(44, [119])
INFO:Reinforcement.Functions:episode: 131, score:[2806.67], loss:[2.98289], sequence:[11], random actions:[54], eInit:[0.2708], init state:[ 2 10 40  0  0  0], end state:[ 4 10 40  1  1  0]
INFO:Reinforcement.Functions:episode: 132, score:[2776.67], loss:[3.23369], sequence:[12], random actions:[47], eInit:[0.2680], init state:[ 2 19 45  0  0  0], end state:[ 4 19 45  0  0  0]
INFO:Reinforcement.Functions:episode: 133, score:[2827.33], loss:[2.68566], sequence:[13], random actions:[47], eInit:[0.2654], init state:[ 6 12 54  0  0  0], end state:[ 1 12 54  0  0  0]
INFO:Reinforcement.Functions:episode: 134, score:[2800.67], loss:[2.53948], sequence:[14], random actions:[52], eInit:[0.2627], init state:[ 1 12 27  0  0  0], end state:[ 3 12 27  0  0  0]
INFO:Reinforcement.Functions:episode: 135, score:[2797.33], loss:[2.34748], sequence:[15], random actions:[64], eInit:[0.2601], init state:[ 6 22 24  1  0  0], end state:[ 1 22 24  1  0  0]
INFO:Reinforcement.Functions:episode: 136, score:[2778.67], loss:[2.63103], sequence:[16], random actions:[58], eInit:[0.2575], init state:[ 5 10 42  0  0  0], end state:[ 0 10 42  0  0  0]
INFO:Reinforcement.Functions:episode: 137, score:[2796.00], loss:[2.76882], sequence:[17], random actions:[51], eInit:[0.2549], init state:[ 1  4 34  0  0  0], end state:[ 3  4 34  0  0  0]
INFO:Reinforcement.Functions:episode: 138, score:[2757.33], loss:[2.65068], sequence:[18], random actions:[46], eInit:[0.2524], init state:[ 4  9 22  0  0  0], end state:[ 6  9 22  0  0  0]
INFO:Reinforcement.Functions:episode: 139, score:[2795.33], loss:[2.99103], sequence:[19], random actions:[54], eInit:[0.2498], init state:[ 6 19 31  0  0  0], end state:[ 1 19 31  0  0  0]
INFO:Reinforcement.Functions:episode: 140, score:[2775.33], loss:[2.97294], sequence:[20], random actions:[48], eInit:[0.2473], init state:[ 5  4 56  0  0  0], end state:[ 0  4 56  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2827.333333333334, [133]) , maxSequence:(44, [119])
INFO:Reinforcement.Functions:episode: 141, score:[2832.00], loss:[2.69355], sequence:[21], random actions:[42], eInit:[0.2449], init state:[ 0  5 46  0  0  0], end state:[ 2  5 46  0  0  0]
INFO:Reinforcement.Functions:episode: 142, score:[2814.00], loss:[2.60861], sequence:[22], random actions:[47], eInit:[0.2424], init state:[ 0  0 13  1  0  0], end state:[ 2  0 13  1  0  0]
INFO:Reinforcement.Functions:episode: 143, score:[2793.33], loss:[2.51800], sequence:[23], random actions:[48], eInit:[0.2400], init state:[ 3  7 24  0  0  0], end state:[ 5  7 24  0  0  0]
INFO:Reinforcement.Functions:episode: 144, score:[2817.33], loss:[2.58829], sequence:[24], random actions:[51], eInit:[0.2376], init state:[ 6  3 10  0  0  0], end state:[ 1  3 10  0  0  0]
INFO:Reinforcement.Functions:episode: 145, score:[2794.67], loss:[2.63356], sequence:[25], random actions:[52], eInit:[0.2352], init state:[ 3 19  0  0  0  0], end state:[ 5 19  0  1  1  0]
INFO:Reinforcement.Functions:episode: 146, score:[2826.67], loss:[2.69474], sequence:[26], random actions:[43], eInit:[0.2329], init state:[ 3  7 42  0  0  0], end state:[ 5  7 42  0  0  0]
INFO:Reinforcement.Functions:episode: 147, score:[2750.00], loss:[2.73808], sequence:[27], random actions:[49], eInit:[0.2305], init state:[ 3 20  4  0  0  0], end state:[ 5 20  4  1  0  0]
INFO:Reinforcement.Functions:episode: 148, score:[2829.33], loss:[2.73797], sequence:[28], random actions:[44], eInit:[0.2282], init state:[ 6  9 34  0  0  0], end state:[ 1  9 34  0  0  0]
INFO:Reinforcement.Functions:episode: 149, score:[2804.00], loss:[2.40855], sequence:[29], random actions:[51], eInit:[0.2259], init state:[5 1 0 0 0 0], end state:[0 1 0 0 0 1]
INFO:Reinforcement.Functions:episode: 150, score:[2762.67], loss:[2.81742], sequence:[30], random actions:[49], eInit:[0.2237], init state:[ 3 11 33  0  0  0], end state:[ 5 11 33  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2832.0000000000005, [141]) , maxSequence:(44, [119])
INFO:Reinforcement.Functions:episode: 151, score:[2797.33], loss:[2.72742], sequence:[31], random actions:[54], eInit:[0.2215], init state:[ 0  9 27  0  0  0], end state:[ 2  9 27  0  0  0]
INFO:Reinforcement.Functions:episode: 152, score:[2818.00], loss:[2.76790], sequence:[32], random actions:[51], eInit:[0.2192], init state:[3 9 3 0 0 0], end state:[5 9 3 0 0 0]
INFO:Reinforcement.Functions:episode: 153, score:[2800.00], loss:[2.69172], sequence:[33], random actions:[43], eInit:[0.2170], init state:[ 4 15 36  0  0  0], end state:[ 6 15 36  0  0  0]
INFO:Reinforcement.Functions:episode: 154, score:[2834.67], loss:[2.33673], sequence:[34], random actions:[37], eInit:[0.2149], init state:[ 6 12 53  0  0  0], end state:[ 1 12 53  0  0  0]
INFO:Reinforcement.Functions:episode: 155, score:[2813.33], loss:[2.35629], sequence:[35], random actions:[53], eInit:[0.2127], init state:[ 6 10 59  0  0  0], end state:[ 1 10 59  0  0  0]
INFO:Reinforcement.Functions:episode: 156, score:[2803.33], loss:[2.55149], sequence:[36], random actions:[56], eInit:[0.2106], init state:[ 6 20 38  1  1  0], end state:[ 1 20 38  1  1  0]
INFO:Reinforcement.Functions:episode: 157, score:[2820.67], loss:[2.41957], sequence:[37], random actions:[47], eInit:[0.2085], init state:[ 3 16  4  0  0  0], end state:[ 5 16  4  0  0  0]
INFO:Reinforcement.Functions:episode: 158, score:[2827.33], loss:[2.00966], sequence:[38], random actions:[48], eInit:[0.2064], init state:[ 1  4 59  0  0  0], end state:[ 3  4 59  0  0  0]
INFO:Reinforcement.Functions:episode: 159, score:[2820.67], loss:[2.19467], sequence:[39], random actions:[39], eInit:[0.2043], init state:[ 2  7 34  0  0  0], end state:[ 4  7 34  0  0  0]
INFO:Reinforcement.Functions:episode: 160, score:[2793.33], loss:[2.56199], sequence:[40], random actions:[53], eInit:[0.2023], init state:[ 4 11 36  1  1  0], end state:[ 6 11 36  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2834.666666666667, [154]) , maxSequence:(44, [119])
INFO:Reinforcement.Functions:episode: 161, score:[2836.00], loss:[2.34291], sequence:[41], random actions:[40], eInit:[0.2003], init state:[ 3  0 30  0  0  1], end state:[ 5  0 30  0  0  0]
INFO:Reinforcement.Functions:episode: 162, score:[2809.33], loss:[2.32132], sequence:[42], random actions:[42], eInit:[0.1983], init state:[ 0 18 24  0  0  0], end state:[ 2 18 24  0  0  0]
INFO:Reinforcement.Functions:episode: 163, score:[2830.00], loss:[2.29173], sequence:[43], random actions:[45], eInit:[0.1963], init state:[ 1  2 34  0  0  0], end state:[ 3  2 34  0  0  0]
INFO:Reinforcement.Functions:episode: 164, score:[2762.67], loss:[3.05141], sequence:[44], random actions:[50], eInit:[0.1943], init state:[ 5 14 54  0  0  0], end state:[ 0 14 54  0  0  0]
INFO:Reinforcement.Functions:episode: 165, score:[2811.33], loss:[2.28891], sequence:[45], random actions:[47], eInit:[0.1924], init state:[ 6 18 45  0  0  0], end state:[ 1 18 45  0  0  0]
INFO:Reinforcement.Functions:episode: 166, score:[2824.00], loss:[2.10396], sequence:[46], random actions:[48], eInit:[0.1905], init state:[ 3 13 11  0  0  0], end state:[ 5 13 11  0  0  0]
INFO:Reinforcement.Functions:episode: 167, score:[2791.33], loss:[2.41870], sequence:[47], random actions:[52], eInit:[0.1886], init state:[ 6  6 20  0  0  0], end state:[ 1  6 20  0  0  0]
INFO:Reinforcement.Functions:episode: 168, score:[2824.67], loss:[2.22083], sequence:[48], random actions:[44], eInit:[0.1867], init state:[ 5 15 14  0  0  0], end state:[ 0 15 14  0  0  0]
INFO:Reinforcement.Functions:episode: 169, score:[2820.67], loss:[2.31457], sequence:[49], random actions:[41], eInit:[0.1848], init state:[ 2 10 26  0  0  0], end state:[ 4 10 26  1  1  0]
INFO:Reinforcement.Functions:episode: 170, score:[2805.33], loss:[2.24655], sequence:[50], random actions:[40], eInit:[0.1830], init state:[ 6 18 20  0  0  0], end state:[ 1 18 20  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2836.0000000000005, [161]) , maxSequence:(50, [170])
INFO:Reinforcement.Functions:episode: 171, score:[2800.67], loss:[2.20753], sequence:[51], random actions:[48], eInit:[0.1811], init state:[ 5  2 29  0  0  0], end state:[ 0  2 29  0  0  0]
INFO:Reinforcement.Functions:episode: 172, score:[2827.33], loss:[2.38976], sequence:[52], random actions:[44], eInit:[0.1793], init state:[ 0  1 11  0  0  0], end state:[ 2  1 11  0  0  0]
INFO:Reinforcement.Functions:episode: 173, score:[2812.00], loss:[2.15375], sequence:[53], random actions:[51], eInit:[0.1775], init state:[ 6  0 13  1  0  0], end state:[ 1  0 13  1  0  0]
INFO:Reinforcement.Functions:episode: 174, score:[2744.00], loss:[2.57948], sequence:[54], random actions:[57], eInit:[0.1757], init state:[ 3 11 27  0  0  0], end state:[ 5 11 27  0  0  0]
INFO:Reinforcement.Functions:episode: 175, score:[2800.67], loss:[2.58510], sequence:[55], random actions:[37], eInit:[0.1740], init state:[ 6  8 36  1  1  0], end state:[ 1  8 36  1  1  0]
INFO:Reinforcement.Functions:episode: 176, score:[2828.00], loss:[2.30069], sequence:[56], random actions:[39], eInit:[0.1722], init state:[ 6  8 45  1  1  0], end state:[ 1  8 45  1  1  0]
INFO:Reinforcement.Functions:episode: 177, score:[2785.33], loss:[2.74310], sequence:[57], random actions:[54], eInit:[0.1705], init state:[ 4  9 25  0  0  0], end state:[ 6  9 25  0  0  0]
INFO:Reinforcement.Functions:episode: 178, score:[2808.00], loss:[2.30266], sequence:[58], random actions:[36], eInit:[0.1688], init state:[ 6 10 43  0  0  0], end state:[ 1 10 43  0  0  0]
INFO:Reinforcement.Functions:episode: 179, score:[2813.33], loss:[2.39635], sequence:[59], random actions:[34], eInit:[0.1671], init state:[ 3  0 57  0  0  1], end state:[ 5  0 57  0  0  1]
INFO:Reinforcement.Functions:episode: 180, score:[2818.00], loss:[2.56178], sequence:[60], random actions:[35], eInit:[0.1655], init state:[ 3  7 27  0  0  0], end state:[ 5  7 27  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2836.0000000000005, [161]) , maxSequence:(60, [180])
INFO:Reinforcement.Functions:episode: 181, score:[2803.33], loss:[2.29225], sequence:[61], random actions:[39], eInit:[0.1638], init state:[ 6 12 41  0  0  0], end state:[ 1 12 41  0  0  0]
INFO:Reinforcement.Functions:episode: 182, score:[2820.00], loss:[2.31912], sequence:[62], random actions:[49], eInit:[0.1622], init state:[ 5  3 26  0  0  0], end state:[ 0  3 26  0  0  0]
INFO:Reinforcement.Functions:episode: 183, score:[2832.67], loss:[2.40117], sequence:[63], random actions:[41], eInit:[0.1605], init state:[ 3 15 27  0  0  0], end state:[ 5 15 27  0  0  0]
INFO:Reinforcement.Functions:episode: 184, score:[2767.33], loss:[2.32596], sequence:[64], random actions:[45], eInit:[0.1589], init state:[ 4 19 33  0  0  0], end state:[ 6 19 33  0  0  0]
INFO:Reinforcement.Functions:episode: 185, score:[2808.67], loss:[2.31536], sequence:[65], random actions:[42], eInit:[0.1574], init state:[ 6 22 32  1  0  0], end state:[ 1 22 32  1  0  0]
INFO:Reinforcement.Functions:episode: 186, score:[2810.67], loss:[2.32090], sequence:[66], random actions:[46], eInit:[0.1558], init state:[ 2 19 28  0  0  0], end state:[ 4 19 28  0  0  0]
INFO:Reinforcement.Functions:episode: 187, score:[2831.33], loss:[2.05746], sequence:[67], random actions:[45], eInit:[0.1542], init state:[ 1 16 35  0  0  0], end state:[ 3 16 35  0  0  0]
INFO:Reinforcement.Functions:episode: 188, score:[2828.67], loss:[2.04883], sequence:[68], random actions:[38], eInit:[0.1527], init state:[ 0  7 42  0  0  0], end state:[ 2  7 42  0  0  0]
INFO:Reinforcement.Functions:episode: 189, score:[2757.33], loss:[2.58664], sequence:[69], random actions:[44], eInit:[0.1512], init state:[4 0 7 1 0 0], end state:[6 0 7 1 0 0]
INFO:Reinforcement.Functions:episode: 190, score:[2782.67], loss:[2.55748], sequence:[70], random actions:[43], eInit:[0.1496], init state:[5 0 5 0 0 0], end state:[0 0 5 1 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2836.0000000000005, [161]) , maxSequence:(70, [190])
INFO:Reinforcement.Functions:episode: 191, score:[2832.00], loss:[2.20114], sequence:[71], random actions:[44], eInit:[0.1481], init state:[3 6 9 0 0 0], end state:[5 6 9 0 0 0]
INFO:Reinforcement.Functions:episode: 192, score:[2817.33], loss:[2.40535], sequence:[72], random actions:[46], eInit:[0.1467], init state:[ 1 12 10  0  0  0], end state:[ 3 12 10  0  0  0]
INFO:Reinforcement.Functions:episode: 193, score:[2784.67], loss:[2.11302], sequence:[73], random actions:[56], eInit:[0.1452], init state:[ 2  3 51  0  0  0], end state:[ 4  3 51  0  0  0]
INFO:Reinforcement.Functions:episode: 194, score:[2837.33], loss:[2.16816], sequence:[74], random actions:[36], eInit:[0.1437], init state:[ 2  2 58  0  0  0], end state:[ 4  2 58  0  0  0]
INFO:Reinforcement.Functions:episode: 195, score:[2822.00], loss:[2.05374], sequence:[75], random actions:[40], eInit:[0.1423], init state:[ 0  0 48  0  0  1], end state:[ 2  0 48  0  0  1]
INFO:Reinforcement.Functions:episode: 196, score:[2766.00], loss:[2.26037], sequence:[76], random actions:[38], eInit:[0.1409], init state:[ 6 18 42  0  0  0], end state:[ 1 18 42  0  0  0]
INFO:Reinforcement.Functions:episode: 197, score:[2782.00], loss:[2.27204], sequence:[77], random actions:[47], eInit:[0.1395], init state:[ 5  0 56  0  0  0], end state:[ 0  0 56  0  0  1]
INFO:Reinforcement.Functions:episode: 198, score:[2836.67], loss:[1.78926], sequence:[78], random actions:[30], eInit:[0.1381], init state:[ 2  0 56  0  0  1], end state:[ 4  0 56  1  0  1]
INFO:Reinforcement.Functions:episode: 199, score:[2836.00], loss:[1.69953], sequence:[79], random actions:[36], eInit:[0.1367], init state:[ 1 16 35  0  0  0], end state:[ 3 16 35  0  0  0]
INFO:Reinforcement.Functions:episode: 200, score:[2830.00], loss:[1.62635], sequence:[80], random actions:[46], eInit:[0.1353], init state:[ 1 12 14  0  0  0], end state:[ 3 12 14  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2837.333333333333, [194]) , maxSequence:(80, [200])
INFO:Reinforcement.Functions:episode: 201, score:[2814.67], loss:[1.84697], sequence:[81], random actions:[42], eInit:[0.1340], init state:[ 3  9 15  0  0  0], end state:[ 5  9 15  0  0  0]
INFO:Reinforcement.Functions:episode: 202, score:[2806.00], loss:[1.70119], sequence:[82], random actions:[50], eInit:[0.1326], init state:[ 5 18 29  1  1  0], end state:[ 0 18 29  0  0  0]
INFO:Reinforcement.Functions:episode: 203, score:[2811.33], loss:[1.99421], sequence:[83], random actions:[42], eInit:[0.1313], init state:[ 1 20  9  0  0  0], end state:[ 3 20  9  0  0  0]
INFO:Reinforcement.Functions:episode: 204, score:[2804.00], loss:[1.89703], sequence:[84], random actions:[36], eInit:[0.1300], init state:[ 3 22 16  1  0  0], end state:[ 5 22 16  1  0  0]
INFO:Reinforcement.Functions:episode: 205, score:[2794.00], loss:[2.10571], sequence:[85], random actions:[36], eInit:[0.1287], init state:[5 1 2 0 0 0], end state:[0 1 2 0 0 1]
INFO:Reinforcement.Functions:episode: 206, score:[2841.33], loss:[1.90731], sequence:[86], random actions:[25], eInit:[0.1274], init state:[ 4  6 47  0  0  0], end state:[ 6  6 47  0  0  0]
INFO:Reinforcement.Functions:episode: 207, score:[2799.33], loss:[2.20141], sequence:[87], random actions:[50], eInit:[0.1261], init state:[ 5 17  5  0  0  0], end state:[ 0 17  5  0  0  0]
INFO:Reinforcement.Functions:episode: 208, score:[2832.67], loss:[1.83695], sequence:[88], random actions:[37], eInit:[0.1249], init state:[ 5 14 27  0  0  0], end state:[ 0 14 27  0  0  0]
INFO:Reinforcement.Functions:episode: 209, score:[2836.00], loss:[1.88196], sequence:[89], random actions:[31], eInit:[0.1236], init state:[ 3 13 42  0  0  0], end state:[ 5 13 42  0  0  0]
INFO:Reinforcement.Functions:episode: 210, score:[2832.67], loss:[1.85702], sequence:[90], random actions:[43], eInit:[0.1224], init state:[0 4 0 0 0 0], end state:[2 4 0 0 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2841.3333333333344, [206]) , maxSequence:(90, [210])
INFO:Reinforcement.Functions:episode: 211, score:[2829.33], loss:[1.69565], sequence:[91], random actions:[29], eInit:[0.1212], init state:[ 4  0 13  1  0  0], end state:[ 6  0 13  1  0  0]
INFO:Reinforcement.Functions:episode: 212, score:[2832.00], loss:[1.88714], sequence:[92], random actions:[31], eInit:[0.1200], init state:[ 5  9 11  0  0  0], end state:[ 0  9 11  0  0  0]
INFO:Reinforcement.Functions:episode: 213, score:[2830.67], loss:[1.61615], sequence:[93], random actions:[36], eInit:[0.1188], init state:[ 3  4 10  0  0  0], end state:[ 5  4 10  0  0  0]
INFO:Reinforcement.Functions:episode: 214, score:[2833.33], loss:[1.63443], sequence:[94], random actions:[40], eInit:[0.1176], init state:[ 0 12 12  0  0  0], end state:[ 2 12 12  0  0  0]
INFO:Reinforcement.Functions:episode: 215, score:[2822.67], loss:[1.65614], sequence:[95], random actions:[48], eInit:[0.1164], init state:[ 6  9 35  0  0  0], end state:[ 1  9 35  0  0  0]
INFO:Reinforcement.Functions:episode: 216, score:[2810.00], loss:[1.65854], sequence:[96], random actions:[43], eInit:[0.1152], init state:[ 6  9 39  0  0  0], end state:[ 1  9 39  0  0  0]
INFO:Reinforcement.Functions:episode: 217, score:[2838.00], loss:[1.48952], sequence:[97], random actions:[37], eInit:[0.1141], init state:[ 0 14 12  0  0  0], end state:[ 2 14 12  0  0  0]
INFO:Reinforcement.Functions:episode: 218, score:[2844.00], loss:[1.46398], sequence:[98], random actions:[31], eInit:[0.1129], init state:[ 3  2 44  0  0  0], end state:[ 5  2 44  0  0  0]
INFO:Reinforcement.Functions:episode: 219, score:[2848.00], loss:[1.52961], sequence:[99], random actions:[29], eInit:[0.1118], init state:[ 3 12 10  0  0  0], end state:[ 5 12 10  0  0  0]
INFO:Reinforcement.Functions:episode: 220, score:[2842.67], loss:[1.49391], sequence:[100], random actions:[33], eInit:[0.1107], init state:[ 2 21 50  1  0  0], end state:[ 4 21 50  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2848.0000000000005, [219]) , maxSequence:(100, [220])
INFO:Reinforcement.Functions:episode: 221, score:[2839.33], loss:[1.52455], sequence:[101], random actions:[34], eInit:[0.1096], init state:[ 6 17  8  0  0  0], end state:[ 1 17  8  0  0  0]
INFO:Reinforcement.Functions:episode: 222, score:[2844.00], loss:[1.37847], sequence:[102], random actions:[30], eInit:[0.1085], init state:[ 0  9 32  0  0  0], end state:[ 2  9 32  0  0  0]
INFO:Reinforcement.Functions:episode: 223, score:[2820.67], loss:[1.35676], sequence:[103], random actions:[35], eInit:[0.1074], init state:[ 2  3 59  0  0  0], end state:[ 4  3 59  0  0  0]
INFO:Reinforcement.Functions:episode: 224, score:[2810.67], loss:[1.35183], sequence:[104], random actions:[24], eInit:[0.1063], init state:[ 2 23 42  1  0  0], end state:[ 4 23 42  0  0  0]
INFO:Reinforcement.Functions:episode: 225, score:[2764.00], loss:[1.79129], sequence:[105], random actions:[35], eInit:[0.1053], init state:[ 5 13  1  0  0  0], end state:[ 0 13  1  0  0  0]
INFO:Reinforcement.Functions:episode: 226, score:[2824.00], loss:[1.87699], sequence:[106], random actions:[34], eInit:[0.1042], init state:[1 6 7 0 0 0], end state:[3 6 7 0 0 0]
INFO:Reinforcement.Functions:episode: 227, score:[2794.00], loss:[1.82597], sequence:[107], random actions:[34], eInit:[0.1032], init state:[ 5 12 19  0  0  0], end state:[ 0 12 19  0  0  0]
INFO:Reinforcement.Functions:episode: 228, score:[2842.67], loss:[1.82292], sequence:[108], random actions:[27], eInit:[0.1021], init state:[ 0 15  9  0  0  0], end state:[ 2 15  9  0  0  0]
INFO:Reinforcement.Functions:episode: 229, score:[2822.00], loss:[1.55228], sequence:[109], random actions:[31], eInit:[0.1011], init state:[ 5 23  2  1  0  0], end state:[ 0 23  2  1  0  0]
INFO:Reinforcement.Functions:episode: 230, score:[2832.67], loss:[1.57256], sequence:[110], random actions:[34], eInit:[0.1001], init state:[ 5  8 27  0  0  0], end state:[ 0  8 27  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2848.0000000000005, [219]) , maxSequence:(110, [230])
INFO:Reinforcement.Functions:episode: 231, score:[2810.00], loss:[1.76538], sequence:[111], random actions:[34], eInit:[0.0991], init state:[ 4  1 36  0  0  0], end state:[ 6  1 36  0  0  0]
INFO:Reinforcement.Functions:episode: 232, score:[2827.33], loss:[1.76626], sequence:[112], random actions:[39], eInit:[0.0981], init state:[ 6 14 27  0  0  0], end state:[ 1 14 27  0  0  0]
INFO:Reinforcement.Functions:episode: 233, score:[2803.33], loss:[1.98904], sequence:[113], random actions:[41], eInit:[0.0971], init state:[ 2  6 44  0  0  0], end state:[ 4  6 44  0  0  0]
INFO:Reinforcement.Functions:episode: 234, score:[2784.00], loss:[2.19661], sequence:[114], random actions:[39], eInit:[0.0962], init state:[ 2 20 33  1  1  0], end state:[ 4 20 33  0  0  0]
INFO:Reinforcement.Functions:episode: 235, score:[2806.67], loss:[2.07611], sequence:[115], random actions:[33], eInit:[0.0952], init state:[ 5  0 35  0  0  0], end state:[ 0  0 35  0  0  1]
INFO:Reinforcement.Functions:episode: 236, score:[2851.33], loss:[1.90757], sequence:[116], random actions:[29], eInit:[0.0942], init state:[ 1 15 35  0  0  0], end state:[ 3 15 35  0  0  0]
INFO:Reinforcement.Functions:episode: 237, score:[2836.67], loss:[2.12811], sequence:[117], random actions:[33], eInit:[0.0933], init state:[ 6 13 35  0  0  0], end state:[ 1 13 35  0  0  0]
INFO:Reinforcement.Functions:episode: 238, score:[2815.33], loss:[1.96246], sequence:[118], random actions:[28], eInit:[0.0924], init state:[ 4 15 49  0  0  0], end state:[ 6 15 49  0  0  0]
INFO:Reinforcement.Functions:episode: 239, score:[2828.67], loss:[1.89418], sequence:[119], random actions:[39], eInit:[0.0914], init state:[5 2 7 0 0 0], end state:[0 2 7 0 0 0]
INFO:Reinforcement.Functions:episode: 240, score:[2836.00], loss:[2.10346], sequence:[120], random actions:[26], eInit:[0.0905], init state:[4 8 8 0 0 0], end state:[6 8 8 1 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(120, [240])
INFO:Reinforcement.Functions:episode: 241, score:[2848.00], loss:[1.90666], sequence:[121], random actions:[35], eInit:[0.0896], init state:[ 6 23 35  1  0  0], end state:[ 1 23 35  1  0  0]
INFO:Reinforcement.Functions:episode: 242, score:[2808.67], loss:[1.94422], sequence:[122], random actions:[36], eInit:[0.0887], init state:[ 5 16 26  0  0  0], end state:[ 0 16 26  0  0  0]
INFO:Reinforcement.Functions:episode: 243, score:[2793.33], loss:[1.91067], sequence:[123], random actions:[36], eInit:[0.0878], init state:[ 5  0 54  0  0  0], end state:[ 0  0 54  0  0  1]
INFO:Reinforcement.Functions:episode: 244, score:[2784.00], loss:[2.17491], sequence:[124], random actions:[38], eInit:[0.0870], init state:[ 5 16 10  0  0  0], end state:[ 0 16 10  0  0  0]
INFO:Reinforcement.Functions:episode: 245, score:[2807.33], loss:[1.90796], sequence:[125], random actions:[38], eInit:[0.0861], init state:[ 2 16  0  0  0  0], end state:[ 4 16  0  0  0  0]
INFO:Reinforcement.Functions:episode: 246, score:[2824.00], loss:[2.22316], sequence:[126], random actions:[38], eInit:[0.0852], init state:[ 4  6 19  0  0  0], end state:[ 6  6 19  0  0  0]
INFO:Reinforcement.Functions:episode: 247, score:[2836.00], loss:[1.96648], sequence:[127], random actions:[31], eInit:[0.0844], init state:[ 5 15  0  0  0  0], end state:[ 0 15  0  0  0  0]
INFO:Reinforcement.Functions:episode: 248, score:[2838.00], loss:[1.84721], sequence:[128], random actions:[36], eInit:[0.0835], init state:[ 0 19  6  0  0  0], end state:[ 2 19  6  0  0  0]
INFO:Reinforcement.Functions:episode: 249, score:[2802.67], loss:[1.93240], sequence:[129], random actions:[39], eInit:[0.0827], init state:[ 5 23 16  1  0  0], end state:[ 0 23 16  1  0  0]
INFO:Reinforcement.Functions:episode: 250, score:[2809.33], loss:[1.94241], sequence:[130], random actions:[36], eInit:[0.0819], init state:[ 2 15 15  0  0  0], end state:[ 4 15 15  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(130, [250])
INFO:Reinforcement.Functions:episode: 251, score:[2840.67], loss:[2.02542], sequence:[131], random actions:[32], eInit:[0.0811], init state:[ 1 19 52  0  0  0], end state:[ 3 19 52  0  0  0]
INFO:Reinforcement.Functions:episode: 252, score:[2838.67], loss:[1.81671], sequence:[132], random actions:[30], eInit:[0.0802], init state:[ 5 19 48  1  0  0], end state:[ 0 19 48  0  0  0]
INFO:Reinforcement.Functions:episode: 253, score:[2846.67], loss:[1.62218], sequence:[133], random actions:[26], eInit:[0.0794], init state:[ 5 18 50  1  1  0], end state:[ 0 18 50  0  0  0]
INFO:Reinforcement.Functions:episode: 254, score:[2810.67], loss:[1.85574], sequence:[134], random actions:[43], eInit:[0.0787], init state:[ 5 10 13  0  0  0], end state:[ 0 10 13  0  0  0]
INFO:Reinforcement.Functions:episode: 255, score:[2790.00], loss:[1.92583], sequence:[135], random actions:[33], eInit:[0.0779], init state:[ 2 21 42  1  0  0], end state:[ 4 21 42  0  0  0]
INFO:Reinforcement.Functions:episode: 256, score:[2849.33], loss:[2.05112], sequence:[136], random actions:[27], eInit:[0.0771], init state:[ 6 14 42  0  0  0], end state:[ 1 14 42  0  0  0]
INFO:Reinforcement.Functions:episode: 257, score:[2823.33], loss:[1.93908], sequence:[137], random actions:[41], eInit:[0.0763], init state:[ 5  2 22  0  0  0], end state:[ 0  2 22  0  0  0]
INFO:Reinforcement.Functions:episode: 258, score:[2834.00], loss:[1.80055], sequence:[138], random actions:[26], eInit:[0.0756], init state:[ 2 21 30  1  0  0], end state:[ 4 21 30  1  0  0]
INFO:Reinforcement.Functions:episode: 259, score:[2821.33], loss:[1.90321], sequence:[139], random actions:[33], eInit:[0.0748], init state:[ 5 11 22  0  0  0], end state:[ 0 11 22  0  0  0]
INFO:Reinforcement.Functions:episode: 260, score:[2822.00], loss:[1.94539], sequence:[140], random actions:[31], eInit:[0.0740], init state:[ 6  9 49  0  0  0], end state:[ 1  9 49  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(140, [260])
INFO:Reinforcement.Functions:episode: 261, score:[2847.33], loss:[1.86968], sequence:[141], random actions:[25], eInit:[0.0733], init state:[ 6 14 10  0  0  0], end state:[ 1 14 10  0  0  0]
INFO:Reinforcement.Functions:episode: 262, score:[2829.33], loss:[1.75381], sequence:[142], random actions:[27], eInit:[0.0726], init state:[ 6  6 47  0  0  0], end state:[ 1  6 47  0  0  0]
INFO:Reinforcement.Functions:episode: 263, score:[2841.33], loss:[1.68905], sequence:[143], random actions:[29], eInit:[0.0718], init state:[ 5 11 27  0  0  0], end state:[ 0 11 27  0  0  0]
INFO:Reinforcement.Functions:episode: 264, score:[2838.00], loss:[1.34961], sequence:[144], random actions:[26], eInit:[0.0711], init state:[6 9 9 0 0 0], end state:[1 9 9 0 0 0]
INFO:Reinforcement.Functions:episode: 265, score:[2838.67], loss:[1.31800], sequence:[145], random actions:[27], eInit:[0.0704], init state:[ 6 15 19  0  0  0], end state:[ 1 15 19  0  0  0]
INFO:Reinforcement.Functions:episode: 266, score:[2767.33], loss:[1.82387], sequence:[146], random actions:[32], eInit:[0.0697], init state:[ 3 20 51  1  1  0], end state:[ 5 20 51  1  0  0]
INFO:Reinforcement.Functions:episode: 267, score:[2847.33], loss:[1.36457], sequence:[147], random actions:[30], eInit:[0.0690], init state:[ 0  7 51  0  0  0], end state:[ 2  7 51  0  0  0]
INFO:Reinforcement.Functions:episode: 268, score:[2824.00], loss:[1.67294], sequence:[148], random actions:[35], eInit:[0.0683], init state:[ 2 19  6  0  0  0], end state:[ 4 19  6  0  0  0]
INFO:Reinforcement.Functions:episode: 269, score:[2782.00], loss:[1.91544], sequence:[149], random actions:[25], eInit:[0.0676], init state:[ 1 19 13  0  0  0], end state:[ 3 19 13  0  0  0]
INFO:Reinforcement.Functions:episode: 270, score:[2824.67], loss:[1.80357], sequence:[150], random actions:[36], eInit:[0.0670], init state:[ 6 14  3  0  0  0], end state:[ 1 14  3  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(150, [270])
INFO:Reinforcement.Functions:episode: 271, score:[2835.33], loss:[1.57505], sequence:[151], random actions:[34], eInit:[0.0663], init state:[ 2 10 45  0  0  0], end state:[ 4 10 45  1  1  0]
INFO:Reinforcement.Functions:episode: 272, score:[2830.00], loss:[1.58815], sequence:[152], random actions:[27], eInit:[0.0656], init state:[ 5 13 56  0  0  0], end state:[ 0 13 56  0  0  0]
INFO:Reinforcement.Functions:episode: 273, score:[2767.33], loss:[1.56848], sequence:[153], random actions:[32], eInit:[0.0650], init state:[ 3 23 51  1  0  0], end state:[ 5 23 51  1  0  0]
INFO:Reinforcement.Functions:episode: 274, score:[2776.00], loss:[1.74486], sequence:[154], random actions:[46], eInit:[0.0643], init state:[ 2  0 46  0  0  1], end state:[ 4  0 46  1  0  1]
INFO:Reinforcement.Functions:episode: 275, score:[2839.33], loss:[1.44830], sequence:[155], random actions:[29], eInit:[0.0637], init state:[ 2 13 11  0  0  0], end state:[ 4 13 11  1  1  0]
INFO:Reinforcement.Functions:episode: 276, score:[2850.00], loss:[1.44699], sequence:[156], random actions:[29], eInit:[0.0630], init state:[ 1 21 34  1  0  0], end state:[ 3 21 34  1  0  0]
INFO:Reinforcement.Functions:episode: 277, score:[2817.33], loss:[1.40031], sequence:[157], random actions:[30], eInit:[0.0624], init state:[ 5 17 52  0  0  0], end state:[ 0 17 52  0  0  0]
INFO:Reinforcement.Functions:episode: 278, score:[2832.00], loss:[1.39132], sequence:[158], random actions:[39], eInit:[0.0618], init state:[ 6 13 40  0  0  0], end state:[ 1 13 40  0  0  0]
INFO:Reinforcement.Functions:episode: 279, score:[2790.67], loss:[1.48516], sequence:[159], random actions:[42], eInit:[0.0612], init state:[ 5  4 33  0  0  0], end state:[ 0  4 33  0  0  0]
INFO:Reinforcement.Functions:episode: 280, score:[2843.33], loss:[1.27710], sequence:[160], random actions:[32], eInit:[0.0606], init state:[ 6  1 53  0  0  0], end state:[ 1  1 53  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(160, [280])
INFO:Reinforcement.Functions:episode: 281, score:[2848.00], loss:[1.17182], sequence:[161], random actions:[27], eInit:[0.0600], init state:[ 6 14  9  0  0  0], end state:[ 1 14  9  0  0  0]
INFO:Reinforcement.Functions:episode: 282, score:[2842.00], loss:[1.04989], sequence:[162], random actions:[33], eInit:[0.0594], init state:[ 0  9 34  0  0  0], end state:[ 2  9 34  0  0  0]
INFO:Reinforcement.Functions:episode: 283, score:[2835.33], loss:[1.00066], sequence:[163], random actions:[36], eInit:[0.0588], init state:[ 6 22 23  1  0  0], end state:[ 1 22 23  1  0  0]
INFO:Reinforcement.Functions:episode: 284, score:[2760.00], loss:[1.57656], sequence:[164], random actions:[33], eInit:[0.0582], init state:[ 3 19 51  0  0  0], end state:[ 5 19 51  1  0  0]
INFO:Reinforcement.Functions:episode: 285, score:[2846.00], loss:[1.56599], sequence:[165], random actions:[22], eInit:[0.0576], init state:[ 5  8 48  0  0  0], end state:[ 0  8 48  1  1  0]
INFO:Reinforcement.Functions:episode: 286, score:[2834.67], loss:[1.40316], sequence:[166], random actions:[31], eInit:[0.0570], init state:[ 2  6 33  0  0  0], end state:[ 4  6 33  0  0  0]
INFO:Reinforcement.Functions:episode: 287, score:[2825.33], loss:[1.48961], sequence:[167], random actions:[28], eInit:[0.0565], init state:[3 5 8 0 0 0], end state:[5 5 8 0 0 0]
INFO:Reinforcement.Functions:episode: 288, score:[2818.00], loss:[1.62331], sequence:[168], random actions:[33], eInit:[0.0559], init state:[ 6  5 12  0  0  0], end state:[ 1  5 12  0  0  0]
INFO:Reinforcement.Functions:episode: 289, score:[2819.33], loss:[1.45569], sequence:[169], random actions:[35], eInit:[0.0553], init state:[ 1 14 53  0  0  0], end state:[ 3 14 53  0  0  0]
INFO:Reinforcement.Functions:episode: 290, score:[2844.00], loss:[1.35817], sequence:[170], random actions:[29], eInit:[0.0548], init state:[ 1 20  5  0  0  0], end state:[ 3 20  5  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(170, [290])
INFO:Reinforcement.Functions:episode: 291, score:[2816.00], loss:[1.29628], sequence:[171], random actions:[25], eInit:[0.0542], init state:[ 6 14 36  0  0  0], end state:[ 1 14 36  0  0  0]
INFO:Reinforcement.Functions:episode: 292, score:[2849.33], loss:[1.15467], sequence:[172], random actions:[25], eInit:[0.0537], init state:[ 2  1 58  0  0  0], end state:[ 4  1 58  0  0  0]
INFO:Reinforcement.Functions:episode: 293, score:[2848.67], loss:[1.18427], sequence:[173], random actions:[28], eInit:[0.0531], init state:[ 2 22 15  1  0  0], end state:[ 4 22 15  0  0  0]
INFO:Reinforcement.Functions:episode: 294, score:[2846.00], loss:[1.15262], sequence:[174], random actions:[31], eInit:[0.0526], init state:[ 0 21 34  1  0  0], end state:[ 2 21 34  1  0  0]
INFO:Reinforcement.Functions:episode: 295, score:[2780.00], loss:[1.45918], sequence:[175], random actions:[31], eInit:[0.0521], init state:[ 4 12 48  1  1  0], end state:[ 6 12 48  0  0  0]
INFO:Reinforcement.Functions:episode: 296, score:[2810.67], loss:[1.59144], sequence:[176], random actions:[38], eInit:[0.0516], init state:[ 6  6 10  0  0  0], end state:[ 1  6 10  0  0  0]
INFO:Reinforcement.Functions:episode: 297, score:[2804.00], loss:[1.30199], sequence:[177], random actions:[35], eInit:[0.0511], init state:[ 3 10 30  0  0  0], end state:[ 5 10 30  0  0  0]
INFO:Reinforcement.Functions:episode: 298, score:[2842.67], loss:[1.17685], sequence:[178], random actions:[35], eInit:[0.0505], init state:[1 3 0 0 0 0], end state:[3 3 0 0 0 0]
INFO:Reinforcement.Functions:episode: 299, score:[2823.33], loss:[1.54805], sequence:[179], random actions:[32], eInit:[0.0500], init state:[ 3  7 49  0  0  0], end state:[ 5  7 49  0  0  0]
INFO:Reinforcement.Functions:episode: 300, score:[2811.33], loss:[1.50177], sequence:[180], random actions:[29], eInit:[0.0495], init state:[ 3 12 47  0  0  0], end state:[ 5 12 47  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(180, [300])
INFO:Reinforcement.Functions:episode: 301, score:[2844.00], loss:[1.33865], sequence:[181], random actions:[26], eInit:[0.0490], init state:[ 1 21 39  1  0  0], end state:[ 3 21 39  1  0  0]
INFO:Reinforcement.Functions:episode: 302, score:[2837.33], loss:[1.52373], sequence:[182], random actions:[35], eInit:[0.0486], init state:[ 6 20 33  1  1  0], end state:[ 1 20 33  1  1  0]
INFO:Reinforcement.Functions:episode: 303, score:[2850.67], loss:[1.24881], sequence:[183], random actions:[28], eInit:[0.0481], init state:[ 0 23 48  1  0  0], end state:[ 2 23 48  1  0  0]
INFO:Reinforcement.Functions:episode: 304, score:[2838.67], loss:[1.18265], sequence:[184], random actions:[28], eInit:[0.0476], init state:[ 0 17 41  0  0  0], end state:[ 2 17 41  0  0  0]
INFO:Reinforcement.Functions:episode: 305, score:[2847.33], loss:[1.32322], sequence:[185], random actions:[28], eInit:[0.0471], init state:[ 6 12 43  0  0  0], end state:[ 1 12 43  0  0  0]
INFO:Reinforcement.Functions:episode: 306, score:[2836.67], loss:[1.31444], sequence:[186], random actions:[32], eInit:[0.0466], init state:[ 6 16 46  0  0  0], end state:[ 1 16 46  0  0  0]
INFO:Reinforcement.Functions:episode: 307, score:[2848.00], loss:[1.32060], sequence:[187], random actions:[23], eInit:[0.0462], init state:[ 1 20 41  1  1  0], end state:[ 3 20 41  1  1  0]
INFO:Reinforcement.Functions:episode: 308, score:[2827.33], loss:[1.70867], sequence:[188], random actions:[27], eInit:[0.0457], init state:[ 5 18 10  1  1  0], end state:[ 0 18 10  0  0  0]
INFO:Reinforcement.Functions:episode: 309, score:[2818.67], loss:[1.87540], sequence:[189], random actions:[23], eInit:[0.0453], init state:[ 6  9 25  0  0  0], end state:[ 1  9 25  0  0  0]
INFO:Reinforcement.Functions:episode: 310, score:[2793.33], loss:[1.67840], sequence:[190], random actions:[31], eInit:[0.0448], init state:[ 4  7 46  0  0  0], end state:[ 6  7 46  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(190, [310])
INFO:Reinforcement.Functions:episode: 311, score:[2850.00], loss:[1.53806], sequence:[191], random actions:[28], eInit:[0.0444], init state:[ 0 20 29  0  0  0], end state:[ 2 20 29  0  0  0]
INFO:Reinforcement.Functions:episode: 312, score:[2808.67], loss:[1.89678], sequence:[192], random actions:[32], eInit:[0.0439], init state:[ 3 10 14  0  0  0], end state:[ 5 10 14  0  0  0]
INFO:Reinforcement.Functions:episode: 313, score:[2850.67], loss:[1.61775], sequence:[193], random actions:[25], eInit:[0.0435], init state:[ 1 11 32  0  0  0], end state:[ 3 11 32  0  0  0]
INFO:Reinforcement.Functions:episode: 314, score:[2830.67], loss:[1.78041], sequence:[194], random actions:[33], eInit:[0.0430], init state:[ 1 21 36  1  0  0], end state:[ 3 21 36  1  0  0]
INFO:Reinforcement.Functions:episode: 315, score:[2836.00], loss:[1.74591], sequence:[195], random actions:[24], eInit:[0.0426], init state:[3 2 0 0 0 0], end state:[5 2 0 0 0 0]
INFO:Reinforcement.Functions:episode: 316, score:[2839.33], loss:[1.54053], sequence:[196], random actions:[34], eInit:[0.0422], init state:[ 1  5 37  0  0  0], end state:[ 3  5 37  0  0  0]
INFO:Reinforcement.Functions:episode: 317, score:[2849.33], loss:[1.51909], sequence:[197], random actions:[26], eInit:[0.0418], init state:[ 1 11 46  0  0  0], end state:[ 3 11 46  0  0  0]
INFO:Reinforcement.Functions:episode: 318, score:[2825.33], loss:[1.70501], sequence:[198], random actions:[38], eInit:[0.0413], init state:[ 5 23 13  1  0  0], end state:[ 0 23 13  1  0  0]
INFO:Reinforcement.Functions:episode: 319, score:[2842.67], loss:[1.48830], sequence:[199], random actions:[24], eInit:[0.0409], init state:[ 1 22 18  1  0  0], end state:[ 3 22 18  1  0  0]
INFO:Reinforcement.Functions:episode: 320, score:[2840.00], loss:[1.48494], sequence:[200], random actions:[22], eInit:[0.0405], init state:[ 5 12 24  0  0  0], end state:[ 0 12 24  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(200, [320])
INFO:Reinforcement.Functions:episode: 321, score:[2833.33], loss:[1.35199], sequence:[201], random actions:[22], eInit:[0.0401], init state:[ 6 20 13  0  0  0], end state:[ 1 20 13  0  0  0]
INFO:Reinforcement.Functions:episode: 322, score:[2812.00], loss:[1.41942], sequence:[202], random actions:[32], eInit:[0.0397], init state:[ 2 13 53  0  0  0], end state:[ 4 13 53  0  0  0]
INFO:Reinforcement.Functions:episode: 323, score:[2835.33], loss:[1.60647], sequence:[203], random actions:[26], eInit:[0.0393], init state:[ 0  0 19  1  0  0], end state:[ 2  0 19  1  0  0]
INFO:Reinforcement.Functions:episode: 324, score:[2845.33], loss:[1.44503], sequence:[204], random actions:[33], eInit:[0.0389], init state:[ 0 18 51  0  0  0], end state:[ 2 18 51  0  0  0]
INFO:Reinforcement.Functions:episode: 325, score:[2844.00], loss:[1.29197], sequence:[205], random actions:[20], eInit:[0.0385], init state:[ 1 21 53  1  0  0], end state:[ 3 21 53  1  0  0]
INFO:Reinforcement.Functions:episode: 326, score:[2827.33], loss:[1.17450], sequence:[206], random actions:[31], eInit:[0.0381], init state:[ 0  9 37  0  0  0], end state:[ 2  9 37  0  0  0]
INFO:Reinforcement.Functions:episode: 327, score:[2784.00], loss:[1.34919], sequence:[207], random actions:[34], eInit:[0.0378], init state:[ 5  1 37  0  0  0], end state:[ 0  1 37  0  0  0]
INFO:Reinforcement.Functions:episode: 328, score:[2802.00], loss:[1.17613], sequence:[208], random actions:[32], eInit:[0.0374], init state:[ 2 20 34  1  1  0], end state:[ 4 20 34  0  0  0]
INFO:Reinforcement.Functions:episode: 329, score:[2848.67], loss:[1.37904], sequence:[209], random actions:[23], eInit:[0.0370], init state:[ 0 23 54  1  0  0], end state:[ 2 23 54  1  0  0]
INFO:Reinforcement.Functions:episode: 330, score:[2800.00], loss:[1.30918], sequence:[210], random actions:[36], eInit:[0.0366], init state:[ 5 11 52  0  0  0], end state:[ 0 11 52  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(210, [330])
INFO:Reinforcement.Functions:episode: 331, score:[2790.00], loss:[1.53911], sequence:[211], random actions:[30], eInit:[0.0363], init state:[ 2 15 52  0  0  0], end state:[ 4 15 52  0  0  0]
INFO:Reinforcement.Functions:episode: 332, score:[2833.33], loss:[1.48494], sequence:[212], random actions:[25], eInit:[0.0359], init state:[ 2  3 55  0  0  0], end state:[ 4  3 55  0  0  0]
INFO:Reinforcement.Functions:episode: 333, score:[2791.33], loss:[1.76706], sequence:[213], random actions:[22], eInit:[0.0356], init state:[ 4 22 22  0  0  0], end state:[ 6 22 22  1  0  0]
INFO:Reinforcement.Functions:episode: 334, score:[2810.00], loss:[1.51956], sequence:[214], random actions:[27], eInit:[0.0352], init state:[ 4 16 39  0  0  0], end state:[ 6 16 39  0  0  0]
INFO:Reinforcement.Functions:episode: 335, score:[2843.33], loss:[1.42660], sequence:[215], random actions:[28], eInit:[0.0348], init state:[ 4 22 25  0  0  0], end state:[ 6 22 25  1  0  0]
INFO:Reinforcement.Functions:episode: 336, score:[2841.33], loss:[1.45253], sequence:[216], random actions:[29], eInit:[0.0345], init state:[6 2 7 0 0 0], end state:[1 2 7 0 0 0]
INFO:Reinforcement.Functions:episode: 337, score:[2783.33], loss:[2.36987], sequence:[217], random actions:[26], eInit:[0.0342], init state:[ 4 12 53  1  1  0], end state:[ 6 12 53  0  0  0]
INFO:Reinforcement.Functions:episode: 338, score:[2842.00], loss:[1.82791], sequence:[218], random actions:[31], eInit:[0.0338], init state:[ 6 23 52  1  0  0], end state:[ 1 23 52  1  0  0]
INFO:Reinforcement.Functions:episode: 339, score:[2788.67], loss:[1.96846], sequence:[219], random actions:[32], eInit:[0.0335], init state:[ 5  0 21  0  0  0], end state:[ 0  0 21  1  0  1]
INFO:Reinforcement.Functions:episode: 340, score:[2802.67], loss:[1.88443], sequence:[220], random actions:[25], eInit:[0.0331], init state:[ 4 12 35  1  1  0], end state:[ 6 12 35  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2851.3333333333335, [236]) , maxSequence:(220, [340])
INFO:Reinforcement.Functions:episode: 341, score:[2840.67], loss:[1.62679], sequence:[221], random actions:[31], eInit:[0.0328], init state:[ 1 13 15  0  0  0], end state:[ 3 13 15  0  0  0]
INFO:Reinforcement.Functions:episode: 342, score:[2824.00], loss:[1.69744], sequence:[222], random actions:[31], eInit:[0.0325], init state:[ 3 14 43  0  0  0], end state:[ 5 14 43  0  0  0]
INFO:Reinforcement.Functions:episode: 343, score:[2844.00], loss:[1.77354], sequence:[223], random actions:[31], eInit:[0.0322], init state:[ 2  1 51  0  0  0], end state:[ 4  1 51  0  0  0]
INFO:Reinforcement.Functions:episode: 344, score:[2822.00], loss:[1.70823], sequence:[224], random actions:[29], eInit:[0.0318], init state:[ 5 18 18  1  1  0], end state:[ 0 18 18  0  0  0]
INFO:Reinforcement.Functions:episode: 345, score:[2803.33], loss:[1.80738], sequence:[225], random actions:[28], eInit:[0.0315], init state:[ 6 16 53  0  0  0], end state:[ 1 16 53  0  0  0]
INFO:Reinforcement.Functions:episode: 346, score:[2847.33], loss:[1.68700], sequence:[226], random actions:[27], eInit:[0.0312], init state:[ 6  4 37  0  0  0], end state:[ 1  4 37  0  0  0]
INFO:Reinforcement.Functions:episode: 347, score:[2855.33], loss:[1.40745], sequence:[227], random actions:[22], eInit:[0.0309], init state:[ 0  6 37  0  0  0], end state:[ 2  6 37  0  0  0]
INFO:Reinforcement.Functions:episode: 348, score:[2847.33], loss:[1.42595], sequence:[228], random actions:[28], eInit:[0.0306], init state:[ 2 19 21  0  0  0], end state:[ 4 19 21  0  0  0]
INFO:Reinforcement.Functions:episode: 349, score:[2794.67], loss:[2.02698], sequence:[229], random actions:[38], eInit:[0.0303], init state:[ 5 23 53  1  0  0], end state:[ 0 23 53  1  0  0]
INFO:Reinforcement.Functions:episode: 350, score:[2846.00], loss:[1.50512], sequence:[230], random actions:[20], eInit:[0.0300], init state:[ 3 13 17  0  0  0], end state:[ 5 13 17  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2855.3333333333335, [347]) , maxSequence:(230, [350])
INFO:Reinforcement.Functions:episode: 351, score:[2808.67], loss:[1.53133], sequence:[231], random actions:[31], eInit:[0.0297], init state:[ 6  6 21  0  0  0], end state:[ 1  6 21  0  0  0]
INFO:Reinforcement.Functions:episode: 352, score:[2842.00], loss:[1.56034], sequence:[232], random actions:[26], eInit:[0.0294], init state:[ 2 18  7  0  0  0], end state:[ 4 18  7  0  0  0]
INFO:Reinforcement.Functions:episode: 353, score:[2823.33], loss:[1.40630], sequence:[233], random actions:[37], eInit:[0.0291], init state:[ 0 19 37  0  0  0], end state:[ 2 19 37  0  0  0]
INFO:Reinforcement.Functions:episode: 354, score:[2818.67], loss:[1.34936], sequence:[234], random actions:[28], eInit:[0.0288], init state:[ 6 13 41  0  0  0], end state:[ 1 13 41  0  0  0]
INFO:Reinforcement.Functions:episode: 355, score:[2829.33], loss:[1.26313], sequence:[235], random actions:[28], eInit:[0.0285], init state:[ 1  6 57  0  0  0], end state:[ 3  6 57  0  0  0]
INFO:Reinforcement.Functions:episode: 356, score:[2828.00], loss:[1.22192], sequence:[236], random actions:[31], eInit:[0.0282], init state:[2 4 2 0 0 0], end state:[4 4 2 0 0 0]
INFO:Reinforcement.Functions:episode: 357, score:[2818.67], loss:[1.60101], sequence:[237], random actions:[32], eInit:[0.0279], init state:[ 4  2 25  0  0  0], end state:[ 6  2 25  0  0  0]
INFO:Reinforcement.Functions:episode: 358, score:[2790.00], loss:[1.91192], sequence:[238], random actions:[25], eInit:[0.0277], init state:[ 4 12 59  1  1  0], end state:[ 6 12 59  0  0  0]
INFO:Reinforcement.Functions:episode: 359, score:[2845.33], loss:[2.15022], sequence:[239], random actions:[25], eInit:[0.0274], init state:[ 5 11 35  0  0  0], end state:[ 0 11 35  0  0  0]
INFO:Reinforcement.Functions:episode: 360, score:[2839.33], loss:[2.21256], sequence:[240], random actions:[27], eInit:[0.0271], init state:[ 4  6 33  0  0  0], end state:[ 6  6 33  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2855.3333333333335, [347]) , maxSequence:(240, [360])
INFO:Reinforcement.Functions:episode: 361, score:[2795.33], loss:[2.46161], sequence:[241], random actions:[38], eInit:[0.0268], init state:[3 8 9 1 0 0], end state:[5 8 9 0 0 0]
INFO:Reinforcement.Functions:episode: 362, score:[2841.33], loss:[2.12030], sequence:[242], random actions:[26], eInit:[0.0266], init state:[ 3 23 17  1  0  0], end state:[ 5 23 17  1  0  0]
INFO:Reinforcement.Functions:episode: 363, score:[2832.67], loss:[2.11347], sequence:[243], random actions:[33], eInit:[0.0263], init state:[ 2 13 26  0  0  0], end state:[ 4 13 26  1  1  0]
INFO:Reinforcement.Functions:episode: 364, score:[2845.33], loss:[2.19633], sequence:[244], random actions:[26], eInit:[0.0260], init state:[ 3  0 53  0  0  1], end state:[ 5  0 53  0  0  0]
INFO:Reinforcement.Functions:episode: 365, score:[2824.67], loss:[2.41575], sequence:[245], random actions:[40], eInit:[0.0258], init state:[ 5 12 55  0  0  0], end state:[ 0 12 55  0  0  0]
INFO:Reinforcement.Functions:episode: 366, score:[2846.67], loss:[2.18955], sequence:[246], random actions:[23], eInit:[0.0255], init state:[ 6  5 32  0  0  0], end state:[ 1  5 32  0  0  0]
INFO:Reinforcement.Functions:episode: 367, score:[2826.00], loss:[2.30349], sequence:[247], random actions:[20], eInit:[0.0253], init state:[ 1 14 20  0  0  0], end state:[ 3 14 20  0  0  0]
INFO:Reinforcement.Functions:episode: 368, score:[2845.33], loss:[2.03849], sequence:[248], random actions:[32], eInit:[0.0250], init state:[ 6 12  1  0  0  0], end state:[ 1 12  1  0  0  0]
INFO:Reinforcement.Functions:episode: 369, score:[2836.00], loss:[1.98761], sequence:[249], random actions:[23], eInit:[0.0248], init state:[ 6 15 53  0  0  0], end state:[ 1 15 53  0  0  0]
INFO:Reinforcement.Functions:episode: 370, score:[2822.00], loss:[1.95739], sequence:[250], random actions:[24], eInit:[0.0245], init state:[ 3  5 34  0  0  0], end state:[ 5  5 34  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2855.3333333333335, [347]) , maxSequence:(250, [370])
INFO:Reinforcement.Functions:episode: 371, score:[2830.00], loss:[1.89318], sequence:[251], random actions:[39], eInit:[0.0243], init state:[ 3 13 58  0  0  0], end state:[ 5 13 58  0  0  0]
INFO:Reinforcement.Functions:episode: 372, score:[2840.67], loss:[2.01244], sequence:[252], random actions:[29], eInit:[0.0240], init state:[ 2 20 27  0  0  0], end state:[ 4 20 27  0  0  0]
INFO:Reinforcement.Functions:episode: 373, score:[2856.00], loss:[1.80091], sequence:[253], random actions:[26], eInit:[0.0238], init state:[2 2 1 0 0 0], end state:[4 2 1 0 0 0]
INFO:Reinforcement.Functions:episode: 374, score:[2849.33], loss:[1.75099], sequence:[254], random actions:[27], eInit:[0.0235], init state:[ 6 11 42  0  0  0], end state:[ 1 11 42  0  0  0]
INFO:Reinforcement.Functions:episode: 375, score:[2778.67], loss:[1.72053], sequence:[255], random actions:[29], eInit:[0.0233], init state:[ 4 15 34  0  0  0], end state:[ 6 15 34  0  0  0]
INFO:Reinforcement.Functions:episode: 376, score:[2848.67], loss:[1.61794], sequence:[256], random actions:[25], eInit:[0.0231], init state:[ 0 17 18  0  0  0], end state:[ 2 17 18  0  0  0]
INFO:Reinforcement.Functions:episode: 377, score:[2816.00], loss:[1.71403], sequence:[257], random actions:[39], eInit:[0.0228], init state:[ 5 12 10  0  0  0], end state:[ 0 12 10  0  0  0]
INFO:Reinforcement.Functions:episode: 378, score:[2836.67], loss:[1.71609], sequence:[258], random actions:[28], eInit:[0.0226], init state:[ 4  4 22  0  0  0], end state:[ 6  4 22  0  0  0]
INFO:Reinforcement.Functions:episode: 379, score:[2797.33], loss:[1.85463], sequence:[259], random actions:[30], eInit:[0.0224], init state:[ 3 17 34  0  0  0], end state:[ 5 17 34  0  0  0]
INFO:Reinforcement.Functions:episode: 380, score:[2853.33], loss:[1.72756], sequence:[260], random actions:[29], eInit:[0.0222], init state:[ 2 23  7  1  0  0], end state:[ 4 23  7  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2856.0000000000005, [373]) , maxSequence:(260, [380])
INFO:Reinforcement.Functions:episode: 381, score:[2822.00], loss:[1.66377], sequence:[261], random actions:[30], eInit:[0.0219], init state:[ 1  4 30  0  0  0], end state:[ 3  4 30  0  0  0]
INFO:Reinforcement.Functions:episode: 382, score:[2816.67], loss:[1.70107], sequence:[262], random actions:[36], eInit:[0.0217], init state:[6 3 1 0 0 0], end state:[1 3 1 0 0 0]
INFO:Reinforcement.Functions:episode: 383, score:[2830.67], loss:[1.57427], sequence:[263], random actions:[22], eInit:[0.0215], init state:[ 4 23 25  0  0  0], end state:[ 6 23 25  1  0  0]
INFO:Reinforcement.Functions:episode: 384, score:[2840.00], loss:[1.39176], sequence:[264], random actions:[32], eInit:[0.0213], init state:[ 1 16 14  0  0  0], end state:[ 3 16 14  0  0  0]
INFO:Reinforcement.Functions:episode: 385, score:[2850.00], loss:[1.48010], sequence:[265], random actions:[28], eInit:[0.0211], init state:[ 2 13 15  0  0  0], end state:[ 4 13 15  1  1  0]
INFO:Reinforcement.Functions:episode: 386, score:[2840.00], loss:[1.31002], sequence:[266], random actions:[28], eInit:[0.0209], init state:[ 4 11 31  1  1  0], end state:[ 6 11 31  0  0  0]
INFO:Reinforcement.Functions:episode: 387, score:[2791.33], loss:[1.48221], sequence:[267], random actions:[29], eInit:[0.0207], init state:[ 3 16 10  0  0  0], end state:[ 5 16 10  0  0  0]
INFO:Reinforcement.Functions:episode: 388, score:[2812.67], loss:[1.48946], sequence:[268], random actions:[23], eInit:[0.0205], init state:[ 5 23 39  1  0  0], end state:[ 0 23 39  1  0  0]
INFO:Reinforcement.Functions:episode: 389, score:[2816.67], loss:[1.52676], sequence:[269], random actions:[32], eInit:[0.0203], init state:[ 3 15 12  0  0  0], end state:[ 5 15 12  0  0  0]
INFO:Reinforcement.Functions:episode: 390, score:[2825.33], loss:[1.41271], sequence:[270], random actions:[31], eInit:[0.0200], init state:[ 5 20 39  1  0  0], end state:[ 0 20 39  1  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2856.0000000000005, [373]) , maxSequence:(270, [390])
INFO:Reinforcement.Functions:episode: 391, score:[2838.00], loss:[1.57206], sequence:[271], random actions:[26], eInit:[0.0198], init state:[ 5  5 31  0  0  0], end state:[ 0  5 31  0  0  0]
INFO:Reinforcement.Functions:episode: 392, score:[2842.00], loss:[1.44586], sequence:[272], random actions:[28], eInit:[0.0196], init state:[ 2  8 45  1  1  0], end state:[ 4  8 45  0  0  0]
INFO:Reinforcement.Functions:episode: 393, score:[2820.67], loss:[1.45712], sequence:[273], random actions:[32], eInit:[0.0195], init state:[ 0 16 34  0  0  0], end state:[ 2 16 34  0  0  0]
INFO:Reinforcement.Functions:episode: 394, score:[2857.33], loss:[1.28258], sequence:[274], random actions:[18], eInit:[0.0193], init state:[ 1 21 58  1  0  0], end state:[ 3 21 58  1  0  0]
INFO:Reinforcement.Functions:episode: 395, score:[2841.33], loss:[1.28766], sequence:[275], random actions:[26], eInit:[0.0191], init state:[ 5  4 42  0  0  0], end state:[ 0  4 42  0  0  0]
INFO:Reinforcement.Functions:episode: 396, score:[2828.00], loss:[1.37536], sequence:[276], random actions:[39], eInit:[0.0189], init state:[ 6  9 35  0  0  0], end state:[ 1  9 35  0  0  0]
INFO:Reinforcement.Functions:episode: 397, score:[2820.67], loss:[1.35183], sequence:[277], random actions:[33], eInit:[0.0187], init state:[ 6  5 56  0  0  0], end state:[ 1  5 56  0  0  0]
INFO:Reinforcement.Functions:episode: 398, score:[2840.67], loss:[1.28008], sequence:[278], random actions:[27], eInit:[0.0185], init state:[ 0  6 52  0  0  0], end state:[ 2  6 52  0  0  0]
INFO:Reinforcement.Functions:episode: 399, score:[2852.00], loss:[1.20739], sequence:[279], random actions:[22], eInit:[0.0183], init state:[2 7 7 0 0 0], end state:[4 7 7 0 0 0]
INFO:Reinforcement.Functions:episode: 400, score:[2816.67], loss:[1.37676], sequence:[280], random actions:[41], eInit:[0.0181], init state:[ 1 10 28  0  0  0], end state:[ 3 10 28  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2857.333333333333, [394]) , maxSequence:(280, [400])
INFO:Reinforcement.Functions:episode: 401, score:[2838.67], loss:[1.23028], sequence:[281], random actions:[27], eInit:[0.0180], init state:[ 4 12  6  1  1  0], end state:[ 6 12  6  0  0  0]
INFO:Reinforcement.Functions:episode: 402, score:[2836.67], loss:[1.22707], sequence:[282], random actions:[29], eInit:[0.0178], init state:[ 2  3 19  0  0  0], end state:[ 4  3 19  0  0  0]
INFO:Reinforcement.Functions:episode: 403, score:[2834.00], loss:[1.27592], sequence:[283], random actions:[28], eInit:[0.0176], init state:[ 4 13 39  0  0  0], end state:[ 6 13 39  0  0  0]
INFO:Reinforcement.Functions:episode: 404, score:[2801.33], loss:[1.37089], sequence:[284], random actions:[31], eInit:[0.0174], init state:[ 3 17 41  0  0  0], end state:[ 5 17 41  0  0  0]
INFO:Reinforcement.Functions:episode: 405, score:[2827.33], loss:[1.36195], sequence:[285], random actions:[20], eInit:[0.0172], init state:[ 4  3 56  0  0  0], end state:[ 6  3 56  0  0  0]
INFO:Reinforcement.Functions:episode: 406, score:[2848.67], loss:[1.37267], sequence:[286], random actions:[25], eInit:[0.0171], init state:[ 4 14 40  0  0  0], end state:[ 6 14 40  0  0  0]
INFO:Reinforcement.Functions:episode: 407, score:[2837.33], loss:[1.29821], sequence:[287], random actions:[29], eInit:[0.0169], init state:[ 6  0 28  1  0  0], end state:[ 1  0 28  1  0  0]
INFO:Reinforcement.Functions:episode: 408, score:[2818.00], loss:[1.45325], sequence:[288], random actions:[27], eInit:[0.0167], init state:[ 5 13  9  0  0  0], end state:[ 0 13  9  0  0  0]
INFO:Reinforcement.Functions:episode: 409, score:[2832.67], loss:[1.37583], sequence:[289], random actions:[29], eInit:[0.0166], init state:[ 5 23 56  1  0  0], end state:[ 0 23 56  1  0  0]
INFO:Reinforcement.Functions:episode: 410, score:[2833.33], loss:[1.37425], sequence:[290], random actions:[39], eInit:[0.0164], init state:[ 1 12 20  0  0  0], end state:[ 3 12 20  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2857.333333333333, [394]) , maxSequence:(290, [410])
INFO:Reinforcement.Functions:episode: 411, score:[2820.00], loss:[1.56300], sequence:[291], random actions:[35], eInit:[0.0162], init state:[ 6 12 34  0  0  0], end state:[ 1 12 34  0  0  0]
INFO:Reinforcement.Functions:episode: 412, score:[2795.33], loss:[1.43114], sequence:[292], random actions:[39], eInit:[0.0161], init state:[ 3 12 10  0  0  0], end state:[ 5 12 10  0  0  0]
INFO:Reinforcement.Functions:episode: 413, score:[2830.00], loss:[1.40011], sequence:[293], random actions:[35], eInit:[0.0159], init state:[ 3 12 21  0  0  0], end state:[ 5 12 21  0  0  0]
INFO:Reinforcement.Functions:episode: 414, score:[2834.00], loss:[1.57504], sequence:[294], random actions:[35], eInit:[0.0158], init state:[1 7 7 0 0 0], end state:[3 7 7 0 0 0]
INFO:Reinforcement.Functions:episode: 415, score:[2849.33], loss:[1.63939], sequence:[295], random actions:[25], eInit:[0.0156], init state:[ 5 19  9  1  0  0], end state:[ 0 19  9  0  0  0]
INFO:Reinforcement.Functions:episode: 416, score:[2790.67], loss:[1.95091], sequence:[296], random actions:[33], eInit:[0.0154], init state:[ 5 16 34  0  0  0], end state:[ 0 16 34  0  0  0]
INFO:Reinforcement.Functions:episode: 417, score:[2835.33], loss:[2.16995], sequence:[297], random actions:[29], eInit:[0.0153], init state:[ 0  9 40  0  0  0], end state:[ 2  9 40  0  0  0]
INFO:Reinforcement.Functions:episode: 418, score:[2782.00], loss:[2.62603], sequence:[298], random actions:[31], eInit:[0.0151], init state:[ 3  8 19  1  0  0], end state:[ 5  8 19  1  0  0]
INFO:Reinforcement.Functions:episode: 419, score:[2852.67], loss:[1.96618], sequence:[299], random actions:[26], eInit:[0.0150], init state:[ 0  3 43  0  0  0], end state:[ 2  3 43  0  0  0]
INFO:Reinforcement.Functions:episode: 420, score:[2850.67], loss:[1.86448], sequence:[300], random actions:[26], eInit:[0.0148], init state:[ 1 15 10  0  0  0], end state:[ 3 15 10  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2857.333333333333, [394]) , maxSequence:(300, [420])
INFO:Reinforcement.Functions:episode: 421, score:[2824.00], loss:[1.84413], sequence:[301], random actions:[34], eInit:[0.0147], init state:[ 3 17 51  0  0  0], end state:[ 5 17 51  1  1  0]
INFO:Reinforcement.Functions:episode: 422, score:[2801.33], loss:[2.34346], sequence:[302], random actions:[36], eInit:[0.0145], init state:[ 2 20 27  0  0  0], end state:[ 4 20 27  0  0  0]
INFO:Reinforcement.Functions:episode: 423, score:[2825.33], loss:[1.91297], sequence:[303], random actions:[31], eInit:[0.0144], init state:[ 6 13 20  0  0  0], end state:[ 1 13 20  0  0  0]
INFO:Reinforcement.Functions:episode: 424, score:[2833.33], loss:[1.94864], sequence:[304], random actions:[30], eInit:[0.0142], init state:[ 2 14 22  0  0  0], end state:[ 4 14 22  0  0  0]
INFO:Reinforcement.Functions:episode: 425, score:[2831.33], loss:[1.87987], sequence:[305], random actions:[29], eInit:[0.0141], init state:[ 5 14 40  0  0  0], end state:[ 0 14 40  0  0  0]
INFO:Reinforcement.Functions:episode: 426, score:[2840.67], loss:[1.76796], sequence:[306], random actions:[27], eInit:[0.0140], init state:[ 0 13 15  0  0  0], end state:[ 2 13 15  0  0  0]
INFO:Reinforcement.Functions:episode: 427, score:[2770.67], loss:[1.96431], sequence:[307], random actions:[34], eInit:[0.0138], init state:[ 4  2 55  0  0  0], end state:[ 6  2 55  0  0  1]
INFO:Reinforcement.Functions:episode: 428, score:[2837.33], loss:[1.96017], sequence:[308], random actions:[33], eInit:[0.0137], init state:[ 4 14 37  0  0  0], end state:[ 6 14 37  0  0  0]
INFO:Reinforcement.Functions:episode: 429, score:[2822.00], loss:[1.84751], sequence:[309], random actions:[35], eInit:[0.0135], init state:[4 0 7 1 0 0], end state:[6 0 7 1 0 0]
INFO:Reinforcement.Functions:episode: 430, score:[2822.67], loss:[1.94448], sequence:[310], random actions:[31], eInit:[0.0134], init state:[ 5 21 57  1  0  0], end state:[ 0 21 57  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2857.333333333333, [394]) , maxSequence:(310, [430])
INFO:Reinforcement.Functions:episode: 431, score:[2810.00], loss:[2.18283], sequence:[311], random actions:[40], eInit:[0.0133], init state:[ 6 17  1  0  0  0], end state:[ 1 17  1  0  0  0]
INFO:Reinforcement.Functions:episode: 432, score:[2838.67], loss:[1.90887], sequence:[312], random actions:[28], eInit:[0.0131], init state:[ 3 17 31  0  0  0], end state:[ 5 17 31  0  0  0]
INFO:Reinforcement.Functions:episode: 433, score:[2859.33], loss:[1.73624], sequence:[313], random actions:[19], eInit:[0.0130], init state:[ 0 17 18  0  0  0], end state:[ 2 17 18  0  0  0]
INFO:Reinforcement.Functions:episode: 434, score:[2822.00], loss:[1.60866], sequence:[314], random actions:[33], eInit:[0.0129], init state:[ 4  2 32  0  0  0], end state:[ 6  2 32  0  0  0]
INFO:Reinforcement.Functions:episode: 435, score:[2798.00], loss:[1.98324], sequence:[315], random actions:[22], eInit:[0.0128], init state:[ 4 13 22  1  1  0], end state:[ 6 13 22  0  0  0]
INFO:Reinforcement.Functions:episode: 436, score:[2797.33], loss:[1.96536], sequence:[316], random actions:[39], eInit:[0.0126], init state:[ 6  0 32  0  0  1], end state:[ 1  0 32  0  0  1]
INFO:Reinforcement.Functions:episode: 437, score:[2838.00], loss:[1.95142], sequence:[317], random actions:[27], eInit:[0.0125], init state:[ 3  0 19  1  0  0], end state:[ 5  0 19  0  0  0]
INFO:Reinforcement.Functions:episode: 438, score:[2853.33], loss:[1.82710], sequence:[318], random actions:[26], eInit:[0.0124], init state:[ 0  1 22  0  0  0], end state:[ 2  1 22  0  0  0]
INFO:Reinforcement.Functions:episode: 439, score:[2805.33], loss:[2.16409], sequence:[319], random actions:[26], eInit:[0.0123], init state:[ 4 20  8  0  0  0], end state:[ 6 20  8  0  0  0]
INFO:Reinforcement.Functions:episode: 440, score:[2848.67], loss:[1.75193], sequence:[320], random actions:[30], eInit:[0.0121], init state:[ 0 17 53  0  0  0], end state:[ 2 17 53  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2859.333333333334, [433]) , maxSequence:(320, [440])
INFO:Reinforcement.Functions:episode: 441, score:[2809.33], loss:[1.75168], sequence:[321], random actions:[34], eInit:[0.0120], init state:[2 1 0 0 0 1], end state:[4 1 0 0 0 1]
INFO:Reinforcement.Functions:episode: 442, score:[2846.67], loss:[1.68029], sequence:[322], random actions:[23], eInit:[0.0119], init state:[ 6 14 21  0  0  0], end state:[ 1 14 21  0  0  0]
INFO:Reinforcement.Functions:episode: 443, score:[2830.00], loss:[1.43649], sequence:[323], random actions:[33], eInit:[0.0118], init state:[ 1 23 33  1  0  0], end state:[ 3 23 33  1  0  0]
INFO:Reinforcement.Functions:episode: 444, score:[2838.67], loss:[1.48415], sequence:[324], random actions:[29], eInit:[0.0117], init state:[ 3  6 17  0  0  0], end state:[ 5  6 17  0  0  0]
INFO:Reinforcement.Functions:episode: 445, score:[2848.00], loss:[1.53730], sequence:[325], random actions:[26], eInit:[0.0115], init state:[ 1  8 21  1  0  0], end state:[ 3  8 21  1  0  0]
INFO:Reinforcement.Functions:episode: 446, score:[2829.33], loss:[1.43081], sequence:[326], random actions:[40], eInit:[0.0114], init state:[ 0 13 13  0  0  0], end state:[ 2 13 13  0  0  0]
INFO:Reinforcement.Functions:episode: 447, score:[2846.00], loss:[1.24068], sequence:[327], random actions:[21], eInit:[0.0113], init state:[ 3 22 44  1  0  0], end state:[ 5 22 44  1  0  0]
INFO:Reinforcement.Functions:episode: 448, score:[2782.00], loss:[1.49577], sequence:[328], random actions:[31], eInit:[0.0112], init state:[ 2 22  9  1  0  0], end state:[ 4 22  9  0  0  0]
INFO:Reinforcement.Functions:episode: 449, score:[2824.00], loss:[1.52059], sequence:[329], random actions:[43], eInit:[0.0111], init state:[5 0 3 0 0 0], end state:[0 0 3 1 0 0]
INFO:Reinforcement.Functions:episode: 450, score:[2861.33], loss:[1.58429], sequence:[330], random actions:[18], eInit:[0.0110], init state:[ 0 14 16  0  0  0], end state:[ 2 14 16  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(330, [450])
INFO:Reinforcement.Functions:episode: 451, score:[2846.67], loss:[1.58064], sequence:[331], random actions:[28], eInit:[0.0109], init state:[ 5  8 23  0  0  0], end state:[ 0  8 23  1  0  0]
INFO:Reinforcement.Functions:episode: 452, score:[2825.33], loss:[1.91056], sequence:[332], random actions:[29], eInit:[0.0108], init state:[ 5  6 32  0  0  0], end state:[ 0  6 32  0  0  0]
INFO:Reinforcement.Functions:episode: 453, score:[2858.00], loss:[1.45474], sequence:[333], random actions:[20], eInit:[0.0106], init state:[ 4 13 28  1  1  0], end state:[ 6 13 28  0  0  0]
INFO:Reinforcement.Functions:episode: 454, score:[2833.33], loss:[1.40490], sequence:[334], random actions:[35], eInit:[0.0105], init state:[ 1 15 55  0  0  0], end state:[ 3 15 55  0  0  0]
INFO:Reinforcement.Functions:episode: 455, score:[2840.00], loss:[1.43875], sequence:[335], random actions:[30], eInit:[0.0104], init state:[ 2 19 41  0  0  0], end state:[ 4 19 41  0  0  0]
INFO:Reinforcement.Functions:episode: 456, score:[2828.00], loss:[1.38900], sequence:[336], random actions:[40], eInit:[0.0103], init state:[ 5 19 31  1  0  0], end state:[ 0 19 31  0  0  0]
INFO:Reinforcement.Functions:episode: 457, score:[2825.33], loss:[1.29301], sequence:[337], random actions:[40], eInit:[0.0102], init state:[ 1 22  5  1  0  0], end state:[ 3 22  5  1  0  0]
INFO:Reinforcement.Functions:episode: 458, score:[2834.67], loss:[1.42774], sequence:[338], random actions:[28], eInit:[0.0101], init state:[ 5 14 45  0  0  0], end state:[ 0 14 45  0  0  0]
INFO:Reinforcement.Functions:episode: 459, score:[2836.67], loss:[1.46724], sequence:[339], random actions:[37], eInit:[0.0100], init state:[ 1 18 30  0  0  0], end state:[ 3 18 30  0  0  0]
INFO:Reinforcement.Functions:episode: 460, score:[2848.00], loss:[1.34588], sequence:[340], random actions:[21], eInit:[0.0100], init state:[ 2 10  3  0  0  0], end state:[ 4 10  3  1  1  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(340, [460])
INFO:Reinforcement.Functions:episode: 461, score:[2829.33], loss:[1.31380], sequence:[341], random actions:[32], eInit:[0.0100], init state:[ 0  6 12  0  0  0], end state:[ 2  6 12  0  0  0]
INFO:Reinforcement.Functions:episode: 462, score:[2849.33], loss:[1.71438], sequence:[342], random actions:[21], eInit:[0.0100], init state:[ 3  1 29  0  0  0], end state:[ 5  1 29  0  0  0]
INFO:Reinforcement.Functions:episode: 463, score:[2851.33], loss:[1.34400], sequence:[343], random actions:[25], eInit:[0.0100], init state:[ 2 16 28  0  0  0], end state:[ 4 16 28  0  0  0]
INFO:Reinforcement.Functions:episode: 464, score:[2820.00], loss:[1.89836], sequence:[344], random actions:[21], eInit:[0.0100], init state:[ 5 16 13  0  0  0], end state:[ 0 16 13  0  0  0]
INFO:Reinforcement.Functions:episode: 465, score:[2848.67], loss:[1.72829], sequence:[345], random actions:[27], eInit:[0.0100], init state:[ 6  9 10  0  0  0], end state:[ 1  9 10  0  0  0]
INFO:Reinforcement.Functions:episode: 466, score:[2840.00], loss:[1.54736], sequence:[346], random actions:[24], eInit:[0.0100], init state:[ 5  5 17  0  0  0], end state:[ 0  5 17  0  0  0]
INFO:Reinforcement.Functions:episode: 467, score:[2838.00], loss:[1.40754], sequence:[347], random actions:[31], eInit:[0.0100], init state:[ 5  3 30  0  0  0], end state:[ 0  3 30  0  0  0]
INFO:Reinforcement.Functions:episode: 468, score:[2826.00], loss:[1.63016], sequence:[348], random actions:[26], eInit:[0.0100], init state:[ 6  9 16  0  0  0], end state:[ 1  9 16  0  0  0]
INFO:Reinforcement.Functions:episode: 469, score:[2834.00], loss:[1.51909], sequence:[349], random actions:[20], eInit:[0.0100], init state:[ 3  1 12  0  0  0], end state:[ 5  1 12  0  0  0]
INFO:Reinforcement.Functions:episode: 470, score:[2850.67], loss:[1.48101], sequence:[350], random actions:[26], eInit:[0.0100], init state:[ 2  0 11  1  0  0], end state:[ 4  0 11  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(350, [470])
INFO:Reinforcement.Functions:episode: 471, score:[2843.33], loss:[1.69894], sequence:[351], random actions:[31], eInit:[0.0100], init state:[ 3  0 11  1  0  0], end state:[ 5  0 11  0  0  0]
INFO:Reinforcement.Functions:episode: 472, score:[2844.67], loss:[1.27126], sequence:[352], random actions:[29], eInit:[0.0100], init state:[ 6  5 57  0  0  0], end state:[ 1  5 57  0  0  0]
INFO:Reinforcement.Functions:episode: 473, score:[2786.67], loss:[1.73026], sequence:[353], random actions:[36], eInit:[0.0100], init state:[ 4 15  5  0  0  0], end state:[ 6 15  5  0  0  0]
INFO:Reinforcement.Functions:episode: 474, score:[2753.33], loss:[1.89739], sequence:[354], random actions:[41], eInit:[0.0100], init state:[ 3 21 17  1  1  0], end state:[ 5 21 17  1  0  0]
INFO:Reinforcement.Functions:episode: 475, score:[2838.67], loss:[1.74969], sequence:[355], random actions:[30], eInit:[0.0100], init state:[ 5 17 19  0  0  0], end state:[ 0 17 19  0  0  0]
INFO:Reinforcement.Functions:episode: 476, score:[2828.67], loss:[1.47201], sequence:[356], random actions:[20], eInit:[0.0100], init state:[ 3 22 34  1  0  0], end state:[ 5 22 34  1  0  0]
INFO:Reinforcement.Functions:episode: 477, score:[2837.33], loss:[1.62158], sequence:[357], random actions:[34], eInit:[0.0100], init state:[4 0 7 1 0 0], end state:[6 0 7 1 0 0]
INFO:Reinforcement.Functions:episode: 478, score:[2833.33], loss:[1.69793], sequence:[358], random actions:[33], eInit:[0.0100], init state:[ 6  1 47  0  0  0], end state:[ 1  1 47  0  0  0]
INFO:Reinforcement.Functions:episode: 479, score:[2831.33], loss:[1.86546], sequence:[359], random actions:[31], eInit:[0.0100], init state:[ 6  2 59  0  0  0], end state:[ 1  2 59  0  0  0]
INFO:Reinforcement.Functions:episode: 480, score:[2813.33], loss:[1.93500], sequence:[360], random actions:[30], eInit:[0.0100], init state:[ 4 10 37  1  1  0], end state:[ 6 10 37  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(360, [480])
INFO:Reinforcement.Functions:episode: 481, score:[2846.00], loss:[1.89944], sequence:[361], random actions:[34], eInit:[0.0100], init state:[ 1  6 53  0  0  0], end state:[ 3  6 53  0  0  0]
INFO:Reinforcement.Functions:episode: 482, score:[2848.67], loss:[1.62748], sequence:[362], random actions:[28], eInit:[0.0100], init state:[ 5  1 14  0  0  0], end state:[ 0  1 14  0  0  0]
INFO:Reinforcement.Functions:episode: 483, score:[2838.67], loss:[1.63399], sequence:[363], random actions:[32], eInit:[0.0100], init state:[ 5 13 50  0  0  0], end state:[ 0 13 50  0  0  0]
INFO:Reinforcement.Functions:episode: 484, score:[2854.00], loss:[1.49413], sequence:[364], random actions:[25], eInit:[0.0100], init state:[ 1  8 33  1  1  0], end state:[ 3  8 33  1  1  0]
INFO:Reinforcement.Functions:episode: 485, score:[2824.67], loss:[1.55697], sequence:[365], random actions:[27], eInit:[0.0100], init state:[ 5  4 50  0  0  0], end state:[ 0  4 50  0  0  0]
INFO:Reinforcement.Functions:episode: 486, score:[2841.33], loss:[1.58640], sequence:[366], random actions:[28], eInit:[0.0100], init state:[ 2 20 43  1  1  0], end state:[ 4 20 43  0  0  0]
INFO:Reinforcement.Functions:episode: 487, score:[2852.67], loss:[1.45659], sequence:[367], random actions:[23], eInit:[0.0100], init state:[ 4 17  6  0  0  0], end state:[ 6 17  6  0  0  0]
INFO:Reinforcement.Functions:episode: 488, score:[2832.00], loss:[1.49877], sequence:[368], random actions:[25], eInit:[0.0100], init state:[ 4 11  6  1  1  0], end state:[ 6 11  6  0  0  0]
INFO:Reinforcement.Functions:episode: 489, score:[2838.00], loss:[1.58899], sequence:[369], random actions:[30], eInit:[0.0100], init state:[ 5 10 18  0  0  0], end state:[ 0 10 18  0  0  0]
INFO:Reinforcement.Functions:episode: 490, score:[2836.67], loss:[1.64192], sequence:[370], random actions:[23], eInit:[0.0100], init state:[ 2 18 34  0  0  0], end state:[ 4 18 34  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(370, [490])
INFO:Reinforcement.Functions:episode: 491, score:[2798.00], loss:[1.69205], sequence:[371], random actions:[31], eInit:[0.0100], init state:[ 2  9 23  0  0  0], end state:[ 4  9 23  0  0  0]
INFO:Reinforcement.Functions:episode: 492, score:[2852.00], loss:[1.58639], sequence:[372], random actions:[26], eInit:[0.0100], init state:[ 4 18 37  0  0  0], end state:[ 6 18 37  0  0  0]
INFO:Reinforcement.Functions:episode: 493, score:[2840.00], loss:[1.32936], sequence:[373], random actions:[28], eInit:[0.0100], init state:[ 1 16 53  0  0  0], end state:[ 3 16 53  0  0  0]
INFO:Reinforcement.Functions:episode: 494, score:[2845.33], loss:[1.34799], sequence:[374], random actions:[27], eInit:[0.0100], init state:[ 5 19 13  1  0  0], end state:[ 0 19 13  0  0  0]
INFO:Reinforcement.Functions:episode: 495, score:[2834.00], loss:[1.92120], sequence:[375], random actions:[27], eInit:[0.0100], init state:[6 0 0 1 0 0], end state:[1 0 0 1 0 0]
INFO:Reinforcement.Functions:episode: 496, score:[2841.33], loss:[1.71018], sequence:[376], random actions:[22], eInit:[0.0100], init state:[ 5  1 23  0  0  0], end state:[ 0  1 23  0  0  0]
INFO:Reinforcement.Functions:episode: 497, score:[2796.67], loss:[1.92212], sequence:[377], random actions:[30], eInit:[0.0100], init state:[ 2 21 38  1  0  0], end state:[ 4 21 38  0  0  0]
INFO:Reinforcement.Functions:episode: 498, score:[2829.33], loss:[1.86256], sequence:[378], random actions:[25], eInit:[0.0100], init state:[ 2 15 25  0  0  0], end state:[ 4 15 25  0  0  0]
INFO:Reinforcement.Functions:episode: 499, score:[2808.67], loss:[1.94440], sequence:[379], random actions:[22], eInit:[0.0100], init state:[ 5 22  2  1  0  0], end state:[ 0 22  2  1  0  0]
INFO:Reinforcement.Functions:episode: 500, score:[2818.67], loss:[1.77075], sequence:[380], random actions:[28], eInit:[0.0100], init state:[ 1 23 28  1  0  0], end state:[ 3 23 28  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(380, [500])
INFO:Reinforcement.Functions:episode: 501, score:[2834.67], loss:[1.71952], sequence:[381], random actions:[37], eInit:[0.0100], init state:[ 1 17 27  0  0  0], end state:[ 3 17 27  0  0  0]
INFO:Reinforcement.Functions:episode: 502, score:[2833.33], loss:[1.89802], sequence:[382], random actions:[30], eInit:[0.0100], init state:[ 1  8 37  1  1  0], end state:[ 3  8 37  1  1  0]
INFO:Reinforcement.Functions:episode: 503, score:[2841.33], loss:[1.71100], sequence:[383], random actions:[28], eInit:[0.0100], init state:[ 5  8 14  0  0  0], end state:[ 0  8 14  1  0  0]
INFO:Reinforcement.Functions:episode: 504, score:[2817.33], loss:[2.13153], sequence:[384], random actions:[35], eInit:[0.0100], init state:[ 6  5 32  0  0  0], end state:[ 1  5 32  0  0  0]
INFO:Reinforcement.Functions:episode: 505, score:[2839.33], loss:[1.80303], sequence:[385], random actions:[25], eInit:[0.0100], init state:[1 8 8 1 0 0], end state:[3 8 8 1 0 0]
INFO:Reinforcement.Functions:episode: 506, score:[2853.33], loss:[1.53914], sequence:[386], random actions:[23], eInit:[0.0100], init state:[ 6 14 29  0  0  0], end state:[ 1 14 29  0  0  0]
INFO:Reinforcement.Functions:episode: 507, score:[2842.67], loss:[1.67495], sequence:[387], random actions:[25], eInit:[0.0100], init state:[ 6  4 30  0  0  0], end state:[ 1  4 30  0  0  0]
INFO:Reinforcement.Functions:episode: 508, score:[2814.00], loss:[1.70002], sequence:[388], random actions:[28], eInit:[0.0100], init state:[ 4 17 57  0  0  0], end state:[ 6 17 57  0  0  0]
INFO:Reinforcement.Functions:episode: 509, score:[2833.33], loss:[1.99505], sequence:[389], random actions:[32], eInit:[0.0100], init state:[ 0 16 18  0  0  0], end state:[ 2 16 18  0  0  0]
INFO:Reinforcement.Functions:episode: 510, score:[2833.33], loss:[1.84481], sequence:[390], random actions:[36], eInit:[0.0100], init state:[ 1  0 14  1  0  0], end state:[ 3  0 14  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(390, [510])
INFO:Reinforcement.Functions:episode: 511, score:[2844.67], loss:[1.75853], sequence:[391], random actions:[30], eInit:[0.0100], init state:[ 0  5 12  0  0  0], end state:[ 2  5 12  0  0  0]
INFO:Reinforcement.Functions:episode: 512, score:[2828.67], loss:[1.72659], sequence:[392], random actions:[30], eInit:[0.0100], init state:[ 5 18 52  1  1  0], end state:[ 0 18 52  0  0  0]
INFO:Reinforcement.Functions:episode: 513, score:[2819.33], loss:[1.86840], sequence:[393], random actions:[28], eInit:[0.0100], init state:[2 9 6 0 0 0], end state:[4 9 6 1 0 0]
INFO:Reinforcement.Functions:episode: 514, score:[2846.67], loss:[1.54636], sequence:[394], random actions:[27], eInit:[0.0100], init state:[ 2  3 20  0  0  0], end state:[ 4  3 20  0  0  0]
INFO:Reinforcement.Functions:episode: 515, score:[2852.67], loss:[1.64314], sequence:[395], random actions:[18], eInit:[0.0100], init state:[ 4 10 15  1  1  0], end state:[ 6 10 15  0  0  0]
INFO:Reinforcement.Functions:episode: 516, score:[2847.33], loss:[1.95676], sequence:[396], random actions:[24], eInit:[0.0100], init state:[ 6 12 35  0  0  0], end state:[ 1 12 35  0  0  0]
INFO:Reinforcement.Functions:episode: 517, score:[2833.33], loss:[1.81306], sequence:[397], random actions:[32], eInit:[0.0100], init state:[ 0 20 52  1  1  0], end state:[ 2 20 52  1  1  0]
INFO:Reinforcement.Functions:episode: 518, score:[2830.00], loss:[2.10340], sequence:[398], random actions:[29], eInit:[0.0100], init state:[ 0 16  2  0  0  0], end state:[ 2 16  2  0  0  0]
INFO:Reinforcement.Functions:episode: 519, score:[2846.67], loss:[2.10303], sequence:[399], random actions:[29], eInit:[0.0100], init state:[ 1  7 53  0  0  0], end state:[ 3  7 53  0  0  0]
INFO:Reinforcement.Functions:episode: 520, score:[2840.00], loss:[2.02480], sequence:[400], random actions:[23], eInit:[0.0100], init state:[ 2 21 40  1  0  0], end state:[ 4 21 40  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(400, [520])
INFO:Reinforcement.Functions:episode: 521, score:[2839.33], loss:[2.06706], sequence:[401], random actions:[32], eInit:[0.0100], init state:[ 0  8 49  1  1  0], end state:[ 2  8 49  1  1  0]
INFO:Reinforcement.Functions:episode: 522, score:[2852.67], loss:[1.89030], sequence:[402], random actions:[23], eInit:[0.0100], init state:[ 1 10 37  0  0  0], end state:[ 3 10 37  0  0  0]
INFO:Reinforcement.Functions:episode: 523, score:[2811.33], loss:[2.04277], sequence:[403], random actions:[30], eInit:[0.0100], init state:[ 5 11 18  0  0  0], end state:[ 0 11 18  0  0  0]
INFO:Reinforcement.Functions:episode: 524, score:[2752.67], loss:[2.42335], sequence:[404], random actions:[25], eInit:[0.0100], init state:[ 4  5 48  0  0  0], end state:[ 6  5 48  0  0  0]
INFO:Reinforcement.Functions:episode: 525, score:[2840.00], loss:[2.24185], sequence:[405], random actions:[27], eInit:[0.0100], init state:[ 4  6 51  0  0  0], end state:[ 6  6 51  0  0  0]
INFO:Reinforcement.Functions:episode: 526, score:[2856.67], loss:[2.06516], sequence:[406], random actions:[25], eInit:[0.0100], init state:[ 1  0 24  1  0  0], end state:[ 3  0 24  1  0  0]
INFO:Reinforcement.Functions:episode: 527, score:[2854.67], loss:[1.70905], sequence:[407], random actions:[25], eInit:[0.0100], init state:[ 0  9 39  0  0  0], end state:[ 2  9 39  0  0  0]
INFO:Reinforcement.Functions:episode: 528, score:[2820.67], loss:[1.85946], sequence:[408], random actions:[29], eInit:[0.0100], init state:[ 3  0 57  0  0  1], end state:[ 5  0 57  0  0  0]
INFO:Reinforcement.Functions:episode: 529, score:[2836.67], loss:[2.11378], sequence:[409], random actions:[31], eInit:[0.0100], init state:[ 2 20 31  1  1  0], end state:[ 4 20 31  0  0  0]
INFO:Reinforcement.Functions:episode: 530, score:[2849.33], loss:[1.99674], sequence:[410], random actions:[25], eInit:[0.0100], init state:[ 2 22 26  1  0  0], end state:[ 4 22 26  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(410, [530])
INFO:Reinforcement.Functions:episode: 531, score:[2827.33], loss:[2.10955], sequence:[411], random actions:[26], eInit:[0.0100], init state:[ 2 12 41  0  0  0], end state:[ 4 12 41  1  1  0]
INFO:Reinforcement.Functions:episode: 532, score:[2814.00], loss:[1.95213], sequence:[412], random actions:[25], eInit:[0.0100], init state:[ 6  8 12  1  0  0], end state:[ 1  8 12  1  0  0]
INFO:Reinforcement.Functions:episode: 533, score:[2844.67], loss:[1.85682], sequence:[413], random actions:[32], eInit:[0.0100], init state:[ 0 17 47  0  0  0], end state:[ 2 17 47  0  0  0]
INFO:Reinforcement.Functions:episode: 534, score:[2849.33], loss:[1.66384], sequence:[414], random actions:[34], eInit:[0.0100], init state:[ 6 20  1  0  0  0], end state:[ 1 20  1  0  0  0]
INFO:Reinforcement.Functions:episode: 535, score:[2844.00], loss:[1.66007], sequence:[415], random actions:[19], eInit:[0.0100], init state:[ 3 14 50  0  0  0], end state:[ 5 14 50  0  0  0]
INFO:Reinforcement.Functions:episode: 536, score:[2816.67], loss:[1.48928], sequence:[416], random actions:[21], eInit:[0.0100], init state:[ 4 15 54  0  0  0], end state:[ 6 15 54  0  0  0]
INFO:Reinforcement.Functions:episode: 537, score:[2854.00], loss:[1.44471], sequence:[417], random actions:[23], eInit:[0.0100], init state:[ 2 11 57  0  0  0], end state:[ 4 11 57  1  1  0]
INFO:Reinforcement.Functions:episode: 538, score:[2849.33], loss:[1.35194], sequence:[418], random actions:[29], eInit:[0.0100], init state:[ 4  2 53  0  0  0], end state:[ 6  2 53  0  0  0]
INFO:Reinforcement.Functions:episode: 539, score:[2840.67], loss:[1.47856], sequence:[419], random actions:[33], eInit:[0.0100], init state:[6 2 6 0 0 0], end state:[1 2 6 0 0 0]
INFO:Reinforcement.Functions:episode: 540, score:[2844.00], loss:[1.29285], sequence:[420], random actions:[26], eInit:[0.0100], init state:[ 3 20 21  0  0  0], end state:[ 5 20 21  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(420, [540])
INFO:Reinforcement.Functions:episode: 541, score:[2816.67], loss:[1.48244], sequence:[421], random actions:[33], eInit:[0.0100], init state:[ 3  4 30  0  0  0], end state:[ 5  4 30  0  0  0]
INFO:Reinforcement.Functions:episode: 542, score:[2840.67], loss:[1.29292], sequence:[422], random actions:[21], eInit:[0.0100], init state:[2 8 3 1 0 0], end state:[4 8 3 0 0 0]
INFO:Reinforcement.Functions:episode: 543, score:[2805.33], loss:[1.35116], sequence:[423], random actions:[31], eInit:[0.0100], init state:[ 5 22 15  1  0  0], end state:[ 0 22 15  1  0  0]
INFO:Reinforcement.Functions:episode: 544, score:[2823.33], loss:[1.39221], sequence:[424], random actions:[36], eInit:[0.0100], init state:[5 4 0 0 0 0], end state:[0 4 0 0 0 0]
INFO:Reinforcement.Functions:episode: 545, score:[2836.67], loss:[1.40715], sequence:[425], random actions:[36], eInit:[0.0100], init state:[ 0  9 31  0  0  0], end state:[ 2  9 31  0  0  0]
INFO:Reinforcement.Functions:episode: 546, score:[2843.33], loss:[1.46846], sequence:[426], random actions:[30], eInit:[0.0100], init state:[ 3 20 44  1  1  0], end state:[ 5 20 44  1  0  0]
INFO:Reinforcement.Functions:episode: 547, score:[2852.67], loss:[1.39189], sequence:[427], random actions:[26], eInit:[0.0100], init state:[ 2 23 56  1  0  0], end state:[ 4 23 56  0  0  0]
INFO:Reinforcement.Functions:episode: 548, score:[2822.67], loss:[1.28028], sequence:[428], random actions:[31], eInit:[0.0100], init state:[ 4  0 48  1  0  1], end state:[ 6  0 48  0  0  1]
INFO:Reinforcement.Functions:episode: 549, score:[2843.33], loss:[1.29616], sequence:[429], random actions:[30], eInit:[0.0100], init state:[ 1  4 16  0  0  0], end state:[ 3  4 16  0  0  0]
INFO:Reinforcement.Functions:episode: 550, score:[2832.00], loss:[1.56880], sequence:[430], random actions:[35], eInit:[0.0100], init state:[6 8 2 1 0 0], end state:[1 8 2 1 0 0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2861.333333333333, [450]) , maxSequence:(430, [550])
INFO:Reinforcement.Functions:episode: 551, score:[2862.00], loss:[1.40821], sequence:[431], random actions:[23], eInit:[0.0100], init state:[ 1 20 37  1  1  0], end state:[ 3 20 37  1  1  0]
INFO:Reinforcement.Functions:episode: 552, score:[2839.33], loss:[1.36680], sequence:[432], random actions:[23], eInit:[0.0100], init state:[ 2  8 51  1  1  0], end state:[ 4  8 51  0  0  0]
INFO:Reinforcement.Functions:episode: 553, score:[2790.00], loss:[1.54110], sequence:[433], random actions:[35], eInit:[0.0100], init state:[ 3 12 31  0  0  0], end state:[ 5 12 31  0  0  0]
INFO:Reinforcement.Functions:episode: 554, score:[2849.33], loss:[1.33590], sequence:[434], random actions:[24], eInit:[0.0100], init state:[ 1 16 58  0  0  0], end state:[ 3 16 58  0  0  0]
INFO:Reinforcement.Functions:episode: 555, score:[2828.67], loss:[1.40354], sequence:[435], random actions:[27], eInit:[0.0100], init state:[ 1  9 38  0  0  0], end state:[ 3  9 38  0  0  0]
INFO:Reinforcement.Functions:episode: 556, score:[2774.67], loss:[1.51064], sequence:[436], random actions:[37], eInit:[0.0100], init state:[ 3 17 20  0  0  0], end state:[ 5 17 20  0  0  0]
INFO:Reinforcement.Functions:episode: 557, score:[2842.00], loss:[1.26917], sequence:[437], random actions:[30], eInit:[0.0100], init state:[ 0 23 56  1  0  0], end state:[ 2 23 56  1  0  0]
INFO:Reinforcement.Functions:episode: 558, score:[2824.00], loss:[1.73422], sequence:[438], random actions:[27], eInit:[0.0100], init state:[ 3  0 18  1  0  0], end state:[ 5  0 18  0  0  0]
INFO:Reinforcement.Functions:episode: 559, score:[2788.67], loss:[1.80102], sequence:[439], random actions:[42], eInit:[0.0100], init state:[ 4 11 18  1  1  0], end state:[ 6 11 18  0  0  0]
INFO:Reinforcement.Functions:episode: 560, score:[2845.33], loss:[1.57922], sequence:[440], random actions:[27], eInit:[0.0100], init state:[ 1  2 49  0  0  0], end state:[ 3  2 49  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2862.0, [551]) , maxSequence:(440, [560])
INFO:Reinforcement.Functions:episode: 561, score:[2830.00], loss:[1.50673], sequence:[441], random actions:[40], eInit:[0.0100], init state:[ 3 17 32  0  0  0], end state:[ 5 17 32  0  0  0]
INFO:Reinforcement.Functions:episode: 562, score:[2782.00], loss:[1.71747], sequence:[442], random actions:[24], eInit:[0.0100], init state:[ 5 12  3  0  0  0], end state:[ 0 12  3  0  0  0]
INFO:Reinforcement.Functions:episode: 563, score:[2850.00], loss:[1.68243], sequence:[443], random actions:[23], eInit:[0.0100], init state:[ 4 20 57  0  0  0], end state:[ 6 20 57  1  1  0]
INFO:Reinforcement.Functions:episode: 564, score:[2848.00], loss:[1.63533], sequence:[444], random actions:[31], eInit:[0.0100], init state:[ 3 14 29  0  0  0], end state:[ 5 14 29  0  0  0]
INFO:Reinforcement.Functions:episode: 565, score:[2825.33], loss:[1.63490], sequence:[445], random actions:[31], eInit:[0.0100], init state:[ 6 21  6  1  1  0], end state:[ 1 21  6  1  1  0]
INFO:Reinforcement.Functions:episode: 566, score:[2812.00], loss:[1.62179], sequence:[446], random actions:[29], eInit:[0.0100], init state:[6 7 7 0 0 0], end state:[1 7 7 0 0 0]
INFO:Reinforcement.Functions:episode: 567, score:[2851.33], loss:[1.40630], sequence:[447], random actions:[27], eInit:[0.0100], init state:[ 6  7 57  0  0  0], end state:[ 1  7 57  0  0  0]
INFO:Reinforcement.Functions:episode: 568, score:[2825.33], loss:[1.52553], sequence:[448], random actions:[38], eInit:[0.0100], init state:[ 6  2 18  0  0  0], end state:[ 1  2 18  0  0  0]
INFO:Reinforcement.Functions:episode: 569, score:[2839.33], loss:[1.59142], sequence:[449], random actions:[31], eInit:[0.0100], init state:[ 1 13 25  0  0  0], end state:[ 3 13 25  0  0  0]
INFO:Reinforcement.Functions:episode: 570, score:[2843.33], loss:[1.37965], sequence:[450], random actions:[24], eInit:[0.0100], init state:[ 5  1 27  0  0  0], end state:[ 0  1 27  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2862.0, [551]) , maxSequence:(450, [570])
INFO:Reinforcement.Functions:episode: 571, score:[2792.00], loss:[2.06630], sequence:[451], random actions:[35], eInit:[0.0100], init state:[ 5 18  0  1  1  0], end state:[ 0 18  0  0  0  0]
INFO:Reinforcement.Functions:episode: 572, score:[2775.33], loss:[1.97501], sequence:[452], random actions:[29], eInit:[0.0100], init state:[ 5 21 19  1  0  0], end state:[ 0 21 19  1  1  0]
INFO:Reinforcement.Functions:episode: 573, score:[2832.67], loss:[1.56497], sequence:[453], random actions:[22], eInit:[0.0100], init state:[ 5  7 24  0  0  0], end state:[ 0  7 24  0  0  0]
INFO:Reinforcement.Functions:episode: 574, score:[2853.33], loss:[1.66735], sequence:[454], random actions:[20], eInit:[0.0100], init state:[ 5  8 41  0  0  0], end state:[ 0  8 41  1  1  0]
INFO:Reinforcement.Functions:episode: 575, score:[2831.33], loss:[1.60592], sequence:[455], random actions:[36], eInit:[0.0100], init state:[ 1  5 14  0  0  0], end state:[ 3  5 14  0  0  0]
INFO:Reinforcement.Functions:episode: 576, score:[2800.67], loss:[1.86862], sequence:[456], random actions:[30], eInit:[0.0100], init state:[ 5  0 32  0  0  0], end state:[ 0  0 32  0  0  1]
INFO:Reinforcement.Functions:episode: 577, score:[2843.33], loss:[1.69153], sequence:[457], random actions:[29], eInit:[0.0100], init state:[ 6 19 18  0  0  0], end state:[ 1 19 18  0  0  0]
INFO:Reinforcement.Functions:episode: 578, score:[2793.33], loss:[1.75510], sequence:[458], random actions:[31], eInit:[0.0100], init state:[ 5 16 15  0  0  0], end state:[ 0 16 15  0  0  0]
INFO:Reinforcement.Functions:episode: 579, score:[2844.67], loss:[1.62896], sequence:[459], random actions:[25], eInit:[0.0100], init state:[ 5 18 34  1  1  0], end state:[ 0 18 34  0  0  0]
INFO:Reinforcement.Functions:episode: 580, score:[2834.67], loss:[1.92028], sequence:[460], random actions:[29], eInit:[0.0100], init state:[ 1  9 24  0  0  0], end state:[ 3  9 24  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2862.0, [551]) , maxSequence:(460, [580])
INFO:Reinforcement.Functions:episode: 581, score:[2856.00], loss:[2.10155], sequence:[461], random actions:[25], eInit:[0.0100], init state:[1 6 0 0 0 0], end state:[3 6 0 0 0 0]
INFO:Reinforcement.Functions:episode: 582, score:[2841.33], loss:[1.83569], sequence:[462], random actions:[33], eInit:[0.0100], init state:[ 0 22 20  1  0  0], end state:[ 2 22 20  1  0  0]
INFO:Reinforcement.Functions:episode: 583, score:[2792.67], loss:[1.49772], sequence:[463], random actions:[30], eInit:[0.0100], init state:[ 3 12 15  0  0  0], end state:[ 5 12 15  0  0  0]
INFO:Reinforcement.Functions:episode: 584, score:[2854.67], loss:[1.73366], sequence:[464], random actions:[23], eInit:[0.0100], init state:[6 3 8 0 0 0], end state:[1 3 8 0 0 0]
INFO:Reinforcement.Functions:episode: 585, score:[2809.33], loss:[1.45234], sequence:[465], random actions:[32], eInit:[0.0100], init state:[ 4  9 52  1  0  0], end state:[ 6  9 52  0  0  0]
INFO:Reinforcement.Functions:episode: 586, score:[2850.00], loss:[1.69195], sequence:[466], random actions:[25], eInit:[0.0100], init state:[ 6 16  7  0  0  0], end state:[ 1 16  7  0  0  0]
INFO:Reinforcement.Functions:episode: 587, score:[2830.67], loss:[1.86398], sequence:[467], random actions:[39], eInit:[0.0100], init state:[0 0 2 1 0 0], end state:[2 0 2 1 0 0]
INFO:Reinforcement.Functions:episode: 588, score:[2848.67], loss:[1.53950], sequence:[468], random actions:[26], eInit:[0.0100], init state:[ 5 19 11  1  0  0], end state:[ 0 19 11  0  0  0]
INFO:Reinforcement.Functions:episode: 589, score:[2839.33], loss:[1.89687], sequence:[469], random actions:[29], eInit:[0.0100], init state:[ 0 13  0  0  0  0], end state:[ 2 13  0  0  0  0]
INFO:Reinforcement.Functions:episode: 590, score:[2836.67], loss:[1.43731], sequence:[470], random actions:[34], eInit:[0.0100], init state:[ 6 17  3  0  0  0], end state:[ 1 17  3  0  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
INFO:Reinforcement.Functions:maxScore:(2862.0, [551]) , maxSequence:(470, [590])
INFO:Reinforcement.Functions:episode: 591, score:[2840.67], loss:[1.26786], sequence:[471], random actions:[29], eInit:[0.0100], init state:[ 5  0 33  0  0  0], end state:[ 0  0 33  0  0  1]
INFO:Reinforcement.Functions:episode: 592, score:[2860.00], loss:[0.94662], sequence:[472], random actions:[18], eInit:[0.0100], init state:[ 4 11 45  1  1  0], end state:[ 6 11 45  0  0  0]
INFO:Reinforcement.Functions:episode: 593, score:[2756.00], loss:[1.43500], sequence:[473], random actions:[33], eInit:[0.0100], init state:[ 3  4 49  0  0  0], end state:[ 5  4 49  0  0  0]
INFO:Reinforcement.Functions:episode: 594, score:[2836.00], loss:[1.50994], sequence:[474], random actions:[27], eInit:[0.0100], init state:[ 5 22 37  1  0  0], end state:[ 0 22 37  1  0  0]
INFO:Reinforcement.Functions:episode: 595, score:[2821.33], loss:[1.13680], sequence:[475], random actions:[33], eInit:[0.0100], init state:[5 6 5 0 0 0], end state:[0 6 5 0 0 0]
INFO:Reinforcement.Functions:episode: 596, score:[2796.00], loss:[2.07920], sequence:[476], random actions:[34], eInit:[0.0100], init state:[ 4  3 28  0  0  0], end state:[ 6  3 28  0  0  0]
INFO:Reinforcement.Functions:episode: 597, score:[2840.67], loss:[1.63164], sequence:[477], random actions:[32], eInit:[0.0100], init state:[1 3 1 0 0 0], end state:[3 3 1 0 0 0]
INFO:Reinforcement.Functions:episode: 598, score:[2834.00], loss:[1.30483], sequence:[478], random actions:[29], eInit:[0.0100], init state:[ 1  6 27  0  0  0], end state:[ 3  6 27  0  0  0]
INFO:Reinforcement.Functions:episode: 599, score:[2753.33], loss:[1.43952], sequence:[479], random actions:[30], eInit:[0.0100], init state:[ 2  2 45  0  0  0], end state:[ 4  2 45  0  0  0]
INFO:Reinforcement.Functions:episode: 600, score:[2841.33], loss:[1.43219], sequence:[480], random actions:[34], eInit:[0.0100], init state:[ 1 22 11  1  0  0], end state:[ 3 22 11  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-0.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-0.h5]
INFO:Reinforcement.Functions:maxScore:(2862.0, [551]) , maxSequence:(480, [600])
INFO:Reinforcement.Functions:episode: 601, score:[2824.00], loss:[1.25289], sequence:[481], random actions:[22], eInit:[0.0100], init state:[ 4 23 14  0  0  0], end state:[ 6 23 14  1  0  0]
INFO:Reinforcement.Functions:episode: 602, score:[2762.67], loss:[1.87859], sequence:[482], random actions:[36], eInit:[0.0100], init state:[ 3 19 35  0  0  0], end state:[ 5 19 35  1  0  0]
INFO:Reinforcement.Functions:episode: 603, score:[2860.67], loss:[1.49476], sequence:[483], random actions:[24], eInit:[0.0100], init state:[ 0 10 24  0  0  0], end state:[ 2 10 24  0  0  0]
INFO:Reinforcement.Functions:episode: 604, score:[2845.33], loss:[1.32213], sequence:[484], random actions:[25], eInit:[0.0100], init state:[6 1 9 0 0 1], end state:[1 1 9 0 0 1]
INFO:Reinforcement.Functions:episode: 605, score:[2845.33], loss:[1.58776], sequence:[485], random actions:[26], eInit:[0.0100], init state:[ 5 14 41  0  0  0], end state:[ 0 14 41  0  0  0]
INFO:Reinforcement.Functions:episode: 606, score:[2843.33], loss:[1.36879], sequence:[486], random actions:[34], eInit:[0.0100], init state:[ 6 22 18  1  0  0], end state:[ 1 22 18  1  0  0]
INFO:Reinforcement.Functions:episode: 607, score:[2818.67], loss:[1.38822], sequence:[487], random actions:[31], eInit:[0.0100], init state:[ 2  6 45  0  0  0], end state:[ 4  6 45  0  0  0]
INFO:Reinforcement.Functions:episode: 608, score:[2844.67], loss:[1.48614], sequence:[488], random actions:[23], eInit:[0.0100], init state:[ 4 19 27  0  0  0], end state:[ 6 19 27  0  0  0]
INFO:Reinforcement.Functions:episode: 609, score:[2794.67], loss:[1.38930], sequence:[489], random actions:[24], eInit:[0.0100], init state:[3 1 8 0 0 1], end state:[5 1 8 0 0 0]
INFO:Reinforcement.Functions:episode: 610, score:[2814.67], loss:[1.32301], sequence:[490], random actions:[22], eInit:[0.0100], init state:[ 3 23 16  1  0  0], end state:[ 5 23 16  1  0  0]
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-1.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-1.h5]
INFO:Reinforcement.Functions:maxScore:(2862.0, [551]) , maxSequence:(490, [610])
INFO:Reinforcement.Functions:episode: 611, score:[2813.33], loss:[1.36418], sequence:[491], random actions:[40], eInit:[0.0100], init state:[ 3 13 46  0  0  0], end state:[ 5 13 46  0  0  0]
INFO:Reinforcement.Functions:episode: 612, score:[2850.67], loss:[1.35063], sequence:[492], random actions:[21], eInit:[0.0100], init state:[ 0  5 14  0  0  0], end state:[ 2  5 14  0  0  0]
INFO:Reinforcement.Functions:episode: 613, score:[2807.33], loss:[1.41484], sequence:[493], random actions:[26], eInit:[0.0100], init state:[ 4 23 42  0  0  0], end state:[ 6 23 42  1  0  0]
INFO:Reinforcement.Functions:episode: 614, score:[2833.33], loss:[1.21016], sequence:[494], random actions:[26], eInit:[0.0100], init state:[ 2  8 23  1  0  0], end state:[ 4  8 23  0  0  0]
INFO:Reinforcement.Functions:episode: 615, score:[2817.33], loss:[1.30716], sequence:[495], random actions:[37], eInit:[0.0100], init state:[ 3  4 11  0  0  0], end state:[ 5  4 11  0  0  0]
INFO:Reinforcement.Functions:episode: 616, score:[2810.67], loss:[1.24794], sequence:[496], random actions:[32], eInit:[0.0100], init state:[ 0 17 55  0  0  0], end state:[ 2 17 55  0  0  0]
INFO:Reinforcement.Functions:episode: 617, score:[2822.00], loss:[1.21490], sequence:[497], random actions:[31], eInit:[0.0100], init state:[ 6 22 43  1  0  0], end state:[ 1 22 43  1  1  0]
INFO:Reinforcement.Functions:episode: 618, score:[2838.67], loss:[1.19503], sequence:[498], random actions:[21], eInit:[0.0100], init state:[ 1  9 36  0  0  0], end state:[ 3  9 36  0  0  0]
INFO:Reinforcement.Functions:episode: 619, score:[2846.67], loss:[1.25248], sequence:[499], random actions:[27], eInit:[0.0100], init state:[ 1 21 34  1  0  0], end state:[ 3 21 34  1  0  0]
INFO:Reinforcement.Functions:episode: 620, score:[2845.33], loss:[1.40330], sequence:[500], random actions:[26], eInit:[0.0100], init state:[ 5  0 23  0  0  0], end state:[ 0  0 23  1  0  0]
INFO:Reinforcement.Functions:maxScore:(2862.0, [551]) , maxSequence:(500, [620])
INFO:Reinforcement.Functions:Saving [Actor] main model as [results/D-14-3-H-15-39-26/Actor-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Actor] target model as [results/D-14-3-H-15-39-26/Actor-target-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] main model as [results/D-14-3-H-15-39-26/Critic-main-model-2.h5]
INFO:Reinforcement.Functions:Saving [Critic] target model as [results/D-14-3-H-15-39-26/Critic-target-model-2.h5]
